import tokens
import parser

dynvar env: LexicalEnv
|" Origin for this property's request. See :ref:`The origin parameter` for more details
dynvar origin: AdaNode
dynvar no_visibility: Bool
dynvar include_ud_indexing: Bool
dynvar dottable_type: AdaNode
dynvar imprecise_fallback: Bool
dynvar logic_context: LogicContext
dynvar entry_point: AdaNode

|" Kind for the result of a cross reference operation.
|"
|" - ``no_ref`` is for no reference, it is the null value for this enum.
|" - ``precise`` is when the reference result is precise.
|" - ``imprecise`` is when there was an error computing the precise result,
|"   and a result was gotten in an imprecise fashion.
|" - ``error`` is for unrecoverable errors (either there is no imprecise path
|"   for the request you made, or the imprecise path errored out too).
@with_default(no_ref)
enum RefResultKind {
    case no_ref, precise, imprecise, error
}

|" Kind of CallExpr type.
|"
|" - ``call`` is when the CallExpr is a procedure or function call.
|" - ``array_slice``, ``array_index`` is when the CallExpr is in fact an
|"   array slice or an array subcomponent access expression, respectively.
|" - ``type_conversion`` is when the CallExpr is a type conversion.
|" - ``family_index`` is for entry calls using a family index.
enum CallExprKind {
    case call, array_slice, array_index, type_conversion, family_index
}

|" Root node class for the Ada syntax tree.
@abstract
@generic_list_type("AdaList")
class AdaNode implements Node[AdaNode] {
    @external()
    fun can_reach(from_node: AdaNode): Bool

    |" Return the scope of definition of this basic declaration.
    @exported
    fun declarative_scope(): DeclarativePart =
        node.parents().find((p) => p is DeclarativePart).as[DeclarativePart]

    |" Return the kind of the compilation unit owning this node.
    fun owning_unit_kind(): AnalysisUnitKind =
        node.unit().root.as![CompilationUnit].unit_kind()

    |" Static method helper. Fetch the unit designated by unit_name. Return
    |" the compilation unit node.
    |"
    |" This is designed in a way that will emit a
    |" ``unit_requested(not_found_is_error=True, ...)`` event when not
    |" finding the unit is supposed to be an error within Ada semantics.
    fun withed_unit_helper(unit_name: Name): CompilationUnit = {
        # Try to fetch the spec and the body for ``unit_name``, but do not emit
        # a unit_requested event yet.
        val unit_name_array = unit_name.as_symbol_array();
        val spec = node.designated_compilation_unit(
            unit_name_array, kind=AnalysisUnitKind.unit_specification, not_found_is_error=false
        );
        val body = if spec.is_null then node.designated_compilation_unit(
            unit_name_array, kind=AnalysisUnitKind.unit_body, not_found_is_error=false
        ) else null[CompilationUnit];
        # Emit an event if one missing unit is actually required by Ada's
        # semantics: either when we have a package body but got no spec, or
        # when we have no body and no spec.
        val _ = if (
            body.do((v1) => v1.decl() is PackageBody) and spec.is_null
        ) or (spec.is_null and body.is_null) then node.designated_compilation_unit(
            unit_name_array, kind=AnalysisUnitKind.unit_specification, not_found_is_error=true
        ) else null[CompilationUnit];

        # Return the requested unit (the spec takes precedence)
        spec or? body
    }

    fun is_contract_aspect(name: Symbol): Bool =
        name in s"Pre" | s"Pre'Class" | s"Post" | s"Post'Class" | s"Refined_Post" | s"Precondition" | s"Postcondition" | s"Precondition'Class" | s"Postcondition'Class" | s"Invariant" | s"Invariant'Class" | s"Type_Invariant" | s"Type_Invariant'Class" | s"Predicate" | s"Static_Predicate" | s"Dynamic_Predicate" | s"Default_Initial_Condition" | s"Initial_Condition" | s"Contract_Cases" | s"Test_Case" | s"Global" | s"Refined_Global" | s"Refined_State" | s"Stable_Properties" | s"Depends" | s"Refined_Depends" | s"Predicate_Failure" | s"SPARK_Mode"

    |" Return True if the given ``name`` is that of an Ada aspect in which
    |" references can designate entities declared *after* the entity on which
    |" this aspect is defined.
    fun aspect_has_forward_visibility(name: Symbol): Bool =
        node.is_contract_aspect(name) or name in s"Iterator_Element" | s"Default_Iterator"

    fun in_aspect_with_forward_visibility(): Bool = not node.parents().find(
        (p) => p.as[AspectAssoc].do(
            (a) => node.aspect_has_forward_visibility(a.id.as_bare_entity.name_symbol())
        ) or? p.as[Pragma].do(
            (p) => node.aspect_has_forward_visibility(p.id.as_bare_entity.name_symbol())
        )
    ).is_null

    |" Return whether self is contained by an aspect whose name is ``name``.
    fun in_aspect(name: Symbol): Bool = node.parents().any(
        (p) => p.as[AspectAssoc].do((a) => a.id.name_is(name))
    )

    fun empty_env(): LexicalEnv =
        node.parents().find((p) => p is CompilationUnit).as[CompilationUnit].get_empty_env()

    |" Return True iff this node is not null.
    fun is_not_null(): Bool =
        # TODO: Remove this once we have better logic predicates: it is
        # currently not possible to pass an arbitrary DSL expression to a
        # predicate, so we must have a property for every expression that we
        # might want to pass to a predicate.
        not self.is_null

    |" Static method. Evaluate the bounds of ``dr``.
    fun eval_discrete_range(dr: DiscreteRange): EvalDiscreteRange =
        if dr == null[DiscreteRange] then raise[EvalDiscreteRange] PreconditionFailure("Attempting to evaluate a null discrete range") else EvalDiscreteRange(
            low_bound=dr.low_bound.do((lb) => lb.eval_as_int(), default_val=0b), high_bound=dr.high_bound.eval_as_int()
        )

    |" Static method. Return the array of symbols joined by separator ``sep``.
    fun sym_join(syms: Array[Symbol], sep: String): String =
        sep.join(syms.map((s) => s.image()))

    |" Return the compilation unit containing this node.
    |"
    |" .. note:: This returns the :typeref:`CompilationUnit` node, which is
    |"    different from the ``AnalysisUnit``. In particular, an analysis unit
    |"    can contain multiple compilation units.
    @exported
    fun enclosing_compilation_unit(): CompilationUnit =
        node.parents().find((n) => n is CompilationUnit).as![CompilationUnit]

    |" Static property. Will return True if current_env is a children of
    |" parent.
    fun is_children_env(parent: LexicalEnv, current_env: LexicalEnv): Bool = if parent == null[LexicalEnv] then false
    elif current_env == parent then true
    elif current_env.is_null then false
    else node.is_children_env(parent, current_env.env_parent)

    |" Return self with an empty metadata field.
    fun without_md(): Entity[AdaNode] = Entity[AdaNode](
        node=self.node, info=EntityInfo(
            md=null[Metadata], rebindings=self.info.rebindings, from_rebound=self.info.from_rebound
        )
    )

    |" Assuming this node comes from an instantiated generic declaration,
    |" return its non-instantiated counterpart lying in the generic
    |" declaration.
    @exported
    fun get_uninstantiated_node(): Entity[AdaNode] = node.as_bare_entity

    |" Return possible completions at this point in the file.
    @exported
    fun complete(): Iterator[CompletionItem] = {
        bind origin = node.origin_node();

        self.complete_items().filter(
            # This property filters out `SyntheticSubpDecl` and
            # `SyntheticObjectDecl` items because they are of no use for
            # completion. This is not entirely true for `SyntheticObjectDecl`
            # since they can be useful in type predicate aspects (yet not
            # implemented since no likely helpful). Additional filtering can be
            # done in `complete_items`.
            (n) => not n.decl is SyntheticSubpDecl | SyntheticObjectDecl
        ).to_iterator()
    }

    |" Specialization of ``complete_item_weight``.
    |"
    |" Set the weight according to the type of the ``item``'s return value in
    |" comparison to the type of the declaration designated by ``name``.
    @with_dynvars(origin)
    fun complete_item_weight_matching_type(item: Entity[BasicDecl], name: Entity[Name]): Int = {
        val te_not_null = not item.type_expression().is_null;
        val td = item.type_expression()?.designated_type_decl();

        # Promote declarations that returns a value
        item.expr_type().do(
            (_) =>
            # Return value type of item matches name's type
            if (name.referenced_decl()?.type_expression()?.designated_type_decl().matching_assign_type(td) and te_not_null) then 100
            # Re-try with best-effort resolution (for incomplete code)
            elif {
                bind imprecise_fallback = true;

                name.referenced_decl()?.type_expression()?.designated_type_decl().matching_assign_type(td) and te_not_null
            } then 70
            # Types don't match but item returns a value
            else 50, default_val=0
        )
    }

    |" Return the list of keywords that are valid at this point in the file.
    |"
    |" .. note::
    |"     This is work in progress. It will return all keywords for now,
    |"     without looking at the context.
    @exported
    fun valid_keywords(): Array[Symbol] =
        [s"abort", s"abs", s"abstract", s"accept", s"access", s"aliased", s"all", s"and", s"array", s"at", s"begin", s"body", s"case", s"constant", s"declare", s"delay", s"delta", s"digits", s"do", s"else", s"elsif", s"end", s"entry", s"exception", s"exit", s"for", s"function", s"generic", s"goto", s"if", s"in", s"interface", s"is", s"limited", s"loop", s"mod", s"new", s"not", s"null", s"others", s"out", s"of", s"or", s"overriding", s"package", s"pragma", s"private", s"procedure", s"protected", s"raise", s"range", s"record", s"rem", s"renames", s"requeue", s"return", s"reverse", s"select", s"separate", s"some", s"subtype", s"synchronized", s"tagged", s"task", s"terminate", s"then", s"type", s"until", s"use", s"when", s"while", s"with", s"xor"]

    |" Assuming that self is the error location of a semantic diagnostic and
    |" that ``ctx`` is one of its logic contexts indicating which subprogram
    |" was tried, return a node that indicates with more precision which part
    |" of the subprogram caused a mismatch. For example, if self corresponds
    |" to the second actual in the ``CallExpr``, this returns the second
    |" parameter of the candidate subprogram.
    @ignored
    fun call_context(ctx: LogicContext): AdaNode = {
        val bd = ctx.decl_node.as[BasicDecl];

        bd?.subp_spec_or_null().do(
            (spec) => ctx.ref_node.as[Name]?.parent_callexpr().do(
                (ce) => if node == ce.node then spec.returns().node else node.match_formals(
                    spec.abstract_formal_params(), ce.params(), bd.info.md.dottable_subp
                ).find(
                    (pm) => pm.actual.assoc.expr().node == node
                ).do(
                    (pm) => pm.formal.formal_decl().type_expression().node, default_val=bd.defining_name().node
                ), default_val=bd.defining_name().node
            ), default_val=ctx.decl_node.node
        )
    }

    |" Return the potentially empty list of generic package/subprogram
    |" instantiations that led to the creation of this entity. Outer-most
    |" instantiations appear last.
    @exported
    fun generic_instantiations(): Array[Entity[GenericInstantiation]] =
        node.generic_instantiations_internal(self.info.rebindings)

    fun generic_instantiations_internal(r: EnvRebindings): Array[Entity[GenericInstantiation]] =
        if r == null[EnvRebindings] then null[Array[Entity[GenericInstantiation]]] else {
            val head = (r.new_env.env_node.as![GenericInstantiation].as_bare_entity);
            val tail = node.generic_instantiations_internal(r.get_parent);

            [head] & tail
        }

    |" If the rebindings in ``base`` end with ``suffix``, ``base`` is
    |" returned without it. Otherwise ``base`` is returned as-is.
    fun remove_rebindings(base: EnvRebindings, suffix: EnvRebindings): EnvRebindings = if base.is_null or suffix.is_null then base
    elif base.old_env == suffix.old_env and base.new_env == suffix.new_env then node.remove_rebindings(base.get_parent, suffix.get_parent)
    else base

    |" Append a new entry ``old_env -> new_env`` to ``base``. This also takes
    |" care of collapsing a subset of the rebindings if ``new_env`` is
    |" actually inside an envinonment which is rebound by an existing entry.
    |" In other words, this collapses generic formal package instantiations
    |" done in a generic context where the actual package is known.
    |" For example in the following snippet:
    |"
    |" .. code:: ada
    |"
    |"     generic
    |"     package Interface_G is
    |"     end Interface_G;
    |"
    |"     generic
    |"         with package I is new Interface_G (<>);
    |"     package Pkg_G is
    |"     end Pkg_G;
    |"
    |"     package My_Interface is new Interface_G;
    |"     package My_Pkg is new Pkg_G (My_Interface);
    |"
    |" Navigating inside ``My_Pkg`` leads us in ``Pkg_G`` with rebindings
    |" ``[My_Pkg]``. From here, navigating inside the instantiation of the
    |" formal package ``I`` would lead us in ``Interface_G`` with rebindings
    |" ``[My_Pkg, I]``. However, ``add_rebinding`` sees that ``I`` is
    |" rebound by the instantiation of ``My_Pkg`` and therefore collapses
    |" the two rebindings from ``[My_Pkg, I]`` to ``[My_Interface]``.
    fun add_rebinding(base: EnvRebindings,
                      old_env: LexicalEnv,
                      new_env: LexicalEnv): EnvRebindings = {
        val parent_env = new_env.env_node.node_env();

        if (
            base.is_null
            or not parent_env.env_node is GenericDecl
            or not node.is_rebound(base, parent_env)
        ) then
            base.append_rebinding(old_env, new_env)
        elif base.old_env == parent_env then
            base.new_env.get_first(
                new_env.env_node.as[GenericPackageInstantiation].name.name_symbol(),
                lookup=LookupKind.minimal
            ).as[GenericPackageInstantiation].do(
                (gpi) => {
                    val gen_env = gpi.nonbound_generic_decl_from_self().node.children_env();
                    val info = EntityInfo(
                        md=null[Metadata],
                        rebindings=node.add_rebinding(
                            base.get_parent,
                            gen_env,
                            gpi.instantiation_env
                        ),
                        from_rebound=false
                    );
                    # Collapsing may make some entries irrelevant, so shed
                    # rebindings at this point to remove those.
                    gen_env.shed_rebindings(info).rebindings
                },
                default_val=base.append_rebinding(old_env, new_env)
            )
        else
            node.add_rebinding(base.get_parent, old_env, new_env)
    }

    |" Return whether ``old_env`` is rebound somewhere inside the given
    |" rebindings.
    fun is_rebound(base: EnvRebindings, old_env: LexicalEnv): Bool = not base.is_null and (
        base.old_env == old_env or node.is_rebound(base.get_parent, old_env)
    )

    |" Append rebindings from ``to_insert`` to ``base``, stopping as soon as
    |" an entry from ``to_insert`` is already rebound in ``base``, such that
    |" for example ``insert_rebindings([A, C], [B, C, D]) = [A, C, D]``.
    fun insert_rebindings(base: EnvRebindings, to_insert: EnvRebindings): EnvRebindings = if to_insert.is_null then base
    elif base.is_null then to_insert
    elif node.is_rebound(base, to_insert.old_env) then base
    else node.add_rebinding(
        node.insert_rebindings(base, to_insert.get_parent), to_insert.old_env, to_insert.new_env
    )

    |" Return whether ``parent`` is a parent of ``base``. This considers
    |" the chain as a whole, i.e. ``has_parent_rebindings([A, B, C], [A, B])``
    |" returns True, but both ``has_parent_rebindings([A, B, C], [B, C])`` as
    |" well as ``has_parent_rebindings([A, C], [A, B])`` return False.
    fun has_parent_rebindings(base: EnvRebindings, parent: EnvRebindings): Bool = base == parent or parent.is_null or (
        not base.is_null and node.has_parent_rebindings(base.get_parent, parent)
    )

    # We mark this property as memoizable because for the moment, we only ever
    # get the first result of logic resolution, so we only ever want the result
    # of the first evaluation of this property. When we change that, we'll
    # probably change the solving API anyway.
    @call_memoizable
    fun logic_val(from_node: Entity[AdaNode], lvar: LogicVar): LogicValResult = {
        val success = from_node.resolve_names_from_closest_entry_point();

        LogicValResult(
            success=success, value=if success then lvar.get_value() else null[Entity[AdaNode]]
        )
    }

    fun semantic_parent_helper(env: LexicalEnv): Entity[AdaNode] = env.do(
        (env) => env.env_node.as_entity or? self.semantic_parent_helper(env.env_parent)
    )

    |" Return the semantic parent for this node, if applicable, null
    |" otherwise.
    |"
    |" .. note:: A node lying outside of a library item's declaration or
    |"     subunit's body does not have a parent environment, meaning that
    |"     this property will return null.
    @exported
    fun semantic_parent(): Entity[AdaNode] =
        self.semantic_parent_helper(self.node_env())

    |" Recursively call ``semantic_parent`` to get all the semantic parents
    |" of this node.
    fun semantic_parents(): Array[Entity[AdaNode]] =
        self.semantic_parent().do((sp) => [sp] & sp.semantic_parents())

    |" Return the parent basic decl for this node, if applicable, null
    |" otherwise.
    |"
    |" .. note:: If the parent BasicDecl of the given node is a generic
    |"     declaration, this call will return the instantiation from which
    |"     the node was retrieved instead, if any. This also applies to bodies
    |"     of generic declarations.
    |"
    |" .. note:: When called on a subunit's body, this property will return
    |"     its corresponding body stub.
    |"
    |" .. note:: When called on a node lying outside of a library item's
    |"     declaration or subunit's body this property will return null.
    @exported
    fun parent_basic_decl(): Entity[BasicDecl] =
        # On synthetic types that are rooted in their parents, we want to
        # call parent_basic_decl on the parent type, to avoid getting the
        # type itself as a parent_basic_decl (since some types introduce a
        # scope).
        if self is ClasswideTypeDecl
                   | DiscreteBaseSubtypeDecl
                   | SynthAnonymousTypeDecl then
            self.semantic_parent().parent_basic_decl()
        else {
            val gen_decl = self.as[GenericDecl];
            val gen_body = self.as[Body]?.decl_part().do(
                (dp) => dp.as[GenericDecl] or? dp.parent.as[GenericDecl]
            );
            (gen_decl or? gen_body).do(
                (gd) => gd.decl().get_instantiation()
            ) or? self.semantic_parent().do((sp) =>
                if sp is GenericSubpInternal | GenericPackageInternal then
                    sp.parent_basic_decl()
                else
                    sp.as[BasicDecl] or? sp.parent_basic_decl()
            )
        }

    |" Helper for the properties ``has_spark_mode_on`` and
    |" ``is_subject_to_proof``.
    |"
    |" This property will determine if the decl or body has SPARK mode on,
    |" with some special paths for bodies.
    |"
    |" It will also, for bodies only, determine whether there are
    |" ``Skip_Proof`` or ``Skip_Flow_And_Proof`` annotations, if the parameter
    |" ``include_skip_proof_annotations`` is True.
    fun is_spark_impl(include_skip_proof_annotations: Bool): Bool = {
        val spark_mode = self.spark_mode_aspect();

        # For bodies, and if `include_skip_proof_annotations` is True,
        # check `Skip_Proof`/`Skip_Flow_And_Proof`.
        if (include_skip_proof_annotations and not self.as[Body].do(
            (b) => b, default_val=self.semantic_parents().find((n) => n is Body).as[Body]
        ).do(
            (b) => b.gnatprove_annotations().find(
                (a) => a.as[Name].name_symbol() in s"Skip_Proof" | s"Skip_Flow_And_Proof"
            )
        ).is_null) then false
        elif not spark_mode.exists then false
        else spark_mode.value.do(
            (mode) => mode.as[Name].name_is(s"On"),
            # `SPARK_Mode` without value is `On` by default
            default_val=true
        )
    }

    |" Returns whether this subprogram has explicitly been set as having
    |" ``Spark_Mode`` to ``On``, directly or indirectly.
    |"
    |" Doesn't include subprograms that can be inferred by GNATprove as being
    |" SPARK.
    @exported
    fun has_spark_mode_on(): Bool = self.is_spark_impl(false)

    |" Returns whether this subprogram body is subject to proof in the context
    |" of the SPARK/GNATprove tools.
    @exported
    fun is_subject_to_proof(): Bool = self.is_spark_impl(true)

    # TODO (S917-027): re-enable this protection or remove it once we
    # moved forward on memoization soundness issues in Langkit.
    # This comment was associated with the following previous libadalang DSL:
    #    call_non_memoizable_because=(
    #        None and
    #        'Getting an analysis unit cannot appear in a memoized context'
    #    )
    |" Return the analysis unit for the given ``kind`` corresponding to this
    |" Name. Return null if ``load_if_needed`` is false and the unit is not
    |" loaded yet.
    |"
    |" For nested library units, this will trigger the processing of parent
    |" library units, so for example, if you ``get_unit('A.B.C')``, this will
    |" load units ``A.B.C``, ``A.B`` and ``A``, except if ``process_parents``
    |" is False.
    |"
    |" ``not_found_is_error`` will condition the parameter of the same name in
    |" the ``Unit_Requested`` callback. The client of ``get_unit`` is supposed
    |" to pass ``True`` if the unit not being found is an error in the Ada
    |" sense.
    @external()
    fun get_unit(name: Array[Symbol], kind: AnalysisUnitKind, load_if_needed: Bool, not_found_is_error: Bool, process_parents: Bool = true): AnalysisUnit

    |" Fetch the compilation unit designated by the given name defined in an
    |" analysis unit of the given kind.
    fun designated_compilation_unit(name: Array[Symbol], kind: AnalysisUnitKind, load_if_needed: Bool = true, not_found_is_error: Bool = true, process_parents: Bool = true): CompilationUnit = {
        val designated_analysis_unit = node.get_unit(
            name, kind, load_if_needed, not_found_is_error, process_parents
        );

        node.compilation_unit_with_name(designated_analysis_unit, name)
    }

    |" Helper for ``designated_compilation_unit``. From a given analysis unit,
    |" that might contain several compilation units, and a name, return the
    |" corresponding compilation unit.
    fun compilation_unit_with_name(unit: AnalysisUnit, name: Array[Symbol]): CompilationUnit = unit.root.do(
        (v1) => match v1 {
            # If the root of the analysis unit is a single compilation unit,
            # it is necessarily the one we look for.
            case single: CompilationUnit => single

            # If the root of the analysis unit comprises multiple compilation
            # units, look for the one with a matching fully qualified name.
            case multi: ASTList[CompilationUnit] => multi.find(
                (c) => c.syntactic_fully_qualified_name() == name
            )

            # If the root is a PragmaNodeList (`pragma No_Body` case), there is
            # no compilation unit for `name`.
            case _: ASTList[Pragma] => null[CompilationUnit]
            case _ => raise[CompilationUnit] PropertyError("Unexpected analysis unit root")
        }
    )

    |" If the corresponding analysis unit is loaded, return the root decl
    |" node for the given analysis unit ``kind`` and corresponding to the
    |" name ``name``. If it's not loaded, return none.
    fun get_unit_root_decl(name: Array[Symbol], kind: AnalysisUnitKind, load_if_needed: Bool = true, not_found_is_error: Bool = true, process_parents: Bool = true): BasicDecl = {
        val cu = node.designated_compilation_unit(
            name, kind, load_if_needed, not_found_is_error, process_parents
        );

        cu?.decl()
    }

    |" Filters out among the list of given units those that cannot refer to
    |" the unit in which this node lies. If transitive is True, the whole
    |" transitive closure of imports will be used to find a reference to the
    |" unit of this node.
    @exported
    @external()
    fun filter_is_imported_by(units: Array[AnalysisUnit], transitive: Bool): Array[AnalysisUnit]

    |" Return the environment to bind initially during the construction of the
    |" xref equation for this node. Note that this only makes sense if this
    |" node is an xref entry point.
    fun xref_initial_env(): LexicalEnv = self.children_env()

    |" This property can be used when an xref_equation needs to bind one of
    |" self's logic vars (given in ``dest``) to one of ``outer_node``'s logic
    |" vars given in ``node_var``, when ``outer_node`` is a node that is not a
    |" children of self. Indeed, due to the stop_resolution mechanism, binding
    |" to such a variable directly may not have the expected effect: if there
    |" is a "stop_resolution" boundary between the current node and the outer
    |" node, then the outer node's variable already has a value when we
    |" construct the current node's equation, hence using it in an equation
    |" will reset its content instead of binding to its value. This property
    |" basically checks whether this is the case or not in order to create an
    |" equation that either assigns ``dest`` to the known value or that binds
    |" it to the given variable.
    @with_dynvars(entry_point)
    fun bind_to_non_local(dest: LogicVar, outer_node: AdaNode, node_var: LogicVar): Equation =
        if outer_node.parents().contains(entry_point) then %eq(dest, node_var) else %eq(dest, node_var.get_value())

    |" Wrapper for xref_equation, meant to be used inside of xref_equation
    |" when you want to get the sub equation of a sub expression. It is
    |" used to change the behavior when xref_equation is called from
    |" another xref_equation call, or from the top level, so that we can do
    |" resolution in several steps.
    @with_dynvars(env, origin, entry_point)
    fun sub_equation(): Equation =
        if self.xref_stop_resolution() then self.stop_resolution_equation() else self.xref_equation()

    |" Internal helper for resolve_names. Resolve names for this node up to
    |" xref_entry_point and xref_stop_resolution boundaries.
    @external(uses_entity_info=true, uses_envs=true)
    @call_memoizable
    @with_dynvars(env, origin, entry_point)
    fun resolve_own_names(generate_diagnostics: Bool): Bool

    |" Internal helper for resolve_names, implementing the recursive logic
    |" needed to resolve names across xref_stop_resolution boundaries.
    @with_dynvars(env, origin)
    fun resolve_children_names(generate_diagnostics: Bool): Bool = node.children.all(
        (c) => c.do(
            # Only resolve nodes that have xref_stop_resolution set, and do not
            # recursively explore nodes that are xref entry points.
            (c) =>
            if c.xref_entry_point() then true else (
                if c.as_entity.xref_stop_resolution() then {
                    bind entry_point = c;
                    bind env = self.xref_initial_env();

                    c.as_entity.resolve_own_names(generate_diagnostics)
                } else true
            ) and c.as_entity.resolve_children_names(generate_diagnostics), default_val=true
        )
    )

    |" Resolves names for this node up to xref_entry_point boundaries.
    @with_dynvars(env, origin)
    fun resolve_names_internal(generate_diagnostics: Bool): Bool = {
        bind entry_point = node;

        self.resolve_own_names(generate_diagnostics) and self.resolve_children_names(generate_diagnostics)
    }

    |" Resolves names in this node with an additional constraint given by
    |" ``additional_equation``, up to xref_entry_point boundaries.
    @with_dynvars(env, origin)
    fun resolve_names_internal_with_eq(additional_equation: Equation): Bool = {
        val eq = {
            bind entry_point = node;

            self.xref_equation()
        } and additional_equation;

        eq.solve() and self.resolve_children_names(false)
    }

    |" This will resolve names for this node. If the operation is successful,
    |" then type_var and ref_var will be bound on appropriate subnodes of the
    |" statement.
    @exported
    @memoized
    @call_memoizable
    fun resolve_names(): Bool = {
        bind env = self.xref_initial_env();
        bind origin = node.origin_node();

        self.resolve_names_internal(false)
    }

    |" Resolve names from the closest entry point up to this node. Note that
    |" unlike ``resolve_names``, this will *not* trigger resolution of every
    |" node with stop_resolution that lie in the sub-tree formed by the
    |" closest entry point. It will only resolve those that are in the path to
    |" resolving self. Consider for example the following entry point:
    |"
    |" .. code::
    |"
    |"     R := (A, B);
    |"
    |" Since aggregate association nodes have ``stop_resolution`` set to True,
    |" calling ``resolve_names_from_closest_entry_point`` on ``B`` will
    |" resolve nodes ``R`` and ``B`` but not ``A``, because ``A`` does not lie
    |" on the path to ``B``.
    |"
    |" This can be useful for resolving aggregates of variant records, because
    |" resolution of a component association can safely call the resolution
    |" of a discriminant association without triggering an infinite recursion,
    |" as both are on different "paths".
    fun resolve_names_from_closest_entry_point(): Bool =
        # This is the closest entry point: resolve its names and stop the
        # recursion.
        if self.xref_entry_point() then {
            bind env = self.xref_initial_env();
            bind origin = node.origin_node();
            bind entry_point = node;

            self.resolve_own_names(false)
        } else (
            # Otherwise, recurse on the parent
            self.parent?.resolve_names_from_closest_entry_point().do(
                (_) => {
                    bind env = self.xref_initial_env();
                    bind origin = node.origin_node();

                    # Resolution succeeded for the parent and this is a
                    # stop resolution, so resolve own names as well.
                    if self.xref_stop_resolution() then {
                        bind entry_point = node;

                        self.resolve_own_names(false)
                    } else (
                        # Resolution succeeded and there is nothing to do
                        # on that particular node: return successfully.
                        true
                    )
                }
            )
        )

    |" Return all the diagnostics produced by ``resolve_own_names`` on this
    |" node. If it was never called on this node, or if it was called without
    |" diagnostic generation enabled, return an empty array.
    @external(uses_entity_info=true, uses_envs=true)
    @call_memoizable
    fun own_nameres_diagnostics(): Array[SolverDiagnostic]

    |" Accumulates all the diagnostics emitted on the children of this node,
    |" up to ``xref_entry_point`` boundaries. This considers all children
    |" nodes and not only those for which ``xref_stop_resolution`` is True,
    |" so as to handle calls to ``resolve_names_internal`` that are done
    |" during the construction of xref equations.
    @with_dynvars(env, origin)
    fun children_nameres_diagnostics(): Array[SolverDiagnostic] = self.children.mapcat(
        (c) => c.do(
            (c) => if c.is_null or c.xref_entry_point() then null[Array[SolverDiagnostic]] else c.own_nameres_diagnostics() & c.children_nameres_diagnostics()
        )
    )

    |" If name resolution on this xref entry point fails, this returns all the
    |" diagnostics that were produced while resolving it.
    @exported
    fun nameres_diagnostics(): Array[SolverDiagnostic] = {
        bind env = self.xref_initial_env();
        bind origin = node.origin_node();

        val _ = self.resolve_names_internal(true);

        self.own_nameres_diagnostics() & self.children_nameres_diagnostics()
    }

    |" Used as a predicate during name resolution to emit a diagnostic
    |" when an entity is not found.
    @predicate_error("no such entity")
    fun missing_entity_error(): Bool = not node.is_null

    |" Static method. Return the analysis unit corresponding to the Standard
    |" package.
    @exported
    @external()
    fun standard_unit(): AnalysisUnit

    |" Static method. Return whether the given token is considered a keyword
    |" in the given version of Ada. Supported values for the language version
    |" argument are: "Ada_83", "Ada_95", "Ada_2005", "Ada_2012", "Ada_2022".
    @exported
    @external()
    fun is_keyword(token: Token, language_version: Symbol): Bool

    |" Retrieves the package corresponding to the Standard unit. Used to
    |" access standard types.
    fun std(): Entity[BasicDecl] =
        node.standard_unit().root.as[CompilationUnit].body.as[LibraryItem].item.as_bare_entity

    |" Get the children env of the Standard package.
    fun std_env(): LexicalEnv = node.std().children_env()

    |" Static property. Return an entity from the standard package with name ``sym``.
    @exported
    fun std_entity(sym: Symbol): Entity[AdaNode] =
        node.unit().root.std_entity_implem(sym)

    @memoized
    fun std_entity_implem(sym: Symbol): Entity[AdaNode] = node.std_env().get_first(
        sym, categories=RefCategories(inherited_primitives=false, _=true)
    )

    |" Static method. Return the standard Boolean type.
    @exported
    fun bool_type(): Entity[BaseTypeDecl] =
        node.std_entity(s"Boolean").as[BaseTypeDecl]

    |" Static method. Return the standard Integer type.
    @exported
    fun int_type(): Entity[BaseTypeDecl] =
        node.std_entity(s"Integer").as[BaseTypeDecl]

    |" Static method. Return the standard Universal Integer type.
    @exported
    fun universal_int_type(): Entity[BaseTypeDecl] =
        node.std_entity(s"Universal_Int_Type_").as[BaseTypeDecl]

    |" Static method. Return the standard Universal Real type.
    @exported
    fun universal_real_type(): Entity[BaseTypeDecl] =
        node.std_entity(s"Universal_Real_Type_").as[BaseTypeDecl]

    |" Static method. Return the standard Universal Fixed type.
    fun universal_fixed_type(): Entity[BaseTypeDecl] =
        node.std_entity(s"Universal_Fixed_Type_").as[BaseTypeDecl]

    |" Static method. Return the standard Character type.
    @exported
    fun std_char_type(): Entity[BaseTypeDecl] =
        node.std_entity(s"Character").as[BaseTypeDecl]

    |" Static method. Return the standard Wide_Character type.
    @exported
    fun std_wide_char_type(): Entity[BaseTypeDecl] =
        node.std_entity(s"Wide_Character").as[BaseTypeDecl]

    |" Static method. Return the standard Wide_Wide_Character type.
    @exported
    fun std_wide_wide_char_type(): Entity[BaseTypeDecl] =
        node.std_entity(s"Wide_Wide_Character").as[BaseTypeDecl]

    |" Static method. Return the standard String type.
    @exported
    fun std_string_type(): Entity[BaseTypeDecl] =
        node.std_entity(s"String").as[BaseTypeDecl]

    |" Static method. Return the standard Wide_String type.
    @exported
    fun std_wide_string_type(): Entity[BaseTypeDecl] =
        node.std_entity(s"Wide_String").as[BaseTypeDecl]

    |" Static method. Return the standard Wide_Wide_String type.
    @exported
    fun std_wide_wide_string_type(): Entity[BaseTypeDecl] =
        node.std_entity(s"Wide_Wide_String").as[BaseTypeDecl]

    |" Static method. Return the package containing the definitions of the
    |" root types.
    fun std_root_types(): LexicalEnv =
        node.std_entity(s"root_types_").as[PackageDecl]?.children_env()

    |" Static method. Return the root_integer type.
    fun root_int_type(): Entity[BaseTypeDecl] = node.std_root_types().get_first(
        s"root_integer", lookup=LookupKind.minimal, categories=RefCategories(inherited_primitives=false, _=true)
    ).as[BaseTypeDecl]

    |" Static method. Return the root_real type.
    fun root_real_type(): Entity[BaseTypeDecl] = node.std_root_types().get_first(
        s"root_real", lookup=LookupKind.minimal, categories=RefCategories(inherited_primitives=false, _=true)
    ).as[BaseTypeDecl]

    |" Static method. Return the System.Address type.
    fun system_address_type(): Entity[BaseTypeDecl] = node.get_unit_root_decl(
        [s"System"], AnalysisUnitKind.unit_specification
    )?.children_env().get_first(s"Address", lookup=LookupKind.flat).as[BaseTypeDecl]

    |" See ``root_type_ops``.
    @memoized
    fun root_type_ops_impl(sym: Symbol): Array[Entity[BasicDecl]] = node.std_root_types().get(
        sym, lookup=LookupKind.minimal, categories=RefCategories(inherited_primitives=false, _=true)
    ).filtermap(
        (n) => n.as[BasicDecl], (n) => n.as![BasicDecl].is_subprogram()
    )

    |" Lookup the given symbol in the builtin ``root_types`` package. This is
    |" used for fast-access to predefined operator on root types.
    fun root_type_ops(sym: Symbol): Array[Entity[BasicDecl]] =
        # Typical strategy for memoizing "static" functions
        node.unit().root.root_type_ops_impl(sym)

    |" Return the type Ada.Exceptions.Exception_Id.
    fun exc_id_type(): Entity[BaseTypeDecl] = node.get_unit_root_decl(
        [s"Ada", s"Exceptions"], AnalysisUnitKind.unit_specification
    )?.children_env().get_first(s"Exception_Id", lookup=LookupKind.flat).as[BaseTypeDecl]

    |" Return the type Ada.Task_Identification.Task_Id.
    fun task_id_type(): Entity[BaseTypeDecl] = node.get_unit_root_decl(
        [s"Ada", s"Task_Identification"], AnalysisUnitKind.unit_specification
    )?.children_env().get_first(s"Task_Id", lookup=LookupKind.flat).as[BaseTypeDecl]

    |" Return the type Ada.Strings.Text_Buffers.Root_Buffer_Type
    fun root_buffer_type(): Entity[BaseTypeDecl] = node.get_unit_root_decl(
        [s"Ada", s"Strings", s"Text_Buffers"], AnalysisUnitKind.unit_specification
    )?.children_env().get_first(
        s"Root_Buffer_Type", lookup=LookupKind.flat
    ).as[BaseTypeDecl]

    |" Return the type Ada.Streams.Root_Stream_Type
    fun root_stream_type(): Entity[BaseTypeDecl] = node.get_unit_root_decl(
        [s"Ada", s"Streams"], AnalysisUnitKind.unit_specification
    )?.children_env().get_first(
        s"Root_Stream_Type", lookup=LookupKind.flat
    ).as[BaseTypeDecl].classwide_type().as[BaseTypeDecl]

    |" Return the type Ada.Numerics.Big_Numbers.Big_Integers.Big_Integer
    fun big_integer_type(): Entity[BaseTypeDecl] = node.get_unit_root_decl(
        [s"Ada", s"Numerics", s"Big_Numbers", s"Big_Integers"],
        AnalysisUnitKind.unit_specification
    )?.children_env().get_first(
        s"Big_Integer", lookup=LookupKind.flat
    ).as[BaseTypeDecl]

    |" Return whether the parent unit of this node has with visibility on
    |" the given analysis unit. In particular, this takes into account
    |" private visibility: for a given node which is inside a body or a
    |" private part, it will forward to the query in the parent unit the
    |" fact that the origin node has visibility on the ``private with``
    |" clauses of the parent unit.
    fun parent_has_with_visibility(refd_unit: AnalysisUnit, self_cu: CompilationUnit, has_private_view: Bool): Bool = {
        val should_have_private_view = has_private_view or self_cu.has_private_view(node);

        self_cu.decl().as_bare_entity.semantic_parent().do((parent) =>
            # In our implementation, the semantic parent of a child package
            # is always the private part of the parent package (see note in
            # ``PackageDecl``'s ``env_spec``). But if we are not supposed
            # to have view on the private part, we must perform the query
            # outside of it, here from the parent of the private part.
            if parent is PrivatePart and not should_have_private_view then parent.parent.has_with_visibility(refd_unit, omit_privacy_check=false) else parent.has_with_visibility(
                refd_unit, omit_privacy_check=should_have_private_view
            )
        )
    }

    |" Return whether this node has a private part amongst its parent. This
    |" implementation uses environments instead of syntactic parents in order
    |" to jump over irrelevant nodes (since we know that a private part has a
    |" lexical environment). Don't go further than ``barrier``. Also return
    |" True for nodes in the prelude of compilation units, as they have the
    |" same visibility privileges of private parts (i.e. they can see "private
    |" with"s).
    fun has_private_part_parent(barrier: AdaNode): Bool = node is PrivatePart or (
        node != barrier and node.node_env().env_node.do(
            (parent) => parent.has_private_part_parent(barrier), default_val=true
        )
    )

    |" Here we assume that ``refd_unit.is_referenced_from(self.unit)`` is
    |" already True, but we now want to check if the clause that made
    |" ``refd_unit`` visible is private and if it is, whether we are in the
    |" private part.
    fun has_private_with_visibility(self_cu: CompilationUnit, refd_unit: AnalysisUnit): Bool = (
        # If the referenced unit is ourself, we don't need further checks
        node.unit() == refd_unit
    ) or (
        # If we have view on "private with"s, we don't need further checks
        self_cu.has_private_view(node)
    ) or (
        # But if we don't, so we must return False if the referenced unit
        # is only visible from private parts.
        not self_cu.privately_imported_units().contains(refd_unit)
    )

    |" Return whether self's unit has ``with visibility`` on ``refd_unit``.
    |"
    |" In other words, whether self's unit has a WITH clause on ``refd_unit``,
    |" or if its spec, or one of its parent specs has one.
    fun has_with_visibility(refd_unit: AnalysisUnit, omit_privacy_check: Bool = false): Bool = {
        val cu = node.enclosing_compilation_unit();

        (
            # First, check whether this unit "with"s the referenced unit
            refd_unit.is_referenced_from(node.unit()) and (
                omit_privacy_check or node.has_private_with_visibility(cu, refd_unit)
            )
        ) or (
            # If it doesn't, check whether its parent unit does
            node.parent_has_with_visibility(
                refd_unit, cu, has_private_view=omit_privacy_check
            )
        ) or (
            # With clauses from a library level subprogram declaration are
            # visible by its corresponding body. Since the decl is not the
            # parent of the body, we must specifically take this case into
            # account.
            cu.decl().as_bare_entity.as[BaseSubpBody].do(
                (b) => if b.is_library_item() then b.defining_name().referenced_unit(
                    AnalysisUnitKind.unit_specification, not_found_is_error=false
                ).do(
                    # A subprogram renaming can appear as a top-level
                    # library item of a unit specification, in which case
                    # the `referenced_unit` call above will return `cu`.
                    # In that case, we must not perform the recursive call,
                    # otherwise we will get an infinite recursion.
                    (u) => if cu == u then false else u?.has_with_visibility(refd_unit, omit_privacy_check=true)
                ) else false
            )
        ) or (
            # because of the GNAT kludge around the child packages of
            # Ada.Text_IO, always consider those to be visible. Otherwise it
            # will break any access to P.Integer_IO & co. for any package P
            # that is a renaming of Ada.Text_IO. Indeed, since Integer_IO & co.
            # must behave as nested packages even though they are implemented
            # as child packages, we must consider them visible as soon as P
            # is visible.
            refd_unit.root.as[CompilationUnit]?.is_text_io_child()
        )
    }

    fun has_visibility(other_entity: Entity[AdaNode]): Bool =
        # We found a synthetic type predicate object decl, check if we are
        # allowed to see it.
        other_entity.as[SyntheticObjectDecl].do(
            (sod) => sod.is_referred_by(node), default_val=true
        ) and (
            (
                # The node is a generic package instantiation coming from a formal
                # package.
                other_entity.as[GenericPackageInstantiation]?.info.from_rebound
            ) or other_entity.as[PackageRenamingDecl]?.info.from_rebound or (
                # The node is not an unit root
                not other_entity.as[BasicDecl]?.is_compilation_unit_root()
            ) or (
                # Else, check with visibility
                node.has_with_visibility(other_entity.node.unit())
            )
        )

    |" Helper property to resolve the actuals of generic instantiations.
    fun resolve_generic_actual(): Entity[AdaNode] = match self {
        case aod: Entity[AnonymousExprDecl] => aod

        # Depending on the formal that matches this actual, this name
        # can be either an object, a type or a subprogram.
        # TODO: the code below should execute a specific logic
        # depending on the corresponding kind of the formal (type, object,
        # subprogram, etc.), so we should find a way to make it available.
        case n: Entity[Name] => (
            n.name_designated_type().as[AdaNode] or? n.as[AttributeRef]?.attribute_subprogram()
        ) or? n.all_env_elements()?[0]

        # We first try to find a type
        # If it's an attribute, it might be a reference to a function
        # If all that didn't work, find something else
        case _ => null[Entity[AdaNode]]
    }

    |" If self is a library item or a subunit, return a flat list of all names
    |" for top-level UsePackageClause nodes. See
    |" UsePackageClause.env_spec.ref_envs for more details.
    fun top_level_use_package_clauses(): Array[AdaNode] =
        node.parent.parent.as![CompilationUnit].prelude.filter((p) => p is UsePackageClause).mapcat(
            (p) => p.as![UsePackageClause].packages.map((n) => n.as[AdaNode])
        )

    |" If self is a library item or a subunit, return a flat list of all names
    |" for top-level UseTypeClause nodes. See UseTypeClause.env_spec
    |" for more details.
    fun top_level_use_type_clauses(): Array[AdaNode] =
        node.parent.parent.as![CompilationUnit].prelude.filter((p) => p is UseTypeClause).mapcat(
            (p) => p.as![UseTypeClause].types.map((n) => n.as[AdaNode])
        )

    |" If self is a library item or a subunit, return a flat list of all names
    |" for top-level UseClause nodes.
    fun top_level_use_clauses(): Array[UseClause] = {
        val cu = node.parent.parent.as![CompilationUnit];

        cu.prelude.filtermap(
            (p) => p.as[UseClause], (p) => p is UseClause
        )
    }

    |" Return a flat list of all package names that are with'ed by top-level
    |" WithClause nodes of the compilation unit this node lies in.
    |" Omit "private with" clauses if ``include_privates`` is False.
    fun top_level_with_package_clauses(include_privates: Bool = true): Array[Name] =
        node.enclosing_compilation_unit().prelude.mapcat(
            (clause) => clause.as[WithClause].do(
                (with_clause) => if with_clause.has_private.as_bool() and not include_privates then null[Array[Name]] else with_clause.packages.as_array()
            )
        )

    |" If self is a library-level SubpBody, fetch the environments USE'd in
    |" its declaration.
    fun use_clauses_in_spec_of_subp_body(): LexicalEnv = {
        val fqn = node.enclosing_compilation_unit().syntactic_fully_qualified_name();
        val spec = node.designated_compilation_unit(
            name=fqn, kind=AnalysisUnitKind.unit_specification, not_found_is_error=false
        );

        spec?.decl()?.top_level_use_clauses().map(
            (clause) => clause.as_bare_entity.used_envs()
        ).env_group()
    }

    |" Assuming self is a generic entity's body that is nested (not a library
    |" item), return the grouped lexical environment containing all the
    |" environments that are referred by use clauses inside formal part of
    |" its generic declaration. Return an empty environment if this is not
    |" the body of a generic decl.
    fun use_clauses_in_generic_formal_part(): LexicalEnv = {
        val gen_decl = self.as[Body]?.safe_generic_decl_part();

        gen_decl.do(
            (gd) => gd.formal_part.use_clauses_envs(), default_val=node.empty_env()
        )
    }

    |" Assuming self is a generic entity's body that is nested (not a library
    |" item), return the lexical environment for the corresponding
    |" GenericPackageDecl (or GenericSubpDecl) node. Return an empty
    |" environment in all other cases.
    |"
    |" This is a helper for generic formals visibility in generic bodies. See
    |" the use in the child_unit macro.
    |"
    |" The following property is evaluated each time we make a recursive
    |" lexical environment lookup on a child unit. As it does itself a lot of
    |" lookups, memoizing it is very important.
    fun nested_generic_formal_part(): LexicalEnv = {
        val gen_decl = node.as_bare_entity.as[Body]?.safe_generic_decl_part();

        gen_decl.do(
            (gd) => gd.node.children_env(), default_val=node.empty_env()
        )
    }

    |" Property helper to determine if an entity is a package or not.
    fun is_package(): Bool =
        node is PackageDecl | PackageBody | GenericPackageInstantiation | PackageRenamingDecl | GenericPackageDecl

    |" Provide the default lexical environment to use in EnvSpec's
    |" initial_env.
    fun default_initial_env(): LexicalEnv = node.parent.do(
        (p) => p.children_env(), default_val=node.children_env()
    )

    |" Static method. Get the top-level decl in ``unit``.  This is the body of
    |" a Subunit, or the item of a ``LibraryItem``.
    @exported
    fun top_level_decl(unit: AnalysisUnit): BasicDecl =
        unit?.root.as![CompilationUnit].decl()

    |" Static method. DefiningName for all parameters.
    fun unpack_formals(formal_params: Array[Entity[BaseFormalParamDecl]]): Array[Entity[DefiningName]] =
        node.unit().root.unpack_formals_impl(formal_params)

    fun unpack_formals_impl(formal_params: Array[Entity[BaseFormalParamDecl]]): Array[Entity[DefiningName]] =
        formal_params.mapcat((spec) => spec.defining_names())

    |" Static method. For each ParamAssoc in a AssocList, return whether we
    |" could find a matching formal in self, and whether this formal is
    |" optional (i.e. has a default value).
    fun match_formals(formal_params: Array[Entity[BaseFormalParamDecl]], params: Entity[AssocList], is_dottable_subp: Bool): Array[ParamMatch] = {
        val unpacked_formals = node.unpack_formals(formal_params);

        params.do(
            (p) => p.unpacked_params().imap(
                (a, i) => if a.name.is_null then {
                    val idx = if is_dottable_subp then i + 1 else i;

                    # Positional parameter case: if this parameter has no
                    # name association, make sure we have enough formals.
                    unpacked_formals?[idx].do(
                        (sp) => ParamMatch(has_matched=true, actual=a, formal=sp)
                    )
                } else (
                    # Named parameter case: make sure the designator is
                    # actually a name and that there is a corresponding
                    # formal.
                    a.name.do(
                        (id) => unpacked_formals.find((p) => p.name.matches(id)).do(
                            (sp) => ParamMatch(has_matched=true, actual=a, formal=sp)
                        )
                    )
                )
            )
        )
    }

    |" Assuming that self is a choice expression (such as what can appear in
    |" an alternative of a case statement or in the RHS of a membership
    |" expression, this property returns whether the given value satisfies it.
    |"
    |" .. ATTENTION::
    |"     This is an experimental feature, so even if it is exposed to allow
    |"     experiments, it is totally unsupported and the API and behavior are
    |"     very likely to change in the future.
    @exported
    fun choice_match(value: BigInt): Bool = match self {
        # If choice is a binop, it is either a range, or a static
        # arithmetic expression.
        case bo: BinOp =>
        # If choice is a range, then check that val is in the range
        if bo.op is Op.DoubleDot then value >= bo.left.eval_as_int() and value <= bo.right.eval_as_int() else value == bo.eval_as_int()

        # If choice is a name, it is either a subtype name, either a
        # constant number name.
        case n: Name => n.name_designated_type().do(
            (dt) => dt.discrete_range().do(
                (dr) => {
                    val edr = node.eval_discrete_range(dr);

                    value >= edr.low_bound and value <= edr.high_bound
                }, default_val=true
            ) and {
                bind origin = node;
                bind imprecise_fallback = false;

                dt.satisfies_type_predicates(value)
            }, default_val=value == n.eval_as_int()
        )

        # If choice is a subtype indication, then get the range
        case st: SubtypeIndication => st.discrete_range().do(
            (dr) => {
                val edr = node.eval_discrete_range(dr);

                value >= edr.low_bound and value <= edr.high_bound
            }, default_val=true
        ) and {
            bind origin = node;
            bind imprecise_fallback = false;

            st.designated_type().satisfies_type_predicates(value)
        }

        # If it is an expr, then just check for equality
        case e: Expr => value == e.eval_as_int()

        # If 'others', always return true
        case _: OthersDesignator => true
        case _ => false
    }

    |" Return a cross reference from this name to a defining identifier,
    |" trying to mimic GNAT's xrefs as much as possible.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun gnat_xref(): Entity[DefiningName] = {
        val bd = self.as[Name].enclosing_defining_name().do((dn) => dn.basic_decl());

        {
            bind origin = node;

            if bd is ParamSpec and (
                bd.semantic_parent() is BasicSubpDecl | ExprFunction | BaseTypeDecl | SubpBodyStub | NullSubpDecl or bd.semantic_parent().as[SubpBody].do(
                    (body) => body.previous_part_for_decl().is_null
                )
            ) then bd.semantic_parent().as[BasicDecl].defining_name()
            elif bd.do((v1) => v1.parent is GenericFormal) then bd.parents().find((p) => p is GenericDecl).as[GenericDecl].decl().defining_name()
            # Deferred constants case
            elif (
                bd is ObjectDecl and not bd.as[ObjectDecl].has_constant.is_null
            ) and bd.is_in_private_part() then self.as[Name].enclosing_defining_name().previous_part()
            # Discriminants case. There are two kinds of GNAT xrefs that apply
            # to discrimimants. The 'd' kind, which points to the type this
            # discriminant belongs to, and the 'r' kind, which, for a private
            # type completion, points to the corresponding discriminant in the
            # public view of that type. Note that 'r' references are simply
            # documented as "reference" in GNAT and might apply to other nodes,
            # but the discriminants case is the single occurence of that kind
            # we found so far.
            elif bd is DiscriminantSpec then {
                val pd = bd.as[DiscriminantSpec].parent_decl();

                if pd.is_in_private_part() then self.as[Name].enclosing_defining_name().previous_part() or? pd.defining_name() else pd.defining_name()
            }
            elif bd is AbstractSubpDecl then bd.as[AbstractSubpDecl].subp_decl_spec().primitive_subp_first_type().defining_name()
            elif bd is BasicSubpDecl then bd.as[BasicSubpDecl].subp_decl_spec().primitive_subp_first_type().do(
                (prim_typ) => prim_typ.is_tagged_type().do(
                    (_) => prim_typ.private_completion().do((pc) => pc.defining_name()) or? prim_typ.defining_name()
                )
            )
            elif bd is BaseSubpBody then bd.as[BaseSubpBody].subp_spec.subp_name
            else self.as[Name]?.gnat_xref_decl().do(
                (ret) => {
                    val dbd = ret.basic_decl();

                    if dbd is ParamSpec then dbd.as[ParamSpec].decl_param(ret)
                    elif dbd is ObjectDecl then (
                        # Since dbd can refer to an object declaration with
                        # multiple defining names, do not call `public_part_decl`
                        # but directly call `previous_part_for_name(self)`.
                        dbd.as[ObjectDecl].previous_part_for_name(self.as[Name].name_symbol()).do((ppn) => ppn.defining_name()) or? ret
                    )
                    elif dbd is Body then (dbd.as[Body].decl_part() or? dbd).defining_name()
                    else ret
                }
            )
        }
    }

    |" Static property. Finds the closest parent which is a ``BaseSubpSpec`` /
    |" ``GenericInstantiation`` / ``ComponentDecl`` / ``RenamingClause``.
    |" Is used by ``env_get`` to implement correct visibility rules for those.
    |" See documentation on that property.
    fun env_get_real_from_node(from_node: AdaNode): AdaNode =
        if from_node.is_null then
            from_node
        else {
            val c = from_node.parents().find((n) =>
                n is GenericInstantiation | BaseSubpSpec | ComponentDecl
                    | RenamingClause
            );

            if c.is_null then
                from_node
            elif c is GenericInstantiation then
                # A generic instantiation may have referenced environments,
                # therefore we don't want the lookup origin to be done on
                # the instantiation node directly, otherwise these references
                # will not be visited, as they won't be considered reachable.
                c.as[GenericInstantiation].as_bare_entity.defining_name().node
            elif c is BaseSubpSpec then
                c.as[BaseSubpSpec].as_bare_entity.name().node
            elif c is RenamingClause then
                # By querying from the parent of the renaming clause, we
                # prevent a SubpRenamingDecl's renamed object from  having
                # visibility over its own parameters.
                c.as[RenamingClause].parent
            else
                c
        }

    |" Static property. Create an entity from the arguments with a null
    |" metadata.
    fun entity_no_md(n: AdaNode, rebindings: EnvRebindings, from_rebound: Bool): Entity[AdaNode] = Entity[AdaNode](
        node=n, info=if n.is_null then null[EntityInfo] else EntityInfo(
            md=null[Metadata], rebindings=rebindings, from_rebound=from_rebound
        )
    )

    |" Static method. Create an env mapping array from a list of BaseId to be
    |" used as keys, and a node to be used as value in the mappings.
    fun env_mappings(defining_names: ASTList[DefiningName], value: AdaNode): Array[EnvAssoc] = defining_names.map(
        (n) => EnvAssoc(
            key=n.name_symbol(), value=value, dest_env=DesignatedEnv(
                kind=DesignatedEnvKind.current_env, env_name=null[Symbol], direct_env=null[LexicalEnv]
            ), metadata=null[Metadata]
        )
    )

    @with_dynvars(origin)
    fun comp_bind(left: LogicVar, right: LogicVar): Equation =
        %eq(right, left, conv_prop=BaseTypeDecl.comp_type)

    |" Static method. Return an equation that will bind type_var to any
    |" integer value, corresponding to the notion of universal_integer in the
    |" Ada RM (see :rmlink:`3.4.1`).
    @with_dynvars(origin)
    fun universal_int_bind(type_var: LogicVar): Equation =
        %eq(type_var, node.universal_int_type())

    |" Static method. Return an equation that will bind type_var to any real
    |" value, corresponding to the notion of universal_real in the Ada RM (see
    |" :rmlink:`3.4.1`).
    @with_dynvars(origin)
    fun universal_real_bind(type_var: LogicVar): Equation =
        %eq(type_var, node.universal_real_type())

    |" Return a null node iff we are in the definition of an aspect clause
    |" where sequential lookup needs to be deactivated. Return self otherwise.
    fun origin_node(): AdaNode =
        if node.in_aspect_with_forward_visibility() then null[AdaNode]
        elif node is ExprFunction then node.as[ExprFunction].expr
        else node

    |" Hook for the EnvSpec of units.
    |"
    |" Return value is not significant: the only purpose of this property lies
    |" in its side effects.
    fun env_hook(): Bool = match node.parent {
        case _: LibraryItem => match node {
            case b: Body => b.env_hook_body()
            case bd: BasicDecl => bd.env_hook_basic_decl()
            case _ => false
        }
        case su: Subunit => su.env_hook_subunit()
        case _ => false
    }

    |" Wrapper for ``env.get``. Refines the results so that Ada visibility
    |" rules for subprogram specifications, generic instantiations and
    |" component declarations are correctly handled: names inside the three
    |" aforementioned constructs do not have visibility on their enclosing
    |" declaration, such that the following is legal:
    |"
    |" .. code:: ada
    |"
    |"     type T is null record;
    |"     procedure T (X : T) is null;
    |"
    |" Here, calling ``env_get("T")`` in the subp spec of subprogram ``T``
    |" must not return the subprogram ``T`` itself, because according to Ada
    |" the subprogram is not yet visible.
    |"
    |" Likewise, in the following snippet:
    |"
    |" .. code:: ada
    |"
    |"     type Rec is record
    |"         Set : access Set.T;
    |"     end record;
    |"
    |" Calling ``env_get("Set")`` inside the type expression of the component
    |" should not include the ``ComponentDecl`` itself in the result.
    fun env_get(env: LexicalEnv, symbol: Symbol, lookup: LookupKind = LookupKind.recursive, from_node: AdaNode = null[AdaNode], categories: RefCategories = RefCategories(_=true)): Array[Entity[AdaNode]] = {
        val real_from_node = node.env_get_real_from_node(from_node);
        val results = env.get(
            symbol, lookup=lookup, from=real_from_node, categories=categories
        );

        # Fetch the BasicDecl corresponding to ``real_from_node``, so that
        # we can filter it out from ``results`` if its name matches the symbol
        # on which we want to perform an env lookup.
        real_from_node.do(
            (rfn) => match rfn {
                case bd: BasicDecl => if bd.as_bare_entity.defining_name()?.name_is(symbol) then bd else null[BasicDecl]
                case dn: DefiningName => if dn.name_is(symbol) then dn.as_bare_entity.basic_decl().node else null[BasicDecl]
                case _ => null[BasicDecl]
            }.do(
                (enclosing_bd) =>
                # We found that our enclosing basic decl's defining name
                # matches the symbol on which we are doing an env lookup:
                # filter it out of the `results` array since it cannot be
                # legal Ada.
                results.filter((r) => r.node != enclosing_bd), default_val=results
            ), default_val=results
        )
    }

    |" Like ``env_get`` but should be used when the results are to be returned
    |" to users: this wrapper takes care of removing internal structures
    |" which are of no use for users.
    fun env_get_public(env: LexicalEnv, symbol: Symbol, lookup: LookupKind = LookupKind.recursive, from_node: AdaNode = null[AdaNode], categories: RefCategories = RefCategories(_=true)): Array[Entity[AdaNode]] = node.env_get(
        env, symbol, lookup, from_node, categories
    ).filter(
        (x) => x.as[PackageDecl].do(
            (pkg) => pkg.name_symbol() != s"root_types_", default_val=true
        )
    )

    |" Synthesizes a defining name and its inner identifier using the given
    |" symbol.
    @memoized
    fun synthesize_defining_name(sym: Symbol): DefiningName = SyntheticDefiningName(
        logic_vars=null[Address], name=SyntheticIdentifier(logic_vars=null[Address], sym=sym)
    )

    |" Synthesizes a subprogram declaration named after the given symbol,
    |" with a "Right" parameter having the ``rhs`` type, and the given
    |" return type.
    @memoized
    fun create_unop_assoc(op: Symbol, rhs: BaseTypeDecl, ret: BaseTypeDecl): EnvAssoc = EnvAssoc(
        key=op, value=SyntheticSubpDecl(
            spec=SyntheticUnarySpec(
                subp_symbol=op, right_param=SyntheticFormalParamDecl(
                    param_name=s"right", param_type=SyntheticTypeExpr(target_type=rhs)
                ), return_type_expr=SyntheticTypeExpr(target_type=ret)
            )
        ), dest_env=DesignatedEnv(
            kind=DesignatedEnvKind.current_env, env_name=null[Symbol], direct_env=null[LexicalEnv]
        ), metadata=null[Metadata]
    )

    |" Implementation for the various ``create_binop_assoc*`` variants. The
    |" shorthands take care of synthesizing type expressions when necessary.
    @memoized
    fun create_binop_assoc_impl(op: Symbol, lhs: TypeExpr, rhs: TypeExpr, ret: TypeExpr): EnvAssoc = EnvAssoc(
        key=op, value=SyntheticSubpDecl(
            spec=SyntheticBinarySpec(
                subp_symbol=op, left_param=SyntheticFormalParamDecl(param_name=s"left", param_type=lhs), right_param=SyntheticFormalParamDecl(param_name=s"right", param_type=rhs), return_type_expr=ret
            )
        ), dest_env=DesignatedEnv(
            kind=DesignatedEnvKind.current_env, env_name=null[Symbol], direct_env=null[LexicalEnv]
        ), metadata=null[Metadata]
    )

    |" Synthesizes a subprogram declaration named after the given symbol,
    |" with a "Left" parameter having the ``lhs`` type, a "Right" parameter
    |" having the ``rhs`` type, and the given return type.
    @memoized
    fun create_binop_assoc(op: Symbol, lhs: BaseTypeDecl, rhs: BaseTypeDecl, ret: BaseTypeDecl): EnvAssoc = node.create_binop_assoc_impl(
        op, SyntheticTypeExpr(target_type=lhs), SyntheticTypeExpr(target_type=rhs), SyntheticTypeExpr(target_type=ret)
    )

    |" Like ``create_binop_assoc`` but the left parameter's type is given as a
    |" type expression.
    @memoized
    fun create_binop_assoc_l_expr(op: Symbol, lhs: TypeExpr, rhs: BaseTypeDecl, ret: BaseTypeDecl): EnvAssoc = node.create_binop_assoc_impl(
        op, lhs, SyntheticTypeExpr(target_type=rhs), SyntheticTypeExpr(target_type=ret)
    )

    |" Like ``create_binop_assoc`` but the right parameter's type is given as
    |" a type expression.
    @memoized
    fun create_binop_assoc_r_expr(op: Symbol, lhs: BaseTypeDecl, rhs: TypeExpr, ret: BaseTypeDecl): EnvAssoc = node.create_binop_assoc_impl(
        op, SyntheticTypeExpr(target_type=lhs), rhs, SyntheticTypeExpr(target_type=ret)
    )

    |" Like ``create_binop_assoc`` but the left and right parameters' types
    |" are given as type expressions.
    @memoized
    fun create_binop_assoc_l_r_expr(op: Symbol, lhs: TypeExpr, rhs: TypeExpr, ret: BaseTypeDecl): EnvAssoc = node.create_binop_assoc_impl(
        op, lhs, rhs, SyntheticTypeExpr(target_type=ret)
    )

    |" Custom Unique identifying text used to recognize this node. Not
    |" applicable to all nodes, but on AdaNode because it spans more than one
    |" hierarchy of node types.
    @ignored
    fun custom_id_text(): String = ""

    |" Internal method used by ``complete`` to get the array of possible
    |" completions for the current node. This method has to be overridden in
    |" order to specialize the completion.
    @with_dynvars(origin)
    fun complete_items(): Array[CompletionItem] =
        node.env_get_public(node.children_env(), null[Symbol]).map(
            (n) => CompletionItem(
                decl=n.as[BasicDecl],
                is_dot_call=n.info.md.dottable_subp,
                is_visible=node.has_visibility(n),
                weight=self.complete_item_weight(n.as[BasicDecl])
            )
        )

    |" Internal method used by ``complete_items`` that can be used to
    |" specialize the completion weight field only.
    |"
    |" Weight is an integer, the higher it is, the more relevant it is in the
    |" given context. In practice, the weight varies from 0 to 100, so that
    |" one has just to sort the completion items by their weight, in
    |" decreasing order, to get the more relevant items first.
    @with_dynvars(origin)
    fun complete_item_weight(@ignored item: Entity[BasicDecl]): Int = 0

    |" Helper for the ``has_spark_mode_on`` and ``is_subject_to_proof``
    |" properties.
    |"
    |" This property will get the applicable aspect defining the SPARK_Mode
    |" for the given node, recursing syntactically and taking into account
    |" configuration files.
    |"
    |" This only implements the base logic for recursing up the tree: nodes
    |" that need a specific logic must override it. See for example
    |" ``BasicDecl.spark_mode_aspect``.
    @exported
    fun spark_mode_aspect(): Aspect =
        if not self.parent.is_null then self.parent.spark_mode_aspect() else (
            # Handle cases where this property is called on a node that is
            # outside of a compilation unit.
            raise[Aspect] PreconditionFailure("SPARK Mode does not apply here")
        )

    |" Return the immediate declarative region (:rmlink:`8.1`)
    |" corresponding to this node, that is, the concatenation of the
    |" declarative parts of itself and all its completion. This does not
    |" include the declarative regions of the enclosed declarations.
    |"
    |" This is mainly used to restrict the scope in which to search for the
    |" previous part of a declaration.
    fun immediate_declarative_region(): LexicalEnv =
        null[LexicalEnv]

    |" This is the base property for constructing equations that, when solved,
    |" will resolve names and types for every sub expression of the expression
    |" you call it on. Note that if you call that on any expression, in some
    |" context it might lack full information and return multiple solutions.
    |" If you want completely precise resolution, you must call that on the
    |" outermost node that supports xref_equation.
    @with_dynvars(env, origin, entry_point)
    # xref_equation is only called from the external property
    # resolve_own_names, so we need to ignore the warning.
    @ignored
    fun xref_equation(): Equation = raise[Equation] PropertyError("Property AdaNode.xref_equation not implemented")

    @with_dynvars(env, origin)
    fun xref_stop_resolution(): Bool = false

    @with_dynvars(env, origin, entry_point)
    fun stop_resolution_equation(): Equation = %true

    |" Designates entities that are entry point for the xref solving
    |" infrastructure. If this returns true, then resolve_names can be called
    |" on it.
    |"
    |" .. note::
    |"     For convenience, and unlike what is defined in the ARM wrt.
    |"     complete contexts for name resolution, ``xref_entry_points`` can be
    |"     nested.
    @exported
    fun xref_entry_point(): Bool = false

    |" Return whether this node is a ``UsePackageClause`` that follows a
    |" ``WithClause`` for the same unit.
    @exported
    fun matching_with_use_clause(): Bool =
        node.as[UsePackageClause].do(
            (uc) => self.previous_sibling().as[WithClause].do(
               (wc) =>
                  uc.packages.length() == wc.packages.length()
                  and uc.packages[0].as_symbol_array()
                      == wc.packages[0].as_symbol_array()
            )
        )
}

|" Qualifier for the ``abort`` keyword.
@qualifier
enum class Abort: AdaNode {
}

|" Qualifier for the ``abstract`` keyword.
@qualifier
enum class Abstract: AdaNode {
}

|" List of AbstractStateDecls.
class AbstractStateDeclList: ASTList[AdaNode] {
}

|" List of alternatives in a ``when ...`` clause.
class AlternativesList: ASTList[AdaNode] {
    |" If this AlternativesList belongs to a case statement, return the type
    |" of the enum this case statement operates on. Null otherwise.
    fun enum_type(): Entity[BaseTypeDecl] =
        self.parent.parent.parent.as[CaseStmt].do((cs) => cs.expr.expression_type())

    |" Return possible completions at this point in the file.
    @with_dynvars(origin)
    fun complete_items(): Array[CompletionItem] = node.children_env().get(null[Symbol]).map(
        (n) => CompletionItem(
            decl=n.as[BasicDecl],
            is_dot_call=n.info.md.dottable_subp,
            is_visible=node.has_visibility(n),
            weight=match n {
                case eld: EnumLiteralDecl => if self.enum_type() == eld.enum_type() then 100 else 0
                case _ => 0
            }
        )
    )
}

|" List of constraints.
class ConstraintList: ASTList[AdaNode] {
}

|" List of declarations.
class DeclList: ASTList[AdaNode] {
}

|" List of statements.
class StmtList: ASTList[AdaNode] {
}

|" List of associations.
class AssocList: ASTList[BasicAssoc] {
    |" Return the actual expression for ``param`` if any, ``default_expr``
    |" otherwise.
    fun actual_for_param_at(param: Entity[DefiningName], pos: Int, default_expr: Entity[Expr] = null[Entity[Expr]]): Entity[Expr] = {
        val up = self.unpacked_params();

        up.find(
            # Search expression for parameter `param` if a named one exists
            (p) => p.name?.matches(param.name.node)
        ).do(
            (a) => a.assoc.expr(),
            # Otherwise, get the parameter using its position if any
            default_val=if up?[pos].is_null or not up?[pos].assoc.names().is_null then (
                # None was found, either by name or by position, return
                # default expression.
                default_expr
            ) else (
                # Use expression for param by position
                up?[pos].assoc.expr()
            )
        )
    }

    |" Given the list of ParamAssoc, that can in certain case designate
    |" several actual parameters at once, create an unpacked list of
    |" SingleActual instances.
    @memoized
    fun unpacked_params(): Array[SingleActual] = self.mapcat(
        (pa) => {
            val names = pa.names();

            if names.length() == 0 then [SingleActual(name=null[Identifier], assoc=pa)] else names.filtermap(
                (i) => SingleActual(name=i.as[BaseId], assoc=pa), (i) => i is BaseId
            )
        }
    )

    |" Returns an array of pairs, associating formal parameters to actual
    |" expressions. The formals to match are retrieved by resolving the call
    |" which this AssocList represents the actuals of.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun zip_with_params(): Array[ParamActual] = {
        # Bind imprecise_fallback to False for now because
        # first_corresponding_decl is not implemented on CallExpr.
        val is_dottable_subp = {
            bind imprecise_fallback = false;

            self.parent.as[Name].do((e) => e.is_dot_call())
        };
        val params = self.parent.do(
            (v1) => match v1 {
                case e: CallExpr => e.called_subp_spec()?.abstract_formal_params()
                case i: GenericInstantiation => i.designated_generic_decl()?.formal_part.abstract_formal_params()
                case c: CompositeConstraint => c.subtype()?.discriminants_list()
                case a: BaseAggregate => {
                    bind origin = node;
                    bind env = node.node_env();

                    a.expression_type().record_def()?.components.abstract_formal_params_for_assocs(
                        self, # Do not get ancestor_expr's components if `a` is an
                        # extended aggregate.
                        stop_recurse_at=a.ancestor_expr_type()
                    )
                }
                case _ => null[Array[Entity[BaseFormalParamDecl]]]
            }
        );
        val others_assoc = self.find(
            (assoc) => assoc.names().any((n) => n is OthersDesignator)
        );
        val explicit_matches = params.do(
            (_) => node.match_formals(params, self, is_dottable_subp).map(
                (m) => ParamActual(
                    param=m.formal, actual=m.actual.assoc.expr()
                )
            )
        );
        val default_subp_matches = params.do(
            (_) => params.filtermap(
                (p) => {
                    # Append implicit actuals of formal subprograms that have a
                    # default value (box expression of explicit reference).
                    val decl = p.as[GenericFormalSubpDecl];
                    val subp = p.as[GenericFormalSubpDecl].decl.as[FormalSubpDecl];

                    ParamActual(
                        param=decl.defining_name(), actual=if subp.default_expr is Name then subp.default_expr else subp.designated_subprogram_from(
                            inst=self.parent.as[GenericInstantiation]
                        )?.defining_name()
                    )
                }, (p) => p.as[GenericFormalSubpDecl].do(
                    (fd) => fd.decl.as[FormalSubpDecl].do(
                        (subp) => (
                            # Generate a new match for formal subprogram which
                            # have a default value.
                            subp.default_expr is BoxExpr | Name
                        ) and (
                            # unless they have already have an explicit match
                            not explicit_matches.any((m) => m.param == subp.defining_name())
                        )
                    )
                )
            )
        );
        val given_matches = explicit_matches & default_subp_matches;
        val others_matches = others_assoc.do(
            (oa) => node.unpack_formals(params).filtermap(
                (p) => ParamActual(param=p, actual=oa.expr()), (p) => not given_matches.any((m) => m.param == p)
            )
        );

        given_matches & others_matches
    }
}

|" List of alternatives in a membership test expression.
class ExprAlternativesList: ASTList[Expr] {
}

|" List of discriminant associations.
class DiscriminantChoiceList: ASTList[Identifier] {
}

|" List of parents in a type declaration.
class ParentList: ASTList[Name] {
}

|" Qualifier for the ``aliased`` keyword.
@qualifier
enum class Aliased: AdaNode {
}

|" Qualifier for the ``all`` keyword.
@qualifier
enum class All: AdaNode {
}

|" Specification for array indexes (:rmlink:`3.6`).
@abstract
class ArrayIndices: AdaNode {
    |" Number of dimensions described in this node.
    @abstract
    fun ndims(): Int

    |" Add a constraint on an expression passed as the index of an array
    |" access expression.
    |"
    |" For example::
    |"
    |"     type A is array (Integer range 1 .. 10) of Integer;
    |"
    |"     A_Inst : A;
    |"
    |"     A_Inst (2);
    |"     --      ^ Will add constraint on lit that it needs to be of type
    |"     --      Integer.
    @abstract
    @with_dynvars(origin)
    fun constrain_index_expr(index_expr: Entity[Expr], dim: Int): Equation

    @abstract
    @with_dynvars(origin)
    fun index_type(dim: Int): Entity[BaseTypeDecl]

    |" Return True iff all index types are static.
    @abstract
    @with_dynvars(imprecise_fallback=false)
    fun is_static(): Bool
}

|" Constrained specification for array indexes (:rmlink:`3.6`).
class ConstrainedArrayIndices: ArrayIndices {
    @parse_field list: ConstraintList

    fun ndims(): Int = node.list.length()

    @with_dynvars(origin)
    fun constrain_index_expr(index_expr: Entity[Expr], dim: Int): Equation =
        %eq(index_expr.expected_type_var(), self.index_type(dim)) and index_expr.matches_expected_type()

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = self.list.logic_all(
        (index) => index.sub_equation() and index.as[Expr].do(
            (expr) => (
                %predicate(AdaNode.is_not_null, expr.type_var()) and %predicate(BaseTypeDecl.is_discrete_type, expr.type_var())
            ) and %predicate(BaseTypeDecl.is_not_root_int_type, expr.type_var()), default_val=%true
        )
    )

    @with_dynvars(origin)
    fun index_type(dim: Int): Entity[BaseTypeDecl] = {
        # We might need to solve self's equation to get the index type
        val _ = node.parents().find((p) => p.xref_entry_point()).as_entity.resolve_names();

        self.list?[dim].do(
            (v1) => match v1 {
                case st: SubtypeIndication => st.designated_type()
                case e: Expr => e.type_val().as[BaseTypeDecl]
                case _ => null[Entity[BaseTypeDecl]]
            }
        )
    }

    @with_dynvars(imprecise_fallback=false)
    fun is_static(): Bool = self.list.all(
        (t) => match t {
            case st: SubtypeIndication => st.is_static_subtype()
            case e: BinOp => e.left.is_static_expr() and e.right.is_static_expr()
            case _ => false
        }
    )
}

|" Unconstrained specification for array indexes (:rmlink:`3.6`).
class UnconstrainedArrayIndices: ArrayIndices {
    @parse_field types: ASTList[UnconstrainedArrayIndex]

    fun ndims(): Int = node.types.length()

    @with_dynvars(origin)
    fun constrain_index_expr(index_expr: Entity[Expr], dim: Int): Equation =
        %eq(index_expr.expected_type_var(), self.index_type(dim)) and index_expr.matches_expected_type()

    @with_dynvars(origin)
    fun index_type(dim: Int): Entity[BaseTypeDecl] =
        self.types?[dim]?.designated_type()

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = self.types.logic_all(
        (typ) => typ.subtype_name.xref_type_equation() and (
            if typ.lower_bound.is_null then %true else typ.lower_bound.sub_equation()
        )
    )

    @with_dynvars(imprecise_fallback=false)
    fun is_static(): Bool = self.types.all(
        (t) => t.subtype_name.is_static_subtype()
    )
}

|" Name/expression association in an aspect.
class AspectAssoc: AdaNode {
    @parse_field id: Name
    @parse_field @nullable expr: Expr

    fun xref_entry_point(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        val target = node.parent.parent.parent;

        # Iterable aspect
        if self.id.name_symbol() in s"Aggregate" | s"Iterable" then
            self.expr.as[Aggregate].assocs.unpacked_params().logic_all(
                (sa) => sa.assoc.expr().as![Name].xref_no_overloading(
                    sequential=false
                )
            )
        # Contracts
        elif self.id.name_symbol() in
             s"Pre" | s"Post" | s"Refined_Post" | s"Type_Invariant" |
             s"Invariant" | s"Predicate" | s"Static_Predicate" |
             s"Dynamic_Predicate" | s"Initial_Condition" then {
            # Ada 2022 allows Pre and Post aspects for
            # access-to-subprogram types. In such case, visibility
            # rules change. The TypeDecl environment should be
            # considered for name resolution.
            bind env =
                if self.id.name_symbol() in s"Pre" | s"Post" and
                   target.as[TypeDecl]?.type_def is AccessToSubpDef
                then
                    target.as[TypeDecl].type_def.children_env()
                else
                    self.node_env();


            %eq(node.expr.expected_type_var(), node.bool_type())
            and self.expr.sub_equation()
            and node.expr.matches_expected_formal_type()
        }
        elif self.id.name_symbol() in
             s"Contract_Cases" | s"Subprogram_Variant"
        then
            self.expr.sub_equation()
        # Put_Image aspect
        elif self.id.name_is(s"Put_Image") then
            self.expr.as![Name].xref_no_overloading(
                sequential=false, all_els=true
            ) and %predicate(
                BasicDecl.is_put_image_subprogram_for_type,
                self.expr.as[Name].ref_var(),
                target.as![BaseTypeDecl].as_entity
            )
        # Global aspect. Depends is always an aggregate, so doesn't need an
        # entry.
        elif self.id.name_is(s"Global")
             or self.id.name_is(s"Refined_Global")
        then
            if self.expr is NullLiteral then %true
            else self.expr.sub_equation()
        # Do not resolve anything inside those aspect, as identifiers act
        # as reserved words. For example, we do not want to resolve `C`
        # in `Convention => C` to the first visible entity named C.
        elif self.id.name_is(s"Convention") then %true
        elif self.id.name_is(s"Stable_Properties") then
            self.stable_properties_assoc_equation()
        elif self.id.name_symbol() in s"Integer_Literal"
                                    | s"Real_Literal"
                                    | s"String_Literal" then
            self.user_defined_literals_equation(target.as[TypeDecl])
        # Constant_Indexing and Variable_Indexing aspects name expression
        # can denotes one or more functions. Since name resolution can set
        # only one reference for a name, only keep the first function
        # returned by constant_indexing_fns and variable_indexing_fns.
        elif self.id.name_is(s"Constant_Indexing") then
            %eq(self.expr.as![Identifier].ref_var(),
                target.as[TypeDecl].as_entity.constant_indexing_fns()?[0])
        elif self.id.name_is(s"Variable_Indexing") then
            %eq(self.expr.as![Identifier].ref_var(),
                target.as[TypeDecl].as_entity.variable_indexing_fns()?[0])
        # For the Annotate aspect, the first two identifiers are not
        # analyzed. The rest are arbitrary expressions (see
        # `Expr.annotate_argument_equation`).
        elif self.id.name_is(s"Annotate") then
            self.expr.as[BaseAggregate].assocs.unpacked_params().ilogic_all(
                (sa, i) => if i < 2 then %true
                           else sa.assoc.expr().annotate_argument_equation()
            )
        elif self.id.name_is(s"Implicit_Dereference") then
            self.implicit_dereference_equation(target.as[TypeDecl])
        # For the Model_Of aspect, the RHS must either denote a type
        # declaration or a subprogram with a matching profile, depending
        # on the kind of entity this aspect is attached to.
        elif self.id.name_is(s"Model_Of") then
            if target is BaseTypeDecl then
                self.expr.as![Name].xref_type_equation()
            else
                self.expr.as![Name].xref_no_overloading(all_els=true)
                and %predicate(
                    BasicDecl.subp_decl_match_signature,
                    self.expr.as![Name].ref_var(),
                    target.as[BasicDecl].as_entity
                )
        # Default resolution: For the moment we didn't encode specific
        # resolution rules for every aspect, so by default at least try to
        # name resolve the expression.
        else self.expr.do(
            (e) => e.sub_equation(), default_val=%true
        ) or %true
    }

    |" Equation for the case where this is an aspect assoc for an
    |" Implicit_Dereference aspect.
    @with_dynvars(env, origin, entry_point)
    fun implicit_dereference_equation(target: TypeDecl): Equation = {
        val id = self.expr.as![Identifier];
        val discr = target.as_entity.discriminants_list().find(
            (l) => l.defining_names().any((n) => n.name_is(id.symbol))
        );

        %eq(id.ref_var(), discr)
    }

    |" Equation for the case where this is an aspect assoc for a
    |" Stable_Properties aspect.
    @with_dynvars(env, origin, entry_point)
    fun stable_properties_assoc_equation(): Equation = {
        # Get the list of names defined by the aspect
        val identifiers = match self.expr {
            # AspectAssoc is of the form: (name1, name2, ...)
            case a: Aggregate => a.assocs.map((i) => i.expr())

            # AspectAssoc is of the form: (name)
            case pe: ParenExpr => [pe.expr]
            case _ => [null[Entity[Expr]]]
        }.map(
            (e) => e.as[UnOp].do(
                # Ignore the `not` keyword (useless for nameres)
                (uo) => if uo.op is Op.Not then uo.expr else e, default_val=e
            )
        ).map((e) => e.as![Identifier]);
        # Names defined by the assoc can only be `Identifier`s

        identifiers.logic_all(
            (i) => node.env_get(
                env, i.sym(), lookup=LookupKind.recursive, from_node=node.origin_node(), categories=RefCategories(_=true)
            ).filter(
                (f) => (
                    # It can only refer to a SubpDecl or an ExprFunction
                    f is SubpDecl | ExprFunction
                ) and i.denotes_the_property_function(f.as[BasicDecl].subp_spec_or_null())
            ).logic_any((f) => %eq(i.ref_var(), f))
        )
    }

    |" Equation for the case where this is an aspect assoc for a
    |" user-defined literal.
    @with_dynvars(env, origin, entry_point)
    fun user_defined_literals_equation(target: TypeDecl): Equation = %eq(
        self.expr.as![Identifier].ref_var(),
        target.as_entity.user_defined_literal_fns(
            self.id.name_symbol()
        )?[
            # First result in the list is the last override if any
            0
        ]
    )

    |" Return the string representation of the given name, which must be a
    |" Name that can appear in an aspect association id.
    fun aspect_name(n: Entity[Name]): String =
        # TODO: would be cleaner to implement a general "image" function in
        # class Name directly.
        match n {
            case bid: BaseId => bid.sym().image()
            case ar: AttributeRef => node.aspect_name(ar.prefix) & "'" & ar.attribute.sym().image()
            case _ => raise[String] PreconditionFailure("aspect_name called on an invalid aspect name")
        }

    |" Return whether this aspect is ghost code or not. See SPARK RM 6.9.
    @exported
    fun is_ghost_code(): Bool =
        self.id.name_symbol() in s"Pre" | s"Post" | s"Contract_Cases"
}

|" Base class for aspect clauses.
@abstract
class AspectClause: AdaNode {
    fun xref_entry_point(): Bool = true
}

|" Representation clause (``for .. use at ...;``) (:rmlink:`13.5.1`).
class AtClause: AspectClause {
    @parse_field name: BaseId
    @parse_field expr: Expr

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.name.sub_equation() and self.expr.sub_equation()
}

|" Clause for an attribute definition (``for ...'Attribute use ...;``)
|" (:rmlink:`13.3`).
class AttributeDefClause: AspectClause {
    @parse_field attribute_expr: Name
    @parse_field expr: Expr

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        val attr = self.attribute_expr.as![AttributeRef];
        val rel_name = attr.attribute.name_symbol();

        if rel_name in s"Read" | s"Write" | s"Input" | s"Output" then (
            self.expr.as![Name].xref_no_overloading(all_els=true) and %predicate(BasicDecl.is_stream_subprogram_for_type, self.expr.as[Name].ref_var(), attr.prefix.name_designated_type(), rel_name == s"Input")
        ) and attr.prefix.sub_equation()
        elif rel_name in s"Put_Image" then (
            self.expr.as![Name].xref_no_overloading(all_els=true) and %predicate(BasicDecl.is_put_image_subprogram_for_type, self.expr.as[Name].ref_var(), attr.prefix.name_designated_type())
        ) and attr.prefix.sub_equation()
        else (
            self.expr.sub_equation() and attr.sub_equation()
        ) and (
            if rel_name == s"External_Tag" then %eq(node.expr.expected_type_var(), node.std_entity(s"String"))
            elif rel_name == s"Address" then %eq(node.expr.expected_type_var(), self.system_address_type())
            else %true
        )
    }
}

|" Representation clause for enumeration types (:rmlink:`13.4`).
class EnumRepClause: AspectClause {
    @parse_field type_name: Name
    @parse_field aggregate: BaseAggregate

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = # TODO: resolve names in ``aggregate``
    self.type_name.xref_type_equation()

    |" Returns an array of pairs, associating enum literals to representation
    |" clause actuals.
    @exported
    fun params(): Array[ParamActual] = {
        # Get the enum literals
        val el = self.type_name.referenced_decl().as[BaseTypeDecl].root_type().as[TypeDecl].type_def.as[EnumTypeDef].enum_literals;
        # Get the representation clause actuals
        val ra = self.aggregate.assocs;

        el.imap(
            (l, i) => ParamActual(
                param=l.name, actual=ra.actual_for_param_at(l.name, i)
            )
        )
    }
}

|" Representation clause for a record type (:rmlink:`13.5.1`).
class RecordRepClause: AspectClause {
    @parse_field name: Name
    @parse_field @nullable at_expr: Expr
    @parse_field components: ASTList[AdaNode]

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.name.xref_type_equation() and self.at_expr.do(
            (e) => e.sub_equation(), default_val=%true
        )
}

|" List of aspects in a declaration (:rmlink:`13.1.1`).
class AspectSpec: AdaNode {
    @parse_field aspect_assocs: ASTList[AspectAssoc]
}

|" Abstract class for a key/value association, where the value is an
|" expression.
@abstract
class BaseAssoc: AdaNode {
    |" Returns the expression side of this assoc node.
    @exported
    @abstract
    fun assoc_expr(): Entity[Expr]
}

|" Single association for the ``Contract_Case`` aspect.
class ContractCaseAssoc: BaseAssoc {
    @parse_field guard: AdaNode
    @parse_field consequence: Expr

    fun assoc_expr(): Entity[Expr] = self.consequence
}

|" Argument association in a pragma.
class PragmaArgumentAssoc: BaseAssoc {
    @parse_field @nullable name: Name
    @parse_field expr: Expr

    fun assoc_expr(): Entity[Expr] = self.expr
}

|" Base class for lists of formal parameters. This is used in every case a
|" list of "formals" can be called or instantiated, so in all the following
|" cases:
|"
|" * Subprogram specifications (and subprogram calls).
|" * Component lists (and aggregates).
|" * Generic formals (and generic instantiations).
|"
|" This allows to share the parameter unpacking/matching logic.
|"
|" This is a Libadalang abstraction that has no existence in the Ada reference
|" manual.
@abstract
class BaseFormalParamHolder: AdaNode {
    |" Return the list of abstract formal parameters for this holder.
    @exported
    @abstract
    fun abstract_formal_params(): Array[Entity[BaseFormalParamDecl]]

    |" Return ``DefiningName`` for all parameters.
    fun unpacked_formal_params(): Array[Entity[DefiningName]] =
        node.unpack_formals(self.abstract_formal_params())

    |" Return all parameters as a ``DefiningName`` array. This property
    |" doesn't return record discriminants nor variants when called on a
    |" record component list.
    @exported
    fun formal_params(): Array[Entity[DefiningName]] = match self {
        case r: ComponentList => node.unpack_formals(r.components.keep[BaseFormalParamDecl])
        case _ => self.unpacked_formal_params()
    }

    fun match_param_list(params: Entity[AssocList], is_dottable_subp: Bool): Array[ParamMatch] = node.match_formals(
        self.abstract_formal_params(), params, is_dottable_subp
    )

    |" Return the minimum number of parameters this subprogram can be called
    |" while still being a legal call.
    @exported
    fun nb_min_params(): Int =
        node.as_bare_entity.unpacked_formal_params().filter((p) => p.formal_decl().is_mandatory()).length()

    |" Return the maximum number of parameters this subprogram can be called
    |" while still being a legal call.
    @exported
    fun nb_max_params(): Int =
        node.as_bare_entity.unpacked_formal_params().length()

    |" Utility function. Given a subprogram spec and whether the subprogram
    |" was referenced using the dot notation, determine if it can be called
    |" without parameters (and hence without a callexpr).
    fun paramless(dottable_subp: Bool, can_be: Bool = true): Bool = {
        val nb_params = if can_be then node.nb_min_params() else node.nb_max_params();

        (dottable_subp and nb_params == 1) or nb_params == 0
    }

    |" Return whether a AssocList is a match for this SubpSpec, i.e.
    |" whether the argument count (and designators, if any) match.
    @with_dynvars(env)
    fun is_matching_param_list(params: Entity[AssocList], is_dottable_subp: Bool): Bool = {
        val bare = node.as_bare_entity;
        val match_list = bare.match_param_list(params, is_dottable_subp);
        # Compute the min and max number of parameters this subprogram takes
        # and adjust that number in case the subprogram is dottable:
        # - Remove 1 to the maximum value if the subprogram is dottable.
        # - Remove 1 to the minimum value iff the subprogram is dottable and
        # its first parameter (the one used for the prefixed notation) is
        # mandatory, because the call to ``bare.nb_min_params`` already takes
        # care of optional parameters, so we won't count it twice.
        val nb_max_params = if is_dottable_subp then bare.nb_max_params() - 1 else bare.nb_max_params();
        val nb_min_params = if is_dottable_subp and (
            # If is dottable and the first parameter is mandatory,
            # remove 1 to the minumum number of parameter. In the
            # other case, ``bare.nb_min_params`` has already counted
            # it.
            node.as_bare_entity.unpacked_formal_params()?[0].formal_decl().is_mandatory()
        ) then bare.nb_min_params() - 1 else bare.nb_min_params();

        params.length() <= nb_max_params and match_list.all((m) => m.has_matched) and match_list.filter(
            (m) => m.formal.formal_decl().is_mandatory()
        ).length() == nb_min_params
    }

    |" Returns the type of each parameter of self.
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun param_types(): Array[Entity[BaseTypeDecl]] = self.unpacked_formal_params().map(
        (fp) => self.real_designated_type(fp.formal_decl().type_expression())
    )

    |" Returns the mode of each parameter of self.
    fun param_modes(): Array[Entity[Mode]] = self.unpacked_formal_params().map(
        (fp) => fp.formal_decl().as[ParamSpec].mode
    )

    |" Scrap all surface-level rebindings pairs that correspond to generic
    |" subprogram instantiations from the given chain of rebindings.
    fun shed_subp_rebindings(r: EnvRebindings): EnvRebindings = if r?.new_env.do(
        (v1) => v1.env_node is GenericSubpInstantiation
    ) then node.shed_subp_rebindings(r.get_parent) else r

    |" Given the name of a parameter defined in a specification of a generic
    |" formal parameter, return its corresponding name in the actual that was
    |" used in the instantiation.
    fun corresponding_actual_param(name: Entity[DefiningName]): Entity[DefiningName] = {
        val actual_spec = self.corresponding_actual();

        if self == actual_spec then name else self.unpacked_formal_params().imapcat(
            (param, i) => if param.node == name.node then [actual_spec.unpacked_formal_params()?[i]] else null[Array[Entity[DefiningName]]]
        )?[0]
    }

    |" Return the real type denoted by ``typ``, taking into account that
    |" ``typ`` might be the type of a derived primitive. In that case, return
    |" the derived primitive type.
    @with_dynvars(origin=null[AdaNode])
    fun real_type(typ: Entity[BaseTypeDecl]): Entity[BaseTypeDecl] = {
        # Compute the type entity of which self is a primitive
        val prim_type = self.entity_no_md(
            self.info.md.primitive, self.info.rebindings, self.info.from_rebound
        ).as[BaseTypeDecl];

        if prim_type.node.is_null then typ
        elif prim_type?.canonical_type().node == typ?.canonical_type().node then match self.entity_no_md(
            self.info.md.primitive_real_type or? typ.node, # This primitive might come from a subprogram instantiation,
            # in which case we don't want to plug its rebindings to the
            # type itself. So simply remove all rebindings at the surface
            # that correspond to subprogram instantiations. We cannot
            # mistakenly remove relevant rebindings, since a derived type
            # cannot come from a subprogram instantiation.
            node.shed_subp_rebindings(self.info.rebindings), self.info.from_rebound
        ) {
            # Since `primitive_real_type` is a node and not an entity, it
            # may refer to a formal type, so we need to manually resolve it
            # to an actual type using the current rebindings in case they
            # are relevant.
            case ft: Entity[FormalTypeDecl] => ft.get_actual()
            case other => other.as[BaseTypeDecl]
        }
        # Handle the case where the primitive is defined on an anonymous
        # access type, by returning an anonymous access type over the
        # real_type of the accessed type.
        elif typ.as[AnonymousTypeDecl].do(
            (td) => not td.type_def is AccessToSubpDef
        ) then typ.accessed_type().do(
            (at) => self.real_type(at).do(
                (rat) => if at == rat then typ else rat.anonymous_access_type()
            )
        )
        else typ
    }

    |" Given a type expression that is part of this subprogram specification
    |" (for example, appearing in a parameter specification), return the real
    |" type it designates, taking into account the fact that self might be
    |" the specification of an inherited subprogram. Overall, we can
    |" distinguish the following cases:
    |"
    |" - self is a primitive subprogram inherited from a base type and
    |"   ``typ`` designates that base type, in which case we should return
    |"   the inheriting type.
    |"
    |" - self is a primitive subprogram inherited from a base type but
    |"   ``typ`` does not designate that base type, in which case we must
    |"   compute the actual designated type by taking into account the
    |"   rebindings associated with the base type. This is done by
    |"   traversing the inheritance hierarchy starting from the inheriting
    |"   type up to the inherited type and extracting the rebindings that we
    |"   got along the way.
    |"
    |" - self is not an inherited primitive subprogram, in which case we
    |"   simply return the designated type using the normal path.
    |"
    |" The first two points are illustrated with the following example.
    |"
    |" .. code::
    |"
    |"     generic
    |"        type G is private;
    |"     package Pkg is
    |"        type T is null record;
    |"
    |"        function Foo (Self : T) return G;      --  A
    |"     end Pkg;
    |"
    |"     package My_Pkg is new Pkg (Integer);      --  B
    |"
    |"     type My_T is new My_Pkg.T;
    |"
    |"     X : My_T    := (null record);
    |"     Y : Integer := Foo (X);                    -- C
    |"
    |" Resolving the reference to ``Foo`` at line C gets us the function
    |" declaration at line A with the appropriate metadata indicating it is a
    |" primitive subprogram of T inherited by My_T.
    |"
    |" Calling this property on the ``T`` node from the ``Self : T`` parameter
    |" specification is an instance of the first case. We should obviously
    |" return ``My_T`` in that case.
    |"
    |" Calling it on ``G`` from the return type specification is an instance
    |" of the second case. We traverse up the inheritance hierarchy starting
    |" from ``My_T`` and get to ``T [B]``, where ``[B]`` indicates the
    |" rebindings corresponding to the instantiation at line B. We can now use
    |" those rebindings to compute the actual designated type (the type
    |" designated by ``G [B]``) which correctly yields ``Integer``.
    |"
    |" This property is used during the construction of xref equations for
    |" call expressions in order to match the right parameter and return
    |" types.
    @with_dynvars(origin)
    fun real_designated_type(typ: Entity[TypeExpr]): Entity[BaseTypeDecl] = {
        val md = self.info.md;

        typ.designated_type()?.without_md().as[BaseTypeDecl].do(
            (t) =>
            # Subprograms retrieved through ``dottable_subps_env``
            # already have their base type rebindings set, so we don't
            # need to adjust it.
            # TODO: we should however compute the real_type just like we
            # do for regular primitives, but this can't be done yet because
            # their ``primitive_real_type`` metadata is not precise enough
            # as it is set on all dottable subprograms, even those which
            # are not actual primitives.
            if md.dottable_subp then t else {
                val rt = self.real_type(t);
                val base_rebindings = md.primitive_real_type.as[BaseTypeDecl].as_bare_entity?.find_base_type_rebindings(md.primitive.as[BaseTypeDecl]);

                if t == rt then if base_rebindings.is_null then t else Entity[TypeExpr](
                    node=typ.node, info=EntityInfo(
                        md=null[Metadata], rebindings=node.insert_rebindings(typ.info.rebindings, base_rebindings), from_rebound=typ.info.from_rebound
                    )
                ).designated_type() else rt
            }
        )
    }

    |" Generate the equation that binds the type_var of this expression
    |" given its corresponding parameter in the context of a subprogram call.
    |" This takes into account the fact that the called subprogram might
    |" be an inherited primitive.
    @with_dynvars(origin, logic_context)
    fun call_argument_equation(param: Entity[BaseFormalParamDecl], arg: Entity[Expr]): Equation = {
        val param_type = self.real_designated_type(param.type_expression());

        %eq(arg.expected_type_var(), param_type, logic_ctx=logic_context) and arg.matches_expected_formal_type()
    }

    |" Check whether self's params match other's.
    @with_dynvars(origin)
    fun match_formal_params(other: Entity[BaseFormalParamHolder], match_names: Bool = true, ignore_first_param: Bool = false): Bool = {
        # Check that there is the same number of formals and that each
        # formal matches.
        val self_params = self.unpacked_formal_params().do(
            (params) => if ignore_first_param then params.ifilter((e, i) => i != 0) else params
        );
        val other_params = other.unpacked_formal_params();
        val self_types = self.param_types().do(
            (types) => if ignore_first_param then types.ifilter((e, i) => i != 0) else types
        );
        val other_types = other.param_types();

        self_params.length() == other_params.length() and self_types.length() == other_types.length() and self_params.iall(
            (p, i) => (
                not match_names or p.name.matches(other_params?[i].name.node)
            ) and self_types?[i]?.matching_type(other_types?[i])
        )
    }

    |" For a ``BaseFormalParamHolder`` (e.g. a ``SubpSpec``), we simply go
    |" to its parent (e.g. a ``FormalSubpDecl``), retrieve its corresponding
    |" actual (e.g. a ``BasicSubpDecl``), and then grab the formal param
    |" holder of that node (e.g. a ``SubpSpec``).
    fun corresponding_actual(): Entity[BaseFormalParamHolder] = self.parent.as[BasicDecl].do(
        (bd) => bd.corresponding_actual()?.formal_param_holder_or_null(), default_val=self
    )

    |" Base method of any BaseFormalParamHolder that checks whether the
    |" other given BaseFormalParamHolder matches. In practice, this will call
    |" match_formal_params, except for BaseSubpSpecs for which it will call
    |" match_signature.
    @with_dynvars(origin)
    fun match_other(other: Entity[BaseFormalParamHolder], match_names: Bool = true): Bool =
        self.match_formal_params(other, match_names)
}

|" Base class for subprogram specifications (:rmlink:`6.1`).
@abstract
class BaseSubpSpec: BaseFormalParamHolder {
    |" Syntax property. Return the name of the subprogram defined by this
    |" specification.
    @exported
    @abstract
    fun name(): Entity[DefiningName]

    |" Syntax property. Return the type expression node corresponding to the
    |" return of this subprogram spec.
    @exported
    @abstract
    fun returns(): Entity[TypeExpr]

    fun abstract_formal_params(): Array[Entity[BaseFormalParamDecl]] =
        self.params().map((p) => p.as[BaseFormalParamDecl])

    @with_dynvars(origin)
    fun match_return_type(other: Entity[BaseSubpSpec]): Bool = {
        # Check that the return type is the same. Caveat: it's not because
        # we could not find the canonical type that it is null!
        #
        # TODO: simplify this code when SubpSpec provides a kind to
        # distinguish functions and procedures.
        val self_ret = self.return_type();
        val other_ret = other.return_type();

        (
            self.returns().is_null and other.returns().is_null
        ) or (
            not self.returns().is_null and not other.returns().is_null and {
                bind origin = node.origin_node();

                self_ret?.matching_type(other_ret)
            }
        )
    }

    |" Return whether SubpSpec's signature matches self's.
    |"
    |" Note that the comparison for types isn't just a name comparison: it
    |" compares the canonical types.
    |"
    |" If match_name is False, then the name of subprogram will not be
    |" checked.
    |"
    |" If use_entity_info is True and self's metadata has values for fields
    |" ``primitive`` and ``primitive_real_type`` (e.g. if it was retrieved
    |" from a primitive_env), those will be taken into account and
    |" match_signature will return True if ``other`` overrides ``self``.
    |"
    |" If ignore_first_param is True, do the signature match by ignoring the
    |" self's first parameter. This can be used for example when matching a
    |" TaskType's procedure with one of its parent interface primitives,
    |" because the subprogram from the task has an implicit self parameter
    |" which does not appear in the subprogram specification.
    @with_dynvars(origin)
    fun match_signature(other: Entity[BaseSubpSpec], match_name: Bool, use_entity_info: Bool = true, ignore_first_param: Bool = false): Bool = {
        val ent = if use_entity_info then self else node.as_bare_entity;

        (
            # Check that the names are the same
            not match_name or ent.name().node.matches(other.name().node)
        ) and ent.match_return_type(other) and ent.match_formal_params(other, match_name, ignore_first_param)
    }

    @with_dynvars(origin)
    fun match_other(other: Entity[BaseFormalParamHolder], match_names: Bool = true): Bool =
        self.match_signature(other.as![BaseSubpSpec], match_names)

    |" Return whether UserDefinedFunctionSubpSpec's signature matches self's.
    fun match_expected_user_defined_function(fn: UserDefinedFunctionSubpSpec): Bool =
        self.return_type().matching_type(fn.subp_return_type) and self.unpacked_formal_params().do(
            (params) => params.length() == fn.subp_params_types.length() and params.ifilter(
                (p, i) => not p.formal_decl().formal_type().matching_type(fn.subp_params_types?[i])
            ).is_null
        )

    |" Helper for BasicDecl.defining_env.
    @with_dynvars(origin)
    fun defining_env(): LexicalEnv =
        if self.returns().is_null then null[LexicalEnv] else self.return_type().defining_env()

    |" If self meets the criteria for being a subprogram callable via the dot
    |" notation, return the type of dottable elements.
    @with_dynvars(origin)
    fun potential_dottable_type(): Entity[BaseTypeDecl] = self.abstract_formal_params()?[0].do(
        (p) => p.type_expression()?.element_type()
    )

    |" If the given type expression designates a type of which self is a
    |" primitive, return that designated type. Otherwise return null.
    |"
    |" If ``canonicalize`` is true, then the returned type will be
    |" canonicalized first. Else, the most complete part of the type will be
    |" returned.
    fun get_candidate_type_for_primitive(type_expr: Entity[TypeExpr], canonicalize: Bool = true): Entity[BaseTypeDecl] = {
        val decl_scope = (
            if node.parent is GenericSubpInternal then (
                # Get the scope of the generic instantiation (if any) when
                # self comes from a generic subprogram.
                self.generic_instantiations()?[0]?.parent?.parent
            ) else node.parent.parent.parent.as_entity
        ).as[DeclarativePart].node;
        val typ = {
            bind origin = node.origin_node();

            match type_expr {
                case at: AnonymousType => at.element_type().do(
                    (et) => (not et.is_classwide()).do((_) => et)
                )

                # TODO: remove this check once S918-021 is done, since it will
                # be checked below in any case.
                case other => other.designated_type()
            }
        };
        # Canonicalize if requested
        val canon_type = if canonicalize then {
            bind origin = node.origin_node();

            typ?.canonical_type()
        } else typ;
        val final_type = canon_type.as[IncompleteTypeDecl].do(
            (i) => i.next_part(), default_val=canon_type
        );
        val type_scope = final_type.do(
            (typ) => typ.node.parent.parent.as[DeclarativePart]
        );

        if (
            (
                # Either both the subprogram and the type are declared in
                # in a package declaration...
                type_scope.do((v1) => v1.parent is BasePackageDecl) and decl_scope.do((v2) => v2.parent is BasePackageDecl)
            ) or (
                # Or, in case of a derived tagged type, a subprogram
                # defined in the same scope may be a primitive even in a
                # non-package scope if that subprogram overrides a previous
                # primitive.
                # Therefore the correct behavior here would be to compute
                # the primitives of `final_type` and check if one of its
                # primitives matches the signature of this subprogram.
                # Unfortunately we cannot do that here, because it would
                # trigger infinite recursions if the parent is defined
                # in the same scope. Therefore, the final filtering is done
                # in `direct_primitive_subps` and the result of this
                # property is not 100% accurate.
                final_type.as[TypeDecl]?.is_derived_tagged_type()
            )
        ) and (
            # A subprogram may not be a primitive of a classwide type
            not final_type?.is_classwide()
        ) and (
            # A subprogram may not be a primitive of a type which is not
            # declared in the same declarative scope as self, or in the
            # private part of the package in which self is defined.
            type_scope.do(
                (ds) => ds in decl_scope | decl_scope?.parent.as[BasePackageDecl]?.public_part
            )
        ) then final_type else null[Entity[BaseTypeDecl]]
    }

    |" Return the types of which this subprogram is a candidate primitive of.
    |" If ``canonicalize`` is true, then the returned types will be
    |" canonicalized.
    @memoized
    fun candidate_primitive_subp_types(canonicalize: Bool = true): Array[Entity[BaseTypeDecl]] = {
        # TODO: This might be improved by checking for spelling before looking
        # up every type.
        val params = self.unpacked_formal_params();
        val types = params.map((p) => p.formal_decl().type_expression()) & self.returns().do((v1) => [v1]);

        types.map(
            (t) => self.get_candidate_type_for_primitive(t, canonicalize=canonicalize)
        ).filter((t) => not t.is_null).map(
            (t) => t.as[IncompleteTypeDecl].do((i) => i.next_part(), default_val=t)
        ).unique()
    }

    |" Return the first type of which this subprogram is a candidate
    |" primitive of.
    fun candidate_primitive_subp_first_type(): Entity[BaseTypeDecl] =
        self.candidate_primitive_subp_types().do((p) => p?[0])

    |" If this subprogram is a primitive for a tagged type, then return this
    |" type. If ``canonicalize`` is true, then the returned types will be
    |" canonicalized.
    @memoized
    fun candidate_primitive_subp_tagged_type(canonicalize: Bool = true): Entity[BaseTypeDecl] = {
        bind origin = node;

        self.candidate_primitive_subp_types(canonicalize).find((t) => t.full_view().is_tagged_type())
    }

    |" If this subp spec is that of the body of an entity, this property
    |" returns the subp spec of the declaration of that entity. It returns
    |" itself otherwise.
    |"
    |" If ``follow_generic`` is set to False, we explicitly return null if
    |" this spec is part of a generic subprogram declaration. See
    |" ``primitive_decl_spec``.
    @with_dynvars(imprecise_fallback=false)
    fun decl_spec(follow_generic: Bool): Entity[BaseSubpSpec] = {
        # The ``name`` field can be null, for example if this subp spec is part
        # of an access-to-subprogram type declaration.
        val bd = self.name()?.basic_decl();

        bd.do(
            (bd) => bd.canonical_part().do(
                (dp) => if not follow_generic and dp is GenericSubpInternal then null[Entity[BaseSubpSpec]] else dp.subp_spec_or_null(follow_generic=follow_generic), default_val=self
            ), default_val=self
        )
    }

    |" Return the subp spec of the declaration of this potential primitive.
    |" Since a generic subprogram cannot be a primitive, we explicitly
    |" set ``follow_generic`` to False to filter out those early.
    @with_dynvars(imprecise_fallback=false)
    fun primitive_decl_spec(): Entity[BaseSubpSpec] =
        self.decl_spec(follow_generic=false)

    |" Given a type that was retrieved by one of the ``candidate_primitive_*``
    |" properties, return itself if the subp spec actually corresponds to a
    |" primitive of this type, otherwise return null. This is needed because
    |" the result of the ``candidate_primitive_*`` properties is an
    |" approximation.
    fun as_primitive_subp_type(typ: Entity[BaseTypeDecl]): Entity[BaseTypeDecl] =
        # `self.name` can be null for access-to-subprogram specifications
        self.name().do(
            (name) => typ?.primitives_env().get(name.name_symbol()).any((b) => b.node == name.basic_decl().node).do(
                # This is node is indeed a primitive if we can find it in `typ`'s
                # primitives env.
                # If seen from an inherited primitive, make sure the returned
                # type corresponds to the derived type and not the base type
                # by using `real_type`.
                (_) => self.real_type(typ)
            )
        )

    |" Return the types of which this subprogram is a primitive of.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun primitive_subp_types(): Array[Entity[BaseTypeDecl]] = self.primitive_decl_spec().do(
        (spec) => spec.candidate_primitive_subp_types().filter(
            (c) => not spec.as_primitive_subp_type(c).is_null
        )
    )

    |" Return the first type of which this subprogram is a primitive of.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun primitive_subp_first_type(): Entity[BaseTypeDecl] = self.primitive_decl_spec().do(
        (spec) => spec.as_primitive_subp_type(
            spec.candidate_primitive_subp_first_type()
        )
    )

    |" If this subprogram is a primitive for a tagged type, then return this
    |" type.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun primitive_subp_tagged_type(): Entity[BaseTypeDecl] = self.primitive_decl_spec().do(
        (spec) => spec.as_primitive_subp_type(
            spec.candidate_primitive_subp_tagged_type()
        )
    )

    |" Return whether this subprogram has a controlling result, i.e. that
    |" it is the primitive of a tagged type ``T`` and its return type is
    |" ``T`` as well.
    @with_dynvars(imprecise_fallback=false)
    fun has_controlling_result(): Bool = {
        val typ = self.candidate_primitive_subp_tagged_type();

        not typ.is_null and typ == self.return_type()
    }

    |" Returns whether the subprogram containing this spec is a subprogram
    |" callable via the dot notation.
    |"
    |" This property doesn't implement Ada standard but the GNAT experimental
    |" feature allowing dot-notation for untagged types.
    @memoized
    fun dottable_subp_of(): Entity[BaseTypeDecl] =
        # See also comments in BaseTypeDecl.dottable_subps
        {
            bind origin = node.origin_node();

            if self.nb_max_params() > 0 then self.potential_dottable_type()?.specific_type() else null[Entity[BaseTypeDecl]]
        }

    |" Returns the return type of self, if applicable (e.g. if self is a
    |" subprogram). Else, returns null.
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun return_type(): Entity[BaseTypeDecl] =
        self.returns().do((rt) => self.real_designated_type(rt))

    fun xref_entry_point(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = self.returns().do(
        (r) => r.sub_equation(), default_val=%true
    )

    |" Returns the array of parameters specification for this subprogram spec.
    @exported
    fun params(): Array[Entity[ParamSpec]] = raise[Array[Entity[ParamSpec]]] PropertyError("Property BaseSubpSpec.params not implemented")
}

|" Entry specification.
|"
|" This node does not have ARM existence, because in the RM subprogram
|" specifications don't encompass the ad-hoc specifications that happen in
|" entry declarations. Entry declarations are described in
|" :rmlink:`9.5.2`.
class EntrySpec: BaseSubpSpec {
    @parse_field entry_name: DefiningName
    @parse_field @nullable family_type: AdaNode
    @parse_field @nullable entry_params: Params

    fun name(): Entity[DefiningName] = self.entry_name

    fun params(): Array[Entity[ParamSpec]] = self.entry_params.do(
        (p) => p.params.map((p) => p), default_val=null[Array[Entity[ParamSpec]]]
    )

    fun returns(): Entity[TypeExpr] = null[Entity[TypeExpr]]

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = self.family_type.do(
        (r) => r.sub_equation(), default_val=%true
    )
}

|" Synthetic node for the abstract subprogram spec of an enum literal.
|"
|" NOTE: This has no existence in the ARM. While enum literals are functions
|" semantically, they're not such syntactically.
@synthetic
class EnumSubpSpec: BaseSubpSpec {
    fun enum_decl(): Entity[EnumLiteralDecl] =
        node.parent.as[EnumLiteralDecl].as_entity

    fun name(): Entity[DefiningName] = self.enum_decl().enum_decl_name()

    fun returns(): Entity[TypeExpr] = self.enum_decl().synth_type_expr()

    fun params(): Array[Entity[ParamSpec]] = null[Array[Entity[ParamSpec]]]
}

|" Subprogram specification (:rmlink:`6.1`).
class SubpSpec: BaseSubpSpec {
    @parse_field subp_kind: SubpKind
    @parse_field @nullable subp_name: DefiningName
    @parse_field @nullable subp_params: Params
    @parse_field @nullable subp_returns: TypeExpr

    fun name(): Entity[DefiningName] = self.subp_name

    fun params(): Array[Entity[ParamSpec]] =
        self.subp_params?.params.map((p) => p)

    fun returns(): Entity[TypeExpr] = self.subp_returns
}

|" Synthetic subprogram specification for binary operators.
@synthetic
class SyntheticBinarySpec: BaseSubpSpec {
    subp_symbol: Symbol
    @parse_field left_param: SyntheticFormalParamDecl
    @parse_field right_param: SyntheticFormalParamDecl
    @parse_field @nullable return_type_expr: TypeExpr

    fun name(): Entity[DefiningName] =
        node.synthesize_defining_name(node.subp_symbol).as_entity

    fun returns(): Entity[TypeExpr] = self.return_type_expr

    fun corresponding_actual(): Entity[BaseFormalParamHolder] = self

    fun abstract_formal_params(): Array[Entity[BaseFormalParamDecl]] =
        [self.left_param.as[BaseFormalParamDecl], self.right_param.as[BaseFormalParamDecl]]
}

|" Synthetic subprogram specification for unary operators.
@synthetic
class SyntheticUnarySpec: BaseSubpSpec {
    subp_symbol: Symbol
    @parse_field right_param: SyntheticFormalParamDecl
    @parse_field return_type_expr: SyntheticTypeExpr

    fun name(): Entity[DefiningName] =
        node.synthesize_defining_name(node.subp_symbol).as_entity

    fun returns(): Entity[TypeExpr] = self.return_type_expr

    fun corresponding_actual(): Entity[BaseFormalParamHolder] = self

    fun abstract_formal_params(): Array[Entity[BaseFormalParamDecl]] =
        [self.right_param.as[BaseFormalParamDecl]]
}

|" List of component declarations (:rmlink:`3.8`).
class ComponentList: BaseFormalParamHolder {
    @parse_field components: ASTList[AdaNode]
    @parse_field @nullable variant_part: VariantPart

    fun type_def(): Entity[TypeDef] = node.parent.parent.as[TypeDef].as_entity

    fun type_decl(): Entity[TypeDecl] = self.type_def().parent.as[TypeDecl]

    fun parent_component_list(): Entity[ComponentList] = {
        bind origin = node;

        self.type_def().as[DerivedTypeDef]?.base_type().record_def()?.comps()
    }

    @with_dynvars(env, origin=null[AdaNode])
    fun abstract_formal_params_for_assocs(assocs: Entity[AssocList], stop_recurse_at: Entity[BaseTypeDecl] = null[Entity[BaseTypeDecl]]): Array[Entity[BaseFormalParamDecl]] = {
        val td = self.type_decl();
        val discriminants = td.discriminants_list(stop_recurse_at);
        # Get param matches for discriminants only
        val discriminants_matches = node.match_formals(discriminants, assocs, false).filter(
            (pm) => not pm.formal.is_null and discriminants.contains(pm.formal.formal_decl())
        );

        # Get param matches for all aggregates' params. Here, we use and pass
        # down the discriminant matches, so that abstract_formal_params_impl is
        # able to calculate the list of components belonging to variant parts,
        # depending on the static value of discriminants.
        td.record_def().comps().abstract_formal_params_impl(
            discriminants=discriminants_matches, stop_recurse_at=stop_recurse_at, assocs=assocs
        )
    }

    |" Return all the components lists of this ComponentList, which includes
    |" the current and parent components, and all the components lists of the
    |" variant part, recursively, regardless of the discriminants values. This
    |" list is used for DeltaAggregate name resolution.
    fun abstract_formal_params_for_delta_assocs(): Array[Entity[BaseFormalParamDecl]] = {
        val variant_part_components = self.variant_part?.variant.mapcat(
            (v) => v.components.abstract_formal_params_for_delta_assocs()
        );
        val self_components = self.components.keep[BaseFormalParamDecl];
        val parent_components = self.parent_component_list()?.abstract_formal_params_for_delta_assocs();

        variant_part_components & self_components & parent_components
    }

    |" Implementation for abstract_formal_params. Warning: this property
    |" is for internal use.
    |"
    |" This property returns the formal parameter declarations of a given
    |" aggregate components list, regarding its ``discriminants`` values.
    |"
    |" * If ``include_discriminants`` is True, discriminants are also returned
    |"   by the property.
    |"
    |" * When ``recurse`` is set, parent's components are appended to the
    |"   result, recursively. In some cases, ``stop_recurse_at`` can be used
    |"   to stop the recursion. This is used for extended aggregates in order
    |"   to not consider the ancestor when looking for parents components. See
    |"   also ``BaseTypeDecl.all_discriminants``.
    |"
    |" * ``assoc`` is the AssocList of the aggregate that can be used to
    |"   get parents components regarding their discriminants values.
    fun abstract_formal_params_impl(discriminants: Array[ParamMatch], include_discriminants: Bool = true, recurse: Bool = true, stop_recurse_at: Entity[BaseTypeDecl] = null[Entity[BaseTypeDecl]], assocs: Entity[AssocList] = null[Entity[AssocList]]): Array[Entity[BaseFormalParamDecl]] = {
        # Get self's components. We pass along discriminants, to get variant
        # part's components too.
        val self_comps = self.components.keep[BaseFormalParamDecl] & self.variant_part?.get_components(discriminants);
        # Append parent's components: the parent could have a variant part too,
        # which discriminants can be constrained by the subtype indication from
        # our DerivedTypeDef. The code below retrieves the relevant components
        # from the parent record taking that into account.
        val ret = if recurse then self.parent_component_list().do(
            (pcl) => if pcl.type_decl().matching_type(stop_recurse_at) then self_comps else pcl.abstract_formal_params_impl(
                pcl.match_formals(
                    pcl.type_decl().discriminants_list(stop_recurse_at), self.type_def().as[DerivedTypeDef].subtype_indication.constraint.as[CompositeConstraint].do(
                        (cc) => cc.constraints, default_val=assocs
                    ), # In case of extension aggregate, discriminants
                    # are not constrained by any subtype
                    # indication, then match the discriminants with
                    # the AssocList of the aggregate.
                    is_dottable_subp=false
                ), include_discriminants=false, stop_recurse_at=stop_recurse_at
            ) & self_comps, default_val=self_comps
        ) else self_comps;

        if include_discriminants then self.type_decl().do(
            (decl) => decl.discriminants_list(stop_recurse_at)
        ) & ret else ret
    }

    fun abstract_formal_params(): Array[Entity[BaseFormalParamDecl]] =
        self.abstract_formal_params_impl(null[Array[ParamMatch]])

    |" Return all the possible shapes that this component list spans.
    fun shapes(): Array[Shape] = {
        val self_comps = self.components.keep[BaseFormalParamDecl];

        self.variant_part.do(
            (vpart) => vpart.variant.mapcat(
                (v) => v.components.shapes().map(
                    (s) => Shape(
                        components=self_comps & s.components, discriminants_values=[DiscriminantValues(
                            discriminant=vpart.discr_name, values=v.choices
                        )] & s.discriminants_values
                    )
                )
            ), default_val=[Shape(
                components=self_comps, discriminants_values=null[Array[DiscriminantValues]]
            )]
        )
    }

    |" Return whether this component list declares at least one component
    |" which is limited. This also looks in all branches of a variant part.
    fun has_limited_component(): Bool = {
        bind origin = null[AdaNode];

        self.components.any(
            (c) => c.as[BaseFormalParamDecl]?.formal_type()?.is_limited_type()
        ) or self.variant_part?.variant.any(
            (v) => v.components.has_limited_component()
        )
    }
}

|" Specification for discriminants in type declarations.
@abstract
class DiscriminantPart: BaseFormalParamHolder {
    fun abstract_formal_params(): Array[Entity[BaseFormalParamDecl]] =
        null[Array[Entity[BaseFormalParamDecl]]]
}

|" Known list of discriminants in type declarations (:rmlink:`3.7`).
class KnownDiscriminantPart: DiscriminantPart {
    @parse_field discr_specs: ASTList[DiscriminantSpec]

    fun abstract_formal_params(): Array[Entity[BaseFormalParamDecl]] = node.discr_specs.map(
        (e) => e.as[BaseFormalParamDecl].as_entity
    )
}

|" Unknown list of discriminants in type declarations (:rmlink:`3.7`).
class UnknownDiscriminantPart: DiscriminantPart {
}

|" Formal parameters for the completion of an ``EntryDecl`` (either an
|" ``EntryBody`` or an ``AcceptStmt``).
class EntryCompletionFormalParams: BaseFormalParamHolder {
    @parse_field @nullable params: Params

    fun abstract_formal_params(): Array[Entity[BaseFormalParamDecl]] =
        self.params?.params.map((p) => p.as[BaseFormalParamDecl])
}

|" List of declaration for generic formals (:rmlink:`12.1`).
class GenericFormalPart: BaseFormalParamHolder {
    @parse_field decls: ASTList[AdaNode]

    fun abstract_formal_params(): Array[Entity[BaseFormalParamDecl]] =
        self.decls.keep[BaseFormalParamDecl]

    |" Returns the envs for all the use clauses declared in this generic
    |" formal part.
    fun use_clauses_envs(): LexicalEnv = self.decls.filtermap(
        (u) => u.as[UseClause].used_envs(), (u) => u is UseClause
    ).env_group()
}

|" Base class for record definitions (:rmlink:`3.8`).
@abstract
class BaseRecordDef: AdaNode {
    @parse_field components: ComponentList

    # TODO: If base subtype is from a formal type, then False
    fun comps(): Entity[ComponentList] = self.components
}

|" Record definition for ``null record``.
class NullRecordDef: BaseRecordDef {
}

|" Record definition that contains components (``record ... end record``).
class RecordDef: BaseRecordDef {
}

|" Association of one or several names to an expression.
@abstract
@with_abstract_list
class BasicAssoc: AdaNode {
    @abstract
    fun expr(): Entity[Expr]

    @abstract
    fun names(): Array[AdaNode]

    |" Return the list of parameters that this association refers to.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun get_params(): Array[Entity[DefiningName]] =
        self.parent.as![AssocList].zip_with_params().filtermap(
            (m) => m.param, (m) => m.actual == self.expr()
        )
}

|" Association (X => Y) used for aggregates associations (:rmlink:`4.3`).
class AggregateAssoc: BasicAssoc {
    @parse_field designators: AlternativesList
    @parse_field r_expr: Expr

    fun expr(): Entity[Expr] = self.r_expr

    fun names(): Array[AdaNode] = node.designators.map((d) => d)

    @with_dynvars(env, origin)
    fun xref_stop_resolution(): Bool = true

    fun base_aggregate(): Entity[BaseAggregate] =
        self.parent.parent.as![BaseAggregate]

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        val agg = self.base_aggregate();
        val mra = agg.multidim_root_aggregate();
        # If we're part of a multidim aggregate, then take the root aggregate's
        # type. Else, this is a regular aggregate. In this case grab the type
        # in type_val.
        val td = if not mra.is_null then
            mra.typ
        else
            self.base_aggregate().type_val().as[BaseTypeDecl];

        val atd = td?.array_def();

        if agg.in_aspect(s"Global") or agg.in_aspect(s"Refined_Global") then
            self.globals_assoc_equation()
        elif agg.in_aspect(s"Depends") or agg.in_aspect(s"Refined_Depends")
            then self.depends_assoc_equation()
        elif agg.in_aspect(s"Test_Case") then
            self.test_case_assoc_equation()
        elif agg.in_aspect(s"Refined_State") then (
            # Simply resolve all names present in the Refined_State aspect,
            # as they must all refer to existing declarations.
            self.exprs_assoc_equation()
        )
        # In the case of Contract_Cases aspect, only the top level
        # aggregate should be resolved by the special equation here. All
        # other agreggates included in the latter should use the regular
        # resolution path.
        elif agg.parent.as[AspectAssoc]?.id.name_is(s"Contract_Cases") then
            self.contract_cases_assoc_equation()
        elif agg.parent.as[AspectAssoc]?.id.name_is(s"Subprogram_Variant") then
            self.subprogram_variant_assoc_equation()
        elif agg is BracketAggregate and td?.has_aspect(s"Aggregate") then
            self.container_aggregate_equation(td)
        elif agg.parent is AspectClause | AspectAssoc | PragmaArgumentAssoc
            then %true
        elif agg is DeltaAggregate then
            self.delta_aggregate_assoc_equation()
        elif atd.is_null then
            self.record_assoc_equation()
        else
            self.array_assoc_equation(atd, mra)
    }

    |" Equation for the case where this is an aggregate assoc for a
    |" container type. This is an Ada 2022 feature (:rmlink:`4.3.5`).
    @with_dynvars(env, origin, entry_point)
    fun container_aggregate_equation(td: Entity[BaseTypeDecl]): Equation = {
        val aggregate_aspect = td.get_aspect(s"Aggregate").value.as[Aggregate];
        val entity_name = self.names()?[0].as[Name];
        val element_type = aggregate_aspect.element_type();
        val key_type = aggregate_aspect.key_type();

        %eq(self.expr().expected_type_var(), element_type) and self.expr().sub_equation() and self.expr().matches_expected_type() and (
            if entity_name.is_null then %true else %eq(entity_name.expected_type_var(), key_type) and entity_name.as_entity.sub_equation() and entity_name.matches_expected_type()
        )
    }

    |" Equation for the case where this is an aggregate assoc for a delta
    |" aggregate. This is an Ada 2022 feature (:rmlink:`4.3.4`). This equation
    |" also supports the so called "deep" delta aggregates, a GNAT
    |" experimental feature.
    @with_dynvars(env, origin, entry_point)
    fun delta_aggregate_assoc_equation(): Equation = {
        val agg = self.base_aggregate();
        val agg_type = agg.type_val().as[BaseTypeDecl];

        # Determine whether this is a delta array aggregate rather than a deep
        # delta aggregate by checking whether any alternative designates a
        # position in an array.
        val positional_assoc = agg_type.is_array() and not self.names().any(
            # leftmost_name returns null if n starts with
            # ArraySubcomponentChoiceName (which denotes a deep aggregate).
            (n) => n.as[Name]?.leftmost_name().is_null
        );

        val agg_components = (not agg_type.is_array()).do(
            (_) => node.unpack_formals(agg.all_components())
        );

        # If this is a record delta aggregate, try to match the components
        # corresponding to these names in order to correctly set the
        # environments from which they should be resolved.
        val matches = self.names().map(
            (n) => if n is Name then
                # Get the leftmost name to match a component with if any
                n.as[Name].leftmost_name().do(
                    (id) => agg_components.find(
                        (c) => c.name.matches(id)
                    )
                )
            # If not a Name, there can be no component match (can be a BinOp
            # denoting a range in an array for example.)
            else null[Expr].as_entity
        );

        self.names().ilogic_all(
            (n, i) => {
                # Resolve the name from the matched component if any
                bind env = matches[i].do(
                    (l) => l.children_env(),
                    default_val=env
                );

                n.as[Expr].as_entity.sub_equation()
            } and (
                # Check that all alternatives resolve to the same type
                if i > 0 then
                    %predicate(BaseTypeDecl.matching_type,
                               n.as[Expr].type_var(),
                               self.names()[0].as[Expr].type_var(),
                               error_location=node)
                else %true
            ) and (
                # We cannot set the expected type of the alternative in case the
                # aggregate is a record aggregate or a deep one (both record and
                # array) because the expected type of the alternative can be any
                # one of the record components (including those from parents).
                # Only simple array aggregate associations's alternatives can
                # have an expected type (i.e., the alternative designates a
                # position or a range).
                if positional_assoc then
                    %eq(n.as[Expr].expected_type_var(),
                        agg_type.index_type(0))
                    and n.as[Expr].matches_expected_type()
                else %true
            )
        ) and (
            # Set the expected type of the expression only once since all the
            # alternatives should have the same type.
            if positional_assoc then
                %eq(self.expr().expected_type_var(), agg_type.comp_type())
            else
                %eq(self.expr().expected_type_var(),
                    self.names()[0].as[Expr].type_var())
        ) and (
            # Build the equation for the expression
            self.expr().sub_equation() and self.expr().matches_expected_type()
        )
    }


    |" Equation for the case where this is an aggregate assoc for a record
    |" type.
    @with_dynvars(env, origin, entry_point)
    fun record_assoc_equation(): Equation = {
        val agg = self.base_aggregate();
        # First, try to find all the discriminants matched by this assoc
        val discr_matches = agg.matched_discriminants().filter((pm) => pm.actual.assoc == self);
        # If there are none, this assoc matches one or several components of
        # the record, so gather them.
        # WARNING: It is important to gather these components ONLY IF this
        # association is not for specifying a discriminant. Indeed,
        # discriminants can (and must) be resolved separately once the type of
        # the aggregate is known. Otherwise, name resolution will enter an
        # infinite loop when trying to match an available component for this
        # association, as it requires statically evaluating discriminants which
        # involves doing name resolution on them, thus introducing a cycle.
        val matches = if not discr_matches.is_null then discr_matches else agg.matched_components().filter((pm) => pm.actual.assoc == self);
        # Whether this is the `others => ...` association
        val is_others_assoc = self.names().any((n) => n is OthersDesignator);
        # Whether this is the `component_choice_list => <>` association (in
        # that case the component_choice_list's components can not be of the
        # same type).
        val is_box_expr = self.expr() is BoxExpr;

        if not is_others_assoc then matches.logic_all(
            (match_var) => (
                # If expr is a box expr do not resolve it since it doesn't have
                # a name nor type.
                if is_box_expr then %true else (
                    %eq(match_var.actual.assoc.expr().expected_type_var(), match_var.formal.formal_decl().type_expression().designated_type()) and match_var.actual.assoc.expr().sub_equation()
                ) and match_var.actual.assoc.expr().matches_expected_assign_type()
            ) and match_var.actual.name.do(
                (n) => %eq(n.ref_var(), match_var.formal.formal_decl()), default_val=%true
            )
        ) else (
            # Since all the formals designated by "others" should have the same
            # type (iff expr is not a box expr), we look for the first formal
            # that was not yet matched and use its type as the type of the
            # expression associated to "others".
            if is_box_expr then %true else agg.first_unmatched_formal().do(
                (unmatched_formal) => (
                    %eq(self.expr().expected_type_var(), unmatched_formal.formal_decl().type_expression().designated_type()) and self.expr().sub_equation()
                ) and self.expr().matches_expected_type(), default_val=%true
            )
        )
    }

    |" Equation for the case where this is an aggregate assoc for an array
    |" type.
    @with_dynvars(env, origin, entry_point)
    fun array_assoc_equation(atd: Entity[ArrayTypeDef], mra: MultidimAggregateInfo): Equation = (
        # If the array is monodimensional, or we're on the last
        # dimension of a multidimensional array ..
        if mra.is_null or mra.rank == atd.array_ndims() - 1 then (
            # .. Then we want to match the component type
            (
                %eq(self.expr().expected_type_var(), atd.comp_type()) and self.expr().sub_equation()
            ) and self.expr().matches_expected_type()
        ) else (
            # .. Else we're on an intermediate dimension of a
            # multidimensional array: do nothing.
            %true
        )
    ) and self.designators.logic_all(
        (n) => n.sub_equation() and (
            if n is Name and not n.as[Name].name_designated_type().is_null then n.as[Name].xref_type_equation() else n.as[Expr].do(
                (n) => %eq(n.expected_type_var(), atd.index_type(mra.rank)) and n.matches_expected_type(), default_val=%true
            )
        )
    )

    |" Equation for the case where this is an aggregate assoc for a Globals
    |" aspect.
    @with_dynvars(env, origin, entry_point)
    fun globals_assoc_equation(): Equation =
        # Assoc expr can either be a name or an aggregate. If a name, then
        # resolve. If an aggregate, resolution will be handled recursively
        # by solve.
        self.expr().sub_equation()

    |" Equation for the case where this is an aggregate assoc for a Depends
    |" aspect.
    @with_dynvars(env, origin, entry_point)
    fun depends_assoc_equation(): Equation = (
        # For both the name and the expr, same as in `globals_equation`, we
        # call sub_equation: If it's a name it will resolve the name. If
        # it's an aggregate it will return LogicTrue() and the content will
        # be resolved separately.
        # The ``null`` literal is a possible value for ```expr``. Do
        # not resolve it.
        if self.expr() is NullLiteral or self.expr().as[UnOp]?.expr.do((v1) => v1 is NullLiteral) then %true else self.expr().sub_equation()
    ) and # Here, we go fetch the first element of the list of names. Since
    # we parse this as an aggregate, the list is elements separated by
    # pipes (alternatives_list), which will ever only have one element
    # in this case. As above, we make sure to not resolve the ``null``
    # literal.
    {
        val n = self.names()?[0];

        if n.is_null or n is NullLiteral then %true else n.as_entity.sub_equation()
    }

    |" Equation for the case where this is an aggregate assoc for a Test_Case
    |" aspect.
    @with_dynvars(env, origin, entry_point)
    fun test_case_assoc_equation(): Equation =
        # Only resolve the right-hand side of `Requires` and `Ensures`,
        # the other associations (Name and Mode) need not be resolved.
        if self.names()?[0].as[BaseId].do(
            (name) => name.name_symbol() in s"Requires" | s"Ensures"
        ) then self.expr().sub_equation() else %true

    |" Equation for the case where this is an aggregate assoc for a
    |" Contract_Cases aspect. Both the ``guard`` and the ``consequence`` must
    |" be of type Boolean.
    @with_dynvars(env, origin, entry_point)
    fun contract_cases_assoc_equation(): Equation = self.designators.logic_all(
        (d) => d.as[Expr].do(
            (e) => (
                %eq(e.expected_type_var(), node.bool_type()) and e.sub_equation()
            ) and e.matches_expected_formal_type(), default_val=%true
        )
    ) and (
        # Nothing to do for `others =>`
        %eq(self.expr().expected_type_var(), node.bool_type())
    ) and self.expr().sub_equation() and self.expr().matches_expected_formal_type()

    |" Equation for the case where this is an aggregate assoc for a
    |" Subprogram_Variant aspect. See SPARK RM 6.1.8 for more details.
    @with_dynvars(env, origin, entry_point)
    fun subprogram_variant_assoc_equation(): Equation =
        self.designators.logic_all((d) => d.as[BaseId].do((name) =>
            if name.name_symbol() in s"Increases" | s"Decreases" then (
                # For a numeric subprogram variant, the expression must
                # be of any discrete type, or the `Big_Integer` type.
                %predicate(
                    BaseTypeDecl.is_discrete_type,
                    self.expr().type_var()
                ) or (
                    %eq(self.expr().expected_type_var(),
                        self.big_integer_type())
                    and self.expr().matches_expected_type()
                )
            ) and self.expr().sub_equation()
            elif name.name_symbol() in s"Structural" then
                # For a structural subprogram variant, the expression must
                # denote a formal parameter of the subprogram, so a simple
                # call to sub_equation will do.
                self.expr().sub_equation()
            else
                %false,
            default_val=%false
        ))

    |" Return the xref equation for the case where this is an aggregate assoc
    |" in which all the designator as well as the RHS are usual expressions
    |" which can be recursively resolved.
    @with_dynvars(env, origin, entry_point)
    fun exprs_assoc_equation(): Equation =
        self.designators.logic_all((d) => d.sub_equation()) and self.expr().as[Name].do(
            (n) => n.sub_equation(), default_val=%true
        )
}

|" Association used for multi-dimension array aggregates.
class MultiDimArrayAssoc: AggregateAssoc {
}

|" Association of discriminant names to an expression (:rmlink:`3.7.1`).
class CompositeConstraintAssoc: BasicAssoc {
    @parse_field ids: DiscriminantChoiceList
    @parse_field constraint_expr: AdaNode

    fun expr(): Entity[Expr] = self.constraint_expr.as![Expr]

    fun names(): Array[AdaNode] = node.ids.map((i) => i.as[AdaNode])
}

|" Iterated association (Ada 2020, :rmlink:`4.3.3`).
class IteratedAssoc: BasicAssoc {
    @parse_field spec: ForLoopSpec
    @parse_field @nullable key_expr: Expr
    @parse_field r_expr: Expr

    fun expr(): Entity[Expr] = self.r_expr

    fun names(): Array[AdaNode] = null[Array[AdaNode]]

    fun base_aggregate(): Entity[BaseAggregate] =
        self.parent.parent.as![BaseAggregate]

    @with_dynvars(env, origin)
    fun xref_stop_resolution(): Bool = self.parent.parent is BaseAggregate

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        val aggregate = self.base_aggregate();
        val root_agg = aggregate.multidim_root_aggregate();
        # If we're part of a multidim aggregate, then take the root aggregate's
        # type. Else, this is a regular aggregate. In this case grab the type
        # in type_val.
        val type_decl = if not root_agg.is_null then root_agg.typ else aggregate.type_val().as[BaseTypeDecl];
        val array_type_def = type_decl?.array_def();
        # The iterated assoc can also be in a container aggregate
        val container_aggregate = type_decl.get_aspect(s"Aggregate").value.as[Aggregate];
        # Get the "component" type of the array or container
        val comp_type = array_type_def.do(
            (atd) => atd.comp_type(), default_val=container_aggregate.element_type()
        );
        # Get the index type of the array or container
        val index_type = array_type_def.do(
            (atd) => atd.index_type(root_agg.rank), default_val=container_aggregate.key_type()
        );
        # NOTE: we need to resolve the spec first so that the indexing variable
        # has a type when resolving `r_expr`.
        # NOTE: if the form of the iterated_component_association is
        # `for I in ..`, Ada requires the type of I to be the index type of the
        # array (taking dimension into account) which we are building an
        # aggregate for.
        val spec_success = self.spec.resolve_names_internal_with_eq(
            if node.spec.loop_type is IterType.In then %eq(self.spec.iter_expr.as[Expr].expected_type_var(), index_type) and self.spec.iter_expr.as[Expr].matches_expected_type() else %true
        );

        if spec_success then # If the array is monodimensional, or we're on the last
        # dimension of a multidimensional array ..
        if root_agg.is_null or root_agg.rank == array_type_def.array_ndims() - 1 then (
            # .. Then we want to match the component type
            (
                (
                    self.expr().sub_equation() and %eq(self.expr().expected_type_var(), comp_type)
                ) and self.expr().matches_expected_type()
            ) and (
                # .. As well as the key expression if it exists
                self.key_expr.do(
                    (ke) => (
                        ke.sub_equation() and %eq(ke.expected_type_var(), index_type)
                    ) and ke.matches_expected_type(), default_val=%true
                )
            )
        ) else (
            # .. Else we're on an intermediate dimension of a
            # multidimensional array: do nothing.
            %true
        ) else %false
    }

    |" Equation specialization for ``ValueSequence`` name resolution (part of
    |" ``ReduceAttributeRef``).
    @with_dynvars(env, origin, entry_point)
    fun xref_equation_for_reduce(): Equation = {
        # The expected type is the expected type of the ReduceAttributeRef
        # holding this iterated assoc.
        val expected_typ = self.parent.as[ValueSequence].iter_assoc.expr().expected_type_var();
        # See self.xref_equation for more details
        val spec_success = self.spec.resolve_names_internal_with_eq(
            if node.spec.loop_type is IterType.In then %eq(self.spec.iter_expr.as[Expr].expected_type_var(), expected_typ) and self.spec.iter_expr.as[Expr].matches_expected_type() else %true
        );

        if spec_success then (
            self.expr().sub_equation() and %eq(self.expr().expected_type_var(), expected_typ)
        ) and self.expr().matches_expected_type() else %false
    }
}

|" Association (X => Y) used for parameter associations (:rmlink:`6.4`).
class ParamAssoc: BasicAssoc {
    @parse_field @nullable designator: AdaNode
    @parse_field r_expr: Expr

    fun expr(): Entity[Expr] = self.r_expr

    fun names(): Array[AdaNode] =
        if node.designator.is_null then null[Array[AdaNode]] else [node.designator]

    fun xref_entry_point(): Bool = node.is_static_attribute_assoc()

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        if node.xref_entry_point() then self.expr().sub_equation() else %false

    fun is_static_attribute_assoc(): Bool = node.parent.parent.as[AttributeRef].do(
        (ar) => ar.attribute.name_symbol() in s"First" | s"Last" | s"Range" | s"Length" | s"Has_Same_Storage" | s"Overlaps_Storage"
    )
}

|" Root class for an Ada declaration (:rmlink:`3.1`). A declaration
|" associates a name with a language entity, for example a type or a variable.
@abstract
@custom_short_image
class BasicDecl: AdaNode {
    @abstract @parse_field @nullable aspects: AspectSpec

    |"
    @memoized
    fun spark_mode_aspect(): Aspect = # Check for direct `SPARK_Mode` aspect definition
    if self.has_aspect(s"SPARK_Mode") then self.get_aspect(s"SPARK_Mode")
    # If there is no aspect on this subprogram, it's `On` if the
    # enclosing subprogram or declarative region is `On`.
    else (
        if self.previous_part_for_decl().do((v1) => v1 is BodyStub) then self.previous_part_for_decl() else self
    ).declarative_scope().as_entity?.spark_mode_aspect().do(
        (asp) => asp,
        # Finally, check for configuration pragmas
        default_val=self.enclosing_compilation_unit().spark_config_pragma().do(
            (p) => p.as_aspect(),
            # No configuration pragma were found
            default_val=null[Aspect]
        )
    )

    |" Implementation for ``BasicDecl.constrain_prefix`` but for subprograms.
    |"
    |" Since subprograms can't have a base class, this is shared here.
    @with_dynvars(origin)
    fun subp_constrain_prefix(prefix: Expr): Equation =
        # If self is a dottable subprogram, then we want to constrain the
        # prefix so that it's type is the type of the first parameter of
        # self.
        if self.info.md.dottable_subp then %eq(prefix.expected_type_var(), self.subp_spec_or_null().unpacked_formal_params()?[0]?.formal_decl().formal_type()) and prefix.matches_expected_prefix_type() else %true

    |" Helper for AdaNode.env_hook. Handle library-level unit decl nodes.
    fun env_hook_basic_decl(): Bool =
        # For library-level subprogram/package declarations, process the
        # parent spec.
        if node is PackageDecl | BasicSubpDecl | PackageRenamingDecl | GenericPackageDecl | GenericPackageInstantiation | GenericSubpInstantiation | GenericSubpDecl | SubpBody then node.as_bare_entity.defining_name().name.as[DottedName].do(
            (dn) => node.get_unit(
                dn.prefix.as_symbol_array(), AnalysisUnitKind.unit_specification, load_if_needed=true, not_found_is_error=not node is SubpBody
            ).do((_) => false)
        ) else false

    |" For library-level subprogram declarations, we always want to populate
    |" the unit containing the body, so that the lexical envs always contain
    |" the spec and the body, no matter which was initially requested.
    fun populate_body_unit(): Bool = if node.is_library_item() then node.get_unit(
        node.as_bare_entity.defining_name().name.as_symbol_array(), AnalysisUnitKind.unit_body, load_if_needed=true, not_found_is_error=false
    ).do((_) => false) else false

    |" Helper for ``has_top_level_env_name``. See its docstring for more
    |" information.
    fun has_top_level_env_name_impl(allow_bodies: Bool): Bool = {
        val is_decl = node is BasePackageDecl | BasicSubpDecl | GenericDecl | TaskTypeDecl | ProtectedTypeDecl | SingleTaskDecl | SingleProtectedDecl;
        val is_body = node is Body;

        node.is_compilation_unit_root() or (
            (is_decl or (allow_bodies and is_body)) and node.node_env().env_node.do(
                (env_node) => env_node.as[BasicDecl].do(
                    (p) => if node == p then true else p.has_top_level_env_name_impl(
                        allow_bodies=allow_bodies and not node is BaseSubpBody and not p is BaseSubpBody
                    ), default_val=env_node is PrivatePart and env_node.parent.as[BasicDecl].do(
                        (bd) => bd.has_top_level_env_name_impl(allow_bodies)
                    )
                ), default_val=true
            )
        )
    }

    |" Return True if this declaration is exposed to other compilation units.
    |" This is equivalent to asking if this declaration's env should be named.
    |"
    |" Find a few examples below.
    |"
    |" .. code::
    |"
    |"     package A is                     -- True
    |"         package B is                 -- True
    |"             procedure Foo;           -- True
    |"         end B;
    |"     end A;
    |"
    |"     package body A is                -- True
    |"         package B is                 -- True
    |"             procedure Foo;           -- True
    |"         end B;
    |"     end A;
    |"
    |"     package body A is                -- True
    |"         package body B is            -- True
    |"             procedure Foo;           -- False
    |"         end B;
    |"     end A;
    |"
    |"     package body A is                -- True
    |"         package body B is            -- True
    |"             procedure Foo is null;   -- True
    |"         end B;
    |"     end A;
    |"
    |"     package body A is                -- True
    |"         procedure B is               -- True
    |"             procedure Foo is null;   -- False
    |"         begin
    |"             ...
    |"         end B;
    |"     end A;
    |"
    |"     procedure A is                   -- True
    |"         procedure Foo;               -- True
    |"     begin
    |"         ...
    |"     end A;
    |"
    |"     procedure A is                   -- True
    |"         package body B is            -- False
    |"             procedure Foo is null;   -- False
    |"         end B;
    |"     begin
    |"         ...
    |"     end A;
    |"
    |"     procedure A is                   -- True
    |"         package B is                 -- True
    |"         end B;
    |"
    |"         package body B is            -- True
    |"         end B;
    |"     begin
    |"     end A;
    fun has_top_level_env_name(): Bool =
        # Gotcha: at this point, self.children_env actual refers to its parent
        # env. That's because self does not have yet have a children env (this
        # property is typically called in env specs before add_env() in order
        # to understand where we should create this children_env).
        node.children_env().env_node.do(
            (env_node) => env_node.as[BasicDecl].do(
                (bd) => bd.has_top_level_env_name_impl(allow_bodies=true), default_val=env_node is PrivatePart and env_node.parent.as[BasicDecl].do(
                    (bd) => bd.has_top_level_env_name_impl(allow_bodies=true)
                )
            ), default_val=true
        )

    |" Helper to implement ``env_spec_fully_qualified_name``.
    fun env_spec_fully_qualified_name_impl(self_env: LexicalEnv): String =
        # For a compilation unit root, simply use the existing syntactic
        # fully qualified name property, which does not rely on envs.
        if node.is_compilation_unit_root() then node.sym_join(
            node.enclosing_compilation_unit().syntactic_fully_qualified_name(), "."
        )
        # For internal nodes, ignore them and recurse on their parent,
        # which are the real declarations.
        elif node is GenericPackageInternal | GenericSubpInternal then node.parent.as[BasicDecl].env_spec_fully_qualified_name_impl(self_env=node.parent.node_env())
        # Find the enclosing BasicDecl
        else (
            self_env.env_node.as[BasicDecl] or? self_env.env_node.as[PrivatePart]?.parent.as[BasicDecl]
        ).do(
            # Recurse and append the basic decl's name
            (bd) => bd.env_spec_fully_qualified_name_impl(self_env=bd.node_env()) & "." & node.name_symbol().image()
        )

    |" Return a the fully qualified name of this declaration to be used by
    |" env specs. This should not be used elsewhere, as it does some
    |" assumption about envs that are not True anymore after envs are
    |" populated.
    fun env_spec_fully_qualified_name(): String =
        # Gotcha: at this point, self.children_env actual refers to its parent
        # env. See similar notice in BasicDecl.has_top_level_env_name.
        node.env_spec_fully_qualified_name_impl(node.children_env())

    |" Return the name that this BasicDecl should use to create its lexical
    |" environment. An empty name is returned if it shouldn't use a named
    |" env.
    fun top_level_env_name(): String =
        if node.has_top_level_env_name() then node.env_spec_fully_qualified_name() else null[String]

    |" Return the initial env for this basic declaration. This is used
    |" to set the parent environment of a child declaration to its actual
    |" parent in terms of Ada semantics.
    |"
    |" If ``private_part`` is True, return the env of the private part of its
    |" parent.
    fun child_decl_initial_env(private_part: Bool = false): DesignatedEnv =
        node.child_decl_initial_env_name(private_part).do(
            (name) => DesignatedEnv(
                kind=DesignatedEnvKind.named_env, env_name=name, direct_env=null[LexicalEnv]
            ), default_val=DesignatedEnv(
                kind=DesignatedEnvKind.direct_env, env_name=null[Symbol], direct_env=node.default_initial_env()
            )
        )

    |" Return an array of env assocs that should be added in the environment
    |" designated by ``dest_env``. In the general case, it simply adds an
    |" entry for self using this declaration's name as key. However, if self
    |" corresponds to the declaration of a ``"="`` operator, we also generate
    |" an order to add an entry for the ``"/="`` operator, as described in
    |" :rmlink:`4.5.2` 25.a.
    fun basic_decl_env_assocs(dest_env: DesignatedEnv): Array[EnvAssoc] = {
        val name = self.name_symbol();
        val base_assoc = [EnvAssoc(
            key=self.name_symbol(), value=node, dest_env=dest_env, metadata=null[Metadata]
        )];
        val implicit_neq_assoc = if name == s"\"=\"" then [EnvAssoc(
            key=s"\"/=\"", value=node, dest_env=dest_env, metadata=null[Metadata]
        )] else null[Array[EnvAssoc]];

        base_assoc & implicit_neq_assoc
    }

    |" Return the env association that describes where to register this
    |" basic declaration. For a child declaration in particular, this orders
    |" adding itself inside its parent declaration's environment.
    |"
    |" .. note::
    |"     This intercepts user-defined "=" operators so as to introduce an
    |"     implicit "/=" operator, as per :rmlink:`4.5.2` 25.a.
    fun child_decl_env_assocs(): Array[EnvAssoc] = {
        val dest_env = node.child_decl_initial_env_name(false).do(
            (non_null_name) => DesignatedEnv(
                kind=DesignatedEnvKind.named_env, env_name=non_null_name, direct_env=null[LexicalEnv]
            ), default_val=DesignatedEnv(
                kind=DesignatedEnvKind.current_env, env_name=null[Symbol], direct_env=null[LexicalEnv]
            )
        );

        self.basic_decl_env_assocs(dest_env)
    }

    |" Whether this decl is the nested decl of a generic formal declaration.
    @exported
    fun is_formal(): Bool = node.parent is GenericFormal

    |" Return the documentation annotations associated with this decl.
    |" Annotations are any comment line of the form::
    |"
    |"     --% [annotation_name]: [annotation]
    |"
    |" Raises a property error if the doc is incorrectly formatted.
    |"
    |" .. ATTENTION:: This is an experimental feature, so even if it is
    |"    exposed to allow experiments, it is totally unsupported and the API
    |"    and behavior are very likely to change in the future.
    @exported
    @external()
    fun doc_annotations(): Array[DocAnnotation]

    |" Return the documentation associated with this decl. Raises a property
    |" error if the doc is incorrectly formatted.
    |"
    |" .. ATTENTION:: This is an experimental feature, so even if it is
    |"    exposed to allow experiments, it is totally unsupported and the API
    |"    and behavior are very likely to change in the future.
    @exported
    @external()
    fun doc(): String

    |" Return the canonical part for this decl. In the case of decls composed
    |" of several parts, the canonical part will be the first part.
    @exported
    @memoized
    @with_dynvars(imprecise_fallback=false)
    fun canonical_part(): Entity[BasicDecl] = self.previous_part_for_decl().do(
        (pp) => pp.canonical_part(), default_val=self
    )

    |" Return all previous parts of this entity, where the first part
    |" is at the beginning of the array.
    @with_dynvars(imprecise_fallback=false)
    fun all_previous_parts(): Array[Entity[BasicDecl]] = self.previous_part_for_decl().do(
        (pp) => if self == pp then null[Array[Entity[BasicDecl]]] else pp.all_previous_parts() & [pp]
    )

    |" Return all next parts of this entity, where the last part is at the
    |" end of the array.
    @with_dynvars(imprecise_fallback=false)
    fun all_next_parts(): Array[Entity[BasicDecl]] = self.next_part_for_decl().do(
        (np) => if self == np then null[Array[Entity[BasicDecl]]] else [np] & np.all_next_parts()
    )

    |" Return all parts that define this entity, sorted from first part to
    |" last part.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun all_parts(): Array[Entity[BasicDecl]] = {
        val prevs = self.all_previous_parts();
        val nexts = self.all_next_parts();

        prevs & [self] & nexts
    }

    |" Put ``rebindings`` back on ``self`` if ``self`` is rebound
    |" somewhere in the chain of rebindings. Ensure coherency, e.g. that if
    |" self already has some rebindings, the one that we add are a superset
    |" of the one it already has.
    fun unshed_rebindings(rebindings: EnvRebindings): Entity[BasicDecl] = if rebindings == null[EnvRebindings] then self
    elif rebindings.old_env.env_node == node then self.unshed_rebindings_helper(rebindings)
    else self.unshed_rebindings(rebindings.get_parent)

    |" Put ``rebindings`` on ``self`` if needed. Ensure coherency, e.g. that
    |" if self already has some rebindings, the one that we add are a
    |" superset of the one it already has.
    fun unshed_rebindings_helper(rebindings: EnvRebindings): Entity[BasicDecl] =
        # If the rebindings are already the same, just return the entity as
        # is.
        if self.info.rebindings == rebindings then self
        elif node.has_parent_rebindings(rebindings, self.info.rebindings) then Entity[BasicDecl](
            node=node, info=EntityInfo(
                md=self.info.md, rebindings=rebindings, from_rebound=self.info.from_rebound
            )
        )
        else raise[Entity[BasicDecl]] PropertyError("Incorrect rebindings")

    fun decl_private_part(): Entity[PrivatePart] = match self {
        case bpd: BasePackageDecl => bpd.private_part
        case ttd: TaskTypeDecl => ttd.definition.private_part
        case td: SingleTaskDecl => td.task_type.definition.private_part
        case ptd: ProtectedTypeDecl => ptd.definition.private_part
        case spd: SingleProtectedDecl => spd.definition.private_part
        case _ => null[Entity[PrivatePart]]
    }

    @memoized
    fun immediate_declarative_region(): LexicalEnv = (self.all_previous_parts() & [self]).mapcat(
        (part) => part.declarative_parts().map((p) => p.children_env())
    ).env_group()

    |" Return an array of AdaNode list corresponding to declarative parts in
    |" which to look for pragmas associated to this entity.
    fun pragma_regions(): Array[Entity[ASTList[AdaNode]]] = {
        # First look in the scope where self is declared. We don't use
        # ``declarative_scope`` here, as this BasicDecl may not necessarily
        # be in a DeclarativePart, as is the case for ComponentDecls.
        # Instead, we simply look among this node's siblings.
        val enclosing_scope = self.parent.as[ASTList[AdaNode]].do((v1) => [v1]);
        # Then, if entity is declared in the public part of a package or
        # protected def, corresponding pragma might be in the private part.
        val private_scope = self.declarative_scope().as[PublicPart].do(
            (pp) => match pp.parent {
                case pkg: BasePackageDecl => pkg.private_part
                case ptd: ProtectedDef => ptd.private_part
                case _ => null[PrivatePart]
            }.do((v2) => [v2.decls.as_entity])
        );
        # Finally, look inside decl, in the first declarative region of decl
        val inner_scope = self.declarative_parts()?[0].do((v3) => [v3.decls]);

        enclosing_scope & private_scope & inner_scope
    }

    |" Return the aspect with name ``name`` for this entity.
    @exported
    fun get_aspect_assoc(name: Symbol): Entity[AspectAssoc] = self.get_aspect_spec()?.aspect_assocs.find(
        (asp) => asp.aspect_name(asp.id) == name.image()
    )

    |" Return the expression associated to the aspect with name ``name`` for
    |" this entity.
    @exported
    fun get_aspect_spec_expr(name: Symbol): Entity[Expr] =
        self.get_aspect_assoc(name)?.expr

    |" If this entity is a library item, return the compilation unit pragmas.
    fun library_item_pragmas(): Entity[ASTList[Pragma]] =
        if self.parent is LibraryItem then self.parent.parent.as[CompilationUnit].pragmas
        elif self.parent.parent is LibraryItem then self.parent.parent.parent.as[CompilationUnit].pragmas
        else null[Entity[ASTList[Pragma]]]

    |" Return the aspect with name ``name`` associated to this entity.
    |"
    |" Aspects are properties of entities that can be specified by the Ada
    |" program, either via aspect specifications, pragmas, or attributes.
    |"
    |" See ``DefiningName.P_Get_Aspect`` for more details.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun get_aspect(name: Symbol, previous_parts_only: Bool = false): Aspect =
        self.defining_name_or_raise()?.get_aspect(name, previous_parts_only)

    |" Returns whether the boolean aspect named ``name`` is set on the entity
    |" represented by this node.
    |"
    |" Aspects are properties of entities that can be specified by the Ada
    |" program, either via aspect specifications, pragmas, or attributes.
    |"
    |" "Aspect" is used as in RM terminology (see :rmlink:`13`).
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun has_aspect(name: Symbol, previous_parts_only: Bool = false): Bool =
        self.defining_name_or_raise()?.has_aspect(name, previous_parts_only)

    |" Return the pragma with name ``name`` associated to this entity.
    |"
    |" Please use the ``p_get_aspect`` property instead if you are interested
    |" in aspects, i.e. information that can be represented by either aspect
    |" specification nodes, pragma nodes or attribute definition nodes.
    @exported
    fun get_pragma(name: Symbol): Entity[Pragma] =
        self.defining_name_or_raise()?.get_pragma(name)

    |" Return the representation clause associated to this type decl that
    |" defines the given attribute name.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun get_representation_clause(name: Symbol): Entity[AttributeDefClause] =
        self.defining_name_or_raise()?.get_representation_clause(name)

    |" Return the at clause associated to this declaration.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun get_at_clause(): Entity[AtClause] =
        self.defining_name_or_raise()?.get_at_clause()

    |" Return all the ``Annotate`` aspects defined on this entity, both
    |" through pragmas and aspect specifications. For a type declaration,
    |" this also includes all annotations defined on its from a base type,
    |" when relevant (the field ``inherited`` will be set for those).
    |" See ``DefiningName.P_Get_Annotations`` for more details.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun get_annotations(): Array[Aspect] =
        self.defining_name_or_raise()?.get_annotations()

    |" Return whether this declaration is ghost code or not. See SPARK RM 6.9.
    @exported
    fun is_ghost_code(): Bool = self.defining_name_or_raise()?.is_ghost_code()

    |" Assuming self is a Generic*Internal node (BasicDecl is their greatest
    |" common parent), return the GenericInstantiation node from which this
    |" Generic*Internal node is derived.
    |"
    |" .. ATTENTION:: If this Generic*Internal is not part of an
    |"     instantiation, but has been fetched through the formal generic
    |"     subprogram, this will return None. None is also returned if the
    |"     rebindings do not correspond to the instantiation of this generic
    |"     declaration.
    fun get_instantiation(): Entity[GenericInstantiation] = {
        val inst_node = self.info.rebindings.do(
            (r) => r.new_env.env_node.as![GenericInstantiation]
        );
        val designated_decl = inst_node.as_bare_entity?.designated_generic_decl();

        if designated_decl.node == node.parent then Entity[GenericInstantiation](
            node=inst_node, info=EntityInfo(
                md=Metadata(),
                # Since we return the instantiation itself, remove
                # it from its rebindings.
                rebindings=node.remove_rebindings(
                    self.info.rebindings, designated_decl.info.rebindings
                ), from_rebound=self.info.from_rebound
            )
        ) else null[Entity[GenericInstantiation]]
    }

    |" Whether a BasicDecl is the root decl for its unit.
    @exported
    fun is_compilation_unit_root(): Bool = node.parent.do(
        (p) => match p {
            case _: LibraryItem => true
            case gen_pkg_decl: GenericPackageDecl => gen_pkg_decl.parent.do((p) => p is LibraryItem)
            case _: Subunit => true
            case _ => false
        }
    )

    fun populate_dependent_units(): Array[CompilationUnit] =
        if node.is_compilation_unit_root() then node.top_level_with_package_clauses().map(
            (package_name) => node.withed_unit_helper(package_name)
        ) else null[Array[CompilationUnit]]

    |" Helper property used to determine whether we should add a
    |" referenced_env to the generic formal part of a given entity.
    fun should_ref_generic_formals(): Bool = # We want to reference the generic formal env if:
    (
        # 1. This potential generic body is not a compilation unit root. In
        # that case, the parent is the lexical parent of the body (eg the
        # containing entity), and we need to reference the formals.
        not node.is_compilation_unit_root()
    ) or (
        # 2. This potential generic body is a subunit. In that case,
        # similarly, the parent is the lexical parent of the stub part, and
        # we need to reference the generic formals.
        node.parent is Subunit
    ) or (
        # 3. This is the declaration of a subprogram body. In that case,
        # we should add a reference to the generic formals even for
        # library-level subprograms, because their parent is not their
        # declaration.
        node is BaseSubpBody
    )

    |" Return whether self can be found in a single env query from the given
    |" ``origin`` node.
    fun is_directly_reachable(origin: Entity[AdaNode]): Bool = origin.node.node_env().get(
        node.name_symbol(), categories=RefCategories(inherited_primitives=false, _=true)
    ).contains(node.as_bare_entity)

    |" Return whether this declaration is visible from the point of view of
    |" the given ``origin`` node.
    |"
    |" .. ATTENTION::
    |"
    |"     Only package-level (public or private) declarations are supported
    |"     for now.
    @exported
    fun is_visible(from_node: Entity[AdaNode]): Bool =
        # If entity comes from resolving an actual of the current generic
        # context, we necessarily have visibility on it.
        if self.info.from_rebound then true
        # For synthetic type decls, forward the computation on their
        # specific type.
        elif self is ClasswideTypeDecl | DiscreteBaseSubtypeDecl then self.parent.as[BaseTypeDecl].is_visible(from_node)
        # If self is declared in a private part, check that we can find it
        # from origin's env.
        elif self.is_in_private_part() then node.is_directly_reachable(from_node) and (
            # Even if the above expression is True, we may not have visibility
            # according to Ada rules: in LAL, library-level child packages'
            # parent environments are defined to be their parent packages'
            # private part. The expression below filters out cases where self
            # is declared in the private part of a library-level package and
            # from_node lies in the public part of a child package.
            from_node.enclosing_compilation_unit().has_private_view(from_node.node)
        )
        # If self is declared in a public part, origin has visibility on it
        # iff it has visibility on the parent of self: do a recursive call
        # on the parent scope.
        elif self.is_in_public_part() or self.parent is GenericFormalPackage then node.is_directly_reachable(from_node) or self.parent_basic_decl().is_visible(from_node)
        # If self is declared at the top-level (but is not a subunit), we
        # necessarily have visibility on it.
        elif self.is_compilation_unit_root() and not self.as[Body]?.is_subunit() then true
        # If self is in any other kind of declarative part, we can perform
        # an env query to figure out if we can reach it.
        elif self.parent.do((v1) => v1.parent is DeclarativePart) then node.is_directly_reachable(from_node)
        # Unhandled case: raise PropertyError
        else raise[Bool] PropertyError("Only package-level declaration support visibility checks for now.")

    @with_dynvars(origin)
    fun subp_decl_match_signature(other: Entity[BasicDecl]): Bool = self.subp_spec_or_null().do(
        (spec) => spec.match_signature(
            other.subp_spec_or_null().as![SubpSpec], false
        ), default_val=false
    )

    |" Predicate to check whether ``other``, is a valid renaming of ``self``,
    |" an explicit dereference of an access to a subprogram object.
    @with_dynvars(origin)
    fun access_to_subp_decl_match_signature(other: Entity[BasicDecl]): Bool = (
        self.expr_type().access_def().as[AccessToSubpDef].subp_spec.do(
            (spec) => spec.match_signature(
                other.subp_spec_or_null().as![SubpSpec], false
            ), default_val=false
        )
    )

    |" Predicate to check whether ``other`` is a valid subprogram renaming
    |" of ``self``.
    |"
    |" In case ``other`` is a subprogram renaming of a prefixed view call of
    |" ``self``, subprograms profiles are not fully conformant. The first
    |" parameter of ``self`` has to be ignored when comparing it to
    |" ``other``, and the object designated by ``prefix`` shall be of the type
    |" of the first parameter of ``self``.
    |"
    |" If ``prefix`` doesn't designate an object (but a package for example),
    |" the ``subp_decl_match_signature`` predicate will match.
    |"
    |"   .. code::
    |"
    |"     procedure Entity (X, Y : T);
    |"
    |"     procedure Other (A, B : T) renames Entity; -- Regular subp renaming
    |"
    |"     procedure Other (B : T) renames A.Entity; -- Prefixed view renaming
    @with_dynvars(origin)
    fun subp_renaming_decl_match_signature(prefix: Entity[BasicDecl], other: Entity[BasicDecl]): Bool = (
        # Check first for a regular subprogram renaming
        self.subp_decl_match_signature(other)
    ) or (
        # Then, check for a renaming of a prefixed view call
        self.subp_spec_or_null().do(
            (spec) => not prefix.is_null and (
                # ``self`` shall be a dottable subprogram for the
                # object's type designated by ``prefix``.
                (
                    prefix.expr_type().do((typ) => typ.accessed_type()) or? prefix.expr_type()
                ) == spec.dottable_subp_of()
            ) and (
                # Then signature profiles shall match by ignoring the first
                # parameter of ``self``.
                spec.match_signature(
                    other.subp_spec_or_null().as![SubpSpec], false, ignore_first_param=true
                )
            ), default_val=false
        )
    )

    |" Actual implementation of ``base_subp_declarations`` that already
    |" assumes self is a subprogram.
    @with_dynvars(imprecise_fallback)
    fun base_subp_declarations_impl(): Array[Entity[BasicDecl]] = {
        val parent = self.canonical_part().parent_basic_decl();
        val task_or_protected = parent is ProtectedTypeDecl | TaskTypeDecl;
        # We use `without_md` below because we don't want to take into
        # account self's metadata, as the result of this property
        # shouldn't depend upon how this node was retrieved.
        val spec = self.without_md().as[BasicDecl].subp_spec_or_null();
        # Retrieve an environment that contains all the candidate subprograms
        # that can be base declarations of this one.
        val prims_env = # If we are in a task or protected type, accumulate the primitives
        # of the parent interfaces, and add the subprogram defined in the
        # scope of the protected or task type.
        if task_or_protected then (
            parent.as[BaseTypeDecl].base_types().map((bt) => bt.full_view().primitives_env()) & [parent.children_env()]
        ).env_group() else (
            # For classical types, we can simply fetch the primitives_env
            spec.candidate_primitive_subp_tagged_type(canonicalize=false).do((t) => t.full_view().primitives_env())
        );

        # We don't want the canonicalized primitive type, but the most
        # visible: the most visible might be a private type that has a
        # more specific derivation than the canonical (public) type:
        #
        # type A is tagged private;
        # type B is new A with private;
        # type P is new A with private;
        # private
        # type P is new B with record ...
        # We can call the `candidate_` version because the over-
        # approximation will get cancelled by the following logic.
        prims_env.get(
            self.name_symbol(), lookup=LookupKind.minimal
        ).filtermap(
            (bd) => bd.as[BasicDecl].canonical_part(), (bd) => bd.as[BasicDecl]?.subp_spec_or_null().do(
                (s) => {
                    bind origin = s.origin_node();

                    # Since `s` is retrieved from `t`'s primitives env,
                    # its metadata fields `primitive` and
                    # `primitive_real_type` are set and therefore
                    # the following `match_signature` call will return
                    # true if `s` is overridable by `spec`.
                    s.match_signature(
                        spec, match_name=false, use_entity_info=true, ignore_first_param=task_or_protected
                    )
                }
            )
        ).unique()
    }

    |" If self declares a primitive subprogram of some tagged type T, return
    |" the set of all subprogram declarations that it overrides (including
    |" itself).
    |"
    |" .. note:: for the moment this only works for tagged types. Remains to
    |"     be seen if we need to extend it.
    @exported
    @memoized
    @with_dynvars(imprecise_fallback=false)
    fun base_subp_declarations(): Array[Entity[BasicDecl]] =
        if self.is_subprogram() then self.base_subp_declarations_impl() else null[Array[Entity[BasicDecl]]]

    |" Actual implementation of ``root_subp_declarations`` that already
    |" assumes self is a subprogram.
    @with_dynvars(origin, imprecise_fallback)
    fun root_subp_declarations_impl(): Array[Entity[BasicDecl]] = {
        # Get all the parent overrides defined for this subprogram. That is,
        # if this subprogram is a primitive of some type T and overrides some
        # subprogram P, get all the other overrides of P which are primitives
        # of parent types of T.
        val raw_base_decls = self.base_subp_declarations();
        # If this subprogram is defined in a protected type or task type,
        # we must do things a bit different since the `primitive` metadata
        # field is not set on those subprograms. Fortunately, the reasoning is
        # quite trivial for those cases: since one cannot override a subprogram
        # defined in a protected type or task type, the root subprogram cannot
        # be self unless there is no other base subprogram. So, simply filter
        # self out of the base subp declarations in that case.
        val parent = self.canonical_part().parent_basic_decl();
        val task_or_protected = parent is ProtectedTypeDecl | TaskTypeDecl;
        val base_decls = if task_or_protected and raw_base_decls.length() > 1 then raw_base_decls.filter((bd) => bd.node != node) else raw_base_decls;
        # Compute the set of all such types for which an override is declared
        val base_types = base_decls.map(
            (d) => d.info.md.primitive.as[BaseTypeDecl].as_bare_entity
        ).unique();

        # Among this set of type, find the ones which are not derived from any
        # of the others, i.e. the base-most types on which the original
        # subprogram is declared.
        base_types.filter(
            (t) => not base_types.any((u) => t != u and t.is_derived_type(u))
        ).map(
            # Get back the subprograms declared on the base types
            (root_type) => base_decls.find(
                (d) => d.info.md.primitive == root_type.node
            )
        )
    }

    |" If self declares a primitive subprogram of some tagged type T, return
    |" the root subprogram declarations that it overrides. There can be
    |" several, as in the following scenario:
    |"
    |" - package Root defines the root tagged type T and subprogram Foo.
    |" - package Itf defines interface I and abstract subprogram Foo.
    |" - package D defines "type U is new Root.T and Itf.I" and an overriding
    |"   subprogram Foo.
    |"
    |" Here, root_subp_declarations of Foo defined in package D will return
    |" both Foo from package Root and Foo from package Itf.
    @exported
    @with_dynvars(origin=null[AdaNode], imprecise_fallback=false)
    fun root_subp_declarations(): Array[Entity[BasicDecl]] =
        if self.is_subprogram() then self.root_subp_declarations_impl() else null[Array[Entity[BasicDecl]]]

    |" If self is the declaration of a primitive of some type T, return
    |" the list of all subprogram that override this subprogram among the
    |" given units.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun find_all_overrides(units: Array[AnalysisUnit]): Array[Entity[BasicDecl]] = {
        val spec = self.subp_spec_or_null();
        # We can call the `candidate_` version because the over-approximation
        # will get cancelled by the following logic.
        val prim_type = spec?.candidate_primitive_subp_tagged_type();
        val derivations = prim_type?.find_all_derived_types(units);

        derivations.mapcat(
            (t) => {
                # Get all primitives that are named just like self
                val prims = t.primitives_env().get(self.name_symbol()).map((p) => p.as![BasicDecl]);

                # Retrieve self among the primitives, so that it carries
                # the adequate real_primitive_type metadata field.
                {
                    val base_p = prims.find((p) => p.node == node);

                    prims.filter(
                        (p) => (
                            # Among all the primitives ``p`` available on type
                            # ``t``, keep ``p`` if it both:
                            # is a primitive "owned" by ``t`` (i.e. not an
                            # inherited one).
                            p.info.md.primitive == t.node
                        ) and (
                            # overrides self
                            {
                                bind origin = base_p.origin_node();

                                base_p.subp_spec_or_null().match_signature(
                                    p.subp_spec_or_null(), match_name=false, use_entity_info=true
                                )
                            }
                        )
                    ).map(
                        (p) => p.canonical_part().without_md().as![BasicDecl]
                    )
                }
            }
        ).unique()
    }

    |" Get all the names of this basic declaration.
    @exported
    @abstract
    fun defining_names(): Array[Entity[DefiningName]]

    |" Get the name of this declaration. If this declaration has several
    |" names, it will return the first one.
    @exported
    fun defining_name(): Entity[DefiningName] = self.defining_names()?[0]

    |" Return the defining name of this ``BasicDecl``, if and only if there
    |" is a unique defining name for it. Otherwise, raise a property error.
    fun defining_name_or_raise(): Entity[DefiningName] = {
        val dns = self.defining_names();

        if dns.length() > 1 then raise[Entity[DefiningName]] PreconditionFailure("BasicDecl with multiple defining names") else dns?[0]
    }

    @with_dynvars(origin)
    fun identity_type(): Entity[BaseTypeDecl] = match self {
        case _: ExceptionDecl => node.exc_id_type()
        case _: SingleTaskDecl => node.task_id_type()

        # An object decl on which you can call 'Identity implies that its
        # type is a task type.
        case _: ObjectDecl => node.task_id_type()

        # As well as for for loop variable declarations and parameter
        # specifications.
        case _: ForLoopVarDecl => node.task_id_type()
        case _: BaseFormalParamDecl => node.task_id_type()
        case _ => null[Entity[BaseTypeDecl]]
    }

    @with_dynvars(origin)
    fun is_array(): Bool = self.array_ndims() > 0

    |" If self is a Subp, returns the specification of this subprogram.
    |"
    |" If ``follow_generic`` is True, will also work for instances of
    |" ``GenericSubpDecl``.
    @exported
    fun subp_spec_or_null(follow_generic: Bool = true): Entity[BaseSubpSpec] = match self {
        case subp: BasicSubpDecl => subp.subp_decl_spec()
        case subp: BaseSubpBody => subp.subp_spec
        case subp: SubpBodyStub => subp.subp_spec
        case gsp: GenericSubpDecl => if follow_generic then gsp.subp_decl.subp_spec else null[Entity[SubpSpec]]
        case gsi: GenericSubpInstantiation => if follow_generic then gsi.designated_subp()?.subp_spec_or_null() else null[Entity[SubpSpec]]
        case gsr: GenericSubpRenamingDecl => if follow_generic then gsr.resolve()?.subp_spec_or_null() else null[Entity[SubpSpec]]
        case _ => null[Entity[SubpSpec]]
    }

    fun formal_param_holder_or_null(): Entity[BaseFormalParamHolder] = match self {
        case t: TypeDecl => t.discriminants
        case e: EntryBody => e.params
        case _ => self.subp_spec_or_null()
    }

    |" Return True if self is a subprogram node in the general sense (which
    |" is, an entity that can be called). This includes separates and entries.
    |"
    |" .. attention: This is a purely syntactic query and will return True for
    |"     everything that is a syntactic entity that can be called like a
    |"     subprogram in some contexts, even generic formal subprograms for
    |"     example.
    @exported
    fun is_subprogram(): Bool =
        node is BasicSubpDecl | BaseSubpBody | SubpBodyStub | EntryDecl | GenericSubpDecl | GenericSubpInstantiation | GenericSubpRenamingDecl

    |" Return True if self is a subprogram node that is a valid reducer
    |" candidate as per RM 4.5.10 definition of the reducer program used by
    |" the ``'Reduce`` attribute (Ada 2022).
    fun is_valid_reducer_candidate(): Bool =
        # A reducer candidate can be a function or a procedure
        self.is_subprogram().do(
            (_) => self.subp_spec_or_null().do(
                (spec) => {
                    val param_types = spec.param_types();
                    val return_type = spec.return_type();

                    (
                        # It should have two params
                        param_types.length() == 2
                    ) and (
                        if return_type.is_null then # If it is a procedure, the first param mode should
                        # be `in out` while the second one should be `in`.
                        {
                            val param_modes = spec.param_modes();

                            param_modes?[0] is Mode.InOut and param_modes?[1] is Mode.In | Mode.Default
                        } else (
                            # Else, it is a function, and its return type
                            # should be identical to its first param type.
                            return_type == param_types?[0]
                        )
                    )
                }
            )
        )

    fun is_stream_subprogram_for_type(typ: Entity[BaseTypeDecl], return_obj: Bool): Bool = {
        val root_stream_type = self.get_unit_root_decl(
            [s"Ada", s"Streams"], AnalysisUnitKind.unit_specification
        )?.children_env().get_first(
            s"Root_Stream_Type", lookup=LookupKind.flat
        ).as[BaseTypeDecl].classwide_type().as[BaseTypeDecl];
        val params = self.subp_spec_or_null()?.unpacked_formal_params();

        bind origin = node.origin_node();

        node.is_subprogram()
        and params?[0].formal_decl().formal_type().is_access_to(root_stream_type)
        and (
            if return_obj then
                self.subp_spec_or_null().return_type().matching_formal_type(typ)
            else
                params?[1].formal_decl().formal_type().matching_formal_type(typ)
        )
    }

    |" Return whether this subprogram has the correct profile to be given
    |" as argument to the ``Put_Image`` aspect.
    fun is_put_image_subprogram_for_type(typ: Entity[BaseTypeDecl]): Bool = {
        val root_buffer_type = node.root_buffer_type().classwide_type().as[BaseTypeDecl];
        val params = self.subp_spec_or_null()?.unpacked_formal_params();

        {
            bind origin = node.origin_node();

            (
                node.is_subprogram() and params?[0].formal_decl().formal_type().matching_formal_type(root_buffer_type)
            ) and params?[1].formal_decl().formal_type().matching_formal_type(typ)
        }
    }

    |" Return true if entity can be a paramless subprogram entity, when used
    |" in an expression context.
    fun can_be_paramless(): Bool = self.subp_spec_or_null().do(
        (ss) => ss.paramless(self.info.md.dottable_subp, can_be=true), default_val=true
    )

    |" Return true if entity is a paramless subprogram entity, when used
    |" in an expression context.
    fun is_paramless(): Bool = self.subp_spec_or_null().do(
        (ss) => ss.paramless(self.info.md.dottable_subp, can_be=false), default_val=true
    )

    |" Return the relative name for self. If self's defining name is
    |" ``A.B.C``, return ``C`` as a node.
    @exported
    fun relative_name(): Entity[Name] = self.defining_name()?.relative_name()

    |" Return the relative name for self, as text.
    @exported
    fun relative_name_text(): Symbol = self.relative_name()?.name_symbol()

    fun name_symbol(): Symbol =
        node.as_bare_entity.relative_name().name_symbol()

    |" Return the body corresponding to this declaration, if applicable.
    |"
    |" .. note:: It is not named body_part, subclasses have more precise
    |"     versions named body_part and returning a more precise result.
    |"     Probably, we want to rename the specific versions, and have the
    |"     root property be named body_part. (TODO R925-008)
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun body_part_for_decl(): Entity[Body] = self.next_part_for_decl().do(
        (np) => match np {
            case stub: BodyStub => stub.next_part_for_decl()
            case other => other
        }
    ).as[Body]

    |" Return the canonical part for this decl. In the case of decls composed
    |" of several parts, the canonical part will be the first part.
    @with_dynvars(imprecise_fallback=false)
    fun canonical_part_for_name(sym: Symbol): Entity[BasicDecl] = self.previous_part_for_name(sym).do(
        (pp) => pp.canonical_part_for_name(sym), default_val=self
    )

    |" Given an origin node and the entity represented by self, this property
    |" returns the most visible completion of self that can be seen by origin,
    |" according to Ada's visibility rules.
    @exported
    @with_dynvars(origin, imprecise_fallback=false)
    fun most_visible_part(): Entity[BasicDecl] = self.most_visible_part_for_name(
        self.defining_name_or_raise().name_symbol()
    )

    |" Internal method for computing the most visible part (going forward or
    |" backwards) of a basic decl according to one of its defining names.
    @with_dynvars(origin, imprecise_fallback)
    fun most_visible_part_for_name(sym: Symbol, only_backwards: Bool = false): Entity[BasicDecl] = {
        # Note that for optimization purposes, we only try to go backwards if
        # this part is in a private part, because that's what is required to
        # implement correct name resolution. Making it work in any
        # circumstances would be more useful for users but does slowdown
        # name resolution, so should probably be done in a wrapper property
        # which we can bypass internally. The complete behavior can be enabled
        # by removing the condition on ``is_in_private_part`` below.
        val self_is_visible = (
            origin.is_null or not self.is_in_private_part()
        ) or self.is_visible(origin.as_bare_entity);

        # If this part is not visible, check if the previous part is, If
        # there is no previous part, return a null node.
        if not self_is_visible then self.previous_part_for_name(sym).do(
            (pp) => pp.most_visible_part_for_name(sym, only_backwards=true)
        )
        # This part is visible but we only want to go backwards, so stop
        # here.
        elif only_backwards then self
        # This part is visible, now check if the next part is as well
        else self.most_visible_forward_part_for_name(sym, seq=true)
    }

    |" Internal method for computing the most visible part (only looking
    |" forward) of a basic decl according to one of its defining names.
    |" If ``seq`` is True, the visibility check is sequential: if a next
    |" part is in the same unit as the origin but defined after it, it will
    |" not be considered visible.
    @with_dynvars(origin, imprecise_fallback=false)
    fun most_visible_forward_part_for_name(sym: Symbol, seq: Bool): Entity[BasicDecl] = {
        val np = self.next_part_for_name(sym);

        # This is already the most visible part
        if np.is_null then self
        # A null origin means any "find the most complete part"
        elif origin.is_null then np.most_visible_forward_part_for_name(sym, seq)
        # The query is sequential and origin can't see the next part
        elif (seq and origin.unit() == np.unit()) and origin <= np.node then self
        # If the entity is not a package declaration, we only need to check
        # if its lexical env is one of the parents of origin's env.
        elif not (
            np.is_in_private_part() or np.is_in_public_part()
        ) then if origin.node_env().get(
            sym, categories=RefCategories(inherited_primitives=false, _=true)
        ).contains(node.as_bare_entity) then np.most_visible_forward_part_for_name(sym, seq) else self
        # Otherwise this is a package declaration, so we can use the
        # is_visible property.
        elif np.is_visible(origin.as_bare_entity) then np.most_visible_forward_part_for_name(sym, seq)
        # Otherwise this was the most visible part
        else self
    }

    |" Return the extra suffix that should be appended to the fully qualified
    |" name of this declaration, for example to append ``'Class`` to classwide
    |" type declarations, etc.
    fun fqn_extra_suffix(): String = if self is ClasswideTypeDecl then "'Class"
    elif self is DiscreteBaseSubtypeDecl then "'Base"
    # For the moment, SynthAnonymousTypeDecl is used solely to
    # generate anonymous access types. We give those a name.
    # NOTE: this is not an Ada type as per the RM, and is used
    # for the GNAT specific 'Unrestricted_Access attribute, so
    # we give this type a name that doesn't exist in the RM
    # either.
    elif self is SynthAnonymousTypeDecl then "'Anonymous_Access"
    else ""

    |" Return the fully qualified name corresponding to this declaration, as
    |" an array of symbols.
    fun fully_qualified_name_string_array(include_profile: Bool = false): Array[String] =
        self.defining_name_or_raise().fully_qualified_name_impl(
            include_profile=include_profile, suffix=self.fqn_extra_suffix()
        )

    |" Return the fully qualified name corresponding to this declaration, as
    |" an array of symbols.
    @exported
    fun fully_qualified_name_array(include_profile: Bool = false): Array[Symbol] =
        self.fully_qualified_name_string_array(include_profile=include_profile).map((t) => t.to_symbol)

    |" Return the fully qualified name corresponding to this declaration.
    @exported
    fun fully_qualified_name(): String =
        ".".join(self.fully_qualified_name_string_array())

    |" Return a canonical representation of the fully qualified name
    |" corresponding to this declaration.
    @exported
    fun canonical_fully_qualified_name(): String =
        self.defining_name_or_raise().canonical_fully_qualified_name_impl(
            include_profile=false, suffix=self.fqn_extra_suffix()
        )

    |" Return a unique identifying name for this declaration, provided this
    |" declaration is a public declaration. In the case of subprograms, this
    |" will include the profile.
    |"
    |" .. attention::
    |"     This will only return a unique name for public declarations.
    |"     Notably, anything nested in an unnamed declare block won't be
    |"     handled correctly.
    @exported
    fun unique_identifying_name(): String =
        self.defining_name_or_raise().unique_identifying_name_impl(suffix=self.fqn_extra_suffix())

    fun custom_id_text(): String = self.subp_spec_or_null().do(
        # For subprograms, we'll compute their profiles as the unique
        # identifying text.
        (ss) => "(" & ss.returns().do((_) => "(") & ss.unpacked_formal_params().do(
            (ufp) => ", ".join(ufp.map(
                (p) => p.formal_decl().type_expression().custom_id_text()
            ))
        ) & ss.returns().do((_) => ")") & ss.returns().do((r) => " -> " & r.custom_id_text()) & ")", default_val=""
    )

    |" Implementation helper for ``CompilationUnit.is_preelaborable``.
    |"
    |" Return whether ``self`` has aspects that make it preelaborable.
    |"
    |" If ``from_body``, consider that ``self`` is a spec and that we are
    |" computing whether its body is preelaborable.
    fun does_aspects_make_preelaborable(from_body: Bool): Bool = {
        bind imprecise_fallback = false;

        (
            # The following aspects apply to bodies...
            self.has_aspect(s"Pure")
        ) or self.has_aspect(s"Preelaborate") or self.has_aspect(s"Shared_Passive") or (
            not from_body and (
                (
                    # ... but the ones below apply only to specs
                    self.has_aspect(s"Remote_Types")
                ) or self.has_aspect(s"Remote_Call_Interface")
            )
        )
    }

    |" Return a public-friendly view of this entity. For now this only needs
    |" to handle the case where self is a ``GenericSubpInternal``, in which
    |" case we prefer to return its parent ``GenericSubpInstantiation`` node.
    |"
    |" .. attention:: Properties typically use ``wrap_public_reference`` to
    |"     sanitize their return value for users. Sometimes however, those
    |"     properties end up being used by internal properties for practical
    |"     reasons, meaning those properties will work on biased values,
    |"     which could become problematic. Moreover, as of yet this property
    |"     only exists to handle the ``GenericSubpInternal`` case, which could
    |"     actually be addressed cleanly in at least two different ways:
    |"
    |"     - By adding interfaces to langkit, so that a
    |"       ``GenericSubpInstantiation`` could be both a
    |"       ``GenericInstantiation`` and a ``BasicSubpDecl``.
    |"
    |"     - By also working with ``GenericSubpInstantiation`` nodes
    |"       internally. This mostly means getting rid of
    |"       ``GenericSubpInternal`` nodes in the envs.
    fun wrap_public_reference(): Entity[BasicDecl] =
        if self is GenericSubpInternal | GenericPackageInternal then self.get_instantiation() or? self else self

    |" If this is a child declaration, return the lexical environment name of
    |" its parent declaration. Otherwise return an empty string.
    |"
    |" If ``private_part`` is True, return the env name of the private part
    |" of its parent.
    fun child_decl_initial_env_name(private_part: Bool = false): Symbol = {
        val defining_name = node.as_bare_entity.defining_name();
        val child_name = defining_name.name.as[DottedName];

        # The standard package is the only library item that does not have
        # a named parent.
        if defining_name.text().to_symbol == s"standard" then null[Symbol]
        elif node.is_library_item() then child_name.do((n) =>
            # If this declaration's name is a dotted name, use the prefix
            # to retrieve the name of its parent.
            if private_part then (n.prefix.text() & ".__privatepart").to_symbol else n.prefix.text().to_symbol, default_val=s"standard"
        )
        # If it's not a dotted name, its parent is the standard package
        # This declaration
        else null[Symbol]
    }

    |" Return the previous part for this decl, if applicable.
    |"
    |" .. note:: It is not named previous_part, because BaseTypeDecl has a
    |"     more precise version of previous_part that returns a BaseTypeDecl.
    |"     Probably, we want to rename the specific versions, and have the
    |"     root property be named previous_part. (TODO R925-008)
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun previous_part_for_decl(): Entity[BasicDecl] = match self {
        case btd: BaseTypeDecl => btd.previous_part(true).as[BasicDecl]
        case bd: Body => bd.previous_part_internal()
        case _ => null[Entity[BasicDecl]]
    }

    |" Return whether this declaration is static.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun is_static_decl(): Bool = false

    |" Given a generic formal entity inside a generic context, return the
    |" actual that was used to instantiate it.
    fun corresponding_actual(): Entity[BasicDecl] = self

    |" Return whether this is a top-level element.
    fun is_library_item(): Bool = node.parent is LibraryItem

    |" Return the declarative parts directly associated to this BasicDecl, if
    |" any.
    fun declarative_parts(): Array[Entity[DeclarativePart]] =
        null[Array[Entity[DeclarativePart]]]

    |" Return the actual AspectSpec to use for this entity. This is typically
    |" overriden by internal nodes that act as wrappers around the concrete
    |" nodes on which the aspects are defined.
    fun get_aspect_spec(): Entity[AspectSpec] = self.aspects

    |" Whether this declaration is imported from another language.
    @exported
    fun is_imported(): Bool = self.defining_name_or_raise()?.is_imported()

    fun is_in_public_part(): Bool = node.parent.parent is PublicPart

    fun is_in_private_part(): Bool = node.parent.parent is PrivatePart

    |" Return a lexical environment that contains entities that are accessible
    |" as suffixes when self is a prefix.
    @with_dynvars(origin, include_ud_indexing=false, dottable_type=null[AdaNode])
    fun defining_env(): LexicalEnv = null[LexicalEnv]

    @with_dynvars(origin)
    fun array_ndims(): Int = self.expr_type().array_ndims()

    |" Return the type declaration corresponding to this basic declaration
    |" has when it is used in an expression context. For example, for this
    |" basic declaration::
    |"
    |"     type Int is range 0 .. 100;
    |"
    |"     A : Int := 12;
    |"
    |" the declaration of the Int type will be returned. For this
    |" declaration::
    |"
    |"     type F is delta 0.01 digits 10;
    |"
    |"     function B return F;
    |"
    |" expr_type will return the declaration of the type F.
    @with_dynvars(origin)
    fun expr_type(): Entity[BaseTypeDecl] =
        self.type_expression().do((te) => te.designated_type())

    |" Return the type expression for this BasicDecl if applicable, a null
    |" otherwise.
    @exported
    fun type_expression(): Entity[TypeExpr] = null[TypeExpr].as_entity

    |" This method is used when self is a candidate suffix in a dotted
    |" expression, to express the potential constraint that the suffix could
    |" express on the prefix.
    |"
    |" For example, given this code::
    |"
    |"     1 type P is record
    |"     2     A, B : Integer;
    |"     3 end record;
    |"     4
    |"     5 P_Inst : P;
    |"     7
    |"     8 P_Inst.A;
    |"       ^^^^^^^^
    |"
    |" A references the A ComponentDecl at line 2, and the constraint that we
    |" want to express on the prefix (P_Inst), is that it needs to be of type
    |" P.
    @with_dynvars(origin)
    fun constrain_prefix(@ignored prefix: Expr): Equation =
        # Default implementation returns logic true => does not add any
        # constraint to the xref equation.
        %true

    |" Return the next part of this declaration, if applicable.
    |"
    |" .. note:: It is not named next_part, because BaseTypeDecl has a
    |"     more precise version of next_part that returns a BaseTypeDecl.
    |"     Probably, we want to rename the specific versions, and have the
    |"     root property be named next_part. (TODO R925-008)
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun next_part_for_decl(): Entity[BasicDecl] = {
        # Fetch the library level body unit that might contain the next part
        # for this declaration.
        val _ = match node.enclosing_compilation_unit().decl() {
            case _: Body => null[CompilationUnit]
            case b: BasicDecl => b.as_bare_entity?.defining_name()?.referenced_unit(
                AnalysisUnitKind.unit_body, not_found_is_error=not (
                    (
                        # Body not mandatory if the library level declaration
                        # is a package (regular, generic, or instantiated). We
                        # don't try to be more precise than that.
                        b is BasePackageDecl | GenericPackageDecl | GenericInstantiation | PackageRenamingDecl | SubpRenamingDecl | GenericRenamingDecl
                    ) or (
                        # A body is not expected if the library level
                        # declaration is an imported subprogram.
                        b is BasicSubpDecl | GenericSubpDecl and (
                            # Now that get_aspect looks in all parts, we must
                            # not call has_aspect("Import") from here to avoid
                            # infinite recursion.
                            not b.as_entity.do(
                                (e) => e.get_aspect_assoc(s"Import") or? e.get_pragma(s"Import")
                            ).is_null
                        )
                    )
                )
            )
        };

        self.children_env().get_first(
            s"__nextpart", lookup=LookupKind.minimal, categories=RefCategories(inherited_primitives=false, _=true)
        ).as[BasicDecl]
    }

    |" Internal method for computing the next part of a basic decl according
    |" to one of its defining names. By default, this property behaves just
    |" like ``next_part_for_decl``. However it can be overridden for node
    |" types for which the next part depends on the defining name to consider.
    |" One example of that are constant declarations:
    |"
    |" .. code:: ada
    |"
    |"     package Pkg is
    |"         X, Y : constant Integer;
    |"     private
    |"         X : constant Integer := 1;
    |"         Y : constant Integer := 2;
    |"     end Pkg;
    |"
    |" So, ``next_part_for_name`` is overridden in ``ObjectDecl``.
    @with_dynvars(imprecise_fallback=false)
    fun next_part_for_name(@ignored sym: Symbol): Entity[BasicDecl] =
        self.next_part_for_decl()

    |" Internal method for computing the previous part of a basic decl
    |" according to one of its defining names. By default, this property
    |" behaves just like ``next_part_for_decl``. However it can be overridden
    |" for node types for which the previous part depends on the defining name
    |" to consider. One example of that are subprogram parameters:
    |"
    |" .. code:: ada
    |"
    |"     package Pkg is
    |"         X : constant Integer;
    |"         Y : constant Integer;
    |"     private
    |"         X, Y : constant Integer := 1;
    |"     end Pkg;
    |"
    |" So, ``previous_part_for_name`` is overridden in ``ObjectDecl``.
    @with_dynvars(imprecise_fallback=false)
    fun previous_part_for_name(@ignored sym: Symbol): Entity[BasicDecl] =
        self.previous_part_for_decl()

    |" Return whether this object is constant or not.
    @exported
    fun is_constant_object(): Bool = raise[Bool] PropertyError("Property BasicDecl.is_constant_object not implemented")
}

|" Contained (directly or indirectly) in an AbstractStateDeclExpr, and is used
|" to represent the BasicDecl associated with the abstract state introduced by
|" the Abstract_State aspect. This node is necessary because all of our name
|" resolution routines expect BasicDecls as environments' values.
|"
|" The only purpose of this node is to populate the env with the abstract
|" state declared through this node, so it can be referred in SPARK aspects
|" such as Global, Depends, Refined_State, etc.
class AbstractStateDecl: BasicDecl {
    @parse_field name: DefiningName
    @parse_field aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] = [self.name]

    fun type_expression(): Entity[TypeExpr] = null[Entity[TypeExpr]]

    env_spec {
        add_to_env_kv(node.name.name_symbol(), node)
    }
}

|" Represents a anonymous declaration that holds an expression.
|"
|" This is used to store the results of queries such as ``referenced_decl``
|" called on references to object formals from inside a instantiated generic
|" in order to return the relevant actual.
|"
|" Indeed, ``referenced_decl`` must return a ``BasicDecl``, but actuals of
|" generic instantiations are ``Expr``. This wrapper node is therefore a
|" way to both satisfy the ``BasicDecl`` interface, and provide to the user
|" the expression of the actual through the ``expr`` field.
@synthetic
class AnonymousExprDecl: BasicDecl {
    |" Return the expression wrapped by this declaration.
    @parse_field expr: Expr
    @parse_field @null_field aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] =
        null[Array[Entity[DefiningName]]]

    @with_dynvars(origin, include_ud_indexing=false, dottable_type=null[AdaNode])
    fun defining_env(): LexicalEnv =
        self.type_expression().defining_env()

    |" Return the generic formal object declaration corresponding to this
    |" actual.
    @exported
    @memoized
    @with_dynvars(imprecise_fallback=false)
    fun get_formal(): Entity[DefiningName] = {
        val assoc = self.expr.parent.as[BasicAssoc];

        assoc.get_params()?[0]
    }

    |" Internal property that actually retrieves the type expression. Since
    |" this property requires non-trivial computation and is used during
    |" name resolution, it's important for the ``get_formal`` to be memoized.
    fun type_expression(): Entity[TypeExpr] =
        self.get_formal().basic_decl().type_expression()

    @with_dynvars(imprecise_fallback=false)
    fun is_static_decl(): Bool = self.expr.is_static_expr()
}

|" Base class for formal parameter declarations. This is used both for records
|" components and for subprogram parameters.
|"
|" This is a Libadalang abstraction, that has no ARM existence.
@abstract
class BaseFormalParamDecl: BasicDecl {
    |" Return the type for this formal.
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun formal_type(): Entity[BaseTypeDecl] =
        self.type_expression()?.designated_type()

    fun parent_decl(): Entity[BasicDecl] =
        self.semantic_parent().as[BasicDecl]

    fun get_param(part: Entity[BasicDecl], param: Symbol): Entity[DefiningName] = part.do(
        (d) => d.formal_param_holder_or_null()?.unpacked_formal_params().find((sf) => sf.name_is(param))
    )

    |" If self is a ParamSpec of a subprogram body or of an accept stmt, go
    |" fetch the equivalent spec in the subprogram decl.
    @with_dynvars(imprecise_fallback=false)
    fun decl_param(param: Entity[DefiningName]): Entity[DefiningName] = self.get_param(
        match self.semantic_parent() {
            case body: BaseSubpBody => body.decl_part()
            case accept: AcceptStmt => accept.corresponding_entry()
            case _ => null[Entity[BasicDecl]]
        }, param.name_symbol()
    ) or? param

    @with_dynvars(imprecise_fallback=false)
    fun next_part_for_name(sym: Symbol): Entity[BasicDecl] = self.get_param(
        self.parent_decl()?.next_part_for_decl(), sym
    )?.basic_decl()

    @with_dynvars(imprecise_fallback=false)
    fun previous_part_for_name(sym: Symbol): Entity[BasicDecl] = self.get_param(
        self.parent_decl()?.previous_part_for_decl(), sym
    )?.basic_decl()

    @with_dynvars(imprecise_fallback=false)
    fun next_part_for_decl(): Entity[BasicDecl] =
        self.next_part_for_name(self.name_symbol())

    @with_dynvars(imprecise_fallback=false)
    fun previous_part_for_decl(): Entity[BasicDecl] =
        self.previous_part_for_name(self.name_symbol())

    fun is_mandatory(): Bool = false
}

|" Declaration for a component (:rmlink:`3.8`).
class ComponentDecl: BaseFormalParamDecl {
    @parse_field ids: ASTList[DefiningName]
    @parse_field component_def: ComponentDef
    @parse_field @nullable default_expr: Expr
    @parse_field aspects: AspectSpec

    |" See BasicDecl.defining_env
    @with_dynvars(origin, include_ud_indexing=false, dottable_type=null[AdaNode])
    fun defining_env(): LexicalEnv =
        self.component_def.type_expr.defining_env()

    fun defining_names(): Array[Entity[DefiningName]] =
        node.ids.map((i) => i.as_entity)

    @with_dynvars(origin)
    fun array_ndims(): Int = self.component_def.type_expr.array_ndims()

    fun type_expression(): Entity[TypeExpr] =
        node.component_def.type_expr.as_entity

    fun is_constant_object(): Bool = false

    @with_dynvars(origin)
    fun constrain_prefix(prefix: Expr): Equation =
        # If self is a component of a SingleProtectedDecl or
        # ProtectedTypeDecl, do not constrain the equation further since
        # they do not have a type.
        if node.parents().any((p) => p is ProtectedDef) then %true else (
            # The expected type of the prefix is the record type of this
            # component.
            %eq(prefix.expected_type_var(), self.container_type()) and prefix.matches_expected_prefix_type()
        )

    |" Return the defining container type for this component declaration.
    fun container_type(): Entity[BaseTypeDecl] =
        node.parents().find((p) => p is BaseTypeDecl).as[BaseTypeDecl].as_entity

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        val typ = self.expr_type();

        self.component_def.type_expr.sub_equation() and self.default_expr.do(
            (de) => (
                %eq(de.expected_type_var(), typ) and de.sub_equation()
            ) and de.matches_expected_assign_type(), default_val=%true
        )
    }

    fun xref_entry_point(): Bool = true

    env_spec {
        add_to_env(node.env_mappings(node.ids, node))
    }
}

|" Known list of discriminants in type declarations (:rmlink:`3.7`).
class DiscriminantSpec: BaseFormalParamDecl {
    @parse_field ids: ASTList[DefiningName]
    @parse_field type_expr: TypeExpr
    @parse_field @nullable default_expr: Expr
    @parse_field aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] =
        node.ids.map((id) => id.as_entity)

    @with_dynvars(origin, include_ud_indexing=false, dottable_type=null[AdaNode])
    fun defining_env(): LexicalEnv = self.type_expr.defining_env()

    fun type_expression(): Entity[TypeExpr] = self.type_expr

    fun xref_entry_point(): Bool = true

    fun is_constant_object(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.type_expr.sub_equation() and self.default_expr.do(
            (de) => (
                %eq(de.expected_type_var(), self.expr_type()) and de.sub_equation()
            ) and de.matches_expected_assign_type(), default_val=%true
        )

    env_spec {
        add_to_env(node.env_mappings(node.ids, node))
    }
}

|" Enclosing declaration for a generic formal. The real declaration is
|" accessible via the ``decl`` field.
@abstract
class GenericFormal: BaseFormalParamDecl {
    @parse_field decl: BasicDecl
    @parse_field @null_field aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] =
        self.decl.defining_names()

    fun type_expression(): Entity[TypeExpr] = self.decl.type_expression()
}

|" Formal declaration for an object.
class GenericFormalObjDecl: GenericFormal {
}

|" Formal declaration for a package (:rmlink:`12.1`).
class GenericFormalPackage: GenericFormal {
}

|" Formal declaration for a subprogram (:rmlink:`12.1`).
class GenericFormalSubpDecl: GenericFormal {
}

|" Formal declaration for a type (:rmlink:`12.1`).
class GenericFormalTypeDecl: GenericFormal {
    fun default_type(): Entity[BaseTypeDecl] = match self.decl {
        case ft: FormalTypeDecl => ft.default_type
        case ift: IncompleteFormalTypeDecl => ift.default_type
        case _ => null[Entity[Name]]
    }?.name_designated_type()
}

|" Specification for a parameter (:rmlink:`6.1`).
class ParamSpec: BaseFormalParamDecl {
    @parse_field ids: ASTList[DefiningName]
    @parse_field has_aliased: Aliased
    @parse_field @nullable mode: Mode
    @parse_field type_expr: TypeExpr
    @parse_field @nullable default_expr: Expr
    @parse_field aspects: AspectSpec

    fun is_mandatory(): Bool = node.default_expr.is_null

    fun defining_names(): Array[Entity[DefiningName]] =
        node.ids.map((id) => id.as_entity)

    fun type_expression(): Entity[TypeExpr] = self.type_expr

    fun is_constant_object(): Bool = node.mode is Mode.In | Mode.Default

    @with_dynvars(origin, include_ud_indexing=false, dottable_type=null[AdaNode])
    fun defining_env(): LexicalEnv = self.type_expr.defining_env()

    @with_dynvars(origin)
    fun constrain_prefix(prefix: Expr): Equation =
        # If a dotted name refers to a parameter, it's necessarily because of
        # fully qualified name access, and thus the prefix of the dotted name
        # is the enclosing subprogram and must:
        #  - not have a type.
        #  - not have a called subp spec.
        %eq(prefix.type_var(), null[Entity[BaseTypeDecl]]) and prefix.as[Name].do(
            (name) => %eq(name.subp_spec_var(), null[Entity[BaseFormalParamHolder]]), default_val=%false
        )

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        val typ = self.expr_type();

        self.type_expr.sub_equation() and self.default_expr.do(
            (de) => (
                %eq(de.expected_type_var(), typ) and de.sub_equation()
            ) and de.matches_expected_assign_type(), default_val=%true
        )
    }

    fun xref_entry_point(): Bool = true

    env_spec {
        add_to_env(node.env_mappings(node.ids, node))
    }
}

|" Synthetic parameter declaration.
@synthetic
class SyntheticFormalParamDecl: BaseFormalParamDecl {
    param_name: Symbol
    @parse_field param_type: TypeExpr
    @parse_field @null_field aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] =
        [node.synthesize_defining_name(node.param_name).as_entity]

    fun is_mandatory(): Bool = true

    fun type_expression(): Entity[TypeExpr] = self.param_type

    fun corresponding_actual(): Entity[BasicDecl] = self
}

|" Base class for package declarations. This will be used
|" both for non-generic package declarations (via :typeref:`PackageDecl`) and
|" for generic ones (via :typeref:`GenericPackageInternal`).
@abstract
class BasePackageDecl: BasicDecl {
    @parse_field package_name: DefiningName
    @parse_field aspects: AspectSpec
    @parse_field public_part: PublicPart
    @parse_field @nullable private_part: PrivatePart
    @parse_field @nullable end_name: EndName

    fun defining_names(): Array[Entity[DefiningName]] = [self.package_name]

    @with_dynvars(origin, include_ud_indexing=false, dottable_type=null[AdaNode])
    fun defining_env(): LexicalEnv = self.children_env()

    |" Return the PackageBody corresponding to this node.
    @exported
    fun body_part(): Entity[PackageBody] = {
        bind imprecise_fallback = false;

        self.body_part_for_decl().as[PackageBody]
    }

    fun declarative_parts(): Array[Entity[DeclarativePart]] =
        [self.public_part.as[DeclarativePart]] & self.private_part.as[DeclarativePart].do((v1) => [v1])

    |" Return the env names that this package defines. Make sure to include
    |" the ``.__privatepart`` env name if this package doesn't have a private
    |" part, as some construct will always try to register themselves in the
    |" private part and therefore expect it to always be defined.
    fun env_names(): Array[Symbol] = {
        val fqn = node.top_level_env_name();

        fqn.do(
            (fqn) => if not node.private_part.is_null then [fqn.to_symbol] else [fqn.to_symbol, (fqn & ".__privatepart").to_symbol]
        )
    }
}

# Implementation note: This exists so that we can insert an environment to
# distinguish between formal parameters and the package's contents.
|" This class denotes the internal package contained by a GenericPackageDecl.
class GenericPackageInternal: BasePackageDecl {
    |" Return whether this is a top-level element.
    fun is_library_item(): Bool = node.parent.parent is LibraryItem

    env_spec {
        add_env(names=node.env_names())
    }
}

|" Non-generic package declarations (:rmlink:`7.1`).
class PackageDecl: BasePackageDecl {
    env_spec {
        do(node.env_hook())
        set_initial_env(
            # TODO: This is wrong (should take into account whether the entity
            # is private or not), but we have no example of cases where this is
            # a problem yet.
            node.child_decl_initial_env(true)
        )
        add_to_env(self.child_decl_env_assocs())
        add_env(names=node.env_names())
        do(node.populate_dependent_units())
        reference(
            node.top_level_use_package_clauses(), Name.use_package_name_designated_env, cond=node.parent is LibraryItem | Subunit
        )
        reference(
            node.top_level_use_type_clauses(), Name.name_designated_type_env, cond=node.parent is LibraryItem | Subunit
        )
    }
}

|" Base class for type declarations. It unifies every kind of type that exists
|" in Ada, including types that have no source existence like classwide types.
@abstract
class BaseTypeDecl: BasicDecl {
    @parse_field @nullable name: DefiningName

    fun defining_names(): Array[Entity[DefiningName]] = [self.name]

    |" If this type decl is a subtype decl, return the base subtype. If not,
    |" return ``self``.
    @exported
    @memoized
    @with_dynvars(origin=null[AdaNode])
    fun base_subtype(): Entity[BaseTypeDecl] = match self {
        case db: DiscreteBaseSubtypeDecl => db
        case st: BaseSubtypeDecl => st.get_type().base_subtype()
        case _ => self
    }

    @memoized
    fun anonymous_access_type(): Entity[BaseTypeDecl] = SynthAnonymousTypeDecl(
        name=node.name, discriminants=null[DiscriminantPart], type_def=AnonymousTypeAccessDef(
            has_not_null=null[NotNull], type_decl=node
        )
    ).as[BaseTypeDecl].as_entity

    fun anonymous_access_type_or_null(): Entity[BaseTypeDecl] =
        self?.anonymous_access_type()

    @lazy
    attributes_repo: TypeAttributesRepository =
        TypeAttributesRepository(base_type=node)

    |" Return the synthetic declaration of the built-in subprogram denoted by
    |" the given attribute name and defined on this type.
    fun synthesize_attribute_subprogram(attr_name: Symbol): Entity[BasicSubpDecl] = {
        val repo = node.attributes_repo;
        val subp = if attr_name == s"succ" then repo.succ
        elif attr_name == s"pred" then repo.pred
        elif attr_name == s"min" then repo.min
        elif attr_name == s"max" then repo.max
        elif attr_name == s"round" then repo.round
        elif attr_name == s"rounding" then repo.rounding
        elif attr_name == s"unbiased_rounding" then repo.unbiased_rounding
        elif attr_name == s"ceiling" then repo.ceiling
        elif attr_name == s"floor" then repo.floor
        elif attr_name == s"truncation" then repo.truncation
        elif attr_name == s"machine" then repo.machine
        elif attr_name == s"machine_rounding" then repo.machine_rounding
        elif attr_name == s"fraction" then repo.fraction
        elif attr_name == s"exponent" then repo.exponent
        elif attr_name == s"copy_sign" then repo.copy_sign
        elif attr_name == s"remainder" then repo.remainder
        elif attr_name == s"adjacent" then repo.adjacent
        elif attr_name == s"scaling" then repo.scaling
        elif attr_name == s"compose" then repo.compose
        elif attr_name == s"leading_part" then repo.leading_part
        elif attr_name == s"mod" then repo.mod
        elif attr_name == s"image" then repo.image
        elif attr_name == s"wide_image" then repo.wide_image
        elif attr_name == s"wide_wide_image" then repo.wide_wide_image
        elif attr_name == s"put_image" then repo.put_image
        elif attr_name == s"value" then repo.value
        elif attr_name == s"wide_value" then repo.wide_value
        elif attr_name == s"wide_wide_value" then repo.wide_wide_value
        elif attr_name == s"fixed_value" then repo.fixed_value
        elif attr_name == s"integer_value" then repo.integer_value
        elif attr_name == s"pos" then repo.pos
        elif attr_name == s"val" then repo.val_attr
        elif attr_name == s"enum_rep" then repo.enum_rep
        elif attr_name == s"enum_val" then repo.enum_val
        elif attr_name == s"read" then repo.read
        elif attr_name == s"write" then repo.write
        elif attr_name == s"input" then repo.input
        elif attr_name == s"output" then repo.output
        elif attr_name == s"asm_input" then repo.asm_input
        elif attr_name == s"asm_output" then repo.asm_output
        elif attr_name == s"model" then repo.model
        else null[BasicSubpDecl];

        Entity[BasicSubpDecl](
            node=subp, info=EntityInfo(
                md=null[Metadata], rebindings=self.info.rebindings, from_rebound=self.info.from_rebound
            )
        )
    }

    |" Return the subprogram declaration denoted by this attribute name and
    |" defined on this type.
    @exported
    fun attribute_subprogram(attr_name: Symbol): Entity[BasicDecl] =
        if attr_name in s"read" | s"write" | s"input" | s"output" then self.get_representation_clause(attr_name).do(
            (x) => x.expr.as![Name].referenced_decl(), default_val=self.synthesize_attribute_subprogram(attr_name)
        )
        elif attr_name == s"put_image" then self?.get_aspect(s"put_image").value.as[Name].do(
            (n) => n.referenced_decl(), default_val=self.synthesize_attribute_subprogram(attr_name)
        )
        else self.synthesize_attribute_subprogram(attr_name)

    |" Return the private completion for this type, if there is one.
    @exported
    @memoized
    fun private_completion(): Entity[BaseTypeDecl] =
        self.declarative_scope().as[PublicPart]?.parent.as[BasePackageDecl]?.private_part?.decls.find(
            (d) => d.as[BaseTypeDecl].do(
                (pp) => pp.name_symbol() == self.name_symbol()
            )
        ).do(
            (t) => Entity[BaseTypeDecl](
                node=t.as[BaseTypeDecl], info=EntityInfo(
                    # Do not propagate the "metadata" and "from_rebound"
                    # information to the next part, as these only apply to
                    # the original part.
                    md=null[Metadata],
                    rebindings=self.info.rebindings,
                    from_rebound=false
                )
            )
        )

    @with_dynvars(origin)
    fun is_array_or_rec(): Bool = not node.is_null and (
        (self.is_array() or self.is_record_type()) or (
            # Also consider container aggregates as array or rec
            origin is BracketAggregate and self.has_aspect(s"Aggregate")
        )
    )

    |" Assuming that P is a primitive of self, return whether the given
    |" primitive P is inherited from one of self's parents.
    @exported
    fun is_inherited_primitive(p: Entity[BasicDecl]): Bool =
        self.node != p.info.md.primitive

    |" Return the record representation clause associated to this type decl,
    |" if applicable (i.e. this type decl defines a record type).
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun get_record_representation_clause(): Entity[RecordRepClause] = self.declarative_scope()?.decls.as_entity.find(
        (d) => d.as[RecordRepClause].do((p) => p.name.referenced_decl() == self)
    ).as[RecordRepClause]

    |" Return the enum representation clause associated to this type decl,
    |" if applicable (i.e. this type decl defines an enum type).
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun get_enum_representation_clause(): Entity[EnumRepClause] = self.declarative_scope()?.decls.as_entity.find(
        (d) => d.as[EnumRepClause].do(
            (p) => p.type_name.referenced_decl() == self
        )
    ).as[EnumRepClause]

    |" Return the list of all subprograms that are direct primitives of this
    |" type. We look for them in the public part and private part of the
    |" package this type is declared in.
    @lazy
    direct_primitive_subps: Array[InnerEnvAssoc] = {
        val scope = node.declarative_scope();
        val is_derived_tagged = node.as_bare_entity.as[TypeDecl]?.is_derived_tagged_type();
        val decl_parts = scope?.parent.as_bare_entity.do(
            (v1) => match v1 {
                case pkg_decl: BasePackageDecl =>
                # self is declared in a package scope, we should check all the
                # declarative parts of it.
                pkg_decl.public_part.decls.as_array() & pkg_decl.private_part?.decls.as_array()
                case _ =>
                # self is not declared in a package scope: the only way that there
                # can be a primitive of self here is if self is a derived tagged
                # type.
                if is_derived_tagged then node.parent.parent.as[DeclarativePart].do(
                    (dp) => dp.as_bare_entity.decls.as_array()
                ) else null[Array[Entity[AdaNode]]]
            }
        );
        val enum_lits = node.as[TypeDecl]?.type_def.as[EnumTypeDef].do(
            (etf) => etf.enum_literals.map(
                (lit) => InnerEnvAssoc(
                    key=lit.name.name_symbol(), value=lit, metadata=Metadata(primitive=node)
                )
            )
        );
        val prim_subps = decl_parts.filter(
            (decl) => decl.as[BasicDecl]?.subp_spec_or_null().do(
                (spec) => spec.candidate_primitive_subp_types().contains(node.as_bare_entity) and (
                    # For candidate primitives not declared in a package decl,
                    # we must further check if they are overriding a parent
                    # primitive.
                    # This check is not done in `candidate_type_for_primitive`
                    # because it may cause infinite recursions if the parent
                    # type is declared in the same scope as self.
                    if not scope.parent is BasePackageDecl then {
                        bind origin = spec.origin_node();

                        node.as_bare_entity.parent_primitives_env().get(spec.name().name_symbol()).any(
                            (x) => x.as[BasicDecl].subp_spec_or_null().match_signature(
                                spec, match_name=false, use_entity_info=true
                            )
                        )
                    } else true
                )
            )
        ).mapcat(
            (decl) => {
                val bd = decl.as[BasicDecl];

                [InnerEnvAssoc(
                    key=bd.defining_name().name_symbol(), value=bd.node, metadata=Metadata(primitive=node)
                )] & (
                    if bd.defining_name().name_is(s"\"=\"") then [InnerEnvAssoc(
                        key=s"\"/=\"", value=bd.node, metadata=Metadata(primitive=node)
                    )] else null[Array[InnerEnvAssoc]]
                )
            }
        );
        # Also add this types' predefined operators to the list of primitives
        val predefined_ops = node.as[TypeDecl]?.as_bare_entity.predefined_operators().map(
            (assoc) => InnerEnvAssoc(
                key=assoc.key, value=assoc.value, metadata=Metadata(primitive=node)
            )
        );

        enum_lits & prim_subps & predefined_ops
    }

    |" Return the environment containing the primitives for self, rebound
    |" using the given rebindings.
    fun own_primitives_env(with_rebindings: EnvRebindings): LexicalEnv =
        self.direct_primitives_env.rebind_env(with_rebindings)

    |" Return the environments containing the primitives for self and its
    |" previous parts, if there are some. All returned environments are
    |" rebound using the given rebindings.
    fun own_primitives_envs(with_rebindings: EnvRebindings): Array[LexicalEnv] =
        # If self has a previous part, it might have primitives too
        self.previous_part(false).as[TypeDecl].do(
            (pp) => [self.own_primitives_env(with_rebindings), pp.own_primitives_env(with_rebindings)], default_val=[self.own_primitives_env(with_rebindings)]
        )

    |" Return the environments containing the primitives for self (if
    |" ``include_self`` is True) and all its base types up to ``stop_at``:
    |" upon rewinding the base type chain, if we stumble on one of the types
    |" included in the ``stop_at`` set, we stop the recursion of that branch.
    |" All returned environments are rebound using the given rebindings.
    fun primitives_envs(with_rebindings: EnvRebindings, stop_at: Array[Entity[BaseTypeDecl]], include_self: Bool = false): Array[LexicalEnv] =
        # TODO: Not clear if the below origin.bind is correct, investigate
        # later.
        {
            bind origin = node;

            self.base_types().mapcat(
                (t) => match t {
                    case td: TypeDecl => td
                    case ttd: TaskTypeDecl => ttd
                    case std: BaseSubtypeDecl => {
                        bind origin = std.node.origin_node();

                        std.get_type().as[TypeDecl]
                    }
                    case _ => null[Entity[TypeDecl]]
                }.do(
                    (bt) => if stop_at.contains(bt) then null[Array[LexicalEnv]] else bt.own_primitives_envs(with_rebindings) & bt.primitives_envs(with_rebindings, stop_at, false)
                )
            ) & (
                if include_self then self.own_primitives_envs(with_rebindings) else null[Array[LexicalEnv]]
            )
        }

    |" Return a environment containing all primitives accessible to self,
    |" with the adjusted ``primitive_real_type`` metadata field.
    @memoized
    fun compute_primitives_env(include_self: Bool = true, stop_at: Array[Entity[BaseTypeDecl]] = null[Array[Entity[BaseTypeDecl]]]): LexicalEnv = self.primitives_envs(
        with_rebindings=self.info.rebindings, stop_at=stop_at, include_self=include_self
    ).env_group(
        with_md=Metadata(primitive_real_type=node)
    )

    |" The environment that contains all subprograms that are direct
    |" primitives of this type, that is, primitives that are not inherited.
    @lazy
    direct_primitives_env: LexicalEnv =
        dynamic_lexical_env(BaseTypeDecl.direct_primitive_subps, transitive_parent=false)

    |" Return the list of all primitive operations that are available on this
    |" type. If ``only_inherited`` is True, it will only return the primitives
    |" that are implicitly inherited by this type, discarding those explicitly
    |" defined on this type. Predefined operators are included in the result
    |" iff ``include_predefined_operators`` is True. It defaults to False.
    @exported
    fun get_primitives(
        only_inherited: Bool = false,
        include_predefined_operators: Bool = false
    ): Array[Entity[BasicDecl]] = {
        val prim_env = if only_inherited then
            self.parent_primitives_env()
        else
            self.primitives_env();

        # First gather the set of names that primitives of this type can have
        val all_prim_names = prim_env.get(null[Symbol]).map(
            (t) => t.as[BasicDecl].defining_name().name_symbol()
        ).unique();

        # Next, for each of these names, we only want to keep the
        # "most overriding" ones.
        all_prim_names.mapcat((name) => {
            val all_prims = prim_env.get(name).map((t) => t.as[BasicDecl]);
            val bds = if include_predefined_operators then
                all_prims
            else
                all_prims.filter((p) => not p is SyntheticSubpDecl);

            bds.ifilter((a, i) => {
                val a_spec = a.subp_spec_or_null();
                val a_prim =
                    a.info.md.primitive.as_bare_entity.as[BaseTypeDecl];

                # Only keep primitive a if it is the "most overriding" one.
                # So, the logic below checks that there isn't a primitive b
                # that overrides it.
                not bds.iany((b, j) => {
                    val b_prim = b.info.md.primitive.as[BaseTypeDecl];

                    (i != j) and {
                        # If two primitives have the same signature...
                        bind origin = b.origin_node();

                        a_spec.match_signature(
                            b.subp_spec_or_null(),
                            match_name=false,
                            use_entity_info=true
                        )
                    } and {
                        val b_prim_ent = b_prim.as_bare_entity;

                        # Test if the type of the first primitive (a) derives
                        # from the type of the second primitive (b)...
                        if a_prim.has_base_type(b_prim_ent.node) then (
                            # Case a derives from b...
                            # If b also derives from a, it means the types are
                            # equal: both primitives are in fact the same
                            # subprogram, but the first one is the declaration
                            # and the second one is the body. In that case we
                            # decide to keep the body.
                            # Else if b does not derive from a, it means the
                            # primitive on a overrides the primitive on b, so
                            # return False.
                            i < j and b_prim_ent.has_base_type(a_prim.node)
                        ) else (
                            # Case a does *not* derive from b...
                            # If b also does not derive from a, the two base
                            # types are unrelated, it means that the primitives
                            # are merged in a single one (remember their
                            # signature match). We keep the one that is
                            # inherited first with respect to the list of
                            # parents.
                            # But if b derives from a, we return True as we
                            # don't want to keep this primitive: we will keep
                            # the most inherited one (defined on b) later
                            # instead.
                            i > j or b_prim_ent.has_base_type(a_prim.node)
                        )
                    }
                })
            })
        })
    }

    |" Return whether this type is an array type.
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun is_array_type(): Bool = self.is_array()

    |" Find types derived from self in the given ``root`` and its children.
    @exported
    @with_dynvars(origin, imprecise_fallback=false)
    fun find_derived_types(root: Entity[AdaNode]): Array[Entity[TypeDecl]] =
        # TODO: Factor the traversal between this and `find_derived_types`
        root.children.do(
            (c) => c.filter(
                (n) => not (n.is_null or n.node == origin)
            ).mapcat((n) => self.find_derived_types(n))
        ) & root.as[TypeDecl].do(
            (type_decl) => type_decl.is_derived_type(self).do((_) => [type_decl])
        )

    |" Create an env_assoc embedding the synthetic object declaration
    |" required for predicates name resolution.
    |"
    |" This property should only be called once by ``env_spec``
    |" (``SubtypeDecl``, ``TypeDecl``).
    @lazy
    synthetic_object_decl_env_assoc: EnvAssoc = EnvAssoc(
        key=node.name_symbol(),
        # This synthetic object declaration is used for resolving the
        # references to its own derived/subtype identifier that can be used
        # in predicates as object references. This virtual object only
        # lives in the scope of the derived/subtype declaration, and has
        # the same name and type than the declaration it derives from.
        value=SyntheticObjectDecl(
            name=node.name,
            # A `SubtypeDecl` has a type expression that we can reuse On
            # the contrary, we have to embed the TypeDecl into a synthetic
            # `TypeExpr` for `TypeDecl`s.
            type_expr=node.as_bare_entity.type_expression().node or? SyntheticTypeExpr(target_type=node)
        ), dest_env=DesignatedEnv(
            kind=DesignatedEnvKind.current_env, env_name=null[Symbol], direct_env=null[LexicalEnv]
        ), metadata=null[Metadata]
    )

    |" Whether type is a scalar type.
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun is_scalar_type(): Bool = (
        (
            (
                self.is_int_type() or self.is_real_type()
            ) or self.is_float_type()
        ) or self.is_fixed_point()
    ) or self.is_enum_type()

    |" Whether self is an implicitly dereferenceable type or not
    @with_dynvars(origin)
    fun is_implicit_deref(): Bool =
        self.access_def().do((d) => not d is AccessToSubpDef) or not self.get_imp_deref().is_null

    |" Return the specific type under a class-wide type. Consider for example:
    |"
    |" .. code-block:: ada
    |"
    |"    subtype S1 is T'Class
    |"    subtype S2 is S1'Class
    |"
    |" Calling this property on ``S2`` will return ``T``.
    @exported
    fun specific_type(): Entity[BaseTypeDecl] = match self {
        # Recurse on the class-wide type because it could be a subtype
        # renaming a class-wide type itself.
        case cw: ClasswideTypeDecl => cw.type_decl().specific_type()
        case bt: BaseSubtypeDecl => {
            val bt = bt.base_subtype();

            # Check if the base subtype is self, to not do an infinite
            # recursion.
            if self == bt then self else bt.specific_type()
        }
        case _ => self
    }

    |" If this type defines an Implicit_Dereference aspect, return the
    |" accessed type, otherwise return self.
    @with_dynvars(origin=null[AdaNode])
    fun derefed_type(): Entity[BaseTypeDecl] =
        if self.is_null or self.get_imp_deref().is_null then self else self.accessed_type()

    |" Return the base subtype of this subtype. If this type defines an
    |" Implicit_Dereference aspect, return the base subtype of the accessed
    |" type instead.
    @with_dynvars(origin=null[AdaNode])
    fun derefed_base_subtype(): Entity[BaseTypeDecl] = if self.is_null then self else (
        if not self.get_imp_deref().is_null then self.accessed_type() else self
    ).base_subtype()

    |" Considering that self is the actual type of the left operand of an
    |" array concatenation and ``other`` the actual type of its right operand,
    |" return the type of the result of the array concatenation.
    @with_dynvars(origin=null[AdaNode])
    fun array_concat_result_type(other: Entity[BaseTypeDecl]): Entity[BaseTypeDecl] =
        if self.is_null or other.is_null then null[Entity[BaseTypeDecl]]
        elif other.matching_formal_type(self) or other.matching_formal_type(self.comp_type()) then self.derefed_base_subtype()
        elif self.matching_formal_type(other) or self.matching_formal_type(other.comp_type()) then other.derefed_base_subtype()
        else null[Entity[BaseTypeDecl]]

    |" Considering that self is the result type of an array concatenation and
    |" ``operand_type`` is the actual type of one of the operands, return the
    |" expected type for that operand. In other words: if the actual type of
    |" the operand is a subtype of the component-type of the resulting array,
    |" return the component type of the array. Otherwise return the array type
    |" itself.
    @with_dynvars(origin=null[AdaNode])
    fun expected_array_concat_operand_type(operand_type: Entity[BaseTypeDecl]): Entity[BaseTypeDecl] =
        if self.is_null or operand_type.is_null then null[Entity[BaseTypeDecl]]
        elif operand_type.matching_formal_type(self) or operand_type.matching_formal_type(self.comp_type()) then operand_type.derefed_base_subtype()
        else null[Entity[BaseTypeDecl]]

    @with_dynvars(origin=null[AdaNode])
    fun is_non_null_char_type(): Bool =
        not node.is_null and self.is_char_type()

    fun scalar_base_type(): Entity[DiscreteBaseSubtypeDecl] =
        node.scalar_base_subtype_node().as_entity

    |" Return whether this type is one of the three universal types (universal
    |" integer, universal fixed, or universal real).
    |"
    |" .. note::
    |"     Returns False if self is null.
    fun is_universal_type(): Bool = not self.is_null and (
        self == node.universal_int_type() or self == node.universal_fixed_type() or self == node.universal_real_type()
    )

    |" Return whether this type is *not* one of the two universal types
    |" (universal integer or universal real).
    |"
    |" .. note::
    |"     Returns False if self is null.
    fun is_not_universal_type(): Bool =
        not self.is_null and not self.is_universal_type()

    |" Predicate to use by logic equation. Return True iff this is an access
    |" type, but checks first that this type is not null, in which case it
    |" returns False.
    @with_dynvars(origin)
    fun is_access_type_predicate(): Bool = self?.is_access_type()

    @with_dynvars(origin)
    fun array_ndims(): Int = 0

    |" Return the expression from the Static_Predicate or the Predicate aspect
    |" defined on this type.
    @with_dynvars(imprecise_fallback=false)
    fun static_predicate(): Entity[Expr] =
        self.get_aspect(s"Static_Predicate").value or? self.get_aspect(s"Predicate").value

    |" Return true if the given value satisfies all of this type's static
    |" predicates, including its parent predicates (in case this is a derived
    |" type) and its base type predicate (if this is a subtype declaration).
    |" Return true if no type predicates are defined for this type.
    @with_dynvars(imprecise_fallback=false, origin=null[AdaNode])
    fun satisfies_type_predicates(value: BigInt): Bool = {
        val true_val = 1b;
        val satisfies_own_predicate = self.static_predicate().do(
            (pred) => true_val == pred.eval_as_int_in_env(
                [Substitution(
                    from_decl=self, to_value=value, value_type=self
                )]
            ), default_val=true
        );
        val from_type = self.as[BaseSubtypeDecl]?.get_type();
        val base_type = self.base_type();

        satisfies_own_predicate and (
            if not from_type.is_null then from_type.satisfies_type_predicates(value)
            elif not base_type.is_null then base_type.satisfies_type_predicates(value)
            else true
        )
    }

    @memoized
    @with_dynvars(origin)
    fun is_iterator_type(): Bool = {
        val iifcs = self.get_unit_root_decl(
            [s"Ada", s"Iterator_Interfaces"], AnalysisUnitKind.unit_specification
        );
        val typ = self.as[ClasswideTypeDecl].do((cw) => cw.type_decl(), default_val=self);

        typ.semantic_parent().semantic_parent().node == iifcs or self.canonical_part().has_aspect(s"Iterable")
    }

    |" Assuming this is an iterator type, return the associated cursor
    |" type.
    @with_dynvars(origin)
    fun cursor_type(): Entity[BaseTypeDecl] =
        # For containers and user defined iterator types, cursor type
        # is defined by the `Cursor` type declaration.
        self.children_env().get_first(s"Cursor").as![BaseTypeDecl]
        # Check out cursor type for types with `Iterable` aspect
        or? self.iterable_cursor_type()

    fun is_not_root_int_type(): Bool =
        not node.is_null and self != node.root_int_type()

    |" Whether a universal integer can be used to initialize a value of this
    |" type. This is true for integer types in general, but also for arbitrary
    |" types that define the Integer_Literal aspect.
    @with_dynvars(origin=null[AdaNode])
    fun allows_universal_int(): Bool = self.is_int_type() or self.base_subtype().do(
        (bt) => not # We check on the base_subtype because the aspect can only be
        # specified on the type's first subtype.
        bt.get_aspect(s"Integer_Literal", true).is_null, default_val=false
    )

    |" Whether a universal real can be used to initialize a value of this
    |" type. This is true for real types in general, but also for arbitrary
    |" types that define the Real_Literal aspect.
    @with_dynvars(origin=null[AdaNode])
    fun allows_universal_real(): Bool = self.is_real_type() or self.base_subtype().do(
        (bt) => not # We check on the base_subtype because the aspect can only be
        # specified on the type's first subtype.
        bt.get_aspect(s"Real_Literal", true).is_null, default_val=false
    )

    |" Predicate that'll check that this type is not null. Meant to be used in
    |" equations, where we know that the expression's type cannot be
    |" determined if there is no expected type, as in::
    |"
    |"     Predicate(BaseTypeDecl.is_not_any_type,
    |"               self.expected_type_var,
    |"               error_location=self)
    @predicate_error("No inferable type for expression")
    fun is_not_any_type(): Bool = not node.is_null

    |" Whether a string literal can be used to initialize a value of this
    |" type. This is true for string types in general, but also for arbitrary
    |" types that define the String_Literal aspect.
    |"
    |" .. note:: We also check that the node is not null because this property
    |"    is used directly as a logic predicate and may be invoked with null
    |"    nodes (unlike the other ``allows_*`` properties).
    @with_dynvars(origin=null[AdaNode])
    @predicate_error("$Self does not allow string literals")
    fun allows_string_literal(): Bool = not node.is_null and (
        self.is_str_type() or self.base_subtype().do(
            (bt) => not # We check on the base_subtype because the aspect can only be
            # specified on the type's first subtype.
            bt.get_aspect(s"String_Literal", true).is_null, default_val=false
        )
    )

    |" Whether this is a string type (a one dimensional array of characters).
    @with_dynvars(origin)
    fun is_str_type(): Bool =
        self.array_ndims() == 1 and self.comp_type()?.is_char_type()

    |" Like ``BaseTypeDecl.accessed_type``, but does not perform an implicit
    |" call if self represents an access-to-subprogram.
    @with_dynvars(origin)
    fun accessed_type_no_call(): Entity[BaseTypeDecl] =
        if self.is_null or self.access_def() is AccessToSubpDef then null[Entity[BaseTypeDecl]] else self.accessed_type()

    |" Call accessed_type recursively until we get the most nested accessed
    |" type. For example, for the following code::
    |"
    |"     type A is access Integer;
    |"     type AA is access A;
    |"     type AAA is access AA;
    |"
    |" ``AAA``'s final_accessed_type is Integer.
    @with_dynvars(origin)
    fun final_accessed_type(first_call: Bool = true): Entity[BaseTypeDecl] = self.accessed_type().do(
        (at) => at.final_accessed_type(false), default_val=if first_call then null[Entity[BaseTypeDecl]] else self
    )

    @with_dynvars(origin)
    fun is_access_to(typ: Entity[BaseTypeDecl]): Bool =
        self?.accessed_type()?.matching_formal_type(typ)

    |" Returns whether self is an access type whose accessed type matches
    |" other.
    @with_dynvars(origin)
    fun is_subp_access_of(other: Entity[BasicDecl]): Bool = self?.access_def().as[AccessToSubpDef].do(
        (sa) => other.subp_spec_or_null().do(
            (se) => sa.subp_spec.match_signature(se, false)
        )
    )

    |" Return whether this type declaration is a generic formal.
    fun is_generic_formal(): Bool =
        node.parent is GenericFormalTypeDecl or node.parent.as[BaseTypeDecl]?.is_generic_formal()

    |" Return whether self is a tagged type after being implicitly
    |" dereferenced.
    @with_dynvars(origin=null[AdaNode])
    @predicate_error("expected tagged type, got $Self")
    fun is_tagged_type_with_deref(): Bool = (
        if not self.get_imp_deref().is_null then self.accessed_type() else self
    ).is_tagged_type()

    |" Return the list of all types that inherit (directly or indirectly) from
    |" self among the given units.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun find_all_derived_types(units: Array[AnalysisUnit]): Array[Entity[TypeDecl]] = {
        bind origin = node;

        self.canonical_type().filter_is_imported_by(units, true).mapcat(
            (u) => u.root.do(
                (r) => self.find_derived_types(r.as_bare_entity)
            )
        )
    }

    |" Return the array definition corresponding to type ``self`` in the
    |" context of array-indexing, e.g. implicitly dereferencing if ``self`` is
    |" an access.
    @with_dynvars(origin)
    fun array_def_with_deref(): Entity[ArrayTypeDef] = if self.is_array() then self.array_def()
    elif self.is_implicit_deref() then self.accessed_type().do((c) => c.array_def())
    else null[Entity[ArrayTypeDef]]

    @with_dynvars(origin)
    fun is_array_def_with_deref(): Bool =
        not node.is_null and not self.array_def_with_deref().is_null

    @with_dynvars(origin)
    fun is_array_def_with_deref_or_null(): Bool =
        node.is_null or not self.array_def_with_deref().is_null

    |" Return the component type of ``self``, if applicable. The component
    |" type is the type you'll get if you call a value whose type is ``self``.
    |" So it can either be:
    |"
    |" 1. The component type for an array.
    |" 2. The return type for an access to function.
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun comp_type(is_subscript: Bool = false): Entity[BaseTypeDecl] = self.do(
        (e) => {
            val ad = if is_subscript then self.array_def_with_deref() else self.array_def();

            ad.do((ad) => ad.comp_type()) or? e.access_def().do(
                (v1) => match v1 {
                    case asd: AccessToSubpDef => asd.subp_spec.return_type()
                    case tad: BaseTypeAccessDef => tad.accessed_type()
                }
            )
        }
    )

    |" Return the index type for dimension ``dim`` for this type, if
    |" applicable.
    |"
    |" .. WARNING:: ``dim`` is 0-based, so the first ``index_type`` is at
    |"     index 0.
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun index_type(dim: Int): Entity[BaseTypeDecl] =
        self.array_def_with_deref().do((ad) => ad.index_type(dim))

    @with_dynvars(origin)
    fun expr_type(): Entity[BaseTypeDecl] =
        # A BaseTypeDecl in an expression context corresponds to a type
        # conversion, so its type is itself.
        self

    |" Whether self is derived from other_type.
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun is_derived_type(other_type: Entity[BaseTypeDecl]): Bool = {
        val entity_can = self.canonical_type();
        val other_can = other_type.canonical_type();

        (
            # The canonical types are the same
            entity_can == other_can
        ) or (
            # Other is classwide, and entity's classwide type is the same as
            # other.
            #
            # NOTE: This only works one way::
            #
            #     T'Class.is_derived_type (T) -> False
            #     T.is_derived_type (T'Class) -> True
            other_can.is_classwide() and entity_can.classwide_type() == other_can
        ) or (
            # Recurse on base types
            self.base_types().any((bt) => bt.is_derived_type(other_type))
        ) or (
            # If both types are classwide, then we also recurse on base types
            # for the specific type of ``self``. While this goes further than
            # the ARM definition of what is a derived type, it is a useful
            # complement.
            entity_can.is_classwide() and other_can.is_classwide() and entity_can.as[ClasswideTypeDecl].type_decl().base_types().any((bt) => bt.is_derived_type(other_type))
        )
    }

    |" Return True iff this type is limited, either because it is explicitly
    |" marked as such, or because it inherits from a limited type or has a
    |" component of a limited type. Also note that protected types and task
    |" types are limited by definition. Moreover, note that Ada requires
    |" all parts of a type to agree of its limitedness (e.g. the public view
    |" of a type must indicate that it is limited if its private completion
    |" ends up being limited), hence this property does not require looking at
    |" any other part of the type to determine its limitedness, excepted for
    |" incomplete type declarations. This implies that for illegal code where
    |" several parts don't agree, this property will return the result for the
    |" particular view of the type on which this property is called.
    @exported
    fun is_limited_type(): Bool =
        # This property does not require an "origin" parameter because as
        # explained above, all parts of a type must agree on the fact that the
        # type is limited or not.
        match self {
            case td: TypeDecl => td.type_def.is_limited_type()
            case sb: SubtypeDecl => sb.get_type().is_limited_type()
            case it: IncompleteTypeDecl => it.full_view().is_limited_type()
            case cw: ClasswideTypeDecl => cw.type_decl().is_limited_type()
            case _: ProtectedTypeDecl => true
            case _: TaskTypeDecl => true
            case _ => false
        }

    @with_dynvars(origin)
    fun iterable_comp_type_or_null(): Entity[BaseTypeDecl] =
        if node.is_null then null[Entity[BaseTypeDecl]] else (
            if self.is_implicit_deref() then self.accessed_type() else self
        ).iterable_comp_type()

    |" Given a dotted expression A.B, where container_type is the container
    |" type for B, and self is a potential type for A, returns whether self is
    |" a valid type for A in the dotted expression.
    @with_dynvars(origin)
    fun matching_prefix_type(container_type: Entity[BaseTypeDecl]): Bool = {
        val cont_type = container_type;

        (
            not node.is_null and not container_type.is_null
        ) and (
            (
                # Derived type case
                self.matching_formal_prim_type(cont_type)
            ) or (
                # Access to derived type case
                self.final_accessed_type()?.matching_formal_prim_type(cont_type)
            ) or (
                # Dot notation: The prefix can be a value type and the formal an
                # access type to this value type.
                cont_type.accessed_type().do(
                    (at) => self.matching_formal_prim_type(at)
                )
            )
        )
    }

    |" Whether self is a matching access type for expected_type.
    @with_dynvars(origin)
    fun matching_access_type(expected_type: Entity[BaseTypeDecl], for_assignment: Bool): Bool = {
        val actual_type = self;

        match expected_type {
            case atd: Entity[AnonymousTypeDecl] => atd.access_def_matches(actual_type, for_assignment)
            case _ => match actual_type {
                case atd2: Entity[AnonymousTypeDecl] => atd2.access_def_matches(expected_type, for_assignment)
                case _ => false
            }
        }
    }

    @with_dynvars(origin)
    @predicate_error("expected $formal_type, got $Self")
    fun matching_formal_prim_type(formal_type: Entity[BaseTypeDecl]): Bool =
        not formal_type.is_null and not node.is_null and self.matching_formal_type_impl(formal_type, true)

    @with_dynvars(origin)
    @predicate_error("expected $formal_type, got $Self")
    fun matching_formal_type(formal_type: Entity[BaseTypeDecl]): Bool =
        not formal_type.is_null and not node.is_null and self.matching_formal_type_impl(formal_type)

    @with_dynvars(origin)
    fun matching_membership_type(formal_type: Entity[BaseTypeDecl]): Bool =
        not formal_type.is_null and not node.is_null and self.matching_formal_type_impl(formal_type, accept_root_types=true)

    @with_dynvars(origin)
    fun matching_formal_type_impl(formal_type: Entity[BaseTypeDecl], accept_derived: Bool = false, accept_root_types: Bool = false): Bool = {
        val actual_type = self;

        (
            (
                formal_type.is_classwide() or accept_derived
            ) and actual_type.specific_type().is_derived_type(formal_type)
        ) or (
            actual_type.is_classwide() and actual_type.specific_type().matching_type(formal_type)
        ) or (
            # Matching of access types parameters
            actual_type.accessed_type().do(
                (actual_accessed_type) => formal_type.accessed_type().do(
                    (formal_accessed_type) => (
                        (
                            formal_accessed_type.is_classwide() or accept_derived
                        ) and actual_accessed_type.specific_type().is_derived_type(formal_accessed_type)
                    ) or (
                        actual_accessed_type.is_classwide() and actual_accessed_type.specific_type().matching_type(formal_accessed_type)
                    ) or (
                        # In a MembershipExpr, if formal_type is a general
                        # access-to-object type, actual_type is convertible to
                        # formal_type (:rmlink:`4.5.2` 30.3/4).
                        accept_root_types and formal_accessed_type.specific_type().is_derived_type(actual_accessed_type)
                    )
                )
            )
        ) or (
            not actual_type.get_imp_deref().is_null and actual_type.accessed_type().matching_formal_type(formal_type)
        ) or actual_type.matching_type(formal_type)
    }

    @with_dynvars(origin)
    @predicate_error("expected $expected_type, got $Self")
    fun matching_assign_type(expected_type: Entity[BaseTypeDecl]): Bool = {
        val actual_type = self;

        (
            not node.is_null and not expected_type.is_null
        ) and (
            self.matching_type(expected_type) or (
                (
                    expected_type.is_classwide() or expected_type.accessed_type()?.is_classwide()
                ) and actual_type.matching_formal_prim_type(expected_type)
            ) or self.matching_access_type(expected_type, true)
        )
    }

    |" Return whether ``self`` matches ``expected_type``.
    @exported
    @with_dynvars(origin=null[AdaNode])
    @predicate_error("expected $expected_type, got $Self")
    fun matching_type(expected_type: Entity[BaseTypeDecl]): Bool = {
        val actual_type = self;

        not expected_type.is_null and not actual_type.is_null and (
            {
                val uit = node.universal_int_type();

                (
                    actual_type == uit and expected_type.allows_universal_int()
                ) or (
                    expected_type == uit and actual_type.is_int_type()
                )
            } or {
                val urt = node.universal_real_type();

                (
                    actual_type == urt and expected_type.allows_universal_real()
                ) or (
                    expected_type == urt and actual_type.is_real_type()
                )
            } or {
                val uft = node.universal_fixed_type();

                (
                    expected_type == uft and actual_type.is_fixed_point()
                ) or (
                    actual_type == uft and expected_type.is_fixed_point()
                )
            } or actual_type.canonical_type() == expected_type.canonical_type() or (
                not actual_type.get_imp_deref().is_null and actual_type.accessed_type().matching_type(expected_type)
            ) or (
                not expected_type.get_imp_deref().is_null and expected_type.accessed_type().matching_type(actual_type)
            ) or actual_type.matching_access_type(expected_type, false)
        )
    }

    @with_dynvars(origin)
    fun matching_allocator_type(allocated_type: Entity[BaseTypeDecl]): Bool =
        self.is_access_type() and allocated_type.matching_formal_type(self.accessed_type())

    |" Return whether this type (after implicit dereference) is or derives
    |" from the standard Boolean type. If this type is null, return False.
    @with_dynvars(origin)
    @predicate_error("expected boolean type, got $Self")
    fun derives_from_std_bool_type(): Bool =
        not node.is_null and self.derefed_base_subtype().is_derived_type(node.bool_type())

    @memoized
    fun classwide_type_node(): ClasswideTypeDecl =
        ClasswideTypeDecl(name=node.name)

    |" Helper for scalar_base_subtype. Return the interned node for the
    |" subtype entity.
    @memoized
    fun scalar_base_subtype_node(): DiscreteBaseSubtypeDecl =
        DiscreteBaseSubtypeDecl(name=node.name)

    |" Return the base subtype for this type. Note that this is only legal for
    |" scalar types.
    fun scalar_base_subtype(): Entity[DiscreteBaseSubtypeDecl] =
        node.scalar_base_subtype_node().as_entity

    |" Returns the previous part for this type decl.
    @exported
    @memoized
    fun previous_part(go_to_incomplete: Bool = true): Entity[BaseTypeDecl] = if node.is_generic_formal() then (
        # A generic formal type never has a previous part
        null[Entity[BaseTypeDecl]]
    )
    elif node is ClasswideTypeDecl then self.as[ClasswideTypeDecl].type_decl().previous_part(go_to_incomplete).do((pp) => pp.classwide_type())
    # Otherwise look for the previous part in the immediate enclosing
    # declarative region.
    else node.name.do(
        (type_name) => self.semantic_parent().immediate_declarative_region().get(
            type_name.name_symbol(), lookup=LookupKind.minimal, from=node
        ).do(
            (pp) => pp.find(
                (pp) => (
                    self.is_in_private_part() and pp.as[BaseTypeDecl]?.is_private()
                ) or (
                    go_to_incomplete and pp is IncompleteTypeDecl
                )
            )
        ).as[BaseTypeDecl]
    )

    |" Returns the next part for this type decl.
    |"
    |" .. note:: Since this property returns a ``BaseTypeDecl``, it cannot be
    |"     used to retrieve the next part of ``TaskTypeDecl`` and
    |"     ``ProtectedTypeDecl`` nodes as their next part is actually a
    |"     ``Body``. Use ``BasicDecl.next_part_for_decl`` for those instead.
    @exported
    @memoized
    fun next_part(): Entity[BaseTypeDecl] = match self {
        case itd: IncompleteTypeDecl => itd.declarative_scope().do(
            # The next part of a (non-private) incomplete type declaration must
            # either be in the same declarative scope...
            (s) => itd.find_next_part_in(s.as_entity)
        ) or? self.is_in_private_part().do(
            (_) => self.declarative_scope().parent.as![BasePackageDecl].as_entity.body_part().do(
                # Or in the particular case of taft-amendment types where the
                # incomplete decl is in the private part of the package spec,
                # the next part can be found in the package's body (RM 3.10.1).
                (p) => itd.find_next_part_in(p.decls)
            )
        )
        case cwt: ClasswideTypeDecl => {
            val td = cwt.type_decl();

            td.next_part().do(
                # Sometimes `next_part` returns self itself, so check
                # that to avoid an infinite loop.
                (np) => if td == np then cwt else np.classwide_type()
            )
        }
        case _ => if self.is_private() and not self.is_generic_formal() then self.private_completion() else null[Entity[BaseTypeDecl]]
    }

    |" Return the full completion of this type.
    @exported
    fun full_view(): Entity[BaseTypeDecl] =
        self.next_part().do((np) => np.full_view(), default_val=self)

    |" Returns whether this is a definite subtype.
    |"
    |" For convenience, this will return ``False`` for incomplete types, even
    |" though the correct answer is more akin to "non applicable".
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun is_definite_subtype(): Bool = match self {
        case _: IncompleteTypeDecl => false
        case td: TypeDecl => td.discriminants.is_null and match td.type_def {
            case dtd: DerivedTypeDef => not dtd.subtype_indication.constraint.is_null or dtd.base_type().is_definite_subtype()
            case atd: ArrayTypeDef => atd.indices is ConstrainedArrayIndices
            case _ => true
        }
        case st: SubtypeDecl => not st.subtype.constraint.is_null or st.get_type().is_definite_subtype()
        case _: ClasswideTypeDecl => false
        case ttd: TaskTypeDecl => ttd.discriminants.is_null
        case ptd: ProtectedTypeDecl => ptd.discriminants.is_null
        case _ => true
    }

    |" Return the list of all discriminants of this type. If this type has no
    |" discriminant or only unknown discriminants, an empty list is returned.
    |"
    |" In order to obtain all the discriminants of an extended type, this
    |" property looks on parents, recursively.
    |"
    |" Extended aggregates can be build from any intermediate parent of an
    |" extended type. In that case, this property shouldn't recurse to the
    |" root type, but the one used as the aggregate's ancestor, designated by
    |" ``stop_recurse_at``.
    @exported
    @abstract
    @with_dynvars(origin=null[AdaNode])
    fun discriminants_list(stop_recurse_at: Entity[BaseTypeDecl] = null[Entity[BaseTypeDecl]]): Array[Entity[BaseFormalParamDecl]]

    |" If self denotes the declaration of a character type (i.e. an enum type
    |" with character literals) and origin is bound to a character literal,
    |" return the EnumLiteralDecl that symbolically corresponds to the
    |" literal, or synthesize one if the enum type is one of the standard
    |" Character types (we need to synthesize them since we cannot declare
    |" them all in our standard package implementation because of their
    |" number).
    @memoized
    @with_dynvars(origin)
    fun corresponding_char_literal(): Entity[BasicDecl] = {
        val root = self.root_type();
        val enum_type = root.as[TypeDecl]?.type_def.as[EnumTypeDef];
        val sym = origin.as[CharLiteral].do((l) => l.symbol);
        val char_lit = enum_type?.enum_literals.find((lit_decl) => lit_decl.name.name_is(sym));

        # If we didn't find a char literal and the enum type is one of the
        # standard characters types, synthesize the corresponding character
        # enum literal.
        if char_lit.is_null and enum_type.is_std_char_type() then SyntheticCharEnumLit(
            name=null[DefiningName], char_symbol=sym, enum_type_decl=enum_type.parent.as[TypeDecl]
        ).as_entity else (
            # Ideally, name should take a SyntheticDefiningName, built from
            # the symbol `sym`, but that would mean that name's parent is
            # self here rather than the SyntheticCharEnumLit we are
            # creating. It matters for the DefiningName.basic_decl property
            # for example. To workaround that issue, we also pass the
            # symbol to the SyntheticCharEnumLit node in order to build the
            # SyntheticDefiningName there, afterwards.
            char_lit
        )
    }

    @with_dynvars(imprecise_fallback=false)
    fun next_part_for_decl(): Entity[BasicDecl] = match self {
        # SingleTaskTypeDecl next part is its parent SingleTaskDecl next
        # part.
        case sttd: SingleTaskTypeDecl => sttd.parent_basic_decl().next_part_for_decl()
        case _: TaskTypeDecl => self.super()
        case _: ProtectedTypeDecl => self.super()
        case _ => self.next_part().as[BasicDecl]
    }

    |" Must be called on a record (sub-)type declaration. Return all the
    |" possible shapes that a value of this record type can take. For example,
    |" consider the following record definition:
    |"
    |" .. code::
    |"
    |"     type R (A : Integer; B : Integer) is record
    |"         X : Integer;
    |"         case A is
    |"             when 1 .. 10 =>
    |"                 Y_1 : Integer;
    |"                 case B is
    |"                     when 1 .. 10 =>
    |"                         Z_1 : Integer;
    |"                     when others => null;
    |"                 end case;
    |"             when 11 .. 20 =>
    |"                 Y_2 : Integer;
    |"                 case B is
    |"                     when 1 .. 10 =>
    |"                         Z_2 : Integer;
    |"                     when others => null;
    |"                 end case;
    |"             when others => null;
    |"         end case;
    |"     end record;
    |"
    |" For this instance, this property will return the following results:
    |"
    |" .. code::
    |"
    |"     [
    |"         [X, Y_1, Z_1],
    |"         [X, Y_1],
    |"         [X, Y_2, Z_2],
    |"         [X, Y_2],
    |"         [X]
    |"     ]
    |"
    |" .. ATTENTION::
    |"     This property is inaccurate when called on a record extension which
    |"     defines components under a certain condition C, and this same
    |"     condition is used to define some components in the parent record:
    |"     in that case, any feasible shape will in practice contain either
    |"     both the components defined under condition C in the child record
    |"     and the parent record, or none of them.
    |"
    |"     However, due to the simplified algorithm we use here to compute the
    |"     feasible shapes, we will also return shapes that include the
    |"     components of the child record but not the parent record, and
    |"     conversely.
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun shapes(include_discriminants: Bool = true): Array[Shape] = {
        val rdef = self.record_def();
        val comps = rdef.components;
        val parent_type = comps.type_def().as[DerivedTypeDef]?.base_type();
        val parent_record = parent_type?.record_def();
        val own_shapes = comps.shapes();
        # include parent shapes only if view on base type is indeed a record
        # (i.e. parent_record is not null).
        val all_shapes = parent_record.do(
            (_) => parent_type.shapes(include_discriminants=false).mapcat(
                (parent_shape) => own_shapes.map(
                    (own_shape) => Shape(
                        components=parent_shape.components & own_shape.components, discriminants_values=parent_shape.discriminants_values & own_shape.discriminants_values
                    )
                )
            ), default_val=own_shapes
        );
        val discrs = comps.type_decl().discriminants_list();

        if include_discriminants then all_shapes.map(
            (s) => Shape(
                components=discrs & s.components, discriminants_values=s.discriminants_values
            )
        ) else all_shapes
    }

    |" The environment that contains all subprograms that can be called with
    |" the dot-notation on values of this type.
    @lazy
    dottable_subps_env: LexicalEnv =
        dynamic_lexical_env(BaseTypeDecl.dottable_subps, transitive_parent=false)

    |" Return the list of all subprograms that can be called with the dot-
    |" notation on values of this type.
    |"
    |" This property doesn't implement Ada standard but the GNAT experimental
    |" feature allowing dot-notation for untagged types.
    @memoized
    fun dottable_subps(): Array[InnerEnvAssoc] = {
        val scope = self.declarative_scope();
        val pkg = scope?.parent.as[PackageBody].do(
            (body) => {
                bind imprecise_fallback = false;

                body.as_entity.previous_part()
            }.as[BasePackageDecl], default_val=scope?.parent.as[BasePackageDecl].as_entity
        );

        # Ada standard would requier to check that this type is tagged to
        # be called with the dot-notation. We do not comply to the standard
        # here in order to support a GNAT experimental feature which allows
        # to use the dot-notation on untagged types too. See
        # https://github.com/AdaCore/ada-spark-rfcs/blob/master/\
        #   prototyped/rfc-prefixed-untagged.rst.
        # If we are in a package, we look for subprograms that can be
        # called with the dot-notation in the public part, private part and
        # body part of the package this type is declared in.
        if not pkg.is_null then self.dottable_subps_in_declaratives_parts(
            [pkg.public_part.as[DeclarativePart], pkg.private_part.as[DeclarativePart], pkg.body_part()?.decls]
        )
        # Else, we look for subprograms in the declarative region this
        # type is declared in.
        else self.dottable_subps_in_declaratives_parts([scope.as_entity])
    }

    |" Return the list of all subprograms that can be called with the
    |" dot-notation on values of this type. We look for them in the
    |" declarative parts array ``parts``.
    fun dottable_subps_in_declaratives_parts(parts: Array[Entity[DeclarativePart]]): Array[InnerEnvAssoc] =
        parts.mapcat((dp) => dp?.decls.as_array()).filtermap(
            (decl) => {
                val bd = decl.as[BasicDecl];

                InnerEnvAssoc(
                    key=bd.defining_name().name_symbol(), value=bd.node, metadata=Metadata(dottable_subp=true)
                )
            }, (decl) => decl.as[BasicDecl]?.subp_spec_or_null()?.dottable_subp_of()?.base_subtype() == self
        )

    |" Helper function for ``find_base_type_rebindings``, which returns the
    |" first occurrence of the ``target`` type among the super types of the
    |" given array of types using a depth-first search.
    @with_dynvars(origin)
    fun find_base_type_rebindings_among(target: BaseTypeDecl, base_types: Array[Entity[BaseTypeDecl]], index: Int): EnvRebindings =
        if index >= base_types.length() then null[EnvRebindings] else base_types?[index].find_base_type_rebindings(target) or? self.find_base_type_rebindings_among(target, base_types, index + 1)

    |" Given self & a target type node, browse the inheritance hierarchy of
    |" self until the target is found, and return its associated rebindings.
    |" For example, consider the following snippet.
    |"
    |" .. code::
    |"
    |"     package My_Vectors is new Ada.Containers.Vectors (...);
    |"
    |"     type My_Vector is new My_Vectors.Vector;
    |"
    |" Calling this property on ``My_Vector`` with the target type
    |" ``Ada.Containers.Vectors.Vector`` will return the rebindings
    |" corresponding to the instantiation in the first line of the snippet
    |" (package My_Vectors).
    @memoized
    @with_dynvars(origin)
    fun find_base_type_rebindings(target: BaseTypeDecl): EnvRebindings =
        if node == target then self.info.rebindings else self.find_base_type_rebindings_among(
            target=target, base_types=self.base_types(), index=0
        )

    |" Implementation of ``has_base_type``, which assumes that ``target`` has
    |" been canonicalized.
    fun has_base_type_impl(target: BaseTypeDecl): Bool =
        self.canonical_type().node == target or self.base_types().any((bt) => bt.has_base_type_impl(target))

    |" Return whether the given type is amongst the bases types (direct or
    |" indirect) of self.
    |"
    |" .. note:: Unlike ``is_derived_type``, we don't care here about the
    |"     rebindings of ``target``, meaning any instance of ``target`` will
    |"     be accepted.
    fun has_base_type(target: BaseTypeDecl): Bool = self.full_view().has_base_type_impl(
        target.as_bare_entity.canonical_type().node
    )

    fun parent_primitives_env(): LexicalEnv = node.empty_env()

    fun primitives_env(): LexicalEnv = null[LexicalEnv]

    |" Return whether this type is a record type.
    |"
    |" .. ATTENTION:: Private tagged types extending public tagged records are
    |"     not considered as record types.
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun is_record_type(): Bool = not self.record_def().is_null

    |" Whether type is a task type
    fun is_task_type(): Bool = false

    |" Whether type is a real type or not.
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun is_real_type(): Bool = false

    |" Whether type is a float type or not.
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun is_float_type(): Bool = false

    |" Whether type is a fixed point type or not.
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun is_fixed_point(): Bool = false

    |" Whether type is an enum type
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun is_enum_type(): Bool = false

    fun is_classwide(): Bool = false

    |" Whether self is an access type or not
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun is_access_type(): Bool = false

    |" Whether self has user defined indexing or not
    fun has_ud_indexing(): Bool = false

    |" For a type with user defined indexing, return the set of all
    |" Constant_Indexing functions.
    fun constant_indexing_fns(): Array[Entity[BasicDecl]] =
        null[Array[Entity[BasicDecl]]]

    |" For a type with user defined indexing, return the set of all
    |" Variable_Indexing functions.
    fun variable_indexing_fns(): Array[Entity[BasicDecl]] =
        null[Array[Entity[BasicDecl]]]

    |" If self has an Implicit_Dereference aspect, return its expression
    fun get_imp_deref(): Entity[Expr] = null[Entity[Expr]]

    @with_dynvars(origin)
    fun access_def(): Entity[AccessDef] = null[Entity[AccessDef]]

    |" Whether type is a character type or not
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun is_char_type(): Bool = false

    # TODO: Not clear if the below origin.bind is correct, investigate later
    |" Return the classwide type for this type, if applicable
    @exported
    fun classwide_type(): Entity[ClasswideTypeDecl] = {
        bind origin = node;

        if self.is_tagged_type() then node.classwide_type_node().as_entity else null[Entity[ClasswideTypeDecl]]
    }

    |" Return the discrete range for this type decl, if applicable.
    @exported
    fun discrete_range(): DiscreteRange = null[DiscreteRange]

    |" Whether type is a discrete type or not.
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun is_discrete_type(): Bool = (
        self.is_int_type() or self.is_enum_type()
    ) or self.is_char_type()

    |" Whether type is an integer type or not.
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun is_int_type(): Bool = false

    |" If this type is an access type, or a type with an Implicit_Dereference
    |" aspect, return the type of a dereference of an instance of this type.
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun accessed_type(): Entity[BaseTypeDecl] = null[Entity[BaseTypeDecl]]

    |" Whether type is tagged or not
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun is_tagged_type(): Bool = false

    |" Return the base type entity for this derived type declaration
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun base_type(): Entity[BaseTypeDecl] = null[Entity[BaseTypeDecl]]

    |" Return the list of base types for self.
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun base_types(): Array[Entity[BaseTypeDecl]] =
        self.base_type().do((bt) => [bt]) & self.base_interfaces()

    @with_dynvars(origin)
    fun base_interfaces(): Array[Entity[BaseTypeDecl]] =
        null[Array[Entity[BaseTypeDecl]]]

    @with_dynvars(origin)
    fun record_def(): Entity[BaseRecordDef] = null[Entity[BaseRecordDef]]

    @with_dynvars(origin)
    fun array_def(): Entity[ArrayTypeDef] = null[Entity[ArrayTypeDef]]

    |" Whether self is a type that is iterable in a for .. of loop
    @with_dynvars(origin)
    fun is_iterable_type(): Bool = false

    |" Return True iff this type declaration is an interface definition.
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun is_interface_type(): Bool = self.full_view().do(
        (v1) => match v1 {
            case td: TypeDecl => td.type_def is InterfaceTypeDef
            case sb: SubtypeDecl => sb.get_type().is_interface_type()
            case _ => false
        }
    )

    @with_dynvars(origin)
    fun iterable_comp_type(): Entity[BaseTypeDecl] =
        null[Entity[BaseTypeDecl]]

    @with_dynvars(origin)
    fun iterable_cursor_type(): Entity[BaseTypeDecl] =
        null[Entity[BaseTypeDecl]]

    |" Return the canonical type declaration for this type declaration. For
    |" subtypes, it will return the base type declaration.
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun canonical_type(): Entity[BaseTypeDecl] = {
        bind imprecise_fallback = false;

        self.canonical_part().as[BaseTypeDecl]
    }

    |" Whether node is a private view of corresponding type.
    @exported
    fun is_private(): Bool = false

    |" Return the type that is at the root of the derivation hierarchy
    |" (ignoring secondary interfaces derivations for tagged types)
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun root_type(): Entity[BaseTypeDecl] = self

    env_spec {
        add_to_env_kv(self.name_symbol(), node)
    }
}

|" Base class for subtype declarations (:rmlink:`3.2.2`).
@abstract
class BaseSubtypeDecl: BaseTypeDecl {
    fun from_type_bound(): Entity[BaseTypeDecl] =
        # TODO: This is a hack, to avoid making all of the predicates on types
        # take an origin. But ultimately, for semantic correctness, it will be
        # necessary to remove this, and migrate every property using it to
        # having a dynamic origin parameter.
        {
            bind origin = null[AdaNode];

            self.get_type()
        }

    |" Get the type for this subtype.
    @exported
    @abstract
    @with_dynvars(origin=null[AdaNode])
    fun get_type(): Entity[BaseTypeDecl]

    fun primitives_env(): LexicalEnv =
        self.from_type_bound().primitives_env()

    @with_dynvars(origin)
    fun array_ndims(): Int = self.get_type().array_ndims()

    @with_dynvars(origin, include_ud_indexing=false, dottable_type=null[AdaNode])
    fun defining_env(): LexicalEnv = self.get_type().defining_env()

    @with_dynvars(origin=null[AdaNode])
    fun canonical_type(): Entity[BaseTypeDecl] =
        self.get_type().canonical_type()

    @with_dynvars(origin)
    fun record_def(): Entity[BaseRecordDef] = self.get_type().record_def()

    @with_dynvars(origin=null[AdaNode])
    fun accessed_type(): Entity[BaseTypeDecl] =
        self.get_type().accessed_type()

    fun is_task_type(): Bool = self.get_type().is_task_type()

    @with_dynvars(origin=null[AdaNode])
    fun is_int_type(): Bool = self.get_type().is_int_type()

    @with_dynvars(origin=null[AdaNode])
    fun is_discrete_type(): Bool = self.get_type().is_discrete_type()

    @with_dynvars(origin=null[AdaNode])
    fun is_real_type(): Bool = self.get_type().is_real_type()

    @with_dynvars(origin=null[AdaNode])
    fun is_float_type(): Bool = self.get_type().is_float_type()

    @with_dynvars(origin=null[AdaNode])
    fun is_fixed_point(): Bool = self.get_type().is_fixed_point()

    @with_dynvars(origin=null[AdaNode])
    fun is_enum_type(): Bool = self.get_type().is_enum_type()

    @with_dynvars(origin=null[AdaNode])
    fun is_access_type(): Bool = self.get_type().is_access_type()

    @with_dynvars(origin)
    fun access_def(): Entity[AccessDef] = self.get_type().access_def()

    @with_dynvars(origin=null[AdaNode])
    fun is_char_type(): Bool = self.get_type().is_char_type()

    @with_dynvars(origin=null[AdaNode])
    fun is_tagged_type(): Bool = self.get_type().is_tagged_type()

    @with_dynvars(origin=null[AdaNode])
    fun base_type(): Entity[BaseTypeDecl] = self.get_type().base_type()

    @with_dynvars(origin)
    fun base_interfaces(): Array[Entity[BaseTypeDecl]] =
        self.get_type().base_interfaces()

    @with_dynvars(origin=null[AdaNode])
    fun base_types(): Array[Entity[BaseTypeDecl]] =
        self.get_type().base_types()

    @with_dynvars(origin)
    fun array_def(): Entity[ArrayTypeDef] = self.get_type().array_def()

    fun is_classwide(): Bool = self.from_type_bound().is_classwide()

    @with_dynvars(origin)
    fun is_iterable_type(): Bool = self.get_type().is_iterable_type()

    @with_dynvars(origin)
    fun iterable_comp_type(): Entity[BaseTypeDecl] =
        self.get_type().iterable_comp_type()

    @with_dynvars(origin)
    fun iterable_cursor_type(): Entity[BaseTypeDecl] =
        self.get_type().iterable_cursor_type()

    @with_dynvars(origin=null[AdaNode])
    fun is_record_type(): Bool = self.get_type().is_record_type()

    fun is_private(): Bool = self.from_type_bound().is_private()

    @with_dynvars(origin=null[AdaNode])
    fun root_type(): Entity[BaseTypeDecl] = self.get_type().root_type()

    fun has_ud_indexing(): Bool = self.from_type_bound().has_ud_indexing()

    fun constant_indexing_fns(): Array[Entity[BasicDecl]] =
        self.from_type_bound().constant_indexing_fns()

    fun variable_indexing_fns(): Array[Entity[BasicDecl]] =
        self.from_type_bound().variable_indexing_fns()

    @with_dynvars(origin=null[AdaNode])
    fun discriminants_list(stop_recurse_at: Entity[BaseTypeDecl] = null[Entity[BaseTypeDecl]]): Array[Entity[BaseFormalParamDecl]] =
        self.get_type().discriminants_list(stop_recurse_at)
}

|" Specific ``BaseSubtypeDecl`` synthetic subclass for the base type of scalar
|" types.
@synthetic
class DiscreteBaseSubtypeDecl: BaseSubtypeDecl {
    @parse_field @null_field aspects: AspectSpec

    @with_dynvars(imprecise_fallback=false)
    # TODO: If base subtype is from a formal type, then False
    fun is_static_decl(): Bool = true

    @with_dynvars(origin=null[AdaNode])
    fun get_type(): Entity[BaseTypeDecl] =
        node.parent.as![BaseTypeDecl].as_entity
}

|" Subtype declaration (:rmlink:`3.2.2`).
class SubtypeDecl: BaseSubtypeDecl {
    @parse_field subtype: SubtypeIndication
    @parse_field aspects: AspectSpec

    @with_dynvars(origin=null[AdaNode])
    fun get_type(): Entity[BaseTypeDecl] = match self.subtype.designated_type() {
        case st: SubtypeDecl => st.get_type()
        case t => t
    }

    @memoized
    fun get_imp_deref(): Entity[Expr] =
       self.get_type().get_imp_deref()

    fun discrete_range(): DiscreteRange = self.subtype.discrete_range()

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = self.subtype.sub_equation()

    @with_dynvars(imprecise_fallback=false)
    fun is_static_decl(): Bool = self.subtype.is_static_subtype()

    fun xref_entry_point(): Bool = true

    env_spec {
        add_to_env_kv(self.name_symbol(), node)
        # Subtype predicates expressions can refers to its own subtype
        # declaration identifier as an object such as in::
        #
        #     subtype Odd is Natural with
        #        Dynamic_Predicate => Odd mod 2 = 1;
        #
        # where ``Odd`` should refer to an anonymous object of the same name
        # and of its own subtype. This object only virtually exists in the
        # subtype environment, so we add a children environement here, just to
        # hold this object.
        add_env(transitive_parent=true)
        add_to_env(self.synthetic_object_decl_env_assoc)
    }
}

|" Synthetic node (not parsed, generated from a property call). Refers to the
|" classwide type for a given tagged type (:rmlink:`3.4.1`).
@synthetic
class ClasswideTypeDecl: BaseTypeDecl {
    @parse_field @null_field aspects: AspectSpec

    fun type_decl(): Entity[BaseTypeDecl] = self.parent.as[BaseTypeDecl]

    fun is_classwide(): Bool = true

    @with_dynvars(origin=null[AdaNode])
    fun is_tagged_type(): Bool = true

    @with_dynvars(origin=null[AdaNode])
    fun base_type(): Entity[BaseTypeDecl] = null[Entity[BaseTypeDecl]]

    @with_dynvars(origin)
    fun base_interfaces(): Array[Entity[BaseTypeDecl]] =
        null[Array[Entity[BaseTypeDecl]]]

    @with_dynvars(origin)
    fun record_def(): Entity[BaseRecordDef] = self.type_decl().record_def()

    fun classwide_type(): Entity[ClasswideTypeDecl] = self

    @with_dynvars(origin)
    fun is_iterable_type(): Bool = self.type_decl().is_iterable_type()

    fun has_ud_indexing(): Bool = self.type_decl().has_ud_indexing()

    fun constant_indexing_fns(): Array[Entity[BasicDecl]] =
        self.type_decl().constant_indexing_fns()

    fun variable_indexing_fns(): Array[Entity[BasicDecl]] =
        self.type_decl().variable_indexing_fns()

    fun is_task_type(): Bool = self.type_decl().is_task_type()

    @with_dynvars(origin)
    fun iterable_comp_type(): Entity[BaseTypeDecl] =
        self.type_decl().iterable_comp_type()

    @with_dynvars(origin, include_ud_indexing=false, dottable_type=null[AdaNode])
    fun defining_env(): LexicalEnv = self.type_decl().defining_env()

    fun is_private(): Bool = self.type_decl().is_private()

    fun is_in_private_part(): Bool = self.type_decl().is_in_private_part()

    fun is_in_public_part(): Bool = self.type_decl().is_in_public_part()

    fun get_aspect_spec(): Entity[AspectSpec] =
        self.type_decl().get_aspect_spec()

    @with_dynvars(origin=null[AdaNode])
    fun is_interface_type(): Bool = self.type_decl().is_interface_type()

    @with_dynvars(origin=null[AdaNode])
    fun discriminants_list(stop_recurse_at: Entity[BaseTypeDecl] = null[Entity[BaseTypeDecl]]): Array[Entity[BaseFormalParamDecl]] =
        self.type_decl().discriminants_list(stop_recurse_at)

    @with_dynvars(origin=null[AdaNode])
    fun canonical_type(): Entity[BaseTypeDecl] =
        self.type_decl().canonical_type().do(
            # The canonical type should be classwide whenever it makes sense
            # (e.g. if the canonical type is a tagged record type.) Otherwise
            # return a non-classwide type.
            (t) => t.classwide_type() or? t
        )

    # We don't want to add the classwide type to the environment
    env_spec {
    }
}

|" Incomplete declaration for a type (:rmlink:`12.5`).
class IncompleteTypeDecl: BaseTypeDecl {
    @parse_field @nullable discriminants: DiscriminantPart
    @parse_field @null_field aspects: AspectSpec

    |" Searches for the next part of self inside the given declarative part.
    |" Since self is an IncompleteTypeDecl, the next part will necessarily be
    |" the first type declaration of the same name that is not self.
    fun find_next_part_in(decl_part: Entity[DeclarativePart]): Entity[BaseTypeDecl] = decl_part.children_env().get(
        node.name_symbol(), lookup=LookupKind.minimal, categories=RefCategories(inherited_primitives=false, _=true)
    ).find(
        (t) => t.as[BaseTypeDecl].do((btd) => self != btd)
    ).as[BaseTypeDecl]

    @with_dynvars(origin, include_ud_indexing=false, dottable_type=null[AdaNode])
    fun defining_env(): LexicalEnv =
        [node.children_env(), node.dottable_subps_env].env_group()

    @with_dynvars(origin=null[AdaNode])
    fun discriminants_list(@ignored stop_recurse_at: Entity[BaseTypeDecl] = null[Entity[BaseTypeDecl]]): Array[Entity[BaseFormalParamDecl]] =
        self.discriminants.abstract_formal_params()

    env_spec {
        add_to_env_kv(self.name_symbol(), node)
        add_env()
    }
}

|" A formal incomplete type declaration.
class IncompleteFormalTypeDecl: IncompleteTypeDecl {
    @parse_field @nullable is_tagged: Tagged
    @parse_field @nullable default_type: Name

    @with_dynvars(origin=null[AdaNode])
    fun is_tagged_type(): Bool = not node.is_tagged.is_null

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = self.default_type.sub_equation()
}

|" Incomplete declaration for a tagged type.
class IncompleteTaggedTypeDecl: IncompleteTypeDecl {
    @parse_field has_abstract: Abstract

    @with_dynvars(origin=null[AdaNode])
    fun is_tagged_type(): Bool = true
}

|" Declaration for a protected type (:rmlink:`9.4`).
class ProtectedTypeDecl: BaseTypeDecl {
    @parse_field @nullable discriminants: DiscriminantPart
    @parse_field aspects: AspectSpec
    @parse_field interfaces: ParentList
    @parse_field definition: ProtectedDef

    @with_dynvars(origin=null[AdaNode])
    fun discriminants_list(@ignored stop_recurse_at: Entity[BaseTypeDecl] = null[Entity[BaseTypeDecl]]): Array[Entity[BaseFormalParamDecl]] =
        self.discriminants.abstract_formal_params()

    @with_dynvars(origin, include_ud_indexing=false, dottable_type=null[AdaNode])
    fun defining_env(): LexicalEnv = self.definition.private_part.do(
        (pp) =>
        # Include private_part's env unconditionally. This is safe since
        # ProtectedTypeDecl can't be overloaded, thus wrong name resolution
        # can only occur on invalid Ada code.
        [self.children_env(), pp.children_env()].env_group(),
        default_val=self.children_env()
    )

    @with_dynvars(origin)
    fun base_interfaces(): Array[Entity[BaseTypeDecl]] =
        self.interfaces.map((i) => i.name_designated_type())

    fun xref_entry_point(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.interfaces.logic_all((ifc) => ifc.xref_equation())

    fun declarative_parts(): Array[Entity[DeclarativePart]] = {
        val pdef = self.definition;

        [pdef.public_part.as[DeclarativePart]] & pdef.private_part.as[DeclarativePart].do((v1) => [v1])
    }

    fun env_names(): Array[Symbol] =
        node.top_level_env_name().do((fqn) => [fqn.to_symbol])

    env_spec {
        add_to_env_kv(self.name_symbol(), node)
        add_env(names=node.env_names())
    }
}

|" Declaration for a task type (:rmlink:`9.1`).
class TaskTypeDecl: BaseTypeDecl {
    @parse_field @nullable discriminants: DiscriminantPart
    @parse_field aspects: AspectSpec
    @parse_field @nullable definition: TaskDef

    fun is_task_type(): Bool = true

    @with_dynvars(origin)
    fun base_interfaces(): Array[Entity[BaseTypeDecl]] =
        self.definition?.interfaces.map((i) => i.name_designated_type())

    fun env_names(): Array[Symbol] =
        node.top_level_env_name().do((fqn) => [fqn.to_symbol])

    @with_dynvars(origin, include_ud_indexing=false, dottable_type=null[AdaNode])
    fun defining_env(): LexicalEnv = self.children_env()

    @memoized
    fun primitives_env(): LexicalEnv =
        self.compute_primitives_env(include_self=true)

    @with_dynvars(origin=null[AdaNode])
    fun discriminants_list(@ignored stop_recurse_at: Entity[BaseTypeDecl] = null[Entity[BaseTypeDecl]]): Array[Entity[BaseFormalParamDecl]] =
        self.discriminants.abstract_formal_params()

    fun xref_entry_point(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = self.definition.do(
        (d) => d.xref_equation(), default_val=%true
    )

    fun declarative_parts(): Array[Entity[DeclarativePart]] = self.definition.do(
        (tdef) => [tdef.public_part.as[DeclarativePart]] & tdef.private_part.as[DeclarativePart].do((v1) => [v1])
    )

    env_spec {
        add_to_env_kv(self.name_symbol(), node)
        add_env(names=node.env_names())
    }
}

|" Type declaration for a single task (:rmlink:`9.1`).
class SingleTaskTypeDecl: TaskTypeDecl {
    env_spec {
        # In this case, we don't want to add this type to the env, because it's
        # the single task that contains this type decl that will be added to
        # the env. So we don't call the inherited env spec.
        add_env()
    }
}

|" Type declarations that embed a type definition node. Corresponds to the
|" ARM's full type declarations (:rmlink:`3.2.1`).
@abstract
class TypeDecl: BaseTypeDecl {
    @parse_field @nullable discriminants: DiscriminantPart
    @parse_field type_def: TypeDef

    |" Whether self is a type that is iterable in a for .. of loop
    @with_dynvars(origin)
    fun is_iterable_type(): Bool =
        self.is_array() or not self.get_aspect(s"Iterator_Element", true).value.is_null or (
            # TODO: The optional `Element` assoc must be defined, if not, a
            # type with the aspect `Iterable` only supports iteration over
            # cursors through the `for .. in` loop (W303-007).
            not self.get_aspect(s"Iterable", true).value.is_null
        )

    @with_dynvars(origin)
    fun iterable_comp_type(): Entity[BaseTypeDecl] = {
        val ie = self.get_aspect(s"Iterator_Element", true).value;
        val it = self.get_aspect(s"Iterable", true).value;

        {
            bind imprecise_fallback = false;

            if self.is_array() then self.comp_type()
            elif not ie.is_null then ie.as[Name].do(
                (name) => {
                    bind env = name.node_env();

                    name.designated_type_impl()
                }
            )
            elif not it.is_null then it.as[Aggregate].assocs.unpacked_params().find((sa) => sa.name.name_is(s"Element")).assoc.expr().as![Name].referenced_decl().expr_type()
            else null[Entity[BaseTypeDecl]]
        }
    }

    |" If self is a type that is iterable (i.e.: it has the Iterable aspect
    |" defined), return the type of the cursor in use by this iterable type.
    @with_dynvars(origin)
    fun iterable_cursor_type(): Entity[BaseTypeDecl] =
        self.get_aspect(s"Iterable", previous_parts_only=true).value.do(
            (it) => it.as[Aggregate].assocs.unpacked_params().find((sa) => sa.name.name_is(s"First")).assoc.expr().as![Name].referenced_decl().expr_type()
        )

    fun discrete_range(): DiscreteRange = self.type_def.discrete_range()

    @with_dynvars(origin=null[AdaNode])
    fun discriminants_list(stop_recurse_at: Entity[BaseTypeDecl] = null[Entity[BaseTypeDecl]]): Array[Entity[BaseFormalParamDecl]] = {
        # TODO: investigate if below origin.bind is valid
        val base_type = self.base_type();
        val self_discs = self.discriminants.do((d) => d.abstract_formal_params());

        if self.is_access_type() then self.accessed_type().discriminants_list(stop_recurse_at)
        elif self_discs.length() > 0 then self_discs
        elif not base_type.is_null and base_type.matching_type(stop_recurse_at) then self_discs
        elif not base_type.is_null then self.base_type().discriminants_list(stop_recurse_at)
        else null[Array[Entity[BaseFormalParamDecl]]]
    }

    @with_dynvars(origin)
    fun array_ndims(): Int = self.type_def.array_ndims()

    @with_dynvars(origin=null[AdaNode])
    fun is_real_type(): Bool = self.type_def.is_real_type()

    @with_dynvars(origin=null[AdaNode])
    fun is_float_type(): Bool = self.type_def.is_float_type()

    @with_dynvars(origin=null[AdaNode])
    fun is_fixed_point(): Bool = self.type_def.is_fixed_point()

    @with_dynvars(origin=null[AdaNode])
    fun is_int_type(): Bool = self.type_def.is_int_type()

    @with_dynvars(origin=null[AdaNode])
    fun is_access_type(): Bool = node.as_bare_entity.type_def.is_access_type()

    @with_dynvars(imprecise_fallback=false)
    fun is_static_decl(): Bool = node.as_bare_entity.type_def.is_static()

    @with_dynvars(origin=null[AdaNode])
    fun accessed_type(): Entity[BaseTypeDecl] = {
        val imp_deref = self.get_imp_deref();

        if imp_deref.is_null then self.type_def.accessed_type() else (
            # Here, we need to call defining_env on TypeDef, in order to not
            # recurse for ever (accessed_type is called by defining_env).
            {
                bind include_ud_indexing = false;

                self.type_def.defining_env().get_first(
                    imp_deref.as[Name].name_symbol(), categories=RefCategories(inherited_primitives=false, _=true)
                )
            }

            # We cast to BaseFormalParamDecl. Following Ada's legality rule,
            # you need to implicit deref on a discriminant, but I see no reason
            # to enforce that here.
            .as![BaseFormalParamDecl].formal_type().accessed_type()
        )
    }

    @with_dynvars(origin)
    fun access_def(): Entity[AccessDef] = match self.type_def {
        case ad: AccessDef => ad
        case dtd: DerivedTypeDef => dtd.base_type().access_def()
        case _ => null[Entity[AccessDef]]
    }

    @with_dynvars(origin=null[AdaNode])
    fun is_tagged_type(): Bool = self.type_def.is_tagged_type()

    fun is_task_type(): Bool = self.type_def.is_task_type()

    @with_dynvars(origin=null[AdaNode])
    fun base_type(): Entity[BaseTypeDecl] = self.type_def.base_type()

    @with_dynvars(origin)
    fun base_interfaces(): Array[Entity[BaseTypeDecl]] =
        self.type_def.base_interfaces()

    @with_dynvars(origin=null[AdaNode])
    fun is_char_type(): Bool = self.type_def.is_char_type()

    @with_dynvars(origin=null[AdaNode])
    fun is_enum_type(): Bool = self.type_def.is_enum_type()

    fun is_private(): Bool =
        node.type_def is PrivateTypeDef or node.type_def.as[DerivedTypeDef].do((dtd) => dtd.has_with_private.as_bool())

    fun is_derived_tagged_type(): Bool =
        self.type_def.is_tagged_type() and self.type_def is DerivedTypeDef | InterfaceTypeDef

    @with_dynvars(origin)
    fun array_def(): Entity[ArrayTypeDef] = match self.type_def {
        case atd: ArrayTypeDef => atd
        case dtd: DerivedTypeDef => dtd.base_type().array_def()
        case _ => null[Entity[ArrayTypeDef]]
    }

    @with_dynvars(origin=null[AdaNode])
    fun root_type(): Entity[BaseTypeDecl] = match self.type_def {
        case dtd: DerivedTypeDef => dtd.base_type().root_type()
        case _ => self
    }

    @with_dynvars(origin, include_ud_indexing=false, dottable_type=null[AdaNode])
    fun defining_env(): LexicalEnv = {
        val imp_deref = self.get_imp_deref();
        # Evaluating in type env, because the defining environment of a type
        # is always its own.
        val self_env = self.type_def.defining_env();

        if not imp_deref.is_null then [self_env, self.accessed_type().defining_env()].env_group()
        elif include_ud_indexing and self.has_ud_indexing() then {
            bind include_ud_indexing = false;

            (
                (
                    self.constant_indexing_fns() & self.variable_indexing_fns()
                ).map((fn) => fn.defining_env()) & [self_env]
            ).env_group()
        }
        else self_env
    }

    @memoized
    fun primitives_env(): LexicalEnv =
        self.compute_primitives_env(include_self=true)

    |" Return all the predefined operators for this type, as an array of env
    |" associations ready to be added to a lexical environment.
    |"
    |" Note that the universal int and universal real types are not real
    |" type declarations and do not have their own operators
    |" (:rmlink:`3.4.1` - 7).
    @memoized
    fun predefined_operators(): Array[EnvAssoc] =
        if self in node.universal_int_type() | node.universal_real_type() then null[Array[EnvAssoc]]
        elif self == node.universal_fixed_type() then node.type_def.as[RealTypeDef].universal_fixed_predefined_operators()
        else node.type_def.predefined_operators()

    @with_dynvars(origin)
    fun record_def(): Entity[BaseRecordDef] = match self.type_def {
        case r: RecordTypeDef => r.record_def

        # If the derived type is tagged, then return its own record def. If
        # it isn't tagged, return the base type's record def.
        case d: DerivedTypeDef => if self.is_tagged_type() then d.record_extension else d.base_type()?.record_def()
        case _ => null[Entity[BaseRecordDef]]
    }

    fun xref_entry_point(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = # TODO: Handle discriminants
    self.type_def.sub_equation()

    @with_dynvars(origin=null[AdaNode])
    fun is_discrete_type(): Bool = self.type_def.is_discrete_type()

    fun parent_primitives_env(): LexicalEnv =
        if node.type_def is DerivedTypeDef | InterfaceTypeDef then self.compute_primitives_env(include_self=false) else node.empty_env()

    |" Return a lexical environment containing the primitives inherited by
    |" this type. This makes sure not to re-include primitives which have
    |" already been inherited by the previous part of this type, so as to:
    |"
    |"  - Not overload lexical envs with useless entries (when one has view
    |"    on this part, it necessarily has view on its previous part).
    |"
    |"  - But most importantly, to fix a visibility issue arising when
    |"    resolving a reference to a subprogram overridden in the public part
    |"    of a package if the type has a refined declaration in its private
    |"    part, in which case the inherited subprogram would take precedence
    |"    over the overridden one (see testcase precise_override_2, U817-024).
    |"
    |"    This change fixes this issue because, by construction, if the
    |"    overridden subprogram lies in the public part, it means the public
    |"    type declaration already has a view on the inherited subprogram,
    |"    which means we won't include it in the environment computed here
    |"    for the private view.
    fun refined_parent_primitives_env(): LexicalEnv = self.compute_primitives_env(
        include_self=false, stop_at=self.previous_part()?.base_types()
    )

    fun get_imp_deref(): Entity[Expr] =
        # Fast path: as the ``Implicit_Deference`` must refer to a
        # discriminant, we know the aspect cannot be defined if this type
        # doesn't have a discriminant part. Besides, if some part of a type
        # defines a discriminant part, then the next parts will necessarily
        # repeat it, therefore we don't need to recurse on this type's previous
        # part. This logic is however not valid for derived types, so don't
        # include them in the fast path.
        if node.discriminants.is_null and not node.type_def is DerivedTypeDef then null[Entity[Expr]] else self.get_aspect(s"Implicit_Dereference", true).value

    fun has_ud_indexing(): Bool =
        not self.get_aspect(s"Constant_Indexing", true).value.is_null or not self.get_aspect(s"Variable_Indexing", true).value.is_null

    |" Return the indexing functions locally defined for this type. If the
    |" type is the one for which the aspect has been defined, then return its
    |" corresponding user-defined functions. If this type is derived from a
    |" type having the aspect, this property only returns any overrides
    |" defined for it.
    fun indexing_fns(name: Entity[Name]): Array[Entity[BasicDecl]] = name.do(
        (name) => {
            bind env = self.node_env();
            bind origin = self.origin_node();

            # Get all elements for name in self's env
            name.all_env_els_impl(seq=false)
        }
    ).filtermap(
        (e) => e.as[BasicDecl], (e) => e.as![BasicDecl].subp_spec_or_null().do(
            (ss) => {
                bind origin = e.node;

                # Unfortunately, we can't use `UserDefinedFunctionSubpSpec` (as in
                # `user_defined_literal_fns`) here to filter candidates since user
                # defined functions can have many parameters without any
                # constraints on them. Only the first parameter should be a the
                # type of self.
                ss.unpacked_formal_params()?[0]?.formal_decl().formal_type().matching_formal_type(self)
            }
        )
    ).unique()

    |" Get all the indexing functions designated by ``name`` defined for
    |" this type by recursing parent types until ``root_type``.
    fun all_indexing_fns_impl(name: Entity[Name], root_type: Entity[TypeDecl]): Array[Entity[BasicDecl]] = self.indexing_fns(name) & self.base_type().do((bt) =>
        # The user indexing functions can be overriden, so recurse on all
        # base types to get them all.
        if self == root_type then null[Array[Entity[BasicDecl]]] else bt.as![TypeDecl].all_indexing_fns_impl(name, root_type)
    )

    |" Return all the indexing functions defined for this type, including
    |" ones defined by its parents.
    fun all_indexing_fns(sym: Symbol): Array[Entity[BasicDecl]] = self.get_aspect(sym, true).value.do(
        (value) => {
            # The indexing function's name is specified on the type for
            # which the aspect is defined (which is returned by
            # `get_aspect` here).
            val fn_name = value.as![Name];
            # The root type of the type derivation chain (to stop the
            # recursion in `all_indexing_fns`).
            val root_type = value.parent.parent.as[TypeDecl];

            self.all_indexing_fns_impl(fn_name, root_type)
        }
    )

    fun constant_indexing_fns(): Array[Entity[BasicDecl]] =
        self.all_indexing_fns(s"Constant_Indexing")

    fun variable_indexing_fns(): Array[Entity[BasicDecl]] =
        self.all_indexing_fns(s"Variable_Indexing")

    |" Return the functions detoned by the user defined literal aspect
    |" ``aspect`` for this type.
    fun user_defined_literal_fns(aspect: Symbol): Array[Entity[BasicDecl]] = {
        # User-defined literal aspects denote a function with a result type of
        # ``self`` and one parameter that is of type ``String`` (or
        # ``Wide_Wide_String`` for ``String_Literal``).
        val expected_spec = UserDefinedFunctionSubpSpec(
            subp_params_types=[if aspect == s"String_Literal" then node.std_wide_wide_string_type() else node.std_string_type()], subp_return_type=self
        );
        # ``Real_Literal`` detoned function can be overrode by a function with
        # a result type of ``self`` and two parameters that are of type
        # ``String``.
        val expected_specs = [if aspect == s"Real_Literal" then UserDefinedFunctionSubpSpec(
            subp_params_types=[node.std_string_type(), node.std_string_type()], subp_return_type=self
        ) else null[UserDefinedFunctionSubpSpec]] & [expected_spec];

        self.get_aspect_spec_expr(aspect).do(
            (a) => a.as![Name].all_env_elements_internal(seq=false).filtermap(
                (e) => e.as[BasicDecl], (e) => e.as![BasicDecl].subp_spec_or_null().do(
                    (ss) => expected_specs.any(
                        (es) => ss.match_expected_user_defined_function(es)
                    )
                )
            )
        )
    }

    env_spec {
        add_to_env_kv(self.name_symbol(), node)
        add_to_env(node.as_entity.predefined_operators())
        add_env()
        handle_children()
        # Add a synthetic object declaration into its environement in order to
        # support name resolution of self-references that can appear in
        # predicates (see `SyntheticObjectDecl`) or in a records' body.
        # TODO: This could be added conditionally to avoid polluting envs with
        # unnecessary objects if we can statically detect whether it will be
        # useful or not, for example by checking if `Predicate` aspect is
        # specified on this type. However, it is not as easy because there can
        # `Predicate` pragmas defined *after* this.
        add_to_env(self.synthetic_object_decl_env_assoc)
        # Make sure the reference to the primitives env is created *AFTER* the
        # synthetic type predicate object has been added to self's env: since
        # this object has the same name as the type, it is indirectly used to
        # hide the type and avoid infinite recursions in invalid Ada code such
        # as ``type X is new X``. See nameres test `invalid_self_reference`.
        reference(
            [node.as[AdaNode]], TypeDecl.refined_parent_primitives_env, kind=transitive, dest_env=node.node_env(), cond=node.type_def is DerivedTypeDef | InterfaceTypeDef, category="inherited_primitives"
        )
    }
}

|" Anonymous type declaration (for anonymous array or access types). This
|" class has no RM existence, and anonymous (sub)types are referred to
|" implicitly in the RM.
class AnonymousTypeDecl: TypeDecl {
    @parse_field @null_field aspects: AspectSpec

    |" Returns whether:
    |"
    |" 1. self and other are both access types.
    |" 2. Their access def matches structurally. If for_assignment is True,
    |"    matching_assign_type is used instead of matching_type to compare
    |"    the two access defs.
    @with_dynvars(origin)
    fun access_def_matches(other: Entity[BaseTypeDecl], for_assignment: Bool): Bool = {
        val self_subp_access = self.type_def.as[AccessToSubpDef];
        val other_subp_access = other.access_def().as[AccessToSubpDef];

        # If the anonymous type is an access type definition, then verify if
        #  the accessed type corresponds to other's accessed type.
        if not self_subp_access.is_null and not other_subp_access.is_null then other_subp_access.subp_spec.match_signature(self_subp_access.subp_spec, false)
        elif self_subp_access.is_null and other_subp_access.is_null then self.type_def.as[AccessDef]?.accessed_type().do(
            (ast) => other.accessed_type().do(
                (oat) => {
                    # Forget the classwide view: GNAT always allows
                    # comparison/assignment between access-to-T and
                    # access-to-T'Class.
                    val exp = ast.specific_type();
                    val act = oat.specific_type();

                    if for_assignment then (
                        # Pass the possibly-classwide view of the expected
                        # type here, because matching_assign_type will
                        # handle this case specifically.
                        act.matching_assign_type(ast)
                    ) else act.matching_type(exp)
                }
            )
        )
        else false
    }

    fun xref_entry_point(): Bool = false

    # We don't want to add anonymous type declarations to the lexical
    # environments, so we reset the env spec.
    env_spec {
    }
}

|" Synthetic anonymous type decl. Used to generate anonymous access types.
@synthetic
class SynthAnonymousTypeDecl: AnonymousTypeDecl {
}

|" A concrete type declaration.
class ConcreteTypeDecl: TypeDecl {
    @parse_field aspects: AspectSpec
}

|" A formal type declaration.
class FormalTypeDecl: TypeDecl {
    @parse_field @nullable default_type: Name
    @parse_field aspects: AspectSpec

    |" Retrieves the actual for this formal type decl by finding the generic
    |" formal part in which self lies in self's rebindings, and then resolving
    |" the corresponding actual.
    fun corresponding_actual_impl(rb: EnvRebindings): Entity[BaseTypeDecl] = if rb.is_null then self
    elif rb.old_env == node.parent.node_env() then rb.new_env.get_first(
        self.defining_name().name_symbol(), lookup=LookupKind.minimal, categories=RefCategories(inherited_primitives=false, _=true)
    ).as[BaseTypeDecl]
    else self.corresponding_actual_impl(rb.get_parent)

    |" For a ``FormalTypeDecl`` we must find the actual by looking in our own
    |" rebindings. See ``corresponding_actual_impl``.
    fun get_actual(): Entity[BaseTypeDecl] =
        self.corresponding_actual_impl(self.info.rebindings)

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = self.super() and self.default_type.do(
        (dt) => dt.sub_equation(), default_val=%true
    )
}

|" Base class for subprogram declarations.
@abstract
class BasicSubpDecl: BasicDecl {
    fun defining_names(): Array[Entity[DefiningName]] =
        [self.subp_decl_spec().name()]

    @with_dynvars(origin, include_ud_indexing=false, dottable_type=null[AdaNode])
    fun defining_env(): LexicalEnv =
        self.subp_decl_spec().defining_env()

    |" The expr type of a subprogram declaration is the return type of the
    |" subprogram if the subprogram is a function.
    fun type_expression(): Entity[TypeExpr] = self.subp_decl_spec().returns()

    @with_dynvars(imprecise_fallback=false)
    fun get_body_in_env(env: LexicalEnv): Entity[Body] = {
        val elements = env.get(
            self.name_symbol(), lookup=LookupKind.flat, categories=RefCategories(inherited_primitives=false, _=true)
        );
        val self_spec = self.subp_decl_spec().node.as_bare_entity;
        val precise = {
            bind origin = self_spec.origin_node();

            elements.find((ent) =>
                # Discard the rebindings of self before trying to match
                # against the tentative body, as those do not carry that info.
                ent.node.as_bare_entity.as[Body]?.formal_param_holder_or_null().match_other(self_spec, true)
            ).as[Body]
        };
        val result = if precise.is_null and imprecise_fallback then elements.find((e) => e is Body).as[Body] else precise;

        # If found, reuse the rebindings of the decl on the body
        result.node.as_entity?.without_md().as[Body]
    }

    @with_dynvars(imprecise_fallback=false)
    fun next_part_for_decl(): Entity[BasicDecl] = {
        val decl_scope = self.declarative_scope();
        val parent_decl = decl_scope.as_entity.do(
            (ds) => ds.semantic_parent().as[BasicDecl]
        );
        val default_next_part = self.super();

        # If __nextpart is registered in the decl's env, simply return
        # that.
        if not default_next_part.is_null then default_next_part
        elif decl_scope is PrivatePart | PublicPart then {
            val other_part = if decl_scope is PrivatePart then parent_decl.next_part_for_decl() else parent_decl.decl_private_part();

            # Search in other part
            other_part.do(
                (op) => self.get_body_in_env(op.children_env())
            ) or? parent_decl.body_part_for_decl().do(
                # If not found, search in body
                (np) => self.get_body_in_env(np.children_env())
            )
        }
        # No declarative scope: Bail out!
        elif decl_scope.is_null then null[Entity[Body]]
        # self is declared in any other declarative scope. Search for decl
        # in it directly.
        else self.get_body_in_env(decl_scope.children_env())
    }

    @with_dynvars(origin)
    fun constrain_prefix(prefix: Expr): Equation =
        self.subp_constrain_prefix(prefix)

    @with_dynvars(origin)
    fun expr_type(): Entity[BaseTypeDecl] =
        self.subp_spec_or_null()?.return_type()

    fun env_names(): Array[Symbol] =
        node.top_level_env_name().do((fqn) => [fqn.to_symbol])

    |" Return the specification for this subprogram
    @exported
    @abstract
    fun subp_decl_spec(): Entity[BaseSubpSpec]

    env_spec {
        # Call the env hook to parse eventual parent unit
        do(node.env_hook())
        set_initial_env(
            # TODO: This is wrong (should take into account whether the entity
            # is private or not), but we have no example of cases where this is
            # a problem yet.
            node.child_decl_initial_env(true)
        )
        add_to_env(self.child_decl_env_assocs())
        add_env(names=node.env_names())
        do(node.populate_dependent_units())
        reference(
            node.top_level_use_package_clauses(), Name.use_package_name_designated_env, cond=node.parent is LibraryItem | Subunit
        )
        reference(
            node.top_level_use_type_clauses(), Name.name_designated_type_env, cond=node.parent is LibraryItem | Subunit
        )
        handle_children()
        do(node.populate_body_unit())
    }
}

|" This is an intermediate abstract class for subprogram declarations with a
|" common structure: overriding indicator, ``SubpSpec``, aspects,
|" <other fields>.
@abstract
class ClassicSubpDecl: BasicSubpDecl {
    @parse_field overriding: Overriding
    @parse_field subp_spec: SubpSpec

    fun subp_decl_spec(): Entity[BaseSubpSpec] = self.subp_spec

    |" Return the BaseSubpBody corresponding to this node.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun body_part(): Entity[BaseSubpBody] =
        self.body_part_for_decl().as![BaseSubpBody]
}

|" Declaration for an abstract subprogram (:rmlink:`3.9.3`).
class AbstractSubpDecl: ClassicSubpDecl {
    @parse_field aspects: AspectSpec
}

|" Formal subprogram declarations, in generic declarations formal parts
|" (:rmlink:`12.6`).
@abstract
class FormalSubpDecl: ClassicSubpDecl {
    @parse_field @nullable default_expr: Expr
    @parse_field aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] =
        [self.subp_spec.name()]

    fun xref_entry_point(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = self.default_expr.do(
        (e) => match e {
            case _: NullLiteral => %true
            case _: BoxExpr => %true
            case n: Name => (
                if n is AttributeRef then n.sub_equation() else n.xref_no_overloading(all_els=true)
            ) and %predicate(BasicDecl.subp_decl_match_signature, n.ref_var(), self.as[BasicDecl])
            case _ => raise[Equation] PropertyError("Should not happen")
        }, default_val=%true
    )

    |" Given the name used in the instantiation for this formal subp decl,
    |" resolve it at the instantiation site to the corresponding declaration.
    |" This property basically replaces ``AdaNode.resolve_generic_actual`` but
    |" is more precise because we have access to the formal spec, which means
    |" we can disambiguate between overloaded actuals.
    |" Note that we cannot simply call ``referenced_decl`` here as this would
    |" cause name resolution recursions which we want to avoid at all cost.
    @memoized
    fun resolve_actual_name(name: Entity[Expr]): Entity[BasicDecl] = {
        bind origin = name.node;

        if name is AttributeRef then
            name.as[AttributeRef].attribute_subprogram()
        elif name is BoxExpr then
            # We are inside an instantiation of formal package without
            # constraint on this function (so, a BoxExpr).
            null[Entity[BasicDecl]]
        elif name is Name then
            name.as[Name].all_env_elements().find(
                (el) => el.as[BasicDecl]?.subp_decl_match_signature(self)
            ).as[BasicDecl]
        else
            raise[Entity[BasicDecl]] PropertyError(
                "invalid actual for subprogram formal"
            )
    }

    |" Retrieves the actual for this formal subprogram by finding the generic
    |" formal part in which self lies in self's rebindings, and then resolving
    |" the corresponding actual.
    fun corresponding_actual_impl(rb: EnvRebindings): Entity[BasicDecl] =
        if rb.is_null then
            self
        elif rb.old_env == node.parent.node_env() then
            rb.new_env.env_node.as[GenericInstantiation].do(
                (inst) => Entity[GenericInstantiation](
                    node=inst, info=EntityInfo(
                        md=null[Metadata],
                        rebindings=rb.get_parent,
                        from_rebound=false
                    )
                )
            ).actual_for_formal(self.defining_name().node).do(
                (name) => self.resolve_actual_name(name)
            ).do(
                (actual) => Entity[BasicDecl](
                    node=actual.node,
                    info=EntityInfo(
                        md=actual.info.md,
                        rebindings=actual.info.rebindings,
                        # We (manually) found an actual for our formal through
                        # the given rebindings, so set the `from_rebound` flag.
                        from_rebound=true
                    )
                ).corresponding_actual()
            ) or? self
        else
            self.corresponding_actual_impl(rb.get_parent)

    |" For a ``FormalSubpDecl`` we must find the actual by looking in our own
    |" rebindings. See ``corresponding_actual_impl``.
    fun corresponding_actual(): Entity[BasicDecl] =
        self.corresponding_actual_impl(self.info.rebindings)

    |" Return the first visible subprogram that can match this formal subp in
    |" the context of an instantiation. This is used to find the matching
    |" subprogram in an instantiation for a formal subp with a box expr.
    |" This property assumes that ``self`` is already in the context of the
    |" given instantiation.
    fun designated_subprogram_from(inst: Entity[GenericInstantiation]): Entity[BasicDecl] = {
        val subps = node.env_get(
            env=inst.node_env(), symbol=self.defining_name().name_symbol(), from_node=inst.node
        );
        # Search for the first subprogram that matches the instantiated profile
        val found = {
            bind origin = inst.origin_node();

            subps.find(
                (subp) => subp.as[BasicDecl].subp_spec_or_null().do(
                    (spec) => self.subp_spec.match_signature(
                        other=spec, # Names must already match due to the env_get call
                        match_name=false
                    )
                )
            ).as[BasicDecl]
        };

        # ``found`` can be null, for example when it is supposed to designate
        # a builtin operator.
        found?.wrap_public_reference()
    }
}

|" Formal declaration for an abstract subprogram (:rmlink:`12.6`).
class AbstractFormalSubpDecl: FormalSubpDecl {
}

|" Formal declaration for a concrete subprogram (:rmlink:`12.6`).
class ConcreteFormalSubpDecl: FormalSubpDecl {
}

|" Regular subprogram declaration (:rmlink:`6.1`).
class SubpDecl: ClassicSubpDecl {
    @parse_field aspects: AspectSpec

    fun is_constant_object(): Bool = true
}

|" Entry declaration (:rmlink:`9.4`).
class EntryDecl: BasicSubpDecl {
    @parse_field overriding: Overriding
    @parse_field spec: EntrySpec
    @parse_field aspects: AspectSpec

    fun subp_decl_spec(): Entity[BaseSubpSpec] = self.spec

    fun defining_names(): Array[Entity[DefiningName]] = [self.spec.name()]

    |" Return the entry body associated to this entry declaration.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun body_part(): Entity[Body] = self.body_part_for_decl()

    |" Return whether this actually declares a family of entries.
    fun has_family(): Bool = not node.spec.family_type.is_null

    |" Return the type designated by the family type, if relevant. Note that
    |" the family type may be an anonymous range, in which case this property
    |" returns None.
    @with_dynvars(origin)
    fun family_type(): Entity[BaseTypeDecl] =
        self.spec.family_type.as[TypeExpr]?.designated_type()

    |" Return an array of accept statements corresponding to this entry.
    @exported
    fun accept_stmts(): Array[Entity[AcceptStmt]] = self.find_accept_stmts(
        # Find the body part of the task declaration for the current entry
        match self.parent_basic_decl() {
            case st: Entity[SingleTaskTypeDecl] => st.parent_basic_decl()
            case tt: TaskTypeDecl => tt
            case _ => raise[Entity[BasicDecl]] PreconditionFailure("Can only be called on EntryDecl in Tasks")
        }.body_part_for_decl()
    )

    |" Find all accept statements in all children of ``root`` that correspond
    |" to this entry declaration.
    fun find_accept_stmts(root: Entity[AdaNode]): Array[Entity[AcceptStmt]] = root.children.do(
        (child) => child.filter((n) => not n.is_null).mapcat((n) => self.find_accept_stmts(n))
    ) & root.as[AcceptStmt].do(
        (stmt) => if stmt.corresponding_entry() == self then [stmt] else null[Array[Entity[AcceptStmt]]]
    )

    |" ``next_part_for_decl implementation``, specific to entry declarations:
    |" Will try both the regular case with an ``EntryBody`` (for protected
    |" objects), and the fallback case with an ``AceptStmtBody``.
    @with_dynvars(imprecise_fallback=false)
    fun next_part_for_decl(): Entity[BasicDecl] =
        # For tasks, get the corresponding accept statement's body
        if self.parent_basic_decl() is SingleTaskTypeDecl | TaskTypeDecl then self.accept_stmts()?[0]?.body_decl else (
            # For protected entries, call the superclass ``next_part_for_decl``
            self.super()
        )

    env_spec {
        add_to_env_kv(self.name_symbol(), node)
        add_env()
    }
}

|" Declaration for an enumeration literal (:rmlink:`3.5.1`).
class EnumLiteralDecl: BasicSubpDecl {
    @parse_field @nullable name: DefiningName
    @parse_field @null_field aspects: AspectSpec

    @with_dynvars(imprecise_fallback=false)
    fun is_static_decl(): Bool = true

    fun is_constant_object(): Bool = true

    |" Return the integer used to encode this enum literal.
    |"
    |" .. note::
    |"     This property is equivalent to GNAT's ``Enum_Rep`` attribute.
    @exported
    fun enum_rep(): BigInt = {
        val enum_type = self.enum_type();
        val rep_clause = enum_type.get_enum_representation_clause();
        # Equivalent of 'Pos: the 0-based position of this enum literal in the
        # type declaration.
        val pos = node.child_index();

        if rep_clause.is_null then (
            # If there is no representation clause for this enum, so 'Enum_Rep
            # is equivalent to 'Pos.
            pos.as_big_int()
        ) else (
            # Ada mandates that elements in the aggregate for the
            # representation clause are in the same order as the enum literals
            # in the type declaration, so we can just use 'Pos to find the
            # correct value.
            rep_clause.aggregate.assocs?[pos].expr().eval_as_int()
        )
    }

    fun defining_names(): Array[Entity[DefiningName]] = [self.name]

    @memoized
    fun synth_type_expr(): Entity[EnumLitSynthTypeExpr] =
        EnumLitSynthTypeExpr().as_entity

    @memoized
    fun subp_decl_spec(): Entity[BaseSubpSpec] = EnumSubpSpec().as_entity

    |" Return the enum type corresponding to this enum literal.
    @exported
    fun enum_type(): Entity[TypeDecl] =
        node.parents().find((p) => p is TypeDecl).as_entity.as[TypeDecl]

    fun enum_decl_name(): Entity[DefiningName] = self.name

    env_spec {
        add_to_env_kv(
            node.name_symbol(), node, dest_env=DesignatedEnv(
                kind=DesignatedEnvKind.direct_env, env_name=null[Symbol], direct_env=self.enum_type().node_env()
            )
        )
        # We add an env here so that parent_basic_decl/semantic_parent on the
        # enum subp spec work correctly and returns the EnumLiteralDecl rt. the
        # type decl.
        add_env()
    }
}

|" Synthetic character enum literal declaration.
@synthetic
class SyntheticCharEnumLit: EnumLiteralDecl {
    char_symbol: Symbol
    enum_type_decl: Entity[TypeDecl]

    fun enum_type(): Entity[TypeDecl] = self.enum_type_decl

    |" Return the CharLiteral expression corresponding to this enum literal.
    @exported
    fun expr(): Entity[DefiningName] = self.defining_names()?[0]

    fun enum_decl_name(): Entity[DefiningName] = self.expr()

    fun defining_names(): Array[Entity[DefiningName]] =
        [node.synthesize_defining_name(node.char_symbol).as_entity]
}

|" Internal node for generic subprograms.
class GenericSubpInternal: BasicSubpDecl {
    @parse_field subp_spec: SubpSpec
    @parse_field aspects: AspectSpec

    fun subp_decl_spec(): Entity[BaseSubpSpec] = self.subp_spec

    env_spec {
        add_env(names=node.env_names())
    }
}

|" Synthetic subprogram declaration.
|"
|" Is used to represent predefined operators. This should also be usable
|" for synthesizing function attributes.
@synthetic
class SyntheticSubpDecl: BasicSubpDecl {
    @parse_field @null_field aspects: AspectSpec
    @parse_field spec: BaseSubpSpec

    fun subp_decl_spec(): Entity[BaseSubpSpec] = self.spec

    @with_dynvars(imprecise_fallback=false)
    fun next_part_for_decl(): Entity[BasicDecl] = null[Entity[BasicDecl]]

    @with_dynvars(imprecise_fallback=false)
    fun is_static_decl(): Bool = true
}

|" Base class for an Ada body (:rmlink:`3.11`). A body is the completion
|" of a declaration.
@abstract
class Body: BasicDecl {
    |" Helper for the AdaNode.env_hook. Handle library-level unit body nodes.
    fun env_hook_body(): Bool =
        # If this a library-level subprogram/package body, load the spec
        # corresponding to this body.
        if node is PackageBody | SubpBody then {
            val _ = node.get_unit(
                node.as_bare_entity.defining_name().as_symbol_array(), AnalysisUnitKind.unit_specification, load_if_needed=true, not_found_is_error=not node is SubpBody
            );

            # A library level subprogram body does not have to have a spec.
            # So we have to compute the parents directly from here.
            node.as[SubpBody].do(
                (subp_body) => subp_body.env_hook_basic_decl()
            )
        } else false

    fun subunit_decl_env(): LexicalEnv = {
        bind env = node.default_initial_env();

        match self.body_scope(true).get(
            self.name_symbol(), categories=RefCategories(inherited_primitives=false, _=true)
        )?[0] {
            case gpd: GenericPackageDecl =>
            # For generic package decls, we regroup the formal part & the
            # package decl itself, since the reference will be
            # non-transitive.
            [gpd.children_env(), gpd.package_decl.children_env()].env_group()
            case pd: BasicDecl => pd.children_env()
            case _ => raise[LexicalEnv] PropertyError()
        }.do(
            (public_part) => public_part.get(
                s"__privatepart", lookup=LookupKind.flat, categories=RefCategories(inherited_primitives=false, _=true)
            )?[0].do(
                # If there is a private part, group it with the rest
                (pp) => [pp.children_env(), public_part].env_group(), default_val=public_part
            )
        )
    }

    |" Return True if ``origin`` is directly in the scope of this body.
    @with_dynvars(origin)
    fun in_scope(): Bool = not origin.is_null and (
        (
            # Either origin and self are in the same unit
            origin.unit() == node.unit() and not origin.parents().find((p) => node == p).is_null
        ) or (
            # Either origin is nested in a subprogam subunit of self
            origin.enclosing_compilation_unit().body.as[Subunit].do(
                (su) => su.bodies_root().any(
                    (br) => br is BaseSubpBody and br.unit() == node.unit()
                )
            )
        )
    )

    |" Return the scope of this body's decl.
    fun body_decl_scope(): LexicalEnv = {
        bind env = node.default_initial_env();

        self.body_scope(true, true)
    }

    |" A package or subprogram body has a named parent env only if it is a
    |" compilation unit root, in which case it will be the name of its
    |" corresponding declaration.
    fun body_initial_env_name(): Symbol = if node.is_library_item() then (
        node.top_level_env_name() & ".__privatepart"
    ).to_symbol
    elif node.is_subunit() then (node.top_level_env_name() & "__stub").to_symbol
    else null[Symbol]

    |" Return the initial env for a body. It's always the current environment
    |" except for compilation unit roots for which we use the environment of
    |" their corresponding declaration.
    fun body_initial_env(): DesignatedEnv = node.body_initial_env_name().do(
        (non_null_name) => DesignatedEnv(
            kind=DesignatedEnvKind.named_env, env_name=non_null_name, direct_env=null[LexicalEnv]
        ), default_val=DesignatedEnv(
            kind=DesignatedEnvKind.current_env, env_name=null[Symbol], direct_env=null[LexicalEnv]
        )
    )

    |" Return the decl corresponding to this body. Specialized implementation
    |" for subprogram bodies.
    |"
    |" .. ATTENTION:: It is important to not perform any signature match in
    |"     cases where we don't need to (top-level subprograms), as the
    |"     robustness of some important properties is at stake (e.g.
    |"     imported_units, and therefore find_all_references).
    @with_dynvars(imprecise_fallback=false)
    fun subp_previous_part(): Entity[BasicDecl] = {
        val parent = if self.is_library_item() then self.parent.parent else self.semantic_parent();
        val elements = if parent.is_null then null[Array[Entity[AdaNode]]]
        # If this is a library-level subprogram, the previous part can be
        # found by fetching the compilation unit spec.
        elif parent is CompilationUnit then parent.as[CompilationUnit].other_part().do(
            # Make sure the previous part is at least a subprogram,
            # and not an arbitrary declaration.
            (cu) => if cu.decl() is BasicSubpDecl | GenericSubpDecl then [cu.decl().as[AdaNode].as_entity] else null[Array[Entity[AdaNode]]]
        )
        # If this subprogram's parent is a BodyStub, this subprogram is
        # necessarily a Subunit and the stub is thus its previous part.
        elif parent is BodyStub then [parent]
        # Otherwise, look in its immediate declarative region
        else parent.immediate_declarative_region().get(
            self.name_symbol(), lookup=LookupKind.minimal
        );
        # Since no overloading is possible for library-level subprograms and
        # separate subprograms, the element we found is already precise, and so
        # we don't need to perform the signature matching below.
        val already_precise = parent is CompilationUnit | BodyStub;
        val precise = (
            if already_precise then elements?[0] else elements.find(
                (sp) => not sp.is_null and sp.node != node and match sp {
                    # If this body completes a generic subprogram, then we
                    # just return it (no need to match the signature).
                    case _: GenericSubpDecl => true

                    # A formal subprogram cannot be the previous part of any
                    # subprogram.
                    case _: FormalSubpDecl => false
                    case subp_decl: BasicSubpDecl => {
                        bind origin = node.origin_node();

                        subp_decl.subp_decl_spec().match_signature(
                            self.subp_spec_or_null().as[SubpSpec], true, # We set use_entity_info to False so as to not
                            # match base subprograms.
                            use_entity_info=false
                        )
                    }
                    case subp_stub: SubpBodyStub => {
                        bind origin = node.origin_node();

                        subp_stub.subp_spec.match_signature(
                            self.subp_spec_or_null().as[SubpSpec], true, # We set use_entity_info to False so as to not
                            # match base subprograms.
                            use_entity_info=false
                        )
                    }
                    case _ => false
                }
            )
        ).as![BasicDecl];

        if precise.is_null and imprecise_fallback then elements.find(
            (sp) => not sp.is_null and sp.node != node and sp is BasicSubpDecl | SubpBodyStub
        ).as![BasicDecl] else precise
    }

    |" Return the EntryDecl corresponding to this node.
    @with_dynvars(env)
    fun entry_previous_part(): Entity[EntryDecl] = {
        val spec = self.as![EntryBody].params;

        env.get(
            self.name_symbol(), categories=RefCategories(inherited_primitives=false, _=true)
        ).find(
            (sp) => not sp.is_null and sp.node != node and match sp {
                case entry_decl: EntryDecl => {
                    bind origin = node.origin_node();

                    entry_decl.spec.match_formal_params(spec)
                }
                case _ => false
            }
        ).as![EntryDecl]
    }

    |" Return the BasePackageDecl corresponding to this node.
    |"
    |" If the case of generic package declarations, this returns the
    |" ``package_decl`` field instead of the ``GenericPackageDecl`` itself.
    @with_dynvars(env)
    fun package_previous_part(): Entity[BasicDecl] = (
        if node.is_library_item() then node.enclosing_compilation_unit().other_part().do(
            (part) => part.decl().as_entity.as[AdaNode].do((v1) => [v1])
        ) else {
            bind origin = node.origin_node();

            self.defining_name().all_env_els_impl(
                categories=RefCategories(inherited_primitives=false, _=true)
            )
        }
    ).map(
        (e) => match e {
            case pkg_decl: PackageDecl => pkg_decl
            case gen_pkg_decl: GenericPackageDecl => gen_pkg_decl.package_decl
            case _ => null[Entity[BasicDecl]]
        }
    ).find((e) => not e.is_null)

    |" Return the task decl corresponding to this node.
    @with_dynvars(env)
    fun task_previous_part(): Entity[BasicDecl] = {
        bind origin = node.origin_node();

        self.defining_name().all_env_els_impl()
    }?[0].as[BasicDecl]

    |" Return the ProtectedDecl corresponding to this node.
    @with_dynvars(env)
    fun protected_previous_part(): Entity[BasicDecl] = self.defining_name().env_elements()?[0].do(
        (v1) => match v1 {
            case prot_type: ProtectedTypeDecl => prot_type
            case prot_decl: SingleProtectedDecl => prot_decl
            case _ => null[Entity[BasicDecl]]
        }
    )

    |" Return the previous part for this body. Might be a declaration or a
    |" body stub.
    @with_dynvars(env, imprecise_fallback=false)
    fun unbound_previous_part(): Entity[BasicDecl] = {
        val pp = match self {
            case _: BaseSubpBody => self.subp_previous_part()
            case _: SubpBodyStub => self.subp_previous_part()
            case _: EntryBody => self.entry_previous_part()
            case _: PackageBody => self.package_previous_part()
            case _: PackageBodyStub => self.package_previous_part()
            case _: ProtectedBody => self.protected_previous_part()
            case _: ProtectedBodyStub => self.protected_previous_part()
            case _: TaskBody => self.task_previous_part()
            case _: TaskBodyStub => self.task_previous_part()
            case a: AcceptStmtBody => a.accept_stmt_previous_part()
        };

        # TODO: It would be cleaner if the previous_part implems returned
        # the stubs, but for the moment they're not even added to the lexical
        # environments.
        if self is BodyStub then pp else {
            val pp_next_part = pp?.next_part_for_decl();

            if pp_next_part is BodyStub then pp_next_part else pp
        }
    }

    |" Return the previous part for this body. Might be a declaration or a
    |" body stub.
    |"
    |" .. note::
    |"     This internal property was introduced by T812-020 in order to break
    |"     an infinite recursion.
    @with_dynvars(imprecise_fallback=false)
    fun previous_part_internal(): Entity[BasicDecl] =
        # Use self.as_bare_entity and not self as a prefix for the following
        # call to unbound_previous_part. The reasoning is that the previous
        # part of a given Body is a static concept that does not depend on a
        # particular context, and thus should not be impacted by an entity's
        # metadata. In particular, this addresses T610-028.
        {
            bind env = node.node_env();

            node.as_bare_entity.unbound_previous_part().node.as_entity
        }

    |" Return the previous part for this body. Might be a declaration or a
    |" body stub.
    @exported
    @memoized
    @with_dynvars(imprecise_fallback=false)
    fun previous_part(): Entity[BasicDecl] = self.previous_part_internal()

    |" Return the decl corresponding to this node if applicable.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun decl_part(): Entity[BasicDecl] = self.previous_part_internal().do(
        (prev_part) => match prev_part {
            # Stubs have one more previous part. Go back one more level
            # to get the decl.
            case stub: BodyStub => stub.previous_part_internal()
            case other => other
        }
    )

    |" Return the generic declaration corresponding to this body, if relevant.
    |" This property is designed to be usable from within env specs.
    fun safe_generic_decl_part(): Entity[GenericDecl] = {
        bind imprecise_fallback = false;

        if node is PackageBody then self.decl_part().do((d) => d.parent.as[GenericPackageDecl])
        elif node is BaseSubpBody | SubpBodyStub then (
            # We're only searching for generics. We look at index 1 and
            # 2, because if self is a subunit, the first entity we find
            # will be the separate declaration. NOTE: We don't use
            # decl_part/previous_part on purpose: They can cause env
            # lookups, hence doing an infinite recursion.
            self.children_env().env_parent.get(
                self.name_symbol(), categories=RefCategories(inherited_primitives=false, _=true)
            )?.find((r) => r is GenericSubpDecl).as[GenericSubpDecl]
        )
        else null[Entity[GenericDecl]]
    }

    |" By default, bodies don't have a next part. This is not true for body
    |" stubs, hence this property is overridden there.
    @with_dynvars(imprecise_fallback=false)
    fun next_part_for_decl(): Entity[BasicDecl] = null[Entity[BasicDecl]]

    fun is_subunit(): Bool = node.parent is Subunit

    |" If self is a subunit, return the body in which it is rooted.
    @exported
    fun subunit_root(): Entity[BasicDecl] =
        node.parent.as[Subunit].do((su) => su.body_root())

    |" Return the scope for this body.
    |" If follow_private, then returns the private part if possible.
    |"
    |" If force_decl, then returns the corresponding declaration's scope,
    |" rather than the parent body's scope.
    @with_dynvars(env)
    fun body_scope(follow_private: Bool, force_decl: Bool = false): LexicalEnv = {
        val scope = # Subunits always appear at the top-level in package bodies. So if
        # this is a subunit, the scope is the same as the scope of the
        # corresponding "is separate" decl, hence: the defining env of this
        # top-level package body.
        if not node.subunit_root().is_null then node.subunit_root().children_env()
        # In case this is a library level subprogram that has no spec
        # (which is legal), we'll register this body in the parent
        # scope.
        elif node.is_subprogram() and node.is_compilation_unit_root() then {
            val dns = self.defining_name().scope();

            # If the scope is self's scope, return parent scope, or
            # else we'll have an infinite recursion.
            if dns.is_null or dns.env_node == node then self.defining_name().parent_scope() else dns
        }
        # If this is a library level unit, or force_decl is True, return
        # the enclosing decl.
        elif node.is_compilation_unit_root() or force_decl then self.defining_name().scope()
        # The rest of cases are nested declarations: In that case we want
        # to take the parent's env.
        else node.parent.children_env();
        # If this the corresponding decl is a generic, go grab the internal
        # package decl.
        val public_scope = scope.env_node.as[GenericPackageDecl].do(
            (gen_pkg_decl) => gen_pkg_decl.package_decl.children_env(), default_val=scope
        );

        # If the package has a private part, then get the private part,
        # else return the public part.
        if follow_private and public_scope.env_node.do(
            (v1) => v1 is BasePackageDecl | SingleProtectedDecl | ProtectedTypeDecl
        ) then public_scope.get(
            s"__privatepart", lookup=LookupKind.flat, categories=RefCategories(inherited_primitives=false, _=true)
        )?[0].do(
            (pp) => pp.children_env(), default_val=public_scope
        ) else public_scope
    }

    |" Get all ``GNATprove`` annotations specified for that body.
    @memoized
    fun gnatprove_annotations(): Array[Entity[Expr]] = {
        val subp_decl_part = self.decl_part();
        # GNATprove annotations are specified in the specification, or else on
        # the body if it doesn't have a specification.
        val aspects = subp_decl_part.do(
            (part) => part.aspects, default_val=self.aspects
        )?.aspect_assocs.filtermap(
            (a) => a.expr.as[Aggregate].assocs?[1].expr(), (a) => (
                a.id.name_is(s"Annotate") and a.expr is Aggregate
            ) and a.expr.as[Aggregate].assocs?[0].expr().as[Name]?.name_is(s"GNATprove")
        );
        # GNATprove pragmas immediately follow the specification, or the body
        # iff it's an `ExprFunction`.
        val pragma_scope = subp_decl_part or? self.as[ExprFunction];
        # List all the pragmas that appear in the same declarative scope,
        # or in the case of a library item, the pragmas at the end of the
        # compilation unit.
        val scope_decls = (
            pragma_scope?.declarative_scope()?.decls.filtermap((p) => p.as[Pragma], (p) => p is Pragma) or? pragma_scope?.library_item_pragmas().map((p) => p.node)
        );
        # Find those that are a "GNATProve" annotation
        val pragmas = scope_decls.filtermap(
            (d) => d.args?[1].as_entity.assoc_expr(), (d) => (
                (
                    d > pragma_scope.node and d?.id.name_is(s"Annotate")
                ) and d.args?[0]?.as_entity.assoc_expr().as[Name]?.name_is(s"GNATprove")
            ) and d.args?[2]?.as_entity.assoc_expr().as[Name]?.name_is(self.defining_names()?[0].name_symbol())
        );
        # Also look for annotations declared on the enclosing bodies
        val enclosing_subp_annotations = self.parents(with_self=false).find((n) => n is BaseSubpBody).as[BaseSubpBody]?.gnatprove_annotations();

        aspects & pragmas & enclosing_subp_annotations
    }

    |" Return the name of the lexical env of the previous part of this body.
    |" For a subunit, the previous part is its stub, otherwise it's the body's
    |" declaration. If that declaration has a named env, it will be registered
    |" with the same top_level_env_name as this body.
    fun previous_part_env_name(): Symbol =
        if node.is_subunit() then (node.top_level_env_name() & "__stub").to_symbol else node.top_level_env_name().to_symbol

    |" Return the env association that describes where to add a ``__nextpart``
    |" entry for this body, if it corresponds to a non-overloadable entity
    |" (i.e. not a subprogram).
    |"
    |" Note that entry navigation is handled a bit differently and in
    |" particular we don't need a ``__nextpart`` link for them. Hence this
    |" property is never called from EntryBody env specs.
    fun previous_part_link_env_assoc(): EnvAssoc = EnvAssoc(
        key=s"__nextpart", value=node, dest_env=node.previous_part_env_name().do(
            (name) => DesignatedEnv(
                kind=DesignatedEnvKind.named_env, env_name=name, direct_env=null[LexicalEnv]
            ), default_val={
                bind env = node.default_initial_env();

                self.body_scope(follow_private=false, force_decl=true)
            }.do(
                (non_null_env) => DesignatedEnv(
                    kind=DesignatedEnvKind.direct_env, env_name=null[Symbol], direct_env=non_null_env
                ), default_val=DesignatedEnv(
                    kind=DesignatedEnvKind.current_env, env_name=null[Symbol], direct_env=null[LexicalEnv]
                )
            )
        ), metadata=null[Metadata]
    )
}

|" BasicDecl that is always the declaration of an AcceptStmt. This is nested
|" *inside* of the accept statement.
class AcceptStmtBody: Body {
    @parse_field name: DefiningName
    @parse_field @null_field aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] = [self.name]

    @with_dynvars(origin, include_ud_indexing=false, dottable_type=null[AdaNode])
    fun defining_env(): LexicalEnv =
        node.parent.as[AcceptStmt].children_env()

    fun accept_stmt_previous_part(): Entity[EntryDecl] =
        self.parent.as![AcceptStmt].corresponding_entry()
}

|" Base class for subprogram bodies (:rmlink:`6.3`).
@abstract
class BaseSubpBody: Body {
    @parse_field overriding: Overriding
    @parse_field subp_spec: SubpSpec

    fun defining_names(): Array[Entity[DefiningName]] =
        [self.subp_spec.name()]

    @with_dynvars(origin)
    fun constrain_prefix(prefix: Expr): Equation =
        self.subp_constrain_prefix(prefix)

    @with_dynvars(origin, include_ud_indexing=false, dottable_type=null[AdaNode])
    fun defining_env(): LexicalEnv =
        if self.in_scope() then [if self.subp_spec_or_null()?.paramless(self.info.md.dottable_subp, can_be=true) then [self.children_env(), self.subp_spec.defining_env()].env_group() else self.children_env(), self.decl_part().do(
            (decl) => decl.as[GenericSubpDecl]?.formal_part?.children_env()
        )].env_group() else (
            # For bodies corresponding to generic declaration, add the
            # declaration's formal_part env to the body one, as for
            # example in:
            #
            # .. code:: ada
            #   procedure Gen_Proc is
            #      C : constant T := Gen_Proc.F;
            #   begin
            #      null;
            #   end Gen_Proc;
            #
            # with `F` being a `Gen_Proc` formal's function:
            #
            # .. code ada
            #   generic
            #     type T is private;
            #     with function F return T is <>;
            #   procedure Gen_Proc;
            self.subp_spec.defining_env()
        )

    fun type_expression(): Entity[TypeExpr] = self.subp_spec.returns()

    @with_dynvars(origin)
    fun expr_type(): Entity[BaseTypeDecl] =
        self.subp_spec_or_null()?.return_type()

    fun initial_env_name(follow_private: Bool = false): Symbol =
        if node.is_library_item() then node.child_decl_initial_env_name(follow_private) else node.body_initial_env_name()

    |" Return the name of the lexical env of the previous part of this
    |" subprogram body. Due to overloading, do not return anything in case
    |" we are not a library item or subunit.
    fun previous_part_env_name(): Symbol =
        if node.is_subunit() then (node.top_level_env_name() & "__stub").to_symbol
        elif node.is_library_item() then node.top_level_env_name().to_symbol
        else null[Symbol]

    env_spec {
        do(node.env_hook())
        set_initial_env(
            node.initial_env_name(true).do(
                (non_null_name) => DesignatedEnv(
                    kind=DesignatedEnvKind.named_env, env_name=non_null_name, direct_env=null[LexicalEnv]
                ), default_val=DesignatedEnv(
                    kind=DesignatedEnvKind.current_env, env_name=null[Symbol], direct_env=null[LexicalEnv]
                )
            )
        )
        add_to_env(
            self.basic_decl_env_assocs(
                node.initial_env_name(false).do(
                    (non_null_name) => DesignatedEnv(
                        kind=DesignatedEnvKind.named_env, env_name=non_null_name, direct_env=null[LexicalEnv]
                    ), default_val=DesignatedEnv(
                        kind=DesignatedEnvKind.current_env, env_name=null[Symbol], direct_env=null[LexicalEnv]
                    )
                )
            )
        )
        add_env(transitive_parent=true)
        add_to_env_kv(
            s"__nextpart", node, dest_env=node.previous_part_env_name().do(
                (name) => DesignatedEnv(
                    kind=DesignatedEnvKind.named_env, env_name=name, direct_env=null[LexicalEnv]
                ),
                # Due to overloading, it's not possible to find the previous
                # part of a non-library item subprogram at this stage if it
                # has a top level env name (e.g. a subprogram declared in a
                # package), since its body could be defined in another unit.
                default_val=if node.has_top_level_env_name() then DesignatedEnv(
                    kind=DesignatedEnvKind.none, env_name=null[Symbol], direct_env=null[LexicalEnv]
                ) else {
                    bind env = node.default_initial_env();

                    self.body_scope(follow_private=false, force_decl=true).do(
                        (non_null_env) => DesignatedEnv(
                            kind=DesignatedEnvKind.direct_env, env_name=null[Symbol], direct_env=non_null_env
                        ),
                        default_val=DesignatedEnv(
                            kind=DesignatedEnvKind.current_env, env_name=null[Symbol], direct_env=null[LexicalEnv]
                        )
                    )
                }
            )
        )
        do(node.populate_dependent_units())
        reference(
            node.top_level_use_package_clauses(), Name.use_package_name_designated_env, cond=node.parent is LibraryItem | Subunit
        )
        reference(
            node.top_level_use_type_clauses(), Name.name_designated_type_env, cond=node.parent is LibraryItem | Subunit
        )
        # If self, which is assumed to be a SubpBody, is a library-level
        # subprogram, it must "inherit" the use clauses of its declaration, if
        # there is one.
        reference(
            node.as[AdaNode].do((v1) => [v1]), AdaNode.use_clauses_in_spec_of_subp_body, cond=node.parent is LibraryItem
        )
        reference(
            node.as[AdaNode].do((v2) => [v2]), AdaNode.nested_generic_formal_part, kind=prioritary, cond=node.should_ref_generic_formals(), shed_corresponding_rebindings=true
        )
        # We must also "inherit" the use clauses from the generic formal part
        # of this body's generic declaration, if relevant.
        reference(
            node.as[AdaNode].do((v3) => [v3]), AdaNode.use_clauses_in_generic_formal_part, cond=node.should_ref_generic_formals()
        )
    }
}

|" Expression function (:rmlink:`6.8`).
class ExprFunction: BaseSubpBody {
    @parse_field expr: Expr
    @parse_field aspects: AspectSpec

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = (
        %eq(self.expr.expected_type_var(), self.subp_spec.return_type()) and self.expr.sub_equation()
    ) and node.expr.matches_expected_assign_type()

    fun xref_entry_point(): Bool = true
}

|" Declaration for a null subprogram (:rmlink:`6.1`).
class NullSubpDecl: BaseSubpBody {
    @parse_field aspects: AspectSpec
}

|" Subprogram body(:rmlink:`6.3`) .
class SubpBody: BaseSubpBody {
    @parse_field aspects: AspectSpec
    @parse_field decls: DeclarativePart
    @parse_field stmts: HandledStmts
    @parse_field @nullable end_name: EndName

    fun declarative_parts(): Array[Entity[DeclarativePart]] = [self.decls]
}

|" Declaration for a subprogram renaming (:rmlink:`8.5.4`).
class SubpRenamingDecl: BaseSubpBody {
    @parse_field renames: RenamingClause
    @parse_field aspects: AspectSpec

    fun xref_entry_point(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        val renamed_object = self.renames.renamed_object;

        (
            if renamed_object is CharLiteral then (
                # If the renamed object is a char literal, simply resolves its
                # equation.
                %eq(renamed_object.expected_type_var(), self.subp_spec.return_type()) and renamed_object.sub_equation()
            )
            elif renamed_object is AttributeRef then (
                # If the renamed object is an attribute ref, do normal
                # resolution to synthesize its corresponding function.
                renamed_object.sub_equation()
            )
            else match renamed_object {
                # If renamed_object is a CallExpr, this is likely the
                # renaming of an entry decl with a family member specified,
                # so use sub_equation.
                case ce: CallExpr => ce.sub_equation()
                case ed: ExplicitDeref => ed.general_xref_equation(renamed_object.node)

                # On the other cases, prefix is a simple identifier
                case o => o.xref_no_overloading(all_els=true)
            } and (
                if renamed_object is DottedName then
                    %predicate(
                        BasicDecl.subp_renaming_decl_match_signature,
                        renamed_object.ref_var(),
                        renamed_object.as[DottedName].prefix.ref_var(),
                        self.as[BasicDecl]
                    )
                elif renamed_object is ExplicitDeref then
                    %predicate(
                        BasicDecl.access_to_subp_decl_match_signature,
                        renamed_object.ref_var(),
                        self.as[BasicDecl]
                    )
                else
                    %predicate(
                        BasicDecl.subp_decl_match_signature,
                        renamed_object.ref_var(),
                        self.as[BasicDecl]
                    )
            )
        ) or (
            # Operators might be built-in, so if we cannot find a reference,
            # we'll just abandon resolution...
            if renamed_object.is_operator_name() then %true else %false
        )
    }
}

|" Base class for a body stub (:rmlink:`10.1.3`). A body stub is meant to
|" be completed by .
@abstract
class BodyStub: Body {
    @with_dynvars(imprecise_fallback=false)
    fun next_part_for_decl(): Entity[BasicDecl] = node.get_unit_root_decl(
        self.syntactic_fully_qualified_name(),
        AnalysisUnitKind.unit_body,
        process_parents=false
    ).as_entity

    |" Return the syntactic fully qualified name to refer to this body.
    |"
    |" Note that this can raise a Property_Error when the stub is in an
    |" illegal place (too nested, in a declare block, etc.).
    @exported
    fun syntactic_fully_qualified_name(): Array[Symbol] = {
        # Compute the "relative" name of the body for this stub
        val rel_name = node.as_bare_entity.defining_name().as_symbol_array();
        # Fetch the compilation unit in which this stub is rooted.
        #
        # Body stubs can appear only in the top-level declarative part of a
        # library-level body or of a subunit. This means that:
        #
        # * ``self.parent`` must be an ``AdaNode.list``,
        # * ``self.parent.parent`` must be a ``DeclarativePart``,
        # * ``self.parent.parent.parent`` must be a library item or subunit
        #   ``Body``.
        val top_body = match node.parent.parent.parent {
            case b: SubpBody => b
            case b: ProtectedBody => b
            case b: PackageBody => b
            case b: TaskBody => b
            case _ => raise[Body] PropertyError("invalid body stub")
        };

        val cu = if top_body.parent is LibraryItem | Subunit then
            top_body.parent.parent.as[CompilationUnit]
        else
            raise[CompilationUnit] PropertyError("invalid body stub");

        cu.syntactic_fully_qualified_name() & rel_name
    }

    |" All body stubs allow for a named environment, which is registered with
    |" a ``__stub`` appended to the body's top_level_env_name.
    fun env_names(): Array[Symbol] =
        [(node.top_level_env_name() & "__stub").to_symbol]

    fun previous_part_link_env_assoc(): EnvAssoc = EnvAssoc(
        key=s"__nextpart", value=node, dest_env=DesignatedEnv(
            kind=DesignatedEnvKind.named_env, env_name=node.top_level_env_name().to_symbol, direct_env=null[LexicalEnv]
        ), metadata=null[Metadata]
    )
}

|" Stub for a package body (``is separate``) (:rmlink:`10.1.3`).
class PackageBodyStub: BodyStub {
    @parse_field name: DefiningName
    @parse_field aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] = [self.name]

    env_spec {
        add_to_env(self.previous_part_link_env_assoc())
        add_env(names=node.env_names())
    }
}

|" Stub for a protected object body (``is separate``) (:rmlink:`10.1.3`).
class ProtectedBodyStub: BodyStub {
    @parse_field name: DefiningName
    @parse_field aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] = [self.name]

    env_spec {
        add_to_env(self.previous_part_link_env_assoc())
        add_env(names=node.env_names())
    }
}

|" Stub for a subprogram body (``is separate``) (:rmlink:`10.1.3`).
class SubpBodyStub: BodyStub {
    @parse_field overriding: Overriding
    @parse_field subp_spec: SubpSpec
    @parse_field aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] =
        [self.subp_spec.name()]
    # Note that we don't have to override the defining_env property here since
    # what we put in lexical environment is their SubpSpec child.

    fun type_expression(): Entity[TypeExpr] = self.subp_spec.returns()

    env_spec {
        add_to_env_kv(node.name_symbol(), node)
        add_env(names=node.env_names())
        reference(
            node.as[AdaNode].do((v1) => [v1]), AdaNode.nested_generic_formal_part, kind=prioritary, cond=node.should_ref_generic_formals(), shed_corresponding_rebindings=true
        )
        # We must also "inherit" the use clauses from the generic formal part
        # of this body's generic declaration, if relevant.
        reference(
            node.as[AdaNode].do((v2) => [v2]), AdaNode.use_clauses_in_generic_formal_part, cond=node.should_ref_generic_formals()
        )
    }
}

|" Stub for a task body (``is separate``) (:rmlink:`10.1.3`).
class TaskBodyStub: BodyStub {
    @parse_field name: DefiningName
    @parse_field aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] = [self.name]

    env_spec {
        add_to_env(self.previous_part_link_env_assoc())
        add_env(names=node.env_names())
    }
}

|" Entry body (:rmlink:`9.5.2`).
class EntryBody: Body {
    @parse_field entry_name: DefiningName
    @parse_field @nullable index_spec: EntryIndexSpec
    @parse_field params: EntryCompletionFormalParams
    @parse_field aspects: AspectSpec
    @parse_field barrier: Expr
    @parse_field decls: DeclarativePart
    @parse_field stmts: HandledStmts
    @parse_field @nullable end_name: EndName

    fun defining_names(): Array[Entity[DefiningName]] = [self.entry_name]

    fun declarative_parts(): Array[Entity[DeclarativePart]] = [self.decls]

    fun xref_entry_point(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        %eq(node.barrier.expected_type_var(), node.bool_type()) and self.barrier.sub_equation() and self.barrier.matches_expected_formal_type()

    env_spec {
        do(node.env_hook())
        set_initial_env(
            DesignatedEnv(
                kind=DesignatedEnvKind.direct_env, env_name=null[Symbol], direct_env={
                    bind env = node.default_initial_env();

                    self.body_scope(false)
                }
            )
        )
        # Add the body to its own parent env
        add_to_env(
            [EnvAssoc(
                key=self.name_symbol(), value=node, dest_env=DesignatedEnv(
                    kind=DesignatedEnvKind.current_env, env_name=null[Symbol], direct_env=null[LexicalEnv]
                ), metadata=null[Metadata]
            )]
        )
        add_env()
    }
}

|" Package body (:rmlink:`7.2`).
class PackageBody: Body {
    @parse_field package_name: DefiningName
    @parse_field aspects: AspectSpec
    @parse_field decls: DeclarativePart
    @parse_field @nullable stmts: HandledStmts
    @parse_field @nullable end_name: EndName

    fun defining_names(): Array[Entity[DefiningName]] = [self.package_name]

    @with_dynvars(origin, include_ud_indexing=false, dottable_type=null[AdaNode])
    fun defining_env(): LexicalEnv = self.children_env()

    fun declarative_parts(): Array[Entity[DeclarativePart]] = [self.decls]

    |" Return the environments for the use clauses of the package decl of this
    |" body. Used because they need to be explicitly referenced.
    fun package_decl_use_clauses_envs(): LexicalEnv = {
        bind imprecise_fallback = false;

        self.decl_part().as![BasePackageDecl]
    }.do(
        (pd) => [pd.public_part.use_clauses_envs(), pd.private_part?.use_clauses_envs()].env_group()
    )

    env_spec {
        do(node.env_hook())
        # Parent link is the package's decl, or private part if there is one
        set_initial_env(node.body_initial_env())
        add_to_env(self.previous_part_link_env_assoc())
        # We make a transitive parent link only when the package is a library
        # level package.
        add_env(transitive_parent=node.is_library_item())
        do(node.populate_dependent_units())
        reference(
            node.top_level_use_package_clauses(), Name.use_package_name_designated_env, cond=node.parent is LibraryItem | Subunit
        )
        reference(
            node.top_level_use_type_clauses(), Name.name_designated_type_env, cond=node.parent is LibraryItem | Subunit
        )
        reference(
            node.as[AdaNode].do((v1) => [v1]), AdaNode.nested_generic_formal_part, kind=prioritary, cond=node.should_ref_generic_formals(), shed_corresponding_rebindings=true
        )
        # We must also "inherit" the use clauses from the generic formal part
        # of this body's generic declaration, if relevant.
        reference(
            node.as[AdaNode].do((v2) => [v2]), AdaNode.use_clauses_in_generic_formal_part, cond=node.should_ref_generic_formals()
        )
        # Separate packages and nested packages basically need to be treated
        # the same way: we cannot use a transitive ref because of hiding
        # issues, so we'll do a prioritary ref, that groups together the
        # necessary envs.
        #
        # TODO: We need to ref use clauses, as in the regular package decl
        # case.
        reference(
            [node.as[AdaNode]], Body.subunit_decl_env, kind=prioritary, cond=node.is_subunit()
        )
        # If self is not a library level package body (and hence is a nested
        # package), we need to explicitly reference its package decl, because
        # it is not in the chain of parents.
        #
        # The reference is non transitive because if it was it would cause some
        # visibility order issues.
        #
        # TODO: We can regroup this ref with the following ref, making
        # body_decl_scope return a grouped env with the use clauses in it.
        reference(
            [node.as[AdaNode]], Body.body_decl_scope, kind=prioritary, cond=not node.is_compilation_unit_root()
        )
        # Since the reference to the package decl is non transitive, we still
        # want to reference the envs that are "used" there.
        reference(
            [node.as[AdaNode]], PackageBody.package_decl_use_clauses_envs, cond=not node.is_compilation_unit_root() or node.is_subunit()
        )
    }
}

|" Protected object body (:rmlink:`9.4`).
class ProtectedBody: Body {
    @parse_field name: DefiningName
    @parse_field aspects: AspectSpec
    @parse_field decls: DeclarativePart
    @parse_field @nullable end_name: EndName

    fun defining_names(): Array[Entity[DefiningName]] = [self.name]

    fun declarative_parts(): Array[Entity[DeclarativePart]] = [self.decls]

    fun protected_type(): Entity[ProtectedTypeDecl] = match self.decl_part() {
        case t: ProtectedTypeDecl => t
        case _: SingleProtectedDecl => null[Entity[ProtectedTypeDecl]]
        case _ => raise[Entity[ProtectedTypeDecl]] PropertyError("Should not happen")
    }

    env_spec {
        do(node.env_hook())
        set_initial_env(node.body_initial_env())
        add_to_env(self.previous_part_link_env_assoc())
        add_env()
        do(node.populate_dependent_units())
        reference(
            node.top_level_use_package_clauses(), Name.use_package_name_designated_env, cond=node.parent is LibraryItem | Subunit
        )
        reference(
            node.top_level_use_type_clauses(), Name.name_designated_type_env, cond=node.parent is LibraryItem | Subunit
        )
        reference(
            node.as[AdaNode].do((v1) => [v1]), AdaNode.nested_generic_formal_part, kind=prioritary, cond=node.should_ref_generic_formals(), shed_corresponding_rebindings=true
        )
        # We must also "inherit" the use clauses from the generic formal part
        # of this body's generic declaration, if relevant.
        reference(
            node.as[AdaNode].do((v2) => [v2]), AdaNode.use_clauses_in_generic_formal_part, cond=node.should_ref_generic_formals()
        )
        reference(
            [node.as[AdaNode]], Body.body_decl_scope, kind=prioritary
        )
        # Reference stub's env if the body is a separate
        reference(
            [node.as[AdaNode]], Body.subunit_decl_env, kind=prioritary, cond=node.is_subunit()
        )
    }
}

|" Task body (:rmlink:`9.1`).
class TaskBody: Body {
    @parse_field name: DefiningName
    @parse_field aspects: AspectSpec
    @parse_field decls: DeclarativePart
    @parse_field stmts: HandledStmts
    @parse_field @nullable end_name: EndName

    fun defining_names(): Array[Entity[DefiningName]] = [self.name]

    @with_dynvars(origin, include_ud_indexing=false, dottable_type=null[AdaNode])
    fun defining_env(): LexicalEnv = self.children_env()

    fun declarative_parts(): Array[Entity[DeclarativePart]] = [self.decls]

    fun task_type_decl_scope(): LexicalEnv = {
        val pp = self.task_type()?.definition?.private_part;

        if pp.is_null then self.task_type().children_env() else pp.children_env()
    }

    fun task_type(): Entity[TaskTypeDecl] = {
        bind imprecise_fallback = false;

        match self.decl_part() {
            case t: TaskTypeDecl => t
            case t: SingleTaskDecl => t.task_type
            case _ => raise[Entity[TaskTypeDecl]] PropertyError("Should not happen")
        }
    }

    env_spec {
        do(node.env_hook())
        set_initial_env(node.body_initial_env())
        add_to_env(self.previous_part_link_env_assoc())
        add_env()
        do(node.populate_dependent_units())
        reference(
            node.top_level_use_package_clauses(), Name.use_package_name_designated_env, cond=node.parent is LibraryItem | Subunit
        )
        reference(
            node.top_level_use_type_clauses(), Name.name_designated_type_env, cond=node.parent is LibraryItem | Subunit
        )
        reference(
            node.as[AdaNode].do((v1) => [v1]), AdaNode.nested_generic_formal_part, kind=prioritary, cond=node.should_ref_generic_formals(), shed_corresponding_rebindings=true
        )
        # We must also "inherit" the use clauses from the generic formal part
        # of this body's generic declaration, if relevant.
        reference(
            node.as[AdaNode].do((v2) => [v2]), AdaNode.use_clauses_in_generic_formal_part, cond=node.should_ref_generic_formals()
        )
        reference(
            [node.as[AdaNode]], TaskBody.task_type_decl_scope, kind=prioritary
        )
        # Reference stub's env if the body is a separate
        reference(
            [node.as[AdaNode]], Body.subunit_decl_env, kind=prioritary, cond=node.is_subunit()
        )
    }
}

|" Index specification for an entry body (:rmlink:`9.5.2`).
class EntryIndexSpec: BasicDecl {
    @parse_field id: DefiningName
    @parse_field subtype: AdaNode
    @parse_field aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] = [self.id]

    @with_dynvars(origin, include_ud_indexing=false, dottable_type=null[AdaNode])
    fun defining_env(): LexicalEnv = self.expr_type().defining_env()

    @with_dynvars(origin)
    fun expr_type(): Entity[BaseTypeDecl] = match self.subtype {
        case subt: SubtypeIndication => subt.designated_type()
        case e => e.as![Expr].expression_type()
    }

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = self.subtype.sub_equation()

    fun xref_entry_point(): Bool = true

    env_spec {
        add_to_env_kv(self.name_symbol(), node)
    }
}

|" Placeholder node for syntax errors in lists of declarations.
class ErrorDecl: BasicDecl implements ErrorNode {
    @parse_field @null_field aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] =
        null[Array[Entity[DefiningName]]]

    |" Override for error decls, which cannot be child decls.
    fun child_decl_initial_env_name(@ignored private_part: Bool = false): Symbol =
        # TODO: investigate if we can/should do better here
        null[Symbol]
}

|" Exception declarations (:rmlink:`11.1`).
class ExceptionDecl: BasicDecl {
    @parse_field ids: ASTList[DefiningName]
    @parse_field @nullable renames: RenamingClause
    @parse_field aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] =
        self.ids.map((id) => id)

    |" An exception declaration never has a next part.
    @with_dynvars(imprecise_fallback=false)
    fun next_part_for_decl(): Entity[BasicDecl] = null[Entity[BasicDecl]]

    fun xref_entry_point(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = self.renames.do(
        (c) => c.renamed_object.xref_no_overloading(), default_val=%true
    )

    env_spec {
        add_to_env(node.env_mappings(node.ids, node))
    }
}

|" Exception handler (:rmlink:`11.2`).
class ExceptionHandler: BasicDecl {
    @parse_field @nullable exception_name: DefiningName
    @parse_field handled_exceptions: AlternativesList
    @parse_field stmts: StmtList
    @parse_field @null_field aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] =
        self.exception_name.do((n) => [n])

    @with_dynvars(origin)
    fun expr_type(): Entity[BaseTypeDecl] = self.get_unit_root_decl(
        [s"Ada", s"Exceptions"], AnalysisUnitKind.unit_specification
    )?.children_env().get_first(
        s"Exception_Occurrence", lookup=LookupKind.flat
    ).as[BaseTypeDecl]

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        node.handled_exceptions.logic_all((he) => he.as_entity.sub_equation())

    fun xref_entry_point(): Bool = true

    fun is_constant_object(): Bool = true

    env_spec {
        add_env()
        add_to_env(
            self.exception_name.do(
                (n) => [n].map(
                    (n) => EnvAssoc(
                        key=n.name_symbol(), value=node, dest_env=DesignatedEnv(
                            kind=DesignatedEnvKind.current_env, env_name=null[Symbol], direct_env=null[LexicalEnv]
                        ), metadata=null[Metadata]
                    )
                )
            )
        )
    }
}

|" Declaration for the controlling variable in a ``for`` loop
|" (:rmlink:`5.5`).
class ForLoopVarDecl: BasicDecl {
    @parse_field id: DefiningName
    @parse_field @nullable id_type: TypeExpr
    @parse_field @null_field aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] = [self.id]

    @with_dynvars(origin, include_ud_indexing=false, dottable_type=null[AdaNode])
    fun defining_env(): LexicalEnv = self.expr_type().defining_env()

    @memoized
    @call_memoizable
    @with_dynvars(origin)
    fun expr_type(): Entity[BaseTypeDecl] = if node.id_type.is_null then (
        # The type of a for loop variable does not need to be annotated, it
        # can eventually be inferred, which necessitates name resolution on
        # the loop specification. Run resolution if necessary.
        # NOTE: if we are in the context of an Ada 202x iterated component
        # association things are a bit different: `id`'s type_var should
        # already be set by the enclosing IteratedAssoc's resolution, and
        # must be retrieved directly. Calling `expression_type` now would
        # trigger an infinite loop because the enclosing ForLoopSpec is
        # not an entry point in this context.
        if node.parent.as[ForLoopSpec].is_iterated_assoc_spec() then node.id.type_val().as![BaseTypeDecl] else self.id.expression_type()
    ) else (
        # If there is a type annotation, just return it
        self.id_type.designated_type()
    )

    fun is_constant_object(): Bool = {
        # TODO: add support for Constant/Variable_Indexing
        val loop_spec = self.parent.as[ForLoopSpec];

        # IterType.alt_of loops are constant if the iterable object is
        # constant.
        if loop_spec.loop_type is IterType.Of then loop_spec.iter_expr.as![Name].is_constant() else (
            # IterType.alt_in loops are always constant
            true
        )
    }

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = self.id.sub_equation() and (
        if self.id_type.is_null then %true else self.id_type.sub_equation()
    )

    env_spec {
        add_to_env_kv(node.name_symbol(), node)
    }
}

|" Base class for generic declarations (:rmlink:`12.1`).
@abstract
@rebindable
class GenericDecl: BasicDecl {
    @parse_field formal_part: GenericFormalPart

    @abstract
    fun decl(): Entity[BasicDecl]

    fun get_aspect_spec(): Entity[AspectSpec] =
        # The aspect is actually on the Generic*Internal node, so forward
        # the call to it.
        self.decl().get_aspect_spec()

    @with_dynvars(imprecise_fallback=false)
    fun next_part_for_decl(): Entity[BasicDecl] =
        self.decl().next_part_for_decl()
}

|" Generic package declaration (:rmlink:`12.1`).
class GenericPackageDecl: GenericDecl {
    @parse_field package_decl: GenericPackageInternal
    @parse_field @null_field aspects: AspectSpec

    @with_dynvars(origin, include_ud_indexing=false, dottable_type=null[AdaNode])
    fun defining_env(): LexicalEnv = self.package_decl.defining_env()

    fun defining_names(): Array[Entity[DefiningName]] =
        [node.package_decl.package_name.as_entity]

    fun declarative_parts(): Array[Entity[DeclarativePart]] =
        self.package_decl.declarative_parts()

    |" Return the PackageBody corresponding to this node, or null if there is
    |" none.
    @exported
    fun body_part(): Entity[PackageBody] = self.package_decl.body_part()

    fun decl(): Entity[BasicDecl] = self.package_decl

    env_spec {
        do(node.env_hook())
        set_initial_env(
            # TODO: This is wrong (should take into account whether the entity
            # is private or not), but we have no example of cases where this is
            # a problem yet.
            node.child_decl_initial_env(true)
        )
        add_to_env(self.child_decl_env_assocs())
        add_env()
        do(node.populate_dependent_units())
        reference(
            node.top_level_use_package_clauses(), Name.use_package_name_designated_env, cond=node.parent is LibraryItem | Subunit
        )
        reference(
            node.top_level_use_type_clauses(), Name.name_designated_type_env, cond=node.parent is LibraryItem | Subunit
        )
    }
}

|" Generic subprogram declaration (:rmlink:`12.1`).
class GenericSubpDecl: GenericDecl {
    @parse_field subp_decl: GenericSubpInternal
    @parse_field @null_field aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] =
        [self.subp_decl.subp_spec.name()]

    |" Return the BaseSubpBody corresponding to this node.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun body_part(): Entity[BaseSubpBody] =
        self.body_part_for_decl().as[BaseSubpBody]

    fun decl(): Entity[BasicDecl] = self.subp_decl

    # Overriding properties forwarding to internal subp decl
    fun is_imported(): Bool = self.subp_decl.is_imported()

    @with_dynvars(imprecise_fallback=false)
    fun next_part_for_decl(): Entity[BasicDecl] =
        self.subp_decl.next_part_for_decl()

    env_spec {
        # Call the env hook to parse eventual parent unit
        do(node.env_hook())
        set_initial_env(
            # TODO: This is wrong (should take into account whether the entity
            # is private or not), but we have no example of cases where this is
            # a problem yet.
            node.child_decl_initial_env(true)
        )
        add_to_env(self.child_decl_env_assocs())
        add_env()
        do(node.populate_dependent_units())
        reference(
            node.top_level_use_package_clauses(), Name.use_package_name_designated_env, cond=node.parent is LibraryItem | Subunit
        )
        reference(
            node.top_level_use_type_clauses(), Name.name_designated_type_env, cond=node.parent is LibraryItem | Subunit
        )
        handle_children()
        do(node.populate_body_unit())
    }
}

|" Instantiations of generics (:rmlink:`12.3`).
@abstract
class GenericInstantiation: BasicDecl {
    @lazy
    instantiation_env: LexicalEnv =
        dynamic_lexical_env(GenericInstantiation.instantiation_bindings, assoc_resolver=AdaNode.resolve_generic_actual, transitive_parent=false)

    fun instantiation_bindings(): Array[InnerEnvAssoc] = {
        # We force the computation of the corresponding generic declaration
        # in this non-memoized property to avoid a false "infinite recursion"
        # property error that can happen when the computation is only done in
        # instantiation_bindings_internal.
        val _ = node.nonbound_generic_decl_from_self();

        self.instantiation_bindings_internal()
    }

    @memoized
    fun instantiation_bindings_internal(): Array[InnerEnvAssoc] =
        if self.is_any_formal() then null[Array[InnerEnvAssoc]] else node.nonbound_generic_decl_from_self().as![GenericDecl].formal_part.match_param_list(self.generic_inst_params(), false).imap(
            (pm, i) => InnerEnvAssoc(
                key=pm.formal.name.name_symbol(),
                # Do not put formal subprograms in the rebindings to
                # avoid them being eagerly resolved to an actual, as
                # the formal part is needed to implement correct name
                # resolution.
                # We will use ``BasicDecl.corresponding_actual``
                # instead to manually resolve it.
                value=if pm.actual.assoc.expr() is BoxExpr or pm.formal.formal_decl() is GenericFormalSubpDecl then null[Expr]
                elif pm.formal.formal_decl() is GenericFormalObjDecl then self.actual_expr_decls?[i]
                else pm.actual.assoc.expr().node, metadata=Metadata()
            )
        ).filter(
            (env_assoc) => not env_assoc.value.is_null
        )

    |" Return the name of the generic entity designated by this generic
    |" instantiation.
    @abstract
    fun generic_entity_name(): Entity[Name]

    |" Return the parameters of this generic instantiation
    @abstract
    fun generic_inst_params(): Entity[AssocList]

    fun is_any_formal(): Bool =
        self.generic_inst_params()?[0].do((v1) => v1.expr() is BoxExpr)

    |" Return the generic package designated by the right hand part of this
    |" generic package instantiation as seen from the current generic context.
    |"
    |" See nonbound_generic_decl_from_self property below for follow_renaming
    |" parameter documentation.
    fun nonbound_generic_decl_from_entity(follow_renaming : Bool = true): Entity[BasicDecl] =
        self.generic_entity_name().all_env_elements_internal(
            seq=true, seq_from=node, categories=RefCategories(inherited_primitives=false, _=true)
        ).find((e) => node.has_visibility(e)).do(
            (v1) => match v1 {
                case b: Body => {
                    bind imprecise_fallback = false;

                    b.decl_part()
                }
                case rd: GenericRenamingDecl => if follow_renaming then rd.resolve() else rd
                case d: BasicDecl => d
                case _ => null[Entity[BasicDecl]]
            }
        )

    |" Return the generic package designated by the right hand part of this
    |" generic package instantiation from a bare generic context.
    |"
    |" By default, this property follows renaming declarations to return the
    |" designated generic declaration. Set follow_renaming to false in order to
    |" return the renaming declaration instead if any.
    fun nonbound_generic_decl_from_self(follow_renaming : Bool = true) : Entity[BasicDecl] =
        node.as_bare_entity.nonbound_generic_decl_from_entity(follow_renaming)

    |" Return the generic decl entity designated by this instantiation,
    |" including instantiation information. This is equivalent to the expanded
    |" generic unit in GNAT.
    @exported
    @abstract
    fun designated_generic_decl(): Entity[GenericDecl]

    |" Return the generic decl designated by this instantiation, but without
    |" the associated generic context.
    fun designated_bare_generic_decl(): Entity[BasicDecl] = {
        val decl = self.designated_generic_decl();

        Entity[AdaNode](
            node=decl.node, info=EntityInfo(
                md=decl.info.md, rebindings=decl.info.rebindings.get_parent, from_rebound=decl.info.from_rebound
            )
        ).as[BasicDecl]
    }

    @lazy
    actual_expr_decls: Array[AnonymousExprDecl] = match node {
        case subp: GenericSubpInstantiation => subp.params
        case pkg: GenericPackageInstantiation => pkg.params
    }.map(
        (assoc) => AnonymousExprDecl(expr=assoc.as_bare_entity.expr().node)
    )

    |" Return the defining environment of the parent of this generic package
    |" instantiation , if it has one. This is used by child package
    |" instantiation to create a reference env to their parent. To see why
    |" this is needed, consider the following snippet:
    |"
    |" .. code::
    |"
    |"     -- pkg_g.ads
    |"     generic package Pkg_G is end Pkg_G;
    |"
    |"     -- pkg_g-child_g.ads
    |"     generic package Pkg_G.Child_G is end Pkg_G.Child_G;
    |"
    |"     -- my_pkg.ads
    |"     package My_Pkg is new Pkg_G;
    |"
    |"     -- my_pkg-my_child.ads
    |"     package My_Pkg.My_Child is new Child_G;
    |"
    |" In the env spec of the last instantiation, we have to set the parent
    |" env of ``My_Child`` to be the ``My_Pkg`` instantiation node. However,
    |" this does not give us visibility on the instantiat*ed* package
    |" ``Pkg_G [My_Pkg]``, which we need in order to resolve the following
    |" non-prefixed reference to ``Child_G``. Therefore, we must explicitly
    |" create a reference from ``My_Pkg.My_Child`` to ``Pkg_G [My_Pkg]`` in
    |" order to gain visibility on ``Child_G [My_Pkg]``.
    fun parent_instantiation_env(): LexicalEnv =
        self.defining_name().name.as[DottedName]?.prefix.do(
            (parent_name) => {
                bind origin = node;
                bind env = self.children_env();

                parent_name.designated_env_no_overloading()
            }, default_val=node.empty_env()
        )

    fun xref_entry_point(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = (
        %eq(self.generic_entity_name().ref_var(), self.nonbound_generic_decl_from_self(false)) and match self.generic_entity_name() {
            case dn: DottedName => dn.prefix.xref_no_overloading()
            case _ => %true
        }
    ) and (
        if self.is_any_formal() then %true else self.designated_generic_decl()?.formal_part.match_param_list(self.generic_inst_params(), false).filter(
            (pm) => not pm.actual.assoc.expr() is BoxExpr
        ).logic_all(
            (pm) => {
                val actual_name = pm.actual.assoc.expr().as[Name];

                match pm.formal.formal_decl().as[GenericFormal].decl {
                    case _: BaseTypeDecl => actual_name.xref_type_equation()
                    case _: GenericPackageInstantiation => actual_name.xref_no_overloading()
                    case subp_decl: Entity[FormalSubpDecl] => if actual_name is AttributeRef then actual_name.sub_equation() else (
                        actual_name.xref_no_overloading(all_els=true) and %predicate(BasicDecl.subp_decl_match_signature, actual_name.ref_var(), subp_decl.as[BasicDecl])
                    ) or %true
                    case obj_decl: ObjectDecl => (
                        %eq(pm.actual.assoc.expr().expected_type_var(), obj_decl.expr_type()) and pm.actual.assoc.expr().sub_equation()
                    ) and pm.actual.assoc.expr().matches_expected_assign_type()
                    case _ => %true
                } and pm.actual.name.do(
                    (n) => %eq(n.ref_var(), pm.formal.node.as_bare_entity.basic_decl()), default_val=%true
                )
            }
        )
    )

    fun initial_env_name(): Symbol =
        if node.is_library_item() then node.child_decl_initial_env_name() else null[Symbol]

    fun env_names(): Array[Symbol] =
        node.top_level_env_name().do((fqn) => [fqn.to_symbol])

    |" Returns an array of pairs, associating formal parameters to actual or
    |" default expressions.
    @exported
    fun inst_params(): Array[ParamActual] = {
        val ap = self.generic_inst_params();

        self.designated_generic_decl()?.formal_part.decls.mapcat(
            # Unpack generic formals with their default expressions
            (d) => match d {
                case t: GenericFormalPackage => [ParamActual(
                    param=t.decl.as[GenericPackageInstantiation].name, actual=null[Entity[Expr]]
                )]
                case t: GenericFormalTypeDecl => [ParamActual(
                    param=t.decl.as[BaseTypeDecl].name, actual=null[Entity[Expr]]
                )]
                case o: GenericFormalObjDecl => o.decl.as[ObjectDecl].ids.map(
                    (i) => ParamActual(
                        param=i, actual=o.decl.as[ObjectDecl].default_expr
                    )
                )
                case sp: GenericFormalSubpDecl => [{
                    val subp = sp.decl.as[FormalSubpDecl];

                    ParamActual(
                        param=sp.defining_name(), actual=if subp.default_expr is BoxExpr then subp.designated_subprogram_from(inst=self)?.defining_name() else subp.default_expr
                    )
                }]
                case _: Pragma => null[Array[ParamActual]]
                case _: UseClause => null[Array[ParamActual]]
                case _ => raise[Array[ParamActual]] PropertyError("unexpected declaration in generic formal part")
            }
        ).imap(
            (dp, i) => ParamActual(
                param=dp.param,
                # Update actuals from instantiation params
                actual=ap.actual_for_param_at(dp.param, i, dp.actual)
            )
        )
    }

    |" Return the expression of the actual used for the given formal in this
    |" generic instantiation. Returns null if none is provided, even if there
    |" is a default value.
    fun actual_for_formal(formal_name: DefiningName): Entity[Expr] = {
        val gen_decl = node.nonbound_generic_decl_from_self().as[GenericDecl];

        gen_decl?.formal_part.match_param_list(self.generic_inst_params(), false).find((pm) => pm.formal.node == formal_name).do((pm) => pm.actual.assoc.expr())
    }

    env_spec {
        do(node.env_hook())
        set_initial_env(
            node.initial_env_name().do(
                (non_null_name) => DesignatedEnv(
                    kind=DesignatedEnvKind.named_env, env_name=non_null_name, direct_env=null[LexicalEnv]
                ), default_val=DesignatedEnv(
                    kind=DesignatedEnvKind.current_env, env_name=null[Symbol], direct_env=null[LexicalEnv]
                )
            )
        )
        add_to_env_kv(self.name_symbol(), node)
        add_env(names=node.env_names())
        do(node.populate_dependent_units())
        reference(
            node.top_level_use_package_clauses(), Name.use_package_name_designated_env, cond=node.parent is LibraryItem | Subunit
        )
        reference(
            node.top_level_use_type_clauses(), Name.name_designated_type_env, cond=node.parent is LibraryItem | Subunit
        )
        reference(
            [node.as[AdaNode]], GenericInstantiation.parent_instantiation_env, cond=node.parent is LibraryItem | Subunit
        )
    }
}

|" Instantiations of a generic package.
class GenericPackageInstantiation: GenericInstantiation {
    @parse_field name: DefiningName
    @parse_field generic_pkg_name: Name
    @parse_field params: AssocList
    @parse_field aspects: AspectSpec

    fun generic_entity_name(): Entity[Name] = self.generic_pkg_name

    fun generic_inst_params(): Entity[AssocList] = self.params

    fun designated_package(): Entity[BasePackageDecl] = self.nonbound_generic_decl_from_entity().do(
        (p) => Entity[BasePackageDecl](
            node=p.node.as[GenericPackageDecl].package_decl, info=EntityInfo(
                md=p.info.md, rebindings=node.add_rebinding(
                    # A subset of ``self``'s rebindings were used to
                    # resolve ``p``, now use ``insert_rebindings`` to add
                    # the rest of them.
                    node.insert_rebindings(p.info.rebindings, self.info.rebindings), # Append the rebindings for the current instantiation.
                    # NOTE: We use the formal env to create rebindings.
                    # There, we purposefully want the children env of the
                    # P node, with no rebindings associated, since the
                    # rebinding indication concerns the *naked* generic.
                    # Hence we use `p.node.children_env`.
                    p.node.children_env(), node.instantiation_env
                ), from_rebound=p.info.from_rebound
            )
        )
    )

    fun designated_generic_decl(): Entity[GenericDecl] =
        self.designated_package().parent.as![GenericDecl]

    |" Specialized function for getting the defining env for this generic
    |" instantiation.
    |"
    |" If ``inst_from_formal`` is True, we know that this generic package
    |" instantiation is coming from a rebound formal package, and that we need
    |" visibility on the formals.
    @with_dynvars(origin)
    fun defining_env_impl(inst_from_formal: Bool = false): LexicalEnv = {
        val dp = self.designated_package();

        # In some specific scenarios on valid Ada code, dp can be null
        # here (see U630-018). For example, consider the following snippet.
        #
        # .. code::
        #   use U; -- U contains the declaration of G
        #   package A is new G;
        #   use A;
        #
        # Now consider an env lookup attempting to traverse the "use U"
        # clause. When calling the use clause's resolver, we lookup "U" and
        # we end up traversing "use A" (this is the critical part: although
        # the use clause is located after, we still traverse it in order
        # to cache further lookups to "U", no matter their origin). When
        # resolving "use A", we need to lookup G. However, since U is
        # already being visited, our lexical env mechanism preventing
        # infinite recursion returns an empty vector, which in turn makes
        # ``self.designated_package`` be null here.
        # Fortunately, returning EmptyEnv in this case is fine, because
        # there would be no way for U to be found through A anyways.
        if dp.is_null then
            null[LexicalEnv]
        else [
            if node.is_formal() or inst_from_formal then
                [dp.children_env(), dp.parent.children_env()].env_group()
            else
                dp.children_env(),
            # The environment of the instantiation needs to be available,
            # because library unit generic package instantiations can be
            # nested, and so need to be available, such as in::
            #
            #     --  a.ads
            #     package A is new Gen_A;
            #
            #     --  a-b.ads
            #     package A.B is new A.Gen_B;
            #
            self.children_env()
        ].env_group()
    }

    @with_dynvars(origin, include_ud_indexing=false, dottable_type=null[AdaNode])
    fun defining_env(): LexicalEnv = self.defining_env_impl()

    fun defining_names(): Array[Entity[DefiningName]] = [self.name]
}

|" Instantiations of a generic subprogram .
class GenericSubpInstantiation: GenericInstantiation {
    @parse_field overriding: Overriding
    @parse_field kind: SubpKind
    @parse_field subp_name: DefiningName
    @parse_field generic_subp_name: Name
    @parse_field params: AssocList
    @parse_field aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] = [self.subp_name]

    fun generic_entity_name(): Entity[Name] = self.generic_subp_name

    fun generic_inst_params(): Entity[AssocList] = self.params

    @with_dynvars(origin)
    fun expr_type(): Entity[BaseTypeDecl] =
        self.subp_spec_or_null()?.return_type()

    @with_dynvars(origin, include_ud_indexing=false, dottable_type=null[AdaNode])
    fun defining_env(): LexicalEnv =
        self.subp_spec_or_null()?.defining_env()

    |" Return the subprogram decl designated by this instantiation.
    @exported
    fun designated_subp(): Entity[BasicSubpDecl] = self.nonbound_generic_decl_from_entity().do(
        (p) => Entity[BasicSubpDecl](
            node=p.node.as[GenericSubpDecl].subp_decl, info=EntityInfo(
                md=self.info.md, rebindings=node.add_rebinding(
                    node.insert_rebindings(p.info.rebindings, self.info.rebindings), p.node.children_env(), node.instantiation_env
                ), from_rebound=p.info.from_rebound
            )
        )
    )

    fun designated_generic_decl(): Entity[GenericDecl] =
        self.designated_subp().parent.as![GenericDecl]
}

|" Base node for all generic renaming declarations (:rmlink:`8.5.5`).
@abstract
class GenericRenamingDecl: BasicDecl {
    @abstract
    fun renaming_name(): Entity[Name]

    |" Resolve the GenericDecl this renaming decl is pointing at
    fun resolve(): Entity[GenericDecl] =
        # We must use `all_env_elements_internal` here and not `env_elements`,
        # as the latter assumes the Name is used in an expression context,
        # which is not the case here.
        self.renaming_name().all_env_elements_internal(
            seq=true, seq_from=node, categories=RefCategories(inherited_primitives=false, _=true)
        ).filter((e) => not e is Body)?[0].do(
            (v1) => match v1 {
                case gd: GenericDecl => gd
                case grd: GenericRenamingDecl => grd.resolve()
                case _ => null[Entity[GenericDecl]]
            }
        )

    fun xref_entry_point(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = self.renaming_name().xref_no_overloading()
}

|" Declaration for a generic package renaming (:rmlink:`8.5.5`).
class GenericPackageRenamingDecl: GenericRenamingDecl {
    @parse_field name: DefiningName
    @parse_field renames: RenamingClause
    @parse_field aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] = [self.name]

    @with_dynvars(origin, include_ud_indexing=false, dottable_type=null[AdaNode])
    fun defining_env(): LexicalEnv = self.resolve().defining_env()

    fun renaming_name(): Entity[Name] = self.renames.renamed_object

    env_spec {
        do(node.env_hook())
        set_initial_env(node.child_decl_initial_env())
        add_to_env_kv(self.name_symbol(), node)
        add_env()
        do(node.populate_dependent_units())
        reference(
            node.top_level_use_package_clauses(), Name.use_package_name_designated_env, cond=node.parent is LibraryItem | Subunit
        )
        reference(
            node.top_level_use_type_clauses(), Name.name_designated_type_env, cond=node.parent is LibraryItem | Subunit
        )
    }
}

|" Declaration for a generic subprogram renaming.
class GenericSubpRenamingDecl: GenericRenamingDecl {
    @parse_field kind: SubpKind
    @parse_field name: DefiningName
    @parse_field renames: RenamingClause
    @parse_field aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] = [self.name]

    fun renaming_name(): Entity[Name] = self.renames.renamed_object

    env_spec {
        do(node.env_hook())
        set_initial_env(node.child_decl_initial_env())
        add_to_env_kv(self.name_symbol(), node)
        add_env()
        do(node.populate_dependent_units())
        reference(
            node.top_level_use_package_clauses(), Name.use_package_name_designated_env, cond=node.parent is LibraryItem | Subunit
        )
        reference(
            node.top_level_use_type_clauses(), Name.name_designated_type_env, cond=node.parent is LibraryItem | Subunit
        )
    }
}

|" Declaration for a code label (:rmlink:`5.1`).
class LabelDecl: BasicDecl {
    @parse_field name: DefiningName
    @parse_field @null_field aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] = [self.name]

    env_spec {
        add_to_env_kv(node.name_symbol(), node)
    }
}

|" BasicDecl that is always the declaration inside a named statement.
class NamedStmtDecl: BasicDecl {
    @parse_field name: DefiningName
    @parse_field @null_field aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] = [self.name]

    @with_dynvars(origin, include_ud_indexing=false, dottable_type=null[AdaNode])
    fun defining_env(): LexicalEnv =
        node.parent.as[NamedStmt].stmt.children_env()
}

|" Declaration for a static constant number (:rmlink:`3.3.2`).
class NumberDecl: BasicDecl {
    @parse_field ids: ASTList[DefiningName]
    @parse_field expr: Expr
    @parse_field @null_field aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] =
        self.ids.map((id) => id)

    @call_memoizable
    @with_dynvars(origin)
    fun expr_type(): Entity[BaseTypeDecl] =
        if self.expr.expression_type().is_int_type() then node.universal_int_type() else node.universal_real_type()

    fun xref_entry_point(): Bool = true

    @with_dynvars(imprecise_fallback=false)
    fun is_static_decl(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = (
        (
            %eq(node.expr.expected_type_var(), node.universal_int_type()) or %eq(node.expr.expected_type_var(), node.universal_real_type())
        ) and self.expr.sub_equation()
    ) and self.expr.matches_expected_type()

    fun is_constant_object(): Bool = true

    env_spec {
        add_to_env(node.env_mappings(node.ids, node))
    }
}

|" Base class for Ada object declarations (:rmlink:`3.3.1`). Ada object
|" declarations are variables/constants declarations that can be declared in
|" any declarative scope.
class ObjectDecl: BasicDecl {
    @parse_field ids: ASTList[DefiningName]
    @parse_field @nullable has_aliased: Aliased
    @parse_field @nullable has_constant: Constant
    @parse_field @nullable mode: Mode
    @parse_field @nullable type_expr: TypeExpr
    @parse_field @nullable default_expr: Expr
    @parse_field @nullable renaming_clause: RenamingClause
    @parse_field aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] =
        self.ids.map((id) => id)

    @with_dynvars(origin, include_ud_indexing=false, dottable_type=null[AdaNode])
    fun defining_env(): LexicalEnv = self.type_expr.defining_env()

    fun type_expression(): Entity[TypeExpr] = self.type_expr

    fun is_constant_object(): Bool = self.has_constant.do((c) => c.as_bool()) or (
        # A GenericFormalObjDecl is constant if the Mode is `in`
        self.mode.do(
            (m) => node.parent is GenericFormalObjDecl and m is Mode.In | Mode.Default
        )
    ) or (
        # Renaming clause is constant if the renamed object is constant
        self.renaming_clause?.renamed_object.is_constant()
    ) or (
        # Constant if the object is protected
        self.type_expr.designated_type_decl() is ProtectedTypeDecl
    )

    @with_dynvars(imprecise_fallback=false)
    fun is_static_decl(): Bool = (
        node.has_constant.as_bool() and self.default_expr.do((expr) => expr.is_static_expr())
    ) or self.renaming_clause?.renamed_object.is_static_expr()

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        val typ = self.expr_type();

        (
            self.type_expr.sub_equation() and self.default_expr.do(
                (de) => (
                    %eq(de.expected_type_var(), typ) and de.sub_equation()
                ) and de.matches_expected_assign_type(), default_val=%true
            )
        ) and self.renaming_clause.do(
            (rc) => (
                %eq(rc.renamed_object.expected_type_var(), typ) and rc.renamed_object.sub_equation()
            ) and rc.renamed_object.matches_expected_assign_type(), default_val=%true
        )
    }

    @with_dynvars(imprecise_fallback=false)
    fun next_part_for_name(sym: Symbol): Entity[BasicDecl] =
        if self.is_in_public_part() and node.has_constant.as_bool() then node.declarative_scope().parent.as_entity.as[BasePackageDecl].private_part?.children_env().get_first(
            sym, lookup=LookupKind.minimal, categories=RefCategories(inherited_primitives=false, _=true)
        ).as[BasicDecl] else null[Entity[BasicDecl]]

    @with_dynvars(imprecise_fallback=false)
    fun previous_part_for_name(sym: Symbol): Entity[BasicDecl] =
        if self.is_in_private_part() and node.has_constant.as_bool() then node.declarative_scope().parent.as_entity.as[BasePackageDecl].public_part.children_env().get_first(
            sym, lookup=LookupKind.minimal, categories=RefCategories(inherited_primitives=false, _=true)
        ).as[BasicDecl] else null[Entity[BasicDecl]]

    |" If this object decl is the constant completion of an object decl in the
    |" public part, return the object decl from the public part.
    @exported
    fun private_part_decl(): Entity[BasicDecl] = self.next_part_for_name(
        self.defining_name_or_raise().name_symbol()
    )

    |" If this object decl is the incomplete declaration of a constant in a
    |" public part, return its completion in the private part.
    @exported
    fun public_part_decl(): Entity[BasicDecl] = self.previous_part_for_name(
        self.defining_name_or_raise().name_symbol()
    )

    @with_dynvars(imprecise_fallback=false)
    fun next_part_for_decl(): Entity[BasicDecl] = self.private_part_decl()

    @with_dynvars(imprecise_fallback=false)
    fun previous_part_for_decl(): Entity[BasicDecl] = self.public_part_decl()

    fun xref_entry_point(): Bool = true

    env_spec {
        add_to_env(node.env_mappings(node.ids, node))
    }
}

|" Object declaration that is part of an extended return statement
|" (:rmlink:`6.5`).
class ExtendedReturnStmtObjectDecl: ObjectDecl {
}

|" Object declaration without subtype indication. This node has been
|" introduced to cover a special case for ``ObjectDecl``, where
|" ``type_expr`` is made optional (AI12-0275), and therefore cannot
|" fit in an ``ObjectDecl``.
class NoTypeObjectRenamingDecl: ObjectDecl {
    @with_dynvars(origin)
    fun expr_type(): Entity[BaseTypeDecl] =
        self.renaming_clause.renamed_object.expression_type()

    @with_dynvars(origin, include_ud_indexing=false, dottable_type=null[AdaNode])
    fun defining_env(): LexicalEnv = self.expr_type().defining_env()

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.renaming_clause.renamed_object.sub_equation()
}

|" Declaration for a package renaming (:rmlink:`8.5.3`).
class PackageRenamingDecl: BasicDecl {
    @parse_field name: DefiningName
    @parse_field renames: RenamingClause
    @parse_field aspects: AspectSpec

    |" Return the declaration of the package that is renamed by self.
    @exported
    fun renamed_package(): Entity[BasicDecl] = {
        # Workaround for V714-016. We perform an initial "dummy" env get query
        # to prepare the referenced envs that will be traversed by the next
        # query by allowing `Name.use_package_name_designated_env` to get
        # memoized. It is important to use the `no_prims` category to avoid
        # traversing primitive environments, as those can trigger name
        # resolution queries (when checking signatures of subprograms in order
        # to determine the primitives of a type), which in turn can cause
        # infinite recursions if those queries need to resolve this package
        # renaming as well.
        val node_env = self.node_env();
        val _ = node_env.get(
            s"__dummy", categories=RefCategories(inherited_primitives=false, _=true)
        );

        # We can then safely perform the actual query which will not trigger
        # the infinite recursion.
        {
            bind env = node_env;

            self.renames.renamed_object.env_elements()?[0].as[BasicDecl]
        }
    }

    |" Return the declaration of the package that is ultimately renamed by
    |" self, skipping through all intermediate package renamings.
    @exported
    fun final_renamed_package(): Entity[BasicDecl] = {
        val pkg = self.renamed_package();

        pkg.as[PackageRenamingDecl].do(
            (r) => r.final_renamed_package(), default_val=pkg
        )
    }

    fun defining_names(): Array[Entity[DefiningName]] = [self.name]

    @with_dynvars(origin, include_ud_indexing=false, dottable_type=null[AdaNode])
    fun defining_env(): LexicalEnv =
        self.renamed_package().defining_env()

    fun xref_entry_point(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.renames.renamed_object.xref_no_overloading()

    env_spec {
        do(node.env_hook())
        set_initial_env(node.child_decl_initial_env())
        add_to_env_kv(self.name_symbol(), node)
        add_env()
        do(node.populate_dependent_units())
        reference(
            node.top_level_use_package_clauses(), Name.use_package_name_designated_env, cond=node.parent is LibraryItem | Subunit
        )
        reference(
            node.top_level_use_type_clauses(), Name.name_designated_type_env, cond=node.parent is LibraryItem | Subunit
        )
    }
}

|" Declaration for a single protected object (:rmlink:`9.4`).
class SingleProtectedDecl: BasicDecl {
    @parse_field name: DefiningName
    @parse_field aspects: AspectSpec
    @parse_field interfaces: ParentList
    @parse_field definition: ProtectedDef

    fun defining_names(): Array[Entity[DefiningName]] = [self.name]

    @with_dynvars(origin, include_ud_indexing=false, dottable_type=null[AdaNode])
    fun defining_env(): LexicalEnv = self.definition.private_part.do(
        (pp) =>
        # Include private_part's env unconditionally. This is safe since
        # SingleProtectedDecl can't be overloaded, thus wrong name
        # resolution can only occur on invalid Ada code.
        [self.children_env(), pp.children_env()].env_group(), default_val=self.children_env()
    )

    fun xref_entry_point(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.interfaces.logic_all((ifc) => ifc.xref_equation())

    fun env_names(): Array[Symbol] =
        node.top_level_env_name().do((fqn) => [fqn.to_symbol])

    fun declarative_parts(): Array[Entity[DeclarativePart]] = {
        val pdef = self.definition;

        [pdef.public_part.as[DeclarativePart]] & pdef.private_part.as[DeclarativePart].do((v1) => [v1])
    }

    env_spec {
        add_to_env_kv(self.name_symbol(), node)
        add_env(names=node.env_names())
    }
}

|" Declaration for a single task (:rmlink:`9.1`).
class SingleTaskDecl: BasicDecl {
    @parse_field task_type: SingleTaskTypeDecl
    @parse_field @null_field aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] =
        self.task_type.defining_names()

    @with_dynvars(origin)
    fun expr_type(): Entity[BaseTypeDecl] = self.task_type

    @with_dynvars(origin, include_ud_indexing=false, dottable_type=null[AdaNode])
    fun defining_env(): LexicalEnv = self.task_type.defining_env()

    fun env_names(): Array[Symbol] =
        node.top_level_env_name().do((fqn) => [fqn.to_symbol])

    env_spec {
        add_to_env_kv(node.name_symbol(), node)
        add_env(names=node.env_names())
    }
}

|" SyntheticObjectDecl is a declaration that holds a virtual object. This is
|" for example used in type predicates to refer to an object of the enclosing
|" type, as in::
|"
|"      subtype Odd is Natural with
|"         Dynamic_Predicate => Odd mod 2 = 1;
|"
|" where we have to create an object named ``Odd``, and of type ``Odd`` so
|" that the name in the aspect expression refers to it and can be properly
|" resolved to the type identifier.
|"
|" This node has no existance in the Ada RM, it's only used for internal name
|" resolution purposes.
@synthetic
class SyntheticObjectDecl: BasicDecl {
    name: DefiningName
    type_expr: TypeExpr
    @parse_field @null_field aspects: AspectSpec

    fun type_expression(): Entity[TypeExpr] = node.type_expr.as_entity

    fun defining_names(): Array[Entity[DefiningName]] = [node.name.as_entity]

    |" Return whether a synthetic type predicate object can be seen from the
    |" given ``origin`` node. If we are outside the type definition, this will
    |" always be the type itself. Otherwise this will always be the synthetic
    |" object, unless we are in an access type definition. In particular, this
    |" allows correctly resolving:
    |"
    |" .. code:: ada
    |"
    |"     type T is record
    |"        X : access T := T'Unrestricted_Access;
    |"        --        (1)  (2)
    |"     end record;
    |"
    |" Here, the reference (1) points to the type, whereas (2) refers to the
    |" synthetic object.
    fun is_referred_by(origin: AdaNode): Bool =
        origin.parents().find((p) => p is AccessDef).is_null and node.is_children_env(
            node.type_expr.as[SyntheticTypeExpr].target_type.children_env(), origin.children_env()
        )
}

|" Alternative in a ``case`` statement (``when ... => ...``).
class CaseStmtAlternative: AdaNode {
    @parse_field choices: AlternativesList
    @parse_field stmts: StmtList

    fun xref_entry_point(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        val case_stmt = self.parent.parent.as![CaseStmt];
        # Trigger name resolution on the case statement
        val selected_type = case_stmt.expr.expression_type();

        self.choices.logic_all(
            (c) => match c {
                # Expression case
                case e: Expr => if e is Name and not e.as[Name].name_designated_type().is_null then e.as[Name].xref_type_equation() else (
                    %eq(e.expected_type_var(), selected_type) and e.sub_equation()
                ) and e.matches_expected_type()

                # SubtypeIndication case (``when Color range Red .. Blue``)
                case t: SubtypeIndication => t.xref_equation()
                case _: OthersDesignator => %true
                case _ => raise[Equation] PropertyError("Should not happen")
            }
        )
    }
}

|" Root node for all Ada analysis units (:rmlink:`10.1.1`).
@ple_unit_root
class CompilationUnit: AdaNode {
    |" ``with``, ``use`` or ``pragma`` statements.
    @parse_field prelude: ASTList[AdaNode]
    @parse_field body: AdaNode
    @parse_field pragmas: ASTList[Pragma]
    no_env: LexicalEnv

    |" Returns an empty env to use in env specs. This is meant as an
    |" optimization: Langkit referenced envs that return empty env can never
    |" be cached, so we used a CompilationUnit specific empty env, that will
    |" live for the same duration as its analysis unit, and then be
    |" invalidated.
    @external(uses_envs=true)
    fun get_empty_env(): LexicalEnv

    |" Return the syntactic fully qualified name of this compilation unit.
    @exported
    fun syntactic_fully_qualified_name(): Array[Symbol] = match node.as_bare_entity.body {
        case li: LibraryItem => li.item.defining_name()?.as_symbol_array()
        case su: Subunit => su.name.as_symbol_array() & su.body.defining_name().as_symbol_array()
        case _ => raise[Array[Symbol]] PropertyError("Unexpected CompilationUnit.f_body attribute")
    }

    |" Return the kind corresponding to this analysis unit.
    @exported
    fun unit_kind(): AnalysisUnitKind = match node.body {
        case li: LibraryItem => match li.item {
            case _: Body => AnalysisUnitKind.unit_body
            case _ => AnalysisUnitKind.unit_specification
        }
        case _: Subunit => AnalysisUnitKind.unit_body
        case _ => raise[AnalysisUnitKind] PropertyError("Unexpected CompilationUnit.f_body attribute")
    }

    |" Return all units referenced in this name. For example in the name
    |" ``A.B.C``, this returns units ``A``,  ``A.B`` and ``A.B.C``.
    fun referenced_units_in(name: Entity[Name]): Array[Entity[CompilationUnit]] = {
        val self_refd = name.referenced_decl()?.enclosing_compilation_unit();

        name.as[DottedName].do(
            (dn) => node.referenced_units_in(dn.prefix), default_val=null[Array[Entity[CompilationUnit]]]
        ) & self_refd.as_bare_entity.do((v1) => [v1])
    }

    |" Look for all "with" clauses at the top of this compilation unit and
    |" return all the compilation units designated by them. For the complete
    |" dependencies list of compilation units, see the ``unit_dependencies``
    |" property. Units imported with a "private with" are included in this
    |" list only if ``include_privates`` is True.
    @exported
    @memoized
    fun withed_units(include_privates: Bool = true): Array[Entity[CompilationUnit]] =
        node.top_level_with_package_clauses(include_privates).mapcat(
            # Try to fetch the compilation unit in a spec file first. If this
            # fails, the "with" must designate a body without spec (e.g. a
            # library-level procedure).
            (p) => node.referenced_units_in(p.as_bare_entity)
        ).unique()

    |" Return all the compilation units that are directly imported by this
    |" one. This includes "with"ed units as well as the direct parent unit.
    |" Units imported with a "private with" are included in this list only if
    |" ``include_privates`` is True.
    @exported
    @memoized
    fun imported_units(include_privates: Bool = true): Array[Entity[CompilationUnit]] =
        node.withed_units(include_privates) & (
            # Library-level subprogram bodies are handled specially here,
            # as their parent environment is *not* their corresponding spec in
            # our implementation (unlike for the rest of the library-level
            # declarations).
            node.decl().as[BaseSubpBody].do(
                # We call subp_previous_part directly to avoid unnecessary
                # detours in which code that raises property errors could
                # be accidentally added.
                (subp) => subp.as_bare_entity.subp_previous_part().do(
                    (pp) => [pp.enclosing_compilation_unit().as_bare_entity]
                )
            ) or? node.decl()?.node_env()?.env_node.do(
                (n) => [n.enclosing_compilation_unit().as_bare_entity]
            )
        )

    |" Return the list of units that are only visible in private parts of this
    |" compilation units. Note that this is not equivalent to the list of
    |" units that are private-withed, as Ada allows the same unit to be both
    |" "with"ed and "private with"ed, in which case it will also be visible in
    |" public parts. So, in order to compute that list, we must subtract the
    |" list of units that are (non-private-)"with"ed from the list of all
    |" "with"ed and "private with"ed units.
    @memoized
    fun privately_imported_units(): Array[AnalysisUnit] =
        # Shortcut: if there are no "private with" clauses, the subtraction
        # will be empty.
        if node.prelude.any(
            (clause) => clause.as[WithClause]?.has_private.as_bool()
        ) then {
            val all_imports = node.imported_units(include_privates=true);
            val public_imports = node.imported_units(include_privates=false);

            all_imports.filtermap(
                (cu) => cu.unit(), (cu) => not public_imports.contains(cu)
            )
        } else null[Array[AnalysisUnit]]

    |" Helper function for "unit_dependencies" that computes transitively
    |" the unit dependencies of the given ``to_visit`` units. The ``visited``
    |" set of units is used to terminate the search once a fix-point has
    |" been reached, which is when all direct dependencies of ``to_visit`` are
    |" already included in the ``visited`` set.
    fun unit_dependencies_helper(visited: Array[Entity[CompilationUnit]], to_visit: Array[Entity[CompilationUnit]]): Array[Entity[CompilationUnit]] = {
        val now_visited = visited & to_visit;
        val new_imports = to_visit.mapcat((c) => c.imported_units()).unique();
        val to_visit_next = new_imports.filter((c) => not now_visited.contains(c));

        if to_visit_next.length() > 0 then node.unit_dependencies_helper(now_visited, to_visit_next) else now_visited
    }

    |" Return the list of all the compilation units that are (direct and
    |" indirect) dependencies of this one. See the
    |" ``withed_units``/``imported_units`` properties to only get the direct
    |" dependencies of this unit.
    @exported
    @memoized
    fun unit_dependencies(): Array[Entity[CompilationUnit]] = node.unit_dependencies_helper(
        null[Array[Entity[CompilationUnit]]], [self]
    ).unique().filter(
        # Remove self from the list of dependencies
        (u) => u.node != node
    )

    |" Get the root basic decl defined in this compilation unit.
    @exported
    fun decl(): BasicDecl = match node.body {
        case li: LibraryItem => li.item
        case su: Subunit => su.body
        case _ => null[BasicDecl]
    }

    |" Implementation helper for ``is_preelaborable``.
    |"
    |" Return whether ``self`` or its spec (if any) make it preelaborable.
    |" ``from_body`` has the same semantics as in
    |" ``does_aspects_make_preelaborate``.
    @with_dynvars(imprecise_fallback=false)
    fun is_preelaborable_impl(from_body: Bool): Bool = match self.body {
        # Subunits are preelaborable iff the body they relate to is
        # preelaborable.
        case su: Subunit => su.body_root().parent.parent.as![CompilationUnit].is_preelaborable_impl(from_body=true)
        case li: LibraryItem => match li.item {
            case subp_decl: SubpDecl => subp_decl.does_aspects_make_preelaborable(from_body)
            case gen_subp_decl: GenericSubpDecl => gen_subp_decl.decl().does_aspects_make_preelaborable(from_body)
            case subp_body: SubpBody => (
                # Subprogram bodies can have elaboration pragmas, so look
                # for them, first.
                subp_body.does_aspects_make_preelaborable(from_body=false)
            ) or (
                # Otherwise recurse on the corresponding procedure spec (if
                # any).
                subp_body.decl_part().do(
                    (dp) => dp.parent.parent.as![CompilationUnit].is_preelaborable_impl(from_body=true)
                )
            )
            case pkg_decl: PackageDecl => pkg_decl.does_aspects_make_preelaborable(from_body)
            case gen_pkg_decl: GenericPackageDecl => gen_pkg_decl.package_decl.does_aspects_make_preelaborable(from_body)
            case pkg_body: PackageBody =>
                # Elaboration control pragmas cannot appear in package
                # bodies, so recurse on the corresponding package spec.
                pkg_body.decl_part().unit().root.as_bare_entity.as![CompilationUnit].is_preelaborable_impl(from_body=true)
            case _ => false
        }
        case _ => false
    }

    |" Whether this compilation unit is preelaborable or not.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun is_preelaborable(): Bool = self.is_preelaborable_impl(from_body=false)

    |" Return the list of restrictions pragmas that appear in the prelude of
    |" this particular unit. We only check the prelude as it's the only place
    |" they are allowed to appear in.
    fun self_restrictions(): Array[Symbol] = node.as_bare_entity.prelude.filtermap(
        (n) => n.as[Pragma].args?[0]?.assoc_expr().as[BaseId].name_symbol(), (n) => n.as[Pragma].do(
            (p) => p.id.name_symbol() == s"Restrictions"
        )
    )

    |" If this compilation unit is of kind UnitSpecification, return its
    |" corresponding body unit, and conversely.
    @exported
    fun other_part(): Entity[CompilationUnit] = {
        val other_kind = if node.unit_kind() == AnalysisUnitKind.unit_specification then AnalysisUnitKind.unit_body else AnalysisUnitKind.unit_specification;

        node.designated_compilation_unit(
            node.syntactic_fully_qualified_name(), kind=other_kind, not_found_is_error=false
        )?.as_bare_entity
    }

    |" Whether this compilation unit is affected by the restriction with the
    |" given name.
    |"
    |" .. WARNING::
    |"     This property only supports the ``No_Elaboration_Code`` restriction
    |"     for now.
    @exported
    fun has_restriction(name: Symbol): Bool =
        if name == s"No_Elaboration_Code" then match node.body {
            # For library items, restriction No_Elaboration_Code can appear
            # in the body or in the spec.
            case li: LibraryItem => node.self_restrictions().contains(name)
                or node.other_part()?.self_restrictions().contains(name)
                # Pragma No_Elaboration_Code_All establishes the restriction
                # No_Elaboration_Code for the current unit and any extended main
                # source units (body and subunits).
                or {
                    val spec = li.item.as_bare_entity.do(
                        (i) => if i is Body then
                            i.as[Body].decl_part()
                        else
                            i
                    );

                    not spec.is_null and spec.defining_name().has_aspect(
                        s"No_Elaboration_Code_All"
                    )
                }
            # For subunits, restriction must appear in the root unit, so
            # we only check that.
            case su: Subunit => su.root_unit()?.has_restriction(name)
            case _ => raise[Bool] PropertyError(
                "Unexpected CompilationUnit.f_body attribute"
            )
        }
        else raise[Bool] PropertyError("Unsupported restriction")

    |" Returns whether this compilation unit defines a child package of
    |" Ada.Text_IO.
    fun is_text_io_child(): Bool = {
        val name_parts = node.syntactic_fully_qualified_name();

        name_parts.length() == 3 and name_parts?[0] == s"ada" and name_parts?[1] in s"text_io" | s"wide_text_io" | s"wide_wide_text_io"
    }

    |" Return the list of pragmas from configuration pragmas files that apply
    |" to ``self``'s unit.
    @external()
    fun external_config_pragmas(): Array[Pragma]

    |" Return the list of configuration pragmas defined in the prelude of the
    |" current unit.
    fun local_config_pragmas(): Array[Pragma] =
        node.prelude.filtermap((n) => n.as[Pragma], (n) => n is Pragma)

    |" Return the list of configuration pragmas defined in Ada sources and
    |" which apply to the current unit.
    fun sources_config_pragmas(include_other_part: Bool = true): Array[Pragma] = {
        # First get pragmas in the prelude
        val current_unit = node.local_config_pragmas();
        # Then get pragmas in related units
        val related_units = # If self is a spec, we need to look at its body, and
        # conversely.
        if include_other_part and node.body is LibraryItem then node.other_part()?.local_config_pragmas()
        # If self is a sub-unit, we need to look at all subunits up in
        # the chain, the root body, and the corresponding spec.
        elif node.body is Subunit then node.body.as[Subunit].root_unit()?.sources_config_pragmas(include_other_part)
        else null[Array[Pragma]];

        current_unit & related_units
    }

    |" Return the list of configuration pragmas that apply to the current
    |" unit.
    @exported
    fun all_config_pragmas(): Array[Entity[Pragma]] = (
        node.sources_config_pragmas() & node.external_config_pragmas()
    ).map((n) => n.as_bare_entity)

    |" Return the ``SPARK_Mode`` configuration pragma that applies to the
    |" current unit.
    fun spark_config_pragma(): Entity[Pragma] = (
        node.external_config_pragmas() & node.sources_config_pragmas(include_other_part=false)
    ).filtermap(
        (n) => n.as_bare_entity, (n) => n.id.name_is(s"SPARK_Mode")
    )?[-1]

    |" Return the list of configuration pragmas with the given name that apply
    |" to the current unit.
    @exported
    fun config_pragmas(name: Symbol): Array[Entity[Pragma]] =
        node.all_config_pragmas().filter((n) => n.id.name_symbol() == name)

    |" Look for the stub in ``self`` corresponding to ``su`` or one of its
    |" parents. Return a null node if unsuccessful.
    |"
    |" For instance, with the following units::
    |"
    |"    procedure A is
    |"       procedure B is separate;
    |"    begin
    |"       null;
    |"    end A;
    |"
    |"    separate (A)
    |"    procedure B is
    |"       procedure C is separate;
    |"    begin
    |"       null;
    |"    end B;
    |"
    |"    separate (A.B)
    |"    procedure C is
    |"    begin
    |"       null;
    |"    end C;
    |"
    |" We have the following::
    |"
    |"    A.stub_for(B) -> "procedure B is separate"
    |"    A.stub_for(C) -> "procedure B is separate"
    |"    B.stub_for(C) -> "procedure C is separate"
    |"
    |" This is an internal helper for ``AdaNode.can_reach``: since it is used
    |" in all lexical env lookups, its implementation cannot do lookups itself
    |" as it would trigger infinite recursions. Libadalang users can use
    |" ``BasicDecl.previous_part_for_decl`` instead.
    |"
    |" Note that this wrapper only takes care of memoization. The actual
    |" implementation is in ``CompilationUnit.stub_for_impl``. Memoizing this
    |" property is very important for performance.
    @memoized
    # At the time of its introduction, this property was used only by
    # AdaNode.can_reach, which was an external property.
    @ignored
    fun stub_for(su: Subunit): BodyStub = node.stub_for_impl(su)

    |" Ada implementation of ``CompilationUnit.stub_for``.
    @external()
    fun stub_for_impl(su: Subunit): BodyStub

    |" Return whether the given ``origin`` node has view on "private withs" of
    |" its unit or parent units.
    fun has_private_view(origin: AdaNode): Bool = {
        val decl = node.decl();

        (
            # A private package necessarily has private-with visibility
            node.body.as[LibraryItem]?.has_private.as_bool()
        ) or (
            # If this compilation doesn't declare a package, then we
            # necessarily have private-with visibility because it means we are
            # inside a body.
            not decl is BasePackageDecl | GenericPackageDecl
        ) or (
            # Otherwise (this compilation unit declares a package), check
            # whether `origin` lies in a private part.
            origin.has_private_part_parent(decl.children_env().env_node)
        )
    }
}

|" Representation clause for a single component (:rmlink:`13.5.1`).
class ComponentClause: AdaNode {
    @parse_field id: Identifier
    @parse_field position: Expr
    @parse_field range: RangeSpec

    fun xref_entry_point(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        # Find the record representation clause in which the component clause
        # appears.
        val rep_clause = self.parent.parent.as![RecordRepClause];
        # rep_clause.name must refer to a subtype, so it's safe to use
        # designated_env_no_overloading.
        val record_env = rep_clause.name.designated_env_no_overloading();

        (
            # Resolve `id` in the environment of the original record
            {
                bind env = record_env;

                self.id.xref_equation()
            }
        ) and self.position.sub_equation() and self.range.sub_equation()
    }
}

|" Definition for a component (:rmlink:`3.6`).
class ComponentDef: AdaNode {
    @parse_field has_aliased: Aliased
    @parse_field has_constant: Constant
    @parse_field type_expr: TypeExpr

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = self.type_expr.sub_equation()
}

|" Qualifier for the ``constant`` keyword.
@qualifier
enum class Constant: AdaNode {
}

|" Base class for type constraints (:rmlink:`3.2.2`).
@abstract
class Constraint: AdaNode {
    fun subtype(): Entity[BaseTypeDecl] = {
        bind origin = node.origin_node();

        node.parent.as![SubtypeIndication].as_entity.designated_type()
    }

    @with_dynvars(imprecise_fallback=false)
    fun is_static(): Bool = match self {
        case rc: RangeConstraint => rc.range.range.is_static_expr()
        case cc: CompositeConstraint => if cc.is_index_constraint() then cc.constraints.all(
            (c) => match c.as[CompositeConstraintAssoc].constraint_expr {
                case st: SubtypeIndication => st.is_static_subtype()
                case e: Expr => e.is_static_expr()
                case _ => false
            }
        ) else cc.constraints.all((c) => c.expr().is_static_expr())
        case dc: DigitsConstraint => dc.range.do(
            (range) => range.range.is_static_expr(), default_val=true
        )
        case dc: DeltaConstraint => dc.range.do(
            (range) => range.range.is_static_expr(), default_val=true
        )
    }
}

|" Constraint for a composite type (:rmlink:`3.6.1`). Due to ambiguities in
|" the Ada grammar, this could be either a list of index constraints, if the
|" owning type is an array type, or a list of discriminant constraints, if the
|" owning type is a discriminated record type.
class CompositeConstraint: Constraint {
    @parse_field constraints: AssocList

    |" Whether this composite constraint is an index constraint.
    @exported
    fun is_index_constraint(): Bool = self.subtype().is_array_type() or (
        self.subtype().is_access_type() and self.subtype().accessed_type().is_array_type()
    )

    @with_dynvars(origin)
    fun complete_item_weight(item: Entity[BasicDecl]): Int =
        # If the constraint's type is an enum, promote EnumLiteralDecl nodes
        # that match that type.
        if self.subtype().discriminants_list().any(
            (td) => td.formal_type() == item.as[EnumLiteralDecl]?.enum_type()
        ) then 100 else self.super(item)

    |" Whether this composite constraint is a discriminant constraint.
    @exported
    fun is_discriminant_constraint(): Bool = not self.is_index_constraint()

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        val typ = self.subtype();

        if self.is_index_constraint() then self.constraints.ilogic_all(
            (c, i) => {
                val ex = c.as[CompositeConstraintAssoc].constraint_expr;

                # If the index constraint is an expression (which means it
                # is either a BinOp (first .. last) or an AttributeRef
                # (X'Range)), we assign to the type of that expression the
                # type of the index which we are constraining, or else it
                # would be resolved without any context and we could get
                # erroneous types in some cases.  Consider for example
                # ``subtype T is List ('A' .. 'B')``: here, 'A' and 'B'
                # could type to e.g. ``Character`` although the index type
                # of ``List`` is for example ``My_Character``. But if we
                # bind the type of ``'A' .. 'B'`` to ``My_Character`` as we
                # now do, the type will be propagated to both 'A' and 'B'
                # and therefore they will get the correct types.
                # Note that it's currently necessary to first assign the
                # expected type to the range before recursively
                # constructing its xref equations, as we have cases (e.g.
                # BinOp) where resolution takes different paths depending
                # on its operands' types (e.g. whether it's a universal
                # type or not).
                ex.as[Expr].do(
                    (e) => %eq(e.expected_type_var(), typ.index_type(i).base_subtype()), default_val=%true
                ) and ex.sub_equation()
            }
        ) else (
            # Regular discriminant constraint case
            node.match_formals(
                typ.discriminants_list(), self.constraints, false
            ).logic_all(
                (pm) => (
                    (
                        %eq(pm.actual.assoc.expr().expected_type_var(), pm.formal.formal_decl().formal_type()) and pm.actual.assoc.expr().sub_equation()
                    ) and pm.actual.assoc.expr().matches_expected_formal_type()
                ) and pm.actual.name.do(
                    (name) => %eq(name.ref_var(), pm.formal.formal_decl()), default_val=%true
                )
            )
        )
    }

    |" Returns an array of pairs, associating each discriminant to its
    |" actual or default expression.
    @exported
    fun discriminant_params(): Array[ParamActual] = {
        # Build a discriminants list with their default expressions
        val discrs = self.subtype().discriminants_list().mapcat(
            (d) => {
                val ds = d.as[DiscriminantSpec];

                ds.ids.map(
                    (i) => ParamActual(param=i, actual=ds.default_expr)
                )
            }
        );

        # Update the constraints expressions if some are provided
        self.constraints.do(
            (c) => discrs.imap(
                (dp, i) => ParamActual(
                    param=dp.param, actual=c.actual_for_param_at(dp.param, i, dp.actual)
                )
            ), default_val=discrs
        )
    }
}

|" Delta and range type constraint (:rmlink:`J.3`).
class DeltaConstraint: Constraint {
    @parse_field delta: Expr
    @parse_field @nullable range: RangeSpec

    |" Build an equation for a delta constraint definition.
    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = (
        # As per :rmlink:`J.3`, the delta expression is expected to be of
        # any real type.
        self.universal_real_bind(self.delta.expected_type_var())
    ) and self.delta.sub_equation() and self.delta.matches_expected_type() and (
        if node.range.is_null then %true else self.range.sub_equation()
    )
}

|" Digits and range type constraint (:rmlink:`3.5.9`).
class DigitsConstraint: Constraint {
    @parse_field digits: Expr
    @parse_field @nullable range: RangeSpec

    |" Build an equation for a digits constraint definition.
    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = (
        # As per :rmlink:`3.5.9`, the digits expression is expected to be
        # of any integer type.
        self.universal_int_bind(self.digits.expected_type_var())
    ) and self.digits.sub_equation() and self.digits.matches_expected_type() and (
        if node.range.is_null then %true else self.range.sub_equation()
    )
}

|" Range-based type constraint (:rmlink:`3.5`).
class RangeConstraint: Constraint {
    @parse_field range: RangeSpec

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        %eq(node.range.range.expected_type_var(), self.subtype().base_subtype()) and self.range.sub_equation() and self.range.range.matches_expected_type()
}

|" List of declarations (:rmlink:`3.11`).
@snaps
class DeclarativePart: AdaNode {
    @parse_field decls: ASTList[AdaNode]

    |" Returns the envs for all the use clauses declared in this declarative
    |" part.
    fun use_clauses_envs(): LexicalEnv = self.decls.children.filtermap(
        (u) => u.as[UseClause].used_envs(), (u) => u is UseClause
    ).env_group()

    |" Return the ``SPARK_Mode`` pragma node declared in this declarative
    |" part if any.
    fun spark_mode_pragma(): Entity[Pragma] =
        # `SPARK_Mode` pragma can only be at the begining of the declarative
        # region.
        self.decls.take_while((decl) => decl is Pragma).find(
            (decl) => decl.as[Pragma].id.name_is(s"SPARK_Mode")
        ).as[Pragma]

    |" Return whether this declarative part has SPARK mode set to On.
    fun spark_mode_aspect(): Aspect =
        # Look if a `SPARK_Mode` pragma has been specified for that part
        self.spark_mode_pragma().do(
            # Then, is it `On` or `Off`?
            (pragma) => pragma.as_aspect(),

            # Else, `SPARK_Mode` can also be specified by an aspect
            default_val=self.parent.as[BasicDecl].do(
                (bd) => bd.get_aspect(s"SPARK_Mode")
                # If not pragma or aspect sets `SPARK_Mode`, have a look at
                # the parent declarative scope.
                or? self.super(),
                default_val=self.super()
            )
        )
}

|" List of declarations in a private part.
class PrivatePart: DeclarativePart {
    |" A private part allows for a named env iff its parent package is a
    |" library item, in which case it will be ``.__privatepart`` appended to
    |" that package's top_level_env_name.
    fun env_names(): Array[Symbol] = node.parent.as[BasePackageDecl].do(
        (pkg) => pkg.top_level_env_name().do(
            (name) => [(name & ".__privatepart").to_symbol]
        )
    )

    fun immediate_declarative_region(): LexicalEnv =
        self.semantic_parent().immediate_declarative_region()

    |" Return whether this private part has SPARK mode set to On.
    fun spark_mode_aspect(): Aspect =
        # Look if a `SPARK_Mode` pragma has been specified for that part
        self.spark_mode_pragma().do(
            (pragma) => pragma.as_aspect(),
            # If not pragma sets `SPARK_Mode`, have a look at the corresponding
            # public part if any.
            default_val=self.parent.as[PackageDecl]?.public_part.spark_mode_aspect()
        )

    env_spec {
        add_to_env_kv(s"__privatepart", node)
        add_env(
            transitive_parent=true, names=node.env_names()
        )
    }
}

|" List of declarations in a public part.
class PublicPart: DeclarativePart {
}

|" ``elsif`` block, part of an ``if`` expression.
class ElsifExprPart: AdaNode {
    @parse_field cond_expr: Expr
    @parse_field then_expr: Expr
}

|" ``elsif`` part in an ``if`` statement block.
class ElsifStmtPart: AdaNode {
    @parse_field cond_expr: Expr
    @parse_field stmts: StmtList

    fun xref_entry_point(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.cond_expr.sub_equation() and node.cond_expr.expect_bool_derived_type()
}

|" Base class for expressions (:rmlink:`4.4`).
@abstract
@with_abstract_list
class Expr: AdaNode {
    logic_vars: Address

    @external()
    fun type_var(): LogicVar

    @external()
    fun expected_type_var(): LogicVar

    fun type_val(): Entity[AdaNode] = node.type_var().get_value()

    |" Return the declaration corresponding to the type of this expression
    |" after name resolution.
    @exported
    fun expression_type(): Entity[BaseTypeDecl] =
        node.logic_val(self, node.type_var()).value.as![BaseTypeDecl]

    |" Return the declaration corresponding to the expected type of this
    |" expression after name resolution.
    @exported
    fun expected_expression_type(): Entity[BaseTypeDecl] =
        node.logic_val(self, node.expected_type_var()).value.as![BaseTypeDecl]

    @with_dynvars(origin)
    fun matches_expected_type(): Equation =
        %predicate(BaseTypeDecl.matching_type, node.type_var(), error_location=node, node.expected_type_var())

    @with_dynvars(origin)
    fun matches_expected_assign_type(): Equation =
        %predicate(BaseTypeDecl.matching_assign_type, node.type_var(), error_location=node, node.expected_type_var())

    @with_dynvars(origin)
    fun matches_expected_formal_type(): Equation =
        %predicate(BaseTypeDecl.matching_formal_type, node.type_var(), error_location=node, node.expected_type_var())

    @with_dynvars(origin)
    fun matches_expected_membership_type(): Equation =
        %predicate(BaseTypeDecl.matching_membership_type, node.type_var(), node.expected_type_var())

    @with_dynvars(origin)
    fun matches_expected_prefix_type(): Equation =
        %predicate(BaseTypeDecl.matching_prefix_type, node.type_var(), node.expected_type_var())

    |" Construct an equation which asserts that the expected type of this
    |" expression is the standard boolean type or any type that derives from
    |" it.
    @with_dynvars(origin)
    fun expect_bool_derived_type(): Equation = (
        %eq(node.expected_type_var(), node.bool_type()) or %eq(node.expected_type_var(), node.type_var(), conv_prop=BaseTypeDecl.derefed_base_subtype)
    ) and %predicate(BaseTypeDecl.derives_from_std_bool_type, node.type_var(), error_location=node)

    |" Build the xref_equation for this expression in the context of an
    |" ``Annotate`` aspect argument, which requires it to either be of any of
    |" the standard String types, or to be a general non-ambiguous expression.
    |" Hence, we try here to resolve it using corresponding expected types.
    |" Note that we don't even check that the expected and actual types match
    |" in order to allow the same kind of flexibility that GNAT has.
    |" GNAT also allows direct references to subprograms (even though they are
    |" not valid expressions per-se), so we also fallback to resolving the
    |" first visible declaration of the given name.
    @with_dynvars(env, origin, entry_point)
    fun annotate_argument_equation(): Equation = (
        self.sub_equation() and %domain(node.expected_type_var(), [null[Entity[BaseTypeDecl]], node.std_string_type(), node.std_wide_string_type(), node.std_wide_wide_string_type()])
    ) or self.as[Name].do(
        (name) => name.xref_no_overloading(), default_val=%false
    )

    |" Returns whether this expression is dynamically tagged (See
    |" :rmlink:`3.9.2`).
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun is_dynamically_tagged(): Bool = # See ARM 3.9.2 for the rules
    {
        bind origin = node.origin_node();

        self.expression_type().is_classwide() or self.expression_type().accessed_type()?.is_classwide() or match self {
            case qual_expr: QualExpr => qual_expr.suffix.is_dynamically_tagged()

            # If expr is a call with a controlling result which has at
            # least one dynamically tagged controlling operand, then it's
            # dynamically tagged.
            case n: Name => n.is_direct_call() and n.called_subp_spec().as[BaseSubpSpec].do(
                (spec) => spec.has_controlling_result() and n.has_dynamic_controlling_operand(spec)
            )
            case cond_expr: CondExpr => cond_expr.dependent_exprs().all((e) => e.is_dynamically_tagged())
            case decl_expr: DeclExpr => decl_expr.expr.is_dynamically_tagged()
            case paren_expr: ParenExpr => paren_expr.expr.is_dynamically_tagged()
            case _ => false
        }
    }

    |" Return whether this call has at least one controlling operand which is
    |" dynamically tagged.
    @with_dynvars(imprecise_fallback=false)
    fun has_dynamic_controlling_operand(spec: Entity[BaseSubpSpec]): Bool =
        # Retrieve the candidate expressions on which the tag check could
        # be made, together with the expected type for them.
        # Then, check that there is a pair (``formal``, ``actual``)
        # where ``formal`` is a controlling formal parameter of the
        # primitive subprogram ``decl``, and ``actual`` is a dynamically
        # tagged expression used for this parameter.
        self.potential_actuals_for_dispatch(spec).any(
            (c) => spec.get_candidate_type_for_primitive(c.expected_type).do(
                (typ) => (
                    # We don't need accurate tagged-visibility information on
                    # `typ` at the callsite, we just want to abort early here
                    # to avoid having to handle nonsensical types in the
                    # `is_dynamically_tagged` property.
                    typ.full_view().is_tagged_type()
                ) and c.expr.is_dynamically_tagged()
            )
        )

    |" Return the closest parent expression that can be a dispatching call and
    |" which can control the tag value of this expression according to Ada
    |" semantics (see :rmlink:`3.9.2` 17/2).
    fun parent_candidate_dispatching_call(): Entity[Expr] = match self.parent {
        case ce: CallExpr => if self == ce.name then ce.parent_candidate_dispatching_call() else ce
        case dn: DottedName => if self == dn.suffix then dn.parent_candidate_dispatching_call() else dn
        case uo: UnOp => if self == uo.op then uo.parent_candidate_dispatching_call() else uo
        case bo: BinOp => if self == bo.op then bo.parent_candidate_dispatching_call() else bo
        case ce: CondExpr => if ce.dependent_exprs().contains(self) then ce.parent_candidate_dispatching_call() else null[Entity[Expr]]
        case pe: ParenExpr => pe.parent_candidate_dispatching_call()
        case qe: QualExpr => qe.parent_candidate_dispatching_call()
        case de: DeclExpr => de.parent_candidate_dispatching_call()
        case pa: ParamAssoc => pa.parent.parent.as[CallExpr]
        case _ => null[Entity[Expr]]
    }

    |" Return whether the tag value for this tag-indeterminate expression can
    |" be determined from the enclosing context, that is, whether this is the
    |" RHS of an assign statement which destination has a classwide type, or a
    |" controlling operand of an enclosing call which is itself dispatching.
    @with_dynvars(imprecise_fallback=false)
    fun has_dynamic_context(): Bool = self.parent.as[AssignStmt].do(
        (a) => (
            # If we're the RHS of an assignment, RM 3.9.2 (18.1/2) applies:
            # The controlling operand is the LHS of the assignment.
            # This only applies to the RHS of the assign statement
            a.expr == self
        ) and self.expected_expression_type().is_classwide(),

        # If we're an argument of an enclosing dispatching call, then
        # RM 3.9.2 (18/2) applies: The controlling tag value of this
        # call is the controlling tag value of the enclosing call.
        default_val=self.parent_candidate_dispatching_call()?.is_dispatching_call()
    )

    |" Common logic for the implementation of is_dispatching_call on the
    |" various node types. ``decl`` should be the declaration of the
    |" subprogram being called.
    @with_dynvars(imprecise_fallback=false)
    fun is_dispatching_call_impl(decl: Entity[BasicDecl]): Bool = {
        val spec = decl.canonical_part().subp_spec_or_null(follow_generic=true);

        (
            # A call to an abstract formal subprogram is necessarily
            # dispatching (see RM 12.6 8.5/2).
            decl is AbstractFormalSubpDecl
        ) or (
            # Alternatively, check if there is a controlling operand that is
            # dynamically tagged.
            self.has_dynamic_controlling_operand(spec)
        ) or (
            # Otherwise, it means that all controlling operands are statically
            # tagged or tag-indeterminate. In the latter case, we need to check
            # that the called primitive has a controlling result and that the
            # tag can be determined from context.
            spec.has_controlling_result() and self.has_dynamic_context()
        )
    }

    |" Return whether this expression is static according to the ARM
    |" definition of static. See :rmlink:`4.9`.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun is_static_expr(): Bool = {
        bind origin = node.origin_node();

        match self {
            case _: NumLiteral => true
            case _: StringLiteral => true
            case ar: AttributeRef => (
                ar.prefix.is_static_expr() and (
                    (
                        not ar.prefix.name_designated_type()?.root_type()?.is_formal() and ar.attribute.name_symbol() == s"Base"
                    ) or (
                        ar.prefix.name_designated_type()?.is_static_decl() and ar.attribute.name_symbol() in s"First" | s"Last" | s"Range" | s"Val" | s"Pos"
                    ) or (
                        ar.prefix.referenced_decl()?.is_array() and ar.attribute.name_symbol() in s"First" | s"Last" | s"Length" | s"Range"
                    )
                )
            ) and ar.args.do(
                (args) => args.all((arg) => arg.expr().is_static_expr()), default_val=true
            )

            # No matter the attribute, if it has arguments they must all be
            # static for the whole thing to be considered static.
            case ce: CallExpr => ce.name.is_static_expr() and ce.params().all((pa) => pa.expr().is_static_expr())
            case qe: QualExpr => qe.prefix.name_designated_type()?.is_static_decl() and qe.suffix.is_static_expr()
            case n: Name => n.referenced_decl()?.is_static_decl()
            case me: MembershipExpr => me.expr.is_static_expr() and me.membership_exprs.all((e) => e.is_static_expr())
            case bo: BinOp => (
                bo.left.is_static_expr() and bo.right.is_static_expr()
            ) and bo.op.referenced_decl().do(
                (decl) => decl.is_static_decl(), default_val=true
            )
            case co: ConcatOperand => co.operand.is_static_expr() and co.operator.referenced_decl().do(
                (decl) => decl.is_static_decl(), default_val=true
            )
            case co: ConcatOp => co.first_operand.is_static_expr() and co.other_operands.all((o) => o.is_static_expr())
            case uo: UnOp => uo.expr.is_static_expr() and uo.op.referenced_decl().do(
                (decl) => decl.is_static_decl(), default_val=true
            )
            case i: IfExpr => (
                (
                    i.cond_expr.is_static_expr() and i.then_expr.is_static_expr()
                ) and i.alternatives.all(
                    (a) => a.cond_expr.is_static_expr() and a.then_expr.is_static_expr()
                )
            ) and i.else_expr.is_static_expr()
            case pe: ParenExpr => pe.expr.is_static_expr()
            case _ => false
        }
    }

    |" Statically evaluates self, and returns the value of the evaluation as
    |" an integer.
    |"
    |" .. note::
    |"     In order for a call to this not to raise, the expression needs to
    |"     be a static expression, as specified in :rmlink:`4.9`. You
    |"     can verify whether an expression is static with the
    |"     ``is_static_expr`` property.
    |"
    |" .. ATTENTION::
    |"     This is an experimental feature, so even if it is exposed to allow
    |"     experiments, it is totally unsupported and the API and behavior are
    |"     very likely to change in the future.
    @exported
    fun eval_as_int(): BigInt =
        self.eval_as_int_in_env(null[Array[Substitution]])

    |" Statically evaluates self, and returns the value of the evaluation as
    |" an integer. The given environment is used to substitute references
    |" to declarations by actual values.
    |"
    |" .. note::
    |"     In order for a call to this not to raise, the expression needs to
    |"     be a static expression, as specified in :rmlink:`4.9`. You
    |"     can verify whether an expression is static with the
    |"     ``is_static_expr`` property.
    |"
    |" .. ATTENTION::
    |"     This is an experimental feature, so even if it is exposed to allow
    |"     experiments, it is totally unsupported and the API and behavior are
    |"     very likely to change in the future.
    @exported
    @external(uses_entity_info=true)
    fun eval_as_int_in_env(env: Array[Substitution]): BigInt

    |" Statically evaluates self, and returns the value of the evaluation as
    |" a string.
    |"
    |" .. note::
    |"     In order for a call to this not to raise, the expression needs to
    |"     be a static expression, as specified in :rmlink:`4.9`. You
    |"     can verify whether an expression is static with the
    |"     ``is_static_expr`` property.
    |"
    |" .. ATTENTION::
    |"     This is an experimental feature, so even if it is exposed to allow
    |"     experiments, it is totally unsupported and the API and behavior are
    |"     very likely to change in the future.
    @exported
    fun eval_as_string(): String =
        self.eval_as_string_in_env(null[Array[Substitution]])

    |" Statically evaluates self, and returns the value of the evaluation as
    |" a string. The given environment is used to substitute references
    |" to declarations by actual values.
    |"
    |" .. note::
    |"     In order for a call to this not to raise, the expression needs to
    |"     be a static expression, as specified in :rmlink:`4.9`. You
    |"     can verify whether an expression is static with the
    |"     ``is_static_expr`` property.
    |"
    |" .. ATTENTION::
    |"     This is an experimental feature, so even if it is exposed to allow
    |"     experiments, it is totally unsupported and the API and behavior are
    |"     very likely to change in the future.
    @exported
    @external(uses_entity_info=true)
    fun eval_as_string_in_env(env: Array[Substitution]): String

    |" Return the discrete range for this expression, if applicable.
    fun discrete_range(): DiscreteRange = match self {
        # TODO: This won't handle array objects
        case ar: AttributeRef => ar.prefix.discrete_range()
        case n: Name => n.name_designated_type().do((dt) => dt.discrete_range())
        case bo: BinOp => DiscreteRange(low_bound=bo.left, high_bound=bo.right)
        case _ => null[DiscreteRange]
    }

    @with_dynvars(env, no_visibility=false)
    fun env_elements(): Array[Entity[AdaNode]] =
        self.env_elements_impl().filter((e) => node.has_visibility(e))

    |" Return the list of AST nodes that can be a match for this expression
    |" before overloading analysis.
    @exported
    fun matching_nodes(): Array[Entity[AdaNode]] = {
        bind env = node.node_env();

        self.env_elements()
    }

    |" This is an internal helper for name resolution: return True if the
    |" type of this expression can be determined without context, i.e. that
    |" when constructing its xref equation, we never need to use its expected
    |" type to find its type. For example, an integer literal can always be
    |" typed to universal integer, so ``has_context_free_type`` returns True
    |" for it. However, the type of a binary operation in general cannot be
    |" determined solely by looking at its operands' types. This is used
    |" to optimize the xref equations we construct for some nodes. See
    |" ``BinOp.no_overload_equation`` for an example.
    fun has_context_free_type(): Bool = true

    |" Assuming self is a call to a subprogram, return an array of pairs
    |" (expected_type, expression) for each expression in the call that could
    |" be used for performing a dynamic dispatch for this call.
    |"
    |" .. note:: Implementations should not check that the call is done in the
    |"    RHS of an assign statement in order to take into account return type
    |"    dispatching, as this logic does not depend on the node kind and
    |"    is therefore factorized in ``is_dispatching_call_impl``.
    @with_dynvars(imprecise_fallback=false)
    fun potential_actuals_for_dispatch(@ignored spec: Entity[BaseSubpSpec]): Array[ExpectedTypeForExpr] = raise[Array[ExpectedTypeForExpr]] PropertyError("Property Expr.potential_actuals_for_dispatch not implemented")

    |" Returns True if this ``Name`` corresponds to a dispatching call,
    |" including:
    |"
    |" - Calls done through subprogram access types.
    |" - Calls to dispatching subprograms, in the object-oriented sense.
    |"
    |" .. note:: This is an experimental feature. There might be some
    |"     discrepancy with the GNAT concept of "dispatching call".
    |"
    |" .. note:: This should only be called on a ``Name`` and ``UnOp``
    |"     or a ``BinOp``.
    |"
    |" .. attention:: There is a known bug, where the ConcatOp node is not
    |"    supported, so calling is_dispatching_call on operators nested inside
    |"    of a concat operator will always return false. (Internal TN:
    |"    VC08-029)
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun is_dispatching_call(): Bool =
        raise[Bool] PreconditionFailure("Invalid node type: expected Name, UnOp or BinOp")

    |" Return the first decl that is lexically named like self in self's
    |" scope.
    @exported
    fun first_corresponding_decl(): Entity[BasicDecl] =
        null[Entity[BasicDecl]]

    |" Returns the lexical environment designated by this name, assuming
    |" that this name cannot be overloaded.
    |"
    |" If ``no_visibility``, discard visibility checks.
    @with_dynvars(env, origin, no_visibility=false)
    fun designated_env_no_overloading(): LexicalEnv =
        self.designated_env()

    |" Returns the lexical environment designated by this name.
    |"
    |" If this name involves overloading, this will return a combination of
    |" the various candidate lexical environments.
    |"
    |" If ``no_visibility``, discard visibility checks.
    @with_dynvars(env, origin, no_visibility=false)
    fun designated_env(): LexicalEnv = raise[LexicalEnv] PropertyError("Property Expr.designated_env not implemented")

    |" Returns the list of annotated elements in the lexical environment
    |" that can statically be a match for expr before overloading analysis.
    @with_dynvars(env)
    fun env_elements_impl(): Array[Entity[AdaNode]] = raise[Array[Entity[AdaNode]]] PropertyError("Property Expr.env_elements_impl not implemented")
}

|" Directly corresponds to the right-hand side of the Abstract_State aspect.
|" Only exists because the RHS of an AspectAssoc must be an expression: the
|" actual logic is in AbstractStateDecl.
class AbstractStateDeclExpr: Expr {
    @parse_field state_decl: AdaNode

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = %true
}

|" Allocator expression (``new ...``) (:rmlink:`4.8`).
class Allocator: Expr {
    @parse_field @nullable subpool: Name
    @parse_field type_or_expr: AdaNode

    fun has_context_free_type(): Bool = false

    |" Return the allocated type for this allocator.
    @exported
    fun get_allocated_type(): Entity[BaseTypeDecl] = {
        bind origin = node.origin_node();

        match self.type_or_expr {
            case t: Entity[SubtypeIndication] => t.designated_type()
            case q: Entity[QualExpr] => q.prefix.name_designated_type()
            case _ => null[Entity[BaseTypeDecl]]
        }
    }

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = (
        self.type_or_expr.sub_equation() and %eq(node.expected_type_var(), node.type_var())
    ) and %predicate(BaseTypeDecl.matching_allocator_type, node.type_var(), self.get_allocated_type())
}

|" Base class for aggregates (:rmlink:`4.3`).
@abstract
class BaseAggregate: Expr {
    @parse_field @nullable ancestor_expr: Expr
    @parse_field assocs: AssocList

    fun has_context_free_type(): Bool = false

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        # An aggregate (or more precisely, its associations) are resolved
        # separately from the rest of an expression. However,resolution of the
        # containing expression can leverage the knowledge that self is an
        # aggregate, by accepting only type that can be represented by an
        # aggregate (e.g. records and arrays).
        val type_constraint = if (
            # In the following cases, the aggregate is not a real expression:
            # it's merely re-used as a pure syntactic construct to aggregate
            # information.
            node.in_aspect(s"Global")
            or node.in_aspect(s"Refined_Global")
            or node.in_aspect(s"Depends")
            or node.in_aspect(s"Refined_Depends")
            or node.in_aspect(s"Test_Case")
            or node.in_aspect(s"Refined_State")
            or node.in_aspect(s"Aggregate")
            or node.in_aspect(s"Subprogram_Variant")
        ) or (
            # Careful: normal aggregates can appear inside a contract_cases
            # aspect's expression, so we must only special case the direct
            # aggregate of that aspect.
            node.is_contract_cases_base_aggregate()
        ) then %true else {
            bind origin = node.origin_node();

            %predicate(BaseTypeDecl.is_array_or_rec, node.expected_type_var()) and %eq(node.expected_type_var(), node.type_var())
        };

        (
            type_constraint and self.ancestor_expr.do(
                (ae) =>
                # We have an ancestor part, which can be either a subtype mark
                # designating a type as in `(Controlled with X => 2)`, or an
                # arbitrary expression as in `(Foo(1) with X => 2)`.
                if ae is Name and not ae.as[Name].name_designated_type().is_null then ae.as[Name].xref_type_equation()
                elif node is DeltaAggregate then ae.sub_equation()
                # If self is not a delta aggregate but has an ancestor part,
                # it means it is an extension aggregate. In that case, ARM
                # 4.3.2 - 4/2 specifies "If the ancestor_part is an expression,
                # it is expected to be of any tagged type", hence we also add
                # the following predicate.
                else ae.sub_equation() and %predicate(BaseTypeDecl.is_tagged_type_with_deref, ae.type_var(), error_location=ae.node), default_val=%true
            )
        ) and self.assocs.logic_all((assoc) => assoc.sub_equation())
    }

    |" Return whether this is the aggregate directly used as the RHS of the
    |" ``Contract_Cases`` aspect.
    fun is_contract_cases_base_aggregate(): Bool = node.parent.as[AspectAssoc].do(
        (aspect) => aspect.id.name_is(s"Contract_Cases")
    )

    |" Return the root parent aggregate if self is part of a multidimensional
    |" array aggregate (either the root or a sub-aggregate).
    @memoized
    @call_memoizable
    @with_dynvars(origin)
    fun multidim_root_aggregate(r: Int = 0): MultidimAggregateInfo =
        # Nested aggregates of a multidimensional array have no types, so we're
        # searching for the first aggregate with a type inside type_val.
        self.type_val().as[BaseTypeDecl].do(
            (tv) =>
            # If we have a multidimensional array type here, return all the
            # needed info (rank, root aggregate and type of the array).
            if tv.array_ndims() > 1 then MultidimAggregateInfo(agg=self, typ=tv, rank=r) else (
                # If we're here, we found a type, and it's not a multidim
                # array: Stop there.
                null[MultidimAggregateInfo]
            ),
            # If we're here, there is a parent aggregate and no type_val:
            # recurse up.
            default_val=self.parent.parent.parent.as[Aggregate]?.multidim_root_aggregate(r + 1)
        )

    |" Return the list of all discriminants that must be associated by this
    |" aggregate.
    |"
    |" .. attention::
    |"     This property is part of the name resolution algorithm for
    |"     AggregateAssocs and therefore is probably not what you're looking
    |"     for, as it makes several assumptions on the content of logic vars.
    |"     Find more details in ``AggregateAssoc.record_assoc_equation``.
    |"
    |" .. note::
    |"     This property must be memoized because all AggregateAssocs that are
    |"     children of this aggregate will call it during their name
    |"     resolution routine.
    @memoized
    @call_memoizable
    @with_dynvars(origin)
    fun all_discriminants(): Array[Entity[BaseFormalParamDecl]] = {
        val td = node.type_val().as[BaseTypeDecl];
        val stop_recurse_at = self.ancestor_expr_type(resolve_type=false);
        val record_decl = td.record_def().comps().type_decl();

        record_decl.discriminants_list(stop_recurse_at)
    }

    |" Return the list of all components that must be associated by this
    |" aggregate.
    |"
    |" .. attention::
    |"     This property is part of the name resolution algorithm for
    |"     AggregateAssocs. More details under ``all_discriminants``.
    @memoized
    @call_memoizable
    @with_dynvars(origin, env)
    fun all_components(): Array[Entity[BaseFormalParamDecl]] = {
        val td = node.type_val().as[BaseTypeDecl];
        val stop_recurse_at = self.ancestor_expr_type(resolve_type=false);
        val comp_list = td.record_def().comps();

        if self is DeltaAggregate then (
            # For delta aggregates, get all the components regardless of the
            # discriminant values.
            comp_list.abstract_formal_params_for_delta_assocs()
        ) else comp_list.abstract_formal_params_for_assocs(self.assocs, stop_recurse_at)
    }

    |" Return the list of all discriminants specified by this aggregate,
    |" together with the actual used for it.
    |"
    |" .. attention::
    |"     This property is part of the name resolution algorithm for
    |"     AggregateAssocs. More details under ``all_discriminants``.
    @memoized
    @with_dynvars(origin)
    fun matched_discriminants(): Array[ParamMatch] = node.match_formals(
        self.all_discriminants(), self.assocs, false
    )

    |" Return the list of all components specified by this aggregate,
    |" together with the actual used for it.
    |"
    |" .. attention::
    |"     This property is part of the name resolution algorithm for
    |"     AggregateAssocs. More details under ``all_discriminants``.
    @memoized
    @with_dynvars(origin, env)
    fun matched_components(): Array[ParamMatch] = node.match_formals(
        self.all_components(), self.assocs, false
    )

    |" Return the first discriminant or component that is not matched
    |" explicitly.
    |"
    |" .. attention::
    |"     This property is part of the name resolution algorithm for
    |"     AggregateAssocs. More details under ``all_discriminants``.
    @with_dynvars(origin, env)
    fun first_unmatched_formal(): Entity[DefiningName] = {
        # Try to find an unmatched discriminant first
        val unmatched_discr = node.unpack_formals(self.all_discriminants()).find(
            (f) => not self.matched_discriminants().any((m) => m.formal == f)
        );

        if not unmatched_discr.is_null then unmatched_discr else (
            # If there is no unmatched discriminant, this means all of them
            # are specified, so the shape of the record is known: we can now
            # try to find the unmatched formal.
            # WARNING: for the same reason stated in
            # AggregateAssoc.record_assoc_equation, this must be done in this
            # order.
            node.unpack_formals(self.all_components()).find(
                (f) => not self.matched_components().any((m) => m.formal == f)
            )
        )
    }

    |" Returns an array of pairs, associating formal parameters to actual
    |" expressions. See ``zip_with_params``.
    @exported
    fun aggregate_params(): Array[ParamActual] = self.assocs.zip_with_params()

    |" Return whether this aggregate is actually a subaggregate of a
    |" multidimensional array aggregate, as described in :rmlink:`4.3.3`.
    @exported
    fun is_subaggregate(): Bool = {
        # The `multidim_root_aggregate` property assumes that the top-level
        # aggregate's type_var has been set, so run nameres beforehand.
        val _ = self.resolve_names_from_closest_entry_point();

        {
            bind origin = node;

            self.multidim_root_aggregate().rank > 0
        }
    }

    |" The ancestor part of an aggregate can either be a subtype mark or an
    |" arbitrary expression. In the first case, this property returns the
    |" type designated by the subtype mark. In the other case, it returns the
    |" type of the expression, after running name resolution if
    |" ``resolve_type`` is True, and otherwise by looking into the ancestor
    |" part's already populated type variable.
    @call_memoizable
    fun ancestor_expr_type(resolve_type: Bool = true): Entity[BaseTypeDecl] = self.ancestor_expr.do(
        (ae) => ae.as[Name].do((n) => n.name_designated_type()) or? (
            if resolve_type then ae.expression_type() else ae.type_val().as[BaseTypeDecl]
        )
    )
}

|" Aggregate that is not a ``null record`` aggregate (:rmlink:`4.3`).
class Aggregate: BaseAggregate {
    |" Return the ``Add_Named`` subprogram parameter specified by ``index``.
    |" This aggregate must be a container aggregate aspect specification.
    fun add_named_param_at(index: Int): Entity[BaseTypeDecl] = {
        # `Add_Named`denotes exactly one procedure that has three parameters,
        # the first an in out parameter of the container type, the second an in
        # parameter of a nonlimited type (the key type of the container type),
        # and the third, an in parameter of a nonlimited type that is called
        # the element type of the container type (so index should be an Int
        # between 0 and 2).
        val add_named = self.assocs.find(
            (assoc) => assoc.as[AggregateAssoc].names()?[0].as[Name].name_is(s"Add_Named")
        );
        val add_named_params = add_named.do(
            (an) => an.expr().as[Name].referenced_decl().subp_spec_or_null().params()
        );

        add_named.do(
            (_) => add_named_params?[index].type_expression().designated_type_decl()
        )
    }

    |" Return the element type of that Aggregate. This aggregate must be a
    |" container aggregate aspect specification.
    fun element_type(): Entity[BaseTypeDecl] = {
        # Position container case: `Add_Unnamed` should be specified. It
        # denotes exactly one procedure that has two parameters, the first an
        # in out parameter of the container type, and the second an in
        # parameter of some nonlimited type, called the element type of the
        # container type.
        val add_unnamed = self.assocs.find(
            (assoc) => assoc.as[AggregateAssoc].names()?[0].as[Name].name_is(s"Add_Unnamed")
        );
        val unnamed_element_type = add_unnamed.do(
            (au) => au.expr().as[Name].referenced_decl().subp_spec_or_null().params()?[1].type_expression().designated_type_decl()
        );
        # Named container case: `Add_Named` should be specified
        val named_element_type = self.add_named_param_at(2);

        if add_unnamed.is_null then named_element_type else unnamed_element_type
    }

    |" Return the key type of that Aggregate. This aggregate must be a
    |" container aggregate aspect specification.
    fun key_type(): Entity[BaseTypeDecl] = {
        # Named container case: `Add_Named` should be specified
        val key_type = self.add_named_param_at(1);

        key_type
        # If add_named is not specified, key_type is the universal integer
        # type used for indexed aggregates.
        or? self.universal_int_type()
    }
}

|" Bracket array or container aggregate (Ada 2020, :rmlink:`4.3`).
class BracketAggregate: Aggregate {
}

|" Aggregate for delta aggregate (Ada 2022, :rmlink:`4.3`).
class DeltaAggregate: BaseAggregate {
}

|" Bracket delta aggregate (Ada 2020, :rmlink:`4.3`).
class BracketDeltaAggregate: DeltaAggregate {
}

|" Aggregate for ``null record`` (:rmlink:`4.3`).
class NullRecordAggregate: BaseAggregate {
}

|" Binary expression.
|"
|" This encompasses several ARM expressions, because it is used for every
|" binary expression in Ada, all documented in ::rmlink:`4.4`.
class BinOp: Expr {
    @parse_field left: Expr
    @parse_field op: Op
    @parse_field right: Expr

    fun has_context_free_type(): Bool = node.op is Op.AndThen | Op.OrElse

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        bind logic_context = LogicContext(
            ref_node=self.op, decl_node=null[Entity[AdaNode]]
        );

        (
            self.left.sub_equation() and self.right.sub_equation()
        ) and (
            if node.op is Op.DoubleDot then self.double_dot_equation()
            elif node.op is Op.AndThen | Op.OrElse then node.test_eq()
            else (
                self.overload_equation() or self.no_overload_equation()
            ) or self.universal_fixed_predefined_operators_equation()
        )
    }

    @with_dynvars(origin, env, logic_context)
    fun double_dot_equation(): Equation = (
        (
            %true or %eq(node.expected_type_var(), node.root_int_type()) or %eq(node.expected_type_var(), node.int_type())
        ) and (
            %predicate(AdaNode.is_not_null, node.expected_type_var()) and %eq(node.expected_type_var(), node.type_var()) and %eq(node.type_var(), node.left.expected_type_var()) and %eq(node.type_var(), node.right.expected_type_var()) and node.left.matches_expected_formal_type() and node.right.matches_expected_formal_type()
        )
    ) and node.use_expected_type_or(
        # In some cases the expected type is given explicitly, so we can
        # simply check that the type inferred for the operands matches.
        # This is generally the case for ranges in component representation
        # clauses or in subtype indications' constraints.
        # However if the expected is not given explicitly, we must infer
        # it here from one of the operands. This is generally the case
        # for ranges in for-loop specs.
        self.infer_from_either_operands(node.type_var())
    )

    @with_dynvars(origin)
    fun test_eq(): Equation =
        %eq(node.left.expected_type_var(), node.bool_type()) and %eq(node.right.expected_type_var(), node.bool_type()) and node.left.expect_bool_derived_type() and node.right.expect_bool_derived_type() and %eq(node.type_var(), node.left.type_var())

    @with_dynvars(origin, env, logic_context)
    fun arguments_eq(spec: Entity[BaseSubpSpec]): Equation = {
        val ps = spec.unpacked_formal_params();

        if ps.length() == 2 then (
            # The subprogram's first argument must match self's left
            # operand.
            (
                spec.call_argument_equation(ps?[0].formal_decl(), self.left) and (
                    # The subprogram's second argument must match self's right
                    # operand.
                    spec.call_argument_equation(ps?[1].formal_decl(), self.right)
                )
            ) and (
                # The subprogram's return type is the type of self
                %eq(node.type_var(), spec.return_type(), logic_ctx=logic_context)
            )
        ) else %false
    }

    @with_dynvars(origin, env, logic_context)
    fun entity_eq(subp: Entity[BasicDecl]): Equation = {
        val spec = subp.subp_spec_or_null();

        self.arguments_eq(spec) and (
            # The operator references the subprogram
            %eq(node.op.ref_var(), subp)
        ) and %eq(node.op.subp_spec_var(), spec)
    }

    @with_dynvars(origin, env)
    fun overload_equation(): Equation = self.op.subprograms().logic_any(
        (subp) => {
            bind logic_context = LogicContext(ref_node=self.op, decl_node=subp);

            self.entity_eq(subp)
        }
    )

    |" When no subprogram is found for this node's operator, try to resolve
    |" it as a universal_fixed predefined operator (:rmlink:`4.5.5` - 18).
    @with_dynvars(origin)
    fun universal_fixed_predefined_operators_equation(): Equation = if node.op is Op.Mult | Op.Div then (
        (
            (
                %eq(node.type_var(), node.universal_fixed_type()) and %eq(node.left.expected_type_var(), node.universal_fixed_type())
            ) and %eq(node.right.expected_type_var(), node.universal_fixed_type())
        ) and node.left.matches_expected_formal_type()
    ) and node.right.matches_expected_formal_type() else %false

    |" Construct the xref equation that first attempts to resolve this binary
    |" operation using the expected type given by the context only, and then
    |" by using the additional equation given as argument (typically this
    |" equation will try to infer the type from one of the operands).
    fun use_expected_type_or(eq: Equation): Equation =
        %predicate(AdaNode.is_not_null, node.expected_type_var()) or eq

    |" Construct the xref equation that must bind the given variable to the
    |" type of this binary operation's operands, assuming we are dealing with
    |" numeric types and arithmetic operators with the following profile:
    |" ``function "op" (X : T, Y : U) return T`` (we want to infer ``T``).
    @with_dynvars(origin, logic_context)
    fun infer_from_left_operand(dest_var: LogicVar): Equation =
        %predicate(BaseTypeDecl.is_not_universal_type, node.left.type_var()) and %eq(dest_var, node.left.type_var(), conv_prop=BaseTypeDecl.derefed_base_subtype, logic_ctx=logic_context)

    |" Construct the xref equation that must bind the given variable to the
    |" type of this binary operation's operands, assuming we are dealing with
    |" numeric types and arithmetic operators with the following profile:
    |" ``function "op" (X : U, Y : T) return T`` (we want to infer ``T``).
    @with_dynvars(origin, logic_context)
    fun infer_from_right_operand(dest_var: LogicVar): Equation =
        %predicate(BaseTypeDecl.is_not_universal_type, node.right.type_var()) and %eq(dest_var, node.right.type_var(), conv_prop=BaseTypeDecl.derefed_base_subtype, logic_ctx=logic_context)

    |" Construct the xref equation that must bind the given variable to the
    |" type of this binary operation's operands, assuming we are dealing with
    |" numeric types and arithmetic operators with the following profile:
    |" ``function "op" (X, Y : T) return T`` (we want to infer ``T``).
    @with_dynvars(origin, logic_context)
    fun infer_from_either_operands(dest_var: LogicVar): Equation = {
        val infer_left = self.infer_from_left_operand(dest_var);
        val infer_right = self.infer_from_right_operand(dest_var);

        infer_left or infer_right
    }

    @with_dynvars(imprecise_fallback=false)
    fun potential_actuals_for_dispatch(spec: Entity[BaseSubpSpec]): Array[ExpectedTypeForExpr] = {
        val params = spec.unpacked_formal_params();

        [ExpectedTypeForExpr(
            expected_type=params?[0].formal_decl().type_expression(), expr=self.left
        ), ExpectedTypeForExpr(
            expected_type=params?[1].formal_decl().type_expression(), expr=self.right
        )]
    }

    @with_dynvars(imprecise_fallback=false)
    fun is_dispatching_call(): Bool = self.op.is_dispatching_call()

    |" When no subprogram is found for this node's operator, use this property
    |" to construct the xref equation for this node.
    @with_dynvars(origin, logic_context)
    fun no_overload_equation(): Equation = (
        (
            # For multiplication operators, we must handle three shapes
            if node.op is Op.Mult | Op.Div then (
                # `function "op" (X, Y : T) return T`
                (
                    %eq(node.type_var(), node.left.expected_type_var()) and %eq(node.type_var(), node.right.expected_type_var())
                ) and node.use_expected_type_or(
                    self.infer_from_either_operands(node.type_var())
                )
            ) or (
                # `function "op" (X : Integer, Y : T) return T`
                (
                    %eq(node.left.expected_type_var(), node.int_type()) and %eq(node.right.expected_type_var(), node.type_var())
                ) and node.use_expected_type_or(
                    self.infer_from_right_operand(node.type_var())
                )
            ) or (
                # `function "op" (X : T, Y : Integer) return T`
                (
                    %eq(node.right.expected_type_var(), node.int_type()) and %eq(node.left.expected_type_var(), node.type_var())
                ) and node.use_expected_type_or(
                    self.infer_from_left_operand(node.type_var())
                )
            )
            # For power operators, we must only handle the shape
            # `function "op" (X : T, Y : Integer) return T`.
            elif node.op is Op.Pow then (
                %eq(node.right.expected_type_var(), node.int_type()) and %eq(node.left.expected_type_var(), node.type_var())
            ) and node.use_expected_type_or(
                self.infer_from_left_operand(node.type_var())
            )
            # For other operators, we only need to handle the shape
            # `function "op" (X, Y : T) return T`.
            else (
                %eq(node.type_var(), node.left.expected_type_var()) and %eq(node.type_var(), node.right.expected_type_var())
            ) and node.use_expected_type_or(
                self.infer_from_either_operands(node.type_var())
            )
        ) and (
            (
                # We have an expected type: we can directly infer the actual type
                # of the result, and of the operands using the equations above.
                # Note that there is a difference between not having an expected
                # type at all (as in a type conversion), and having an expected
                # type but not inferrable from the context (as in an operand of a
                # comparison operator `(A + B) = 2`. The latter simply means
                # that the expected type itself will be inferred from the operands
                # using one of `self.infer_from_*` properties.
                %predicate(AdaNode.is_not_null, node.expected_type_var()) and %eq(node.type_var(), node.expected_type_var(), conv_prop=BaseTypeDecl.derefed_base_subtype, logic_ctx=logic_context)
            ) or (
                # There is no expected type (e.g. we are in a type conversion).
                # In this case, the type of the result will be inferred from the
                # type of operands: we know that at least one of them has a
                # context-free type (otherwise this wouldn't be valid Ada code).
                %eq(node.expected_type_var(), null[Entity[BaseTypeDecl]])
            )
        )
    ) and (
        node.left.matches_expected_formal_type() and node.right.matches_expected_formal_type()
    )
}

|" Binary operation that compares two value, producing a boolean
|" (:rmlink:`4.4`).
class RelationOp: BinOp {
    fun has_context_free_type(): Bool = true

    @with_dynvars(origin, logic_context)
    fun no_overload_equation(): Equation = (
        (
            (
                %eq(node.type_var(), node.bool_type()) and %eq(node.left.expected_type_var(), node.right.expected_type_var())
            ) and self.infer_from_either_operands(node.left.expected_type_var())
        ) and node.left.matches_expected_formal_type()
    ) and node.right.matches_expected_formal_type()
}

|" Box expression (``<>``).
|"
|" This is not an expression per-se in Ada, but treating it as one helps us
|" keep coherent types in some cases, like aggregates expressions.
class BoxExpr: Expr {
    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        %eq(node.type_var(), node.expected_type_var())
}

|" Alternative in a ``case`` expression (``when ... => ...``).
class CaseExprAlternative: Expr {
    @parse_field choices: AlternativesList
    @parse_field expr: Expr
}

|" Concatenation expression.
|"
|" Since concatenation expression can be huge in practice, this node handles
|" them as a list of operands rather than a deep tree of binary operators, in
|" order to avoid crashes while parsing of running name resolution on such
|" huge expression.
|"
|" The purpose of this node is to replace the arbitrarily too deep tree of
|" binary operators (which can lead to a stack overflow), as for example with
|" ``"A & B & C & D & E"``:
|"
|" .. code::
|"
|"     BinOp(
|"       Binop(
|"         BinOp(
|"           BinOp(A, &, B), & , C), &, D), &, E)
|"
|" by a single operator, handling a list of operands that can be processed
|" without having to perform deep recursions:
|"
|" .. code::
|"
|"     ConcatOp(A,
|"       ConcatOperand(&, B),
|"       ConcatOperand(&, C),
|"       ConcatOperand(&, D),
|"       ConcatOperand(&, E))
class ConcatOp: Expr {
    @parse_field first_operand: Expr
    @parse_field other_operands: ASTList[ConcatOperand]

    |" Return the operands of this concatenation expression
    @exported
    fun operands(): Array[Entity[Expr]] =
        [self.first_operand] & self.other_operands.map((oo) => oo.operand)

    fun has_context_free_type(): Bool = false

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        val operand_count = node.other_operands.length();
        val last_operand = node.other_operands?[operand_count - 1];
        val concat_subprograms = self.other_operands?[0].operator.subprograms();

        # Perform expression resolution from left to right
        (
            (
                (
                    self.first_operand.sub_equation() and self.other_operands.logic_all(
                        (concat_operand) => concat_operand.operand.sub_equation()
                    )
                ) and (
                    # Build the equations for the concatenations themselves.
                    # WARNING: for now, the equations should appear in the order
                    # below, that is: the equation constraining the leftmost
                    # operand should be first, and equations for successive operands
                    # should follow in the corresponding order, with the rightmost
                    # operand having its equation last. This allows optimal resolution
                    # (performance-wise) until eng/libadalang/langkit#725 is addressed.
                    self.other_operands.ilogic_all(
                        (_, index) => {
                            val pos = operand_count - index - 1;

                            {
                                val left = if pos > 0 then self.other_operands?[pos - 1] else self.first_operand;
                                val concat_operand = self.other_operands?[pos];
                                val right = self.other_operands?[pos].operand;

                                (
                                    # TODO: this is implementation is actually not correct
                                    # w.r.t. visibility (eng/libadalang/libadalang#1138).
                                    # First, try to resolve this operator using built-in
                                    # operators only.
                                    self.operator_no_subprogram_equation(left, concat_operand, right)
                                ) or (
                                    # If that didn't work, try to resolve it by considering
                                    # visible user-defined overloads of "&". NOTE: for
                                    # performance reasons it is better to first try the
                                    # built-in operators first.
                                    concat_subprograms.logic_any(
                                        (subp) => {
                                            val spec = subp.subp_spec_or_null();

                                            {
                                                bind logic_context = LogicContext(
                                                    ref_node=concat_operand.operator, decl_node=subp
                                                );

                                                self.arguments_eq(spec, left, concat_operand, right) and %eq(concat_operand.operator.ref_var(), subp) and %eq(concat_operand.operator.subp_spec_var(), spec)
                                            }
                                        }
                                    )
                                )
                            }
                        }
                    )
                )
            ) and (
                # Just propagate last operand's type/expected_type to self
                %eq(node.type_var(), last_operand.type_var())
            )
        ) and %eq(node.expected_type_var(), last_operand.expected_type_var())
    }

    @with_dynvars(origin, env, logic_context)
    fun arguments_eq(spec: Entity[BaseSubpSpec], left: Entity[Expr], op: Entity[ConcatOperand], right: Entity[Expr]): Equation = {
        val ps = spec.unpacked_formal_params();

        if ps.length() == 2 then (
            # The subprogram's first argument must match left operand
            (
                spec.call_argument_equation(ps?[0].formal_decl(), left) and (
                    # The subprogram's second argument must match right operand
                    spec.call_argument_equation(ps?[1].formal_decl(), right)
                )
            ) and (
                # The subprogram's return type is the type of op
                %eq(op.type_var(), spec.return_type())
            )
        ) else %false
    }

    |" When no subprogram is found for this operator, use this property to
    |" construct the xref equation for this node.
    @with_dynvars(origin)
    fun operator_no_subprogram_equation(left: Entity[Expr], op: Entity[ConcatOperand], right: Entity[Expr]): Equation = {
        bind logic_context = LogicContext(
            ref_node=op.operator, decl_node=null[Entity[AdaNode]]
        );

        (
            %predicate(BaseTypeDecl.is_array_def_with_deref_or_null, op.expected_type_var()) and %predicate(BaseTypeDecl.is_array_def_with_deref, op.type_var())
        ) and (
            (
                # If the expected is not null, use it to infer self's type
                # and the type of the operands.
                %predicate(AdaNode.is_not_null, op.expected_type_var()) and self.array_concat_expected_type_equation(left, op, right)
            ) or (
                # If the expected type is null (e.g. we are in a type
                # conversion), we must infer self's type from the operands.
                # Since we assume Ada code, either the LHS or the RHS will have
                # a context-free type which we can use to infer the rest.
                # Make sure to propagate the base type of the inferred type so
                # that concatenation between compatible array subtypes works
                # as expected.
                %eq(op.expected_type_var(), null[BaseTypeDecl]) and (
                    (
                        # Type is determined by the LHS
                        (
                            %eq(op.type_var(), left.type_var(), conv_prop=BaseTypeDecl.derefed_base_subtype, logic_ctx=logic_context) and %eq(op.type_var(), left.expected_type_var())
                        ) and (
                            %eq(op.type_var(), right.expected_type_var()) or node.comp_bind(op.type_var(), right.expected_type_var())
                        )
                    ) or (
                        # Type is determined by the RHS
                        (
                            %eq(op.type_var(), right.type_var(), conv_prop=BaseTypeDecl.derefed_base_subtype, logic_ctx=logic_context) and %eq(op.type_var(), right.expected_type_var())
                        ) and (
                            %eq(op.type_var(), left.expected_type_var()) or node.comp_bind(op.type_var(), left.expected_type_var())
                        )
                    )
                )
            )
        )
    }

    |" Assume this operator represents a predefined array concatenation
    |" operator, construct the xref equation that must bind the operator's
    |" type to the type of the result of the concatenation, using the type of
    |" the operands or the type from the context.
    @with_dynvars(origin, logic_context)
    fun array_concat_expected_type_equation(left: Entity[Expr], op: Entity[ConcatOperand], right: Entity[Expr]): Equation = {
        val left_ctx_free = left.has_context_free_type();
        val right_ctx_free = right.has_context_free_type();

        # Generate different xref equations depending on which operands have a
        # context-free type. This helps reduce the final number of disjunction
        # compared to handling all the cases in a single equation.
        if left_ctx_free and right_ctx_free then (
            # Both operands have a context-free type, so use their types to
            # find the type of the result. This equation handles the
            # following operators:
            #  - "&" (Array_Of_T, T) -> Array_Of_T
            #  - "&" (T, Array_Of_T) -> Array_Of_T
            #  - "&" (Array_Of_T, Array_Of_T) -> Array_Of_T.
            (
                %propagate(op.type_var(), BaseTypeDecl.array_concat_result_type, logic_ctx=logic_context, left.type_var(), right.type_var()) and %propagate(left.expected_type_var(), BaseTypeDecl.expected_array_concat_operand_type, logic_ctx=logic_context, op.type_var(), left.type_var())
            ) and %propagate(right.expected_type_var(), BaseTypeDecl.expected_array_concat_operand_type, logic_ctx=logic_context, op.type_var(), right.type_var())
        ) or (
            # But we need another disjunction to handle the case:
            #  - "&" (T, T) -> Array_Of_T
            # For this case, we necessarily need to use the type of the
            # context even though both operands have a context-free type.
            (
                (
                    (
                        %eq(op.type_var(), op.expected_type_var(), conv_prop=BaseTypeDecl.derefed_base_subtype, logic_ctx=logic_context) and node.comp_bind(op.type_var(), left.expected_type_var())
                    ) and node.comp_bind(op.type_var(), right.expected_type_var())
                ) and left.matches_expected_formal_type()
            ) and right.matches_expected_formal_type()
        )
        elif left_ctx_free then (
            (
                (
                    # Left operand has a context free, use to infer the type of the
                    # result. This can handle the cases:
                    #  - "&" (Array_Of_T, *) -> Array_Of_T.
                    %eq(op.type_var(), left.type_var(), conv_prop=BaseTypeDecl.derefed_base_subtype, logic_ctx=logic_context) and %eq(op.type_var(), left.expected_type_var())
                ) or (
                    # We need another disjunction to handle the remaining cases:
                    #  - "&" (T, *) -> Array_Of_T
                    # For both these cases, we need to use the type of the context
                    # even though LHS has a context-free type.
                    (
                        %eq(op.type_var(), op.expected_type_var(), conv_prop=BaseTypeDecl.derefed_base_subtype, logic_ctx=logic_context) and node.comp_bind(op.type_var(), left.expected_type_var())
                    ) and left.matches_expected_formal_type()
                )
            ) and (
                # The type of op has been inferred from the LHS, use it to
                # determine the type of the RHS.
                %eq(op.type_var(), right.expected_type_var()) or node.comp_bind(op.type_var(), right.expected_type_var())
            )
        ) and right.matches_expected_formal_type()
        elif right_ctx_free then (
            (
                (
                    # Right operand has a context free, use to infer the type of
                    # the result. This can handle the cases:
                    #  - "&" (*, Array_Of_T) -> Array_Of_T.
                    %eq(op.type_var(), right.type_var(), conv_prop=BaseTypeDecl.derefed_base_subtype, logic_ctx=logic_context) and %eq(op.type_var(), right.expected_type_var())
                ) or (
                    # We need another disjunction to handle the remaining cases:
                    #  - "&" (*, T) -> Array_Of_T
                    # For both these cases, we need to use the type of the context
                    # even though RHS has a context-free type.
                    (
                        %eq(op.type_var(), op.expected_type_var(), conv_prop=BaseTypeDecl.derefed_base_subtype, logic_ctx=logic_context) and node.comp_bind(op.type_var(), right.expected_type_var())
                    ) and right.matches_expected_formal_type()
                )
            ) and (
                # The type of op has been inferred from the RHS, use it to
                # determine the type of the LHS.
                %eq(op.type_var(), left.expected_type_var()) or node.comp_bind(op.type_var(), left.expected_type_var())
            )
        ) and left.matches_expected_formal_type()
        # None of the operands have a context-free type, so we necessarily
        # have an expected type (otherwise it wouldn't be valid Ada code).
        # Use it to determine the type of the operands.
        else (
            (
                (
                    %eq(op.type_var(), op.expected_type_var(), conv_prop=BaseTypeDecl.derefed_base_subtype, logic_ctx=logic_context) and (
                        %eq(op.type_var(), left.expected_type_var()) or node.comp_bind(op.type_var(), left.expected_type_var())
                    )
                ) and (
                    %eq(op.type_var(), right.expected_type_var()) or node.comp_bind(op.type_var(), right.expected_type_var())
                )
            ) and left.matches_expected_formal_type()
        ) and right.matches_expected_formal_type()
    }
}

|" A concatenation operator and its RHS operand.
|"
|" This node is used to represent the tuple ("&", operand) used by the
|" ``ConcatOp`` node to store its ``other_operands`` list.
class ConcatOperand: Expr {
    @parse_field operator: Op.Concat
    @parse_field operand: Expr

    fun has_context_free_type(): Bool = false
}

|" Base class for a conditional expressions (:rmlink:`4.5.7`).
@abstract
class CondExpr: Expr {
    |" Return the dependent expressions for this conditional expression.
    @exported
    @abstract
    fun dependent_exprs(): Array[Entity[Expr]]
}

|" ``case`` expression (:rmlink:`4.5.7`).
class CaseExpr: CondExpr {
    @parse_field expr: Expr
    @parse_field cases: ASTList[CaseExprAlternative]

    fun has_context_free_type(): Bool = false

    fun dependent_exprs(): Array[Entity[Expr]] = self.cases.map((c) => c.expr)

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        # We solve self.expr separately because it is not dependent on the rest
        # of the semres.
        val _ = self.expr.resolve_names_internal_with_eq(
            %predicate(BaseTypeDecl.is_discrete_type, node.expr.type_var())
        );

        self.cases.logic_all(
            (alt) => (
                (
                    (
                        (
                            alt.choices.logic_all(
                                (c) => match c {
                                    # Expression case
                                    case e: Expr => if e is Name and not e.as[Name].name_designated_type().is_null then e.as[Name].xref_type_equation() else (
                                        %eq(e.expected_type_var(), node.expr.type_val()) and e.sub_equation()
                                    ) and e.matches_expected_type()

                                    # SubtypeIndication case (``when Color range Red .. Blue``)
                                    case t: SubtypeIndication => t.xref_equation()
                                    case _: OthersDesignator => %true
                                    case _ => raise[Equation] PropertyError("Should not happen")
                                }
                            ) and (
                                # Equations for the dependent expressions
                                %eq(node.type_var(), alt.expr.expected_type_var())
                            )
                        ) and %eq(alt.expr.expected_type_var(), node.expected_type_var(), conv_prop=BaseTypeDecl.derefed_base_subtype)
                    ) and alt.expr.sub_equation()
                ) and alt.expr.matches_expected_type()
            ) and (
                if alt.expr.has_context_free_type() then (
                    (
                        %predicate(BaseTypeDecl.is_not_universal_type, alt.expr.type_var()) and %eq(alt.expr.expected_type_var(), alt.expr.type_var(), conv_prop=BaseTypeDecl.base_subtype)
                    ) and %eq(alt.expr.expected_type_var(), node.expected_type_var())
                ) or %true else %true
            )
        )
    }
}

|" ``if`` expression (:rmlink`4.5.7`).
class IfExpr: CondExpr {
    @parse_field cond_expr: Expr
    @parse_field then_expr: Expr
    @parse_field alternatives: ASTList[ElsifExprPart]
    @parse_field @nullable else_expr: Expr

    fun has_context_free_type(): Bool = false

    fun dependent_exprs(): Array[Entity[Expr]] =
        [self.then_expr] & self.alternatives.map((a) => a.then_expr) & self.else_expr.do((v1) => [v1])

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = (
        # Construct sub equations for common sub exprs
        (
            (
                (
                    self.cond_expr.sub_equation() and self.cond_expr.expect_bool_derived_type()
                ) and (
                    # Construct the equation for the then branch
                    self.then_expr.sub_equation()
                )
            ) and self.alternatives.logic_all(
                (elsif) => (
                    # Build the sub equations for cond and then exprs
                    elsif.cond_expr.sub_equation() and elsif.cond_expr.expect_bool_derived_type()
                ) and elsif.then_expr.sub_equation()
            )
        ) and (
            if not node.else_expr.is_null then (
                # If there is an else, then construct sub equation
                self.else_expr.sub_equation()
            ) else (
                # If no else, then the then_expression has type bool
                self.then_expr.expect_bool_derived_type()
            )
        )
    ) and (
        (
            %predicate(AdaNode.is_not_null, node.expected_type_var()) and self.expected_type_equation()
        ) or (
            %eq(node.expected_type_var(), null[BaseTypeDecl]) and self.no_expected_type_equation()
        )
    )

    |" Return the equation to use in the case where the expected type for this
    |" if-expression is known. In that case, we can use it to infer the
    |" branches' types.
    @with_dynvars(env, origin, entry_point)
    fun expected_type_equation(): Equation = (
        (
            %eq(node.type_var(), node.then_expr.expected_type_var()) and (
                if not node.else_expr.is_null then (
                    (
                        (
                            %eq(node.type_var(), node.else_expr.expected_type_var()) and %eq(node.else_expr.expected_type_var(), node.expected_type_var(), conv_prop=BaseTypeDecl.derefed_base_subtype)
                        ) and %eq(node.then_expr.expected_type_var(), node.expected_type_var(), conv_prop=BaseTypeDecl.derefed_base_subtype)
                    ) and self.else_expr.matches_expected_formal_type()
                ) and self.then_expr.matches_expected_formal_type() else %true
            )
        ) and self.alternatives.logic_all(
            (elsif) => (
                %eq(node.type_var(), elsif.then_expr.expected_type_var()) and %eq(elsif.then_expr.expected_type_var(), node.expected_type_var(), conv_prop=BaseTypeDecl.derefed_base_subtype)
            ) and elsif.then_expr.matches_expected_formal_type()
        )
    ) and self.dependent_exprs().filter((e) => e.has_context_free_type()).logic_all(
        (e) => (
            %predicate(BaseTypeDecl.is_not_universal_type, e.type_var()) and %eq(e.expected_type_var(), e.type_var(), conv_prop=BaseTypeDecl.base_subtype)
        ) or %true
    )

    |" Return the equation to use when the expected type is not known, for
    |" example if we are inside a type conversion. In that case, we'll infer
    |" the type of the if expression by taking the common base subtype of the
    |" context-free types of all the sub-branches.
    @with_dynvars(env, origin, entry_point)
    fun no_expected_type_equation(): Equation =
        self.dependent_exprs().filter((e) => e.has_context_free_type()).logic_all(
            (e) => %predicate(BaseTypeDecl.is_universal_type, e.type_var()) or (
                %predicate(AdaNode.is_not_null, e.type_var()) and %eq(node.type_var(), e.type_var(), conv_prop=BaseTypeDecl.base_subtype)
            )
        )
}

|" List of associations for the ``Contract_Case`` aspect.
|"
|" Contract cases is a non standard Ada extension that's mainly useful in
|" SPARK. See `the SPARK RM <https://docs.adacore.com/spark2014-docs/>`_ for
|" more details.
class ContractCases: Expr {
    @parse_field contract_cases: ASTList[ContractCaseAssoc]
}

|" Declare expression (Ada 2022, :rmlink:`4.5.9`).
class DeclExpr: Expr {
    @parse_field decls: ASTList[AdaNode]
    @parse_field expr: Expr

    fun has_context_free_type(): Bool = node.expr.has_context_free_type()

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        bind env = self.children_env();

        self.expr.sub_equation()
    } and %eq(node.expr.expected_type_var(), node.expected_type_var()) and %eq(node.expr.type_var(), node.type_var())

    env_spec {
        add_env()
    }
}

|" Interpolated string expression.
|"
|" See :gnat_rm:`string-interpolation` for more details.
class FormatStringLiteral: Expr {
    @parse_field opening_chunk: FormatStringTokStart
    @parse_field mid_exprs: ASTList[FormatStringChunk]

    # This field is null when no expressions to expand are given in the
    # interpolated string, for example with `f"a dummy interpolated string"`.
    @parse_field @nullable trailing_expr: FormatStringChunk

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = (
         %predicate(
             BaseTypeDecl.allows_string_literal,
             node.expected_type_var(),
             error_location=node
         ) and %eq(node.expected_type_var(), node.type_var())
         and self.trailing_expr.do(
            (te) => te.sub_equation(),
            default_val=%true
         )
    ) and self.mid_exprs.logic_all((m) => m.expr.sub_equation())
}

|" Represent a membership test (in/not in operators) (:rmlink:`4.4`).
|"
|" Note that we don't consider them as binary operators since multiple
|" expressions on the right hand side are allowed.
class MembershipExpr: Expr {
    @parse_field expr: Expr
    @parse_field op: Op
    @parse_field membership_exprs: ExprAlternativesList

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = (
        %eq(node.type_var(), node.bool_type()) and self.expr.sub_equation()
    ) and self.membership_exprs.logic_all(
        (m) => {
            val typ = m.as[Name]?.name_designated_type();

            if not typ.is_null then (
                # Tagged type check or subtype membership check
                m.as[Name].xref_type_equation() and (
                    # If testing a specific tagged type membership, the
                    # expected type of the tested expression is the type at
                    # the root of the tagged type hierarchy.
                    #
                    # TODO: This is currently not possible to express
                    # because of an unrelated bug (see V408-038), but we
                    # can at least constrain the resulting type to be
                    # tagged after implicit dereference.
                    if typ.is_tagged_type() then %eq(node.expr.expected_type_var(), null[Entity[BaseTypeDecl]]) and %predicate(BaseTypeDecl.is_tagged_type_with_deref, node.expr.type_var(), error_location=node) else (
                        # This is a simple subtype membership test, so the
                        # expected type of the tested expression is the
                        # subtype's base type.
                        %eq(node.expr.expected_type_var(), typ.base_subtype()) and node.expr.matches_expected_membership_type()
                    )
                )
            ) else (
                # Regular membership check
                %eq(m.expected_type_var(), node.expr.type_var()) and m.sub_equation() and m.matches_expected_type()
            )
        }
    )
}

|" Base class for names (:rmlink:`4.1`).
@abstract
class Name: Expr {
    |" If this name is part of a defining name, return the enclosing defining
    |" name node.
    @exported
    fun enclosing_defining_name(): Entity[DefiningName] =
        self.parents().find((p) => p is DefiningName).as[DefiningName]

    |" Return True if this name is part of a defining name.
    @exported
    fun is_defining(): Bool = (
        # Obvious case
        node is DefiningName
    ) or (
        # The whole Identifier/DottedName contained in the defining name
        # is always considered defining.
        node.parent is DefiningName
    ) or (
        # And in case of a dotted name, the suffix of the outermost dotted
        # name is also considered defining.
        node.parent.parent is DefiningName and node.parent.as[DottedName]?.suffix == node
    )

    |" Helper. Check that this name matches ``sym``.
    @exported
    fun name_is(sym: Symbol): Bool = node.name_symbol().do((ns) => ns == sym)

    |" Return True iff this name represents a call to a subprogram which is
    |" referred by its defining name. (i.e. not through a subprogram access).
    @exported
    fun is_direct_call(): Bool =
        self.is_call() and not self.called_subp_spec().parent is AccessToSubpDef

    |" Return True iff this name represents a call to subprogram through
    |" an access type.
    @exported
    fun is_access_call(): Bool =
        self.is_call() and self.called_subp_spec().parent is AccessToSubpDef

    |" Returns True if this Name corresponds to a call.
    @exported
    fun is_call(): Bool =
        not self.is_defining() and not self.called_formal_subp_spec().is_null

    |" Returns True if this Name corresponds to a dot notation call.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun is_dot_call(): Bool =
        not self.is_defining() and self.referenced_decl().info.md.dottable_subp

    |" Failsafe version of ``referenced_defining_name``. Returns a
    |" ``RefdDef``, which can be precise, imprecise, or error.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun failsafe_referenced_def_name(): RefdDef = {
        val ref_decl = self.failsafe_referenced_decl();
        val def_name = ref_decl.decl.do(
            (ref_decl) => self.name_symbol().do(
                (rel_name) => ref_decl.defining_names().find((dn) => dn.name_is(rel_name))
            ) or? ref_decl.defining_name(), default_val=null[Entity[DefiningName]]
        );

        RefdDef(def_name=def_name, kind=ref_decl.kind)
    }

    |" Like ``referenced_decl``, but will return the defining identifier for
    |" the decl, rather than the basic declaration node itself.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun referenced_defining_name(): Entity[DefiningName] = {
        val ref_decl = self.referenced_decl();

        ref_decl.do(
            (ref_decl) => self.name_symbol().do(
                (rel_name) => ref_decl.defining_names().find((dn) => dn.name_is(rel_name))
            ) or? ref_decl.defining_name(), default_val=null[Entity[DefiningName]]
        )
    }

    |" Implementation helper for DefiningName.gnat_xref. TODO: Get rid of that
    |" by inlining in DefiningName.gnat_xref.
    @with_dynvars(imprecise_fallback=false)
    fun gnat_xref_decl(): Entity[DefiningName] = {
        val dn = self.is_defining().do((_) => self.enclosing_defining_name());
        val bd = dn.do((dn) => dn.basic_decl());

        if bd.do((bd) => bd is ParamSpec) then bd.as[ParamSpec].decl_param(dn)
        elif bd.do((bd) => bd is Body) then bd.as[Body].decl_part()?.defining_name()
        elif bd.do(
            (bd) => bd is BaseTypeDecl and bd.as[BaseTypeDecl].is_in_private_part()
        ) then bd.as[BaseTypeDecl].previous_part(true)?.defining_name()
        elif bd.do((bd) => bd is ObjectDecl) then (
            # TODO: Implement jumping to full object decl view for constant
            # object decls with no value.
            null[Entity[DefiningName]]
        )
        elif bd.do((bd) => bd is NumberDecl) then (
            # Number decls cannot have a next part, always return None
            null[Entity[DefiningName]]
        )
        elif bd.do((bd) => bd is BasicDecl) then dn
        else self.referenced_defining_name()
    }

    |" Internal property like all_env_elements, but accepting an additional
    |" ``categories`` parameter for internal uses.
    fun all_env_elements_internal(seq: Bool = true, seq_from: AdaNode = null[AdaNode], categories: RefCategories = RefCategories(_=true)): Array[Entity[AdaNode]] = {
        bind origin = node.origin_node();
        bind env = self.node_env();

        self.all_env_els_impl(
            seq=seq, seq_from=seq_from, categories=categories
        )
    }

    |" Return all elements in self's scope that are lexically named like self.
    @exported
    fun all_env_elements(seq: Bool = true, seq_from: AdaNode = null[AdaNode]): Array[Entity[AdaNode]] =
        self.all_env_elements_internal(seq, seq_from)

    fun first_corresponding_decl(): Entity[BasicDecl] =
        if node.parent is DottedName and node.is_suffix() then self.parent.as[DottedName].first_corresponding_decl() else self.all_env_elements_internal()?[0].as[BasicDecl]

    |" Constructs the xref equations for all the argument lists of CallExprs
    |" appearing between ``self`` and ``root``. This is done in a single
    |" distinct pass instead of directly inside the ``parent_name_equation``
    |" & co. properties as we were accidentally duplicating the construction
    |" of xref equations for some arguments lists and fixing this inside these
    |" properties proved to be difficult.
    @with_dynvars(env, origin, entry_point)
    fun all_args_xref_equation(root: Name): Equation = self.as[CallExpr].do(
        (ce) => ce.params()?.logic_all((pa) => pa.expr().sub_equation()), default_val=%true
    ) and self.parent_name(root).do(
        (name) => name.all_args_xref_equation(root), default_val=%true
    )

    |" Return an equation that always emits a diagnostic indicating that the
    |" entity designated by this name is missing.
    fun undefined_reference_equation(): Equation =
        %eq(node.ref_var(), null[Entity[AdaNode]]) and %predicate(AdaNode.missing_entity_error, node.ref_var(), error_location=node)

    @with_dynvars(env, origin, entry_point)
    fun bottom_up_name_equation(): Equation = match node.innermost_name().as_entity {
        case ce: CallExpr => ce.general_xref_equation(node)
        case ed: ExplicitDeref => ed.general_xref_equation(node)
        case qe: QualExpr => qe.general_xref_equation(node)
        case _ => %false
    }

    |" Helper property. Return the innermost name following the name chain.
    |" For example, given::
    |"
    |"     A (B) (C) (D)
    |"     ^-----------^ self
    |"     ^-------^     self.name
    |"     ^---^         self.name.name
    |"
    |" ``self.innermost_name`` will return the node corresponding to
    |" ``self.name.name``.
    fun innermost_name(): Name = {
        val name = match node {
            case ce: CallExpr => ce.name
            case ed: ExplicitDeref => ed.prefix
            case _ => null[Name]
        };

        if name is CallExpr | ExplicitDeref then name.innermost_name()
        elif name is QualExpr then name
        else node
    }

    |" Returns the leftmost name following the name chain.
    |" For example, given::
    |"
    |"     A (B) (C) (D)  -- Case 1: CallExpr
    |"     (A) (B)        -- Case 2: ArraySubcomponentChoiceName
    |"     A.B.C (D).E    -- Case 3: DottedName
    |"     A              -- Case 4: Identifier
    |"     A'First        -- Case 5: AttributeRef
    |"
    |" ``self.leftmost_name`` will return:
    |"
    |"   - A for Case 1,
    |"   - null for Case 2,
    |"   - A for Case 3,
    |"   - A for Case 4,
    |"   - A for Case 5.
    |"
    |" This property has been introduced to resolve deep delta aggregates so it
    |" may not be useful in other context as is. Do not make it exported.
    fun leftmost_name(): Name = match node {
        case ce: CallExpr => ce.name.leftmost_name()
        case ascn: ArraySubcomponentChoiceName =>
            ascn.name?.leftmost_name()
        case dn: DottedName => dn.prefix.leftmost_name()
        case ar: AttributeRef => ar.prefix.leftmost_name()
        case _ => node
    }

    |" Construct the xref equation for the chain of parent nested names.
    @with_dynvars(env, origin, entry_point)
    fun parent_name_equation(typ: Entity[BaseTypeDecl], root: Name): Equation = {
        val as_subp_access = typ?.access_def().as[AccessToSubpDef];
        val is_paramless = as_subp_access?.subp_spec.paramless(dottable_subp=false, can_be=false);
        val can_be_paramless = as_subp_access?.subp_spec.paramless(dottable_subp=false, can_be=true);
        val comp_type = # TODO: Try to perform this test directly in comp_type. We can't do
        # it at the moment since iterable_comp_type can call comp_type,
        # leading to an infinite recursion.
        if typ?.is_iterable_type() then typ?.iterable_comp_type() else typ?.comp_type(is_subscript=not node is ExplicitDeref);

        if typ.is_null then %false else match node {
            case ce: CallExpr => ce.as_entity.subscriptable_type_equation(typ)
            case ed: ExplicitDeref => ed.as_entity.eq_for_type(typ) and (
                # If ``typ`` is an access to subprogram, it means self (an
                # ExplicitDeref) is actually a call to that subprogram. So,
                # bind its subp_spec_var to the subprogram spec of the access.
                %eq(node.subp_spec_var(), as_subp_access?.subp_spec)
            )
            case _ => %eq(node.type_var(), null[Entity[AdaNode]].node)
        } and self.parent_name(root).do(
            (pn) => if node is ExplicitDeref and not as_subp_access.is_null then (
                # If self is an explicit deref of a subprogram access type,
                # we need to handle several cases:
                # The subprogram doesn't take parameters, in which case
                # the explicit dereference necessarily means accessing
                # the component type of the access type (it represents
                # the call).
                if is_paramless then pn.parent_name_equation(comp_type, root)
                # The subprogram can be called without parameters, in
                # which case we don't know for sure whether the
                # explicit dereference accesses the component type or
                # if it is the parent CallExpr that will.
                elif can_be_paramless then pn.parent_name_equation(comp_type, root) or pn.parent_name_equation(typ, root)
                # The subprogram must be called with parameters, in
                # which case the parent CallExpr will expect the non-
                # dereferenced type.
                else pn.parent_name_equation(typ, root)
            )
            # If self is an array slice, we recurse with the same type
            elif self.as[CallExpr]?.check_array_slice(typ) then pn.parent_name_equation(typ, root)
            # Otherwise the name necessarily accesses the
            # component type of typ.
            else pn.parent_name_equation(comp_type, root), default_val=%true
        )
    }

    @with_dynvars(env, origin, entry_point)
    fun subtype_indication_equation(): Equation = self.xref_type_equation()

    |" Return True if this name can refer to a primitive subprogram.
    |" This is used in env lookups to avoid visiting referenced primitive envs
    |" when it is not relevant.
    |"
    |" .. note:: This is not an optimisation, it actually prevents potential
    |"     infinite recursions during lookups.
    fun can_designate_primitive(): Bool = match node.parent {
        case n: Name => n.can_designate_primitive()
        case r: RenamingClause => not r.parent is PackageRenamingDecl
        case _ => true
    }

    |" Will return the parent name until the stop point.
    fun parent_name(stop_at: Name): Entity[Name] =
        if stop_at.is_null or node == stop_at then null[Entity[Name]] else self.parent.as[Name]

    |" If this name qualifies the prefix in a call expression, this returns
    |" the corresponding CallExpr node. Return null otherwise. For example::
    |"
    |"     C (12, 15);
    |"     ^ parent_callexpr = <CallExpr>
    |"
    |"     A.B.C (12, 15);
    |"         ^ parent_callexpr = <CallExpr>
    |"
    |"     A.B.C (12, 15);
    |"       ^ parent_callexpr = null
    |"
    |"     C (12, 15);
    |"        ^ parent_callexpr = null
    fun parent_callexpr(): Entity[CallExpr] = self.parents().take_while(
        (p) => p is CallExpr or (
            p is DottedName | BaseId and match p.parent {
                case pfx: DottedName => pfx.suffix == p
                case ce: CallExpr => ce.name == p
                case _ => false
            }
        )
    ).find((p) => p is CallExpr).as[CallExpr]

    |" Predicate that returns True if self is a range attribute ref.
    fun is_range_attribute(): Bool = node.as[AttributeRef].do(
        (attr_ref) => attr_ref.as_bare_entity.attribute.name_is(s"Range")
    )

    |" Return the subprogram specification of the subprogram or subprogram
    |" access that is being called by this exact Name, if relevant. Note that
    |" when inside an instantiated generic, this will return the spec of the
    |" actual subprogram.
    @exported
    fun called_subp_spec(): Entity[BaseFormalParamHolder] =
        self.called_formal_subp_spec()?.corresponding_actual()

    |" Return the declaration this node references after name resolution.
    |" If imprecise_fallback is True, errors raised during resolution of the
    |" xref equation are caught and a fallback mechanism is triggered, which
    |" tries to find the referenced declaration in an ad-hoc way.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun referenced_decl(): Entity[BasicDecl] =
        self.referenced_decl_internal().decl

    |" Failsafe version of ``referenced_decl``. Returns a ``RefdDecl``, which
    |" can be precise, imprecise, or error.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun failsafe_referenced_decl(): RefdDecl =
        try
        self.referenced_decl_internal()
         else RefdDecl(kind=RefResultKind.error)

    |" Wrapper to get the referenced declaration inside ``self.ref_var``.
    |"
    |" This wrapper will put back the generic context on generic bodies. When
    |" you are inside an instantiation and you lookup the generic by name,
    |" such as in this example:
    |"
    |" .. code-block:: ada
    |"
    |"     generic procedure P2_G;
    |"
    |"     procedure P2_G is
    |"     begin
    |"         P2_G; <- Reference to the generic body
    |"     end;
    |"
    |"     procedure P2 is new P2_G; <- Through this instantiation
    |"
    |" It needs to return the instantiated generic, but by default this will
    |" not work.
    |"
    |" TODO: This is kind of a special case, and we need to investigate
    |" whether a rework of the rebindings mechanism can simplify this or not.
    fun get_referenced_decl(): LogicValResult = {
        val val_result = node.logic_val(self, node.ref_var());
        val entity = val_result.value.as![BasicDecl];
        val generic_context_node = self.info.rebindings?.old_env.env_node;
        # Put back the generic context on entity if applicable as per the
        # example in the docstring.
        val entity_with_generic_context = if not generic_context_node.is_null and (
            (
                # The referenced node is the generic declaration inside of
                # which we are.
                generic_context_node == entity.node
            ) or (
                # The referenced node is the generic body inside of which we
                # are.
                generic_context_node == entity.as[Body]?.decl_part()?.node
            )
        ) then (
            # Add back the rebindings if the conditions are satisfied
            entity.unshed_rebindings_helper(self.info.rebindings)
        ) else entity;

        val_result.success.do(
            (s) => LogicValResult(
                success=s, value=entity_with_generic_context
            )
        )
    }

    |" Return the declaration this node references. Try not to run name res if
    |" already resolved.
    @with_dynvars(imprecise_fallback=false)
    fun referenced_decl_internal(): RefdDecl =
        # First, check whether the name is defining, in which case it
        # cannot be a reference.
        if self.is_defining() then null[RefdDecl] else (
            if imprecise_fallback then # The imprecise_fallback path cannot raise
            {
                val v = try
                self.get_referenced_decl() else null[LogicValResult];

                if v.success then (
                    # If we resolved correctly using full nameres, return a
                    # precise result.
                    RefdDecl(
                        decl=v.value.as[BasicDecl], kind=RefResultKind.precise
                    )
                ) else (
                    # Else, just take the first corresponding declaration,
                    # return as an imprecise result.
                    self?.first_corresponding_decl().do(
                        (fcd) => RefdDecl(decl=fcd, kind=RefResultKind.imprecise), default_val=RefdDecl(kind=RefResultKind.error)
                    )
                )
            } else # No fallback path
            {
                val v = self.get_referenced_decl();

                if v.success then RefdDecl(
                    decl=v.value.as![BasicDecl], kind=RefResultKind.precise
                ) else RefdDecl(
                    decl=null[Entity[BasicDecl]], kind=RefResultKind.error
                )
            }
        ).do(
            (res) => RefdDecl(
                decl=res.decl?.wrap_public_reference(), kind=res.kind
            ).do(
                # Never return a null node with a Precise result: this
                # indicates that it should be a no_ref (e.g. builtin operator).
                (res) => if res.decl.is_null and res.kind == RefResultKind.precise then null[RefdDecl] else res
            )
        )

    |" Like SubtypeIndication.designated_type, but on names, since because of
    |" Ada's ambiguous grammar, some subtype indications will be parsed as
    |" names.
    @exported
    fun name_designated_type(): Entity[BaseTypeDecl] = {
        bind env = self.node_env();
        bind origin = node.origin_node();

        self.designated_type_impl()
    }

    |" Returns whether self denotes a static subtype or not.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun is_static_subtype(): Bool =
        self.name_designated_type().is_static_decl()

    # ATTENTION: As for Name.use_package_name_designated_env this property must
    # not be memoized because of an unsoundness issue between infinite
    # recursion guards in lexical envs and memoized properties. See
    # libadalang#1307.
    fun name_designated_type_env(): LexicalEnv =
        self.name_designated_type()?.primitives_env()

    |" Return the compilation unit referenced by this name and for the given
    |" unit kind, if there is one.
    fun referenced_unit(kind: AnalysisUnitKind, not_found_is_error: Bool = true): CompilationUnit = node.designated_compilation_unit(
        node.as_symbol_array(), kind, true, not_found_is_error
    )

    |" Return whether two names match each other.
    |"
    |" This only handles Identifiers, SyntheticIdentifiers, StringLiteral,
    |" DefiningName and DottedName nodes: it always returns False for any
    |" other node kind.
    fun matches(n: Name): Bool = if (
        node is Identifier | SyntheticIdentifier and n is Identifier | SyntheticIdentifier
    ) or (
        node is StringLiteral and n is StringLiteral
    ) then node.name_symbol() == n.name_symbol()
    elif node is DefiningName then node.as[DefiningName].name.matches(n)
    elif n is DefiningName then node.matches(n.as[DefiningName].name)
    elif node is DottedName and n is DottedName then node.as[DottedName].prefix.matches(n.as[DottedName].prefix) and node.as[DottedName].suffix.matches(n.as[DottedName].suffix)
    else false

    |" Return whether two names match each other.
    |"
    |" This compares the symbol for Identifier and StringLiteral nodes. We
    |" consider that there is no match for all other node kinds.
    @exported
    fun name_matches(n: Entity[Name]): Bool = node.matches(n.node)

    # ATTENTION: this property must not be memoized because of an unsoundness
    # issue between infinite recursion guards in lexical envs and memoized
    # properties. See VC13-023.
    |" Assuming self is a name that is the direct child of a
    |" UsePackageClause's package name list, return the memoized designated
    |" environment for it.
    fun use_package_name_designated_env(): LexicalEnv =
        self.parent.parent.as![UsePackageClause].designated_env(node.child_index())

    |" Simple xref equation for names designating types. Doesn't try to
    |" resolve overloads. Originally derived from xref_no_overloading to match
    |" the behavior of designated_type properties.
    @with_dynvars(env, origin, entry_point)
    fun xref_type_equation(): Equation = match self {
        case dn: DottedName => dn.prefix.xref_no_overloading(sequential=true, all_els=false) and {
            bind env = dn.prefix.designated_env_no_overloading();

            dn.suffix.xref_type_equation()
        }
        case i: BaseId => i.designated_type_impl().do(
            (type) => %eq(i.ref_var(), type),
            default_val=self.undefined_reference_equation()
        )
        case ar: AttributeRef => ar.prefix.xref_type_equation() and (
            if ar.attribute.sym() == s"Class" then %eq(ar.ref_var(), ar.prefix.ref_var(), conv_prop=BaseTypeDecl.classwide_type)
            elif ar.attribute.sym() == s"Base" then %eq(ar.ref_var(), ar.prefix.ref_var(), conv_prop=BaseTypeDecl.scalar_base_type)
            else %true
        )
        case _ => %false
    }

    |" Simple xref equation for names. Doesn't try to resolve overloads. If
    |" ``all_els`` is True, then the name will be bound to the domain of all
    |" elements that corresponds. Else, it will be bound to the first one.
    |"
    |" ``sequential`` determines whether the lookup will be sequential or not.
    @with_dynvars(env, origin, entry_point)
    fun xref_no_overloading(sequential: Bool = true, all_els: Bool = false): Equation = match self {
        case dn: DottedName => dn.prefix.xref_no_overloading(sequential, all_els) and {
            bind env = dn.prefix.designated_env();

            dn.suffix.xref_no_overloading(sequential, all_els)
        }
        case i: BaseId => if all_els and node.is_suffix() then %domain(i.ref_var(), node.env_get(
            env, i.name_symbol(), from_node=if sequential then self.node else null[Name], lookup=if node.is_prefix() then LookupKind.recursive else LookupKind.flat
        ).filter((e) => node.has_visibility(e))) else %eq(i.ref_var(), i.env_get_first_visible(
            env, from_node=if sequential then self.node else null[Name], lookup_type=if node.is_prefix() then LookupKind.recursive else LookupKind.flat
        ))
        case _ => %false
    }

    |" Returns whether self is the prefix in name. Is used to determine
    |" whether lookups on this name should be recursive or not, without having
    |" to pass down the information as a function parameter.
    @memoized
    fun is_prefix(): Bool = (
        (
            node.parent is DottedName and node.parent.as[DottedName].prefix == node
        ) and node.parent.as[Name].is_prefix()
    ) or not node.parent is DottedName

    |" Returns whether self is the suffix in name.
    @memoized
    fun is_suffix(): Bool = (
        (
            node.parent is DottedName and node.parent.as[DottedName].suffix == node
        ) and node.parent.as[Name].is_suffix()
    ) or not node.parent is DottedName

    |" Return whether the name that self designates is an operator.
    @exported
    fun is_operator_name(): Bool =
        self.name_symbol() in s"\"=\"" | s"\"=\"" | s"\"/=\"" | s"\"<\"" | s"\"<=\"" | s"\">\"" | s"\">=\"" | s"\"and\"" | s"\"or\"" | s"\"xor\"" | s"\"abs\"" | s"\"*\"" | s"\"/\"" | s"\"mod\"" | s"\"rem\"" | s"\"+\"" | s"\"-\"" | s"\"&\"\"+\"" | s"\"-\"" | s"\"not\"" | s"\"abs\""

    |" Whether this name is a write reference.
    |"
    |" For example, ``X`` is a write reference in the following cases:
    |"
    |" 1. ``X := 2;``
    |" 2. ``X (2) := 2;``
    |" 3. ``P(F => X)`` where F is declared ``out`` or ``in out``.
    |" 4. ``P(F => T (X))`` where F is declared ``out`` or ``in out``
    |" 5. ``X'Access``.
    |" 6. ``X.C := 2``, ``R.X := 2``
    |" 7. ``X.P`` where the formal for X is declared ``out`` or ``in out``.
    |"
    |" .. note:: This is an experimental feature. There might be some
    |"     discrepancy with the GNAT concept of "write reference".
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun is_write_reference(): Bool = match self.parent {
        # Handle assignment case::
        #     X := 2;
        case a: AssignStmt => a.dest == self

        # Handle assignment to component case::
        #     X (2) := 2;
        case c: CallExpr => c.name == self and (
            # self is the name of component access
            c.is_write_reference()
        )

        # Handle assignment to component case::
        #    X.C := 2
        #    R.X := 2
        #
        # As well as calls using the dot notation with out/inout operand.
        case d: DottedName => (
            # Component writes
            d.is_write_reference()
        ) or (
            # Dot calls with "out" first parameter
            d.prefix == self and d.suffix.called_subp_spec().do(
                (spec) => spec.info.md.dottable_subp and spec.abstract_formal_params()?[0].as[ParamSpec]?.mode?.is_writable()
            )
        )

        # Handle out/inout param case
        case p: ParamAssoc => if {
            bind env = node.node_env();
            bind origin = node.origin_node();

            p.parent.parent.as[CallExpr]?.is_type_conversion()
        } then p.parent.parent.as[CallExpr].is_write_reference() else p.get_params().any(
            (m) => m.basic_decl().as[ParamSpec]?.mode?.is_writable()
        )

        # handle 'Access case
        case a: AttributeRef => a.prefix == self and a.is_access_attr()
        case l: AlternativesList => l.parent is AggregateAssoc
        case _ => false
    }

    |" Implementation for calls done via a CallExpr, a DottedName
    |" or an Identifier. The result includes the prefix of the call in case
    |" the dot-notation is used.
    @with_dynvars(imprecise_fallback=false)
    fun potential_actuals_for_dispatch(spec: Entity[BaseSubpSpec]): Array[ExpectedTypeForExpr] = {
        # Handle calls done using the dot notation. Retrieve the prefix and
        # match it with the type of the first parameter of the called
        # subprogram.
        val prefix = self.is_dot_call().do(
            (_) => match self {
                case c: CallExpr => c.name.as![DottedName]
                case d: DottedName => d
                case i: Identifier => i.parent.as![DottedName]
                case _ => null[Entity[DottedName]]
            }.do(
                (d) => [ExpectedTypeForExpr(
                    expected_type=spec.unpacked_formal_params()?[0].formal_decl().type_expression(), expr=d.prefix
                )]
            )
        );
        # Handle the rest of the arguments if this is a CallExpr, matching
        # them with the types of the parameters of the called subprogram.
        val args = self.as[CallExpr]?.params()?.zip_with_params().map(
            (pm) => ExpectedTypeForExpr(
                expected_type=pm.param.basic_decl().type_expression(), expr=pm.actual
            )
        );

        prefix & args
    }

    @with_dynvars(imprecise_fallback=false)
    fun is_dispatching_call(): Bool = self.is_access_call() or (
        self.is_direct_call() and (self.parent_callexpr().as[Name] or? self).is_dispatching_call_impl(self.referenced_decl())
    )

    |" Returns True if this Name corresponds to a static non-dispatching call.
    |" In other words, this will return True if and only if the target of the
    |" call is known statically.
    |"
    |" .. note:: This is an experimental feature. There might be some
    |"     discrepancy with the GNAT concept of "static call".
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun is_static_call(): Bool =
        self.is_call() and not self.is_dispatching_call()

    |" Return the array of SingleTokNode nodes that compose this name.
    |"
    |" Only simple name kinds are allowed: Identifier, DottedName and
    |" DefiningName. Any other kind will trigger a PreconditionFailure.
    fun as_single_tok_node_array(): Array[SingleTokNode] = match node {
        case dname: DefiningName => dname.name.as_single_tok_node_array()
        case tok: SingleTokNode => [tok]
        case dot: DottedName => dot.prefix.as_single_tok_node_array() & dot.suffix.as_single_tok_node_array()
        case _ => raise[Array[SingleTokNode]] PreconditionFailure()
    }

    |" Returns an array of pairs, associating formal parameters to actual or
    |" default expressions.
    @exported
    fun call_params(): Array[ParamActual] = {
        val formal_spec = self.called_formal_subp_spec();
        val is_call = not formal_spec.is_null;
        val is_prefix_call = if is_call then self.is_dot_call() or self is AttributeRef else false;
        val offset = if is_prefix_call then 1 else 0;
        val call_prefix = match self.as[CallExpr].do((ce) => ce.name) or? self {
            case dn: DottedName => dn.prefix
            case ar: AttributeRef => ar.prefix
            case _ => null[Entity[Expr]]
        };
        # Get the actuals of this call expression if any
        val aparams = self.as[CallExpr]?.params();
        # Get the formals of the called subprogams
        val fparams = formal_spec?.abstract_formal_params();
        # Get a flatten list of the parameters of the actual subprogram, so
        # that we can easily find them by index when mapping from the
        # parameter of the formal subprogram.
        val actual_formals = formal_spec?.corresponding_actual().unpacked_formal_params();

        if is_call then # Create an array of pairs from the subprogram formals and
        # default expressions.
        {
            val dparams = fparams.imapcat(
                (p, i) => p.defining_names().map(
                    (n) => ParamActual(
                        param=n,
                        # Handling dot notation (first actual is
                        # denoted by the prefix of the dot call).
                        actual=if is_prefix_call and i == 0 then call_prefix else p.as[ParamSpec]?.default_expr
                    )
                )
            );

            # Create a new array by updating the actuals if the call
            # expression provides some.
            aparams.do(
                (ap) => dparams.imap(
                    (dp, i) => ParamActual(
                        param=actual_formals?[i],
                        # Search if a named param expression exists for
                        # this formal param in the call assoc list.
                        # Handling dot notation (do not update first
                        # actual).
                        actual=if is_prefix_call and i == 0 then dp.actual else ap.actual_for_param_at(dp.param, i - offset, dp.actual)
                    )
                ), default_val=dparams
            )
        } else raise[Array[ParamActual]] PreconditionFailure("this name doesn't reference a call expression")
    }

    |" Returns the lexical environment that is the scope in which the
    |" entity designated by this name is defined/used.
    @with_dynvars(env)
    fun parent_scope(): LexicalEnv = raise[LexicalEnv] PropertyError("Property Name.parent_scope not implemented")

    @with_dynvars(env, origin)
    fun all_env_els_impl(@ignored seq: Bool = true, @ignored seq_from: AdaNode = null[AdaNode], @ignored categories: RefCategories = RefCategories(_=true)): Array[Entity[AdaNode]] = raise[Array[Entity[AdaNode]]] PropertyError("Property Name.all_env_els_impl not implemented")

    |" Lexical environment this identifier represents. This is similar to
    |" designated_env although it handles only cases for child units and it is
    |" used only during the environment population pass so it does not return
    |" orphan environments.
    @with_dynvars(env)
    fun scope(): LexicalEnv = null[LexicalEnv]

    |" This property proxies the logic variable that points to the entity that
    |" this name refers to. For example, for a simple dotted name::
    |"
    |"     A.B
    |"
    |" The dotted name's ref var is the one of the SingleTokNode B.
    fun ref_var(): LogicVar = raise[LogicVar] PropertyError("Property Name.ref_var not implemented")

    |" This logic variable holds the specification of the subprogram or
    |" subprogram access that is being called by this exact Name.
    fun subp_spec_var(): LogicVar = raise[LogicVar] PropertyError("Property Name.subp_spec_var not implemented")

    fun defines_subp_spec_var(): Bool =
        # A null logic variable could have been used instead of this additional
        # property to indicate that an AST node does not define subp_spec_var.
        # Unfortunately, No(LogicVar) is not a valid dsl expression. Therefore,
        # we provide a default implementation for this property, which is then
        # overridden in relevant child classes to indicate that one can call
        # p_subp_spec_var.
        false

    |" Return the subprogram specification of the subprogram or subprogram
    |" access that is being called by this exact Name, if relevant. Note that
    |" when inside an instantiated generic, this will return the spec of the
    |" formal subprogram.
    fun called_formal_subp_spec(): Entity[BaseFormalParamHolder] =
        if node.defines_subp_spec_var() then node.logic_val(
            from_node=self, lvar=node.subp_spec_var()
        ).value.as[BaseFormalParamHolder] else null[Entity[BaseFormalParamHolder]]

    |" Assuming this name designates a type, return this type.
    |"
    |" Since in Ada this can be resolved locally without any non-local
    |" analysis, this doesn't use logic equations.
    @with_dynvars(env, origin)
    fun designated_type_impl(): Entity[BaseTypeDecl] =
        null[Entity[BaseTypeDecl]]

    |" Returns the relative name of this instance. For example,
    |" for a prefix ``A.B.C``, this will return ``C``.
    @exported
    fun relative_name(): Entity[Name] = raise[Entity[Name]] PropertyError("Property Name.relative_name not implemented")

    fun name_symbol(): Symbol =
        node.as_bare_entity.relative_name().name_symbol()

    |" Turn this name into an array of symbols.
    |"
    |" For instance, a node with name ``A.B.C`` is turned into
    |" ``['A', 'B', 'C']``.
    |"
    |" Only simple name kinds are allowed: Identifier, DottedName and
    |" DefiningName. Any other kind will trigger a PreconditionFailure.
    @exported
    fun as_symbol_array(): Array[Symbol] =
        node.as_single_tok_node_array().map((t) => t.symbol)

    |" Return a canonicalized version of this name's text.
    |"
    |" Only simple name kinds are allowed: Identifier, DottedName and
    |" DefiningName. Any other kind will trigger a PreconditionFailure.
    @exported
    fun canonical_text(): Symbol =
        node.sym_join(node.as_symbol_array(), ".").to_symbol

    |" Return whether this name denotes a constant value.
    @exported
    fun is_constant(): Bool = raise[Bool] PropertyError("Property Name.is_constant not implemented")
}

|" Expression to reference an attribute (:rmlink:`4.1.4`).
class AttributeRef: Name {
    @parse_field prefix: Name
    @parse_field attribute: Identifier
    @parse_field args: AssocList
    r_ref_var: LogicVar

    fun ref_var(): LogicVar = node.r_ref_var

    fun relative_name(): Entity[Name] = self.prefix.relative_name()

    fun is_constant(): Bool = true

    @with_dynvars(env, origin)
    fun designated_type_impl(): Entity[BaseTypeDecl] =
        if node.attribute.sym() == s"Class" then self.prefix.designated_type_impl()?.classwide_type()
        elif node.attribute.sym() == s"Base" then self.prefix.designated_type_impl().scalar_base_subtype()
        else null[Entity[BaseTypeDecl]]

    fun has_context_free_type(): Bool = not node.is_access_attr()

    fun is_access_attr(): Bool =
        node.attribute.name_symbol() in s"Access" | s"Unchecked_Access" | s"Unrestricted_Access"

    @with_dynvars(env, origin, no_visibility=false)
    fun designated_env(): LexicalEnv =
        if self.is_access_attr() or self.attribute.name_is(s"Old") then
            self.prefix.designated_env()
        elif self.attribute.name_is(s"Result") then
            node.parents().find(
                (p) => p is BasicSubpDecl | BaseSubpBody
            ).as_entity.as[BasicDecl].subp_spec_or_null().return_type()
            .defining_env()
        else null[LexicalEnv]

    |" Return the subprogram declaration referred by this attribute name,
    |" assuming its prefix denotes a type.
    fun attribute_subprogram(): Entity[BasicDecl] =
        self.prefix.name_designated_type()?.attribute_subprogram(self.attribute.name_symbol())

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        val rel_name = self.attribute.name_symbol();

        # Attributes that have arguments
        if rel_name in s"First" | s"Last" | s"Range" | s"Length" then self.array_attr_equation()
        # Attributes that simply return subprograms
        elif rel_name in s"Succ" | s"Pred" | s"Min" | s"Max" | s"Ceiling" | s"Floor" | s"Rounding" | s"Unbiased_Rounding" | s"Leading_Part" | s"Truncation" | s"Exponent" | s"Fraction" | s"Copy_Sign" | s"Remainder" | s"Adjacent" | s"Machine" | s"Machine_Rounding" | s"Scaling" | s"Compose" | s"Mod" | s"Value" | s"Wide_Value" | s"Wide_Wide_Value" | s"Fixed_Value" | s"Integer_Value" | s"Pos" | s"Val" | s"Enum_Val" | s"Write" | s"Read" | s"Output" | s"Input" | s"Put_Image" | s"Asm_Input" | s"Asm_Output" | s"Model" | s"Round" then self.attribute_subprogram_equation()
        elif rel_name in s"Size" | s"VADS_Size" then self.size_equation()
        elif rel_name in s"Max_Size_In_Storage_Elements" | s"Max_Alignment_For_Allocation"
            | s"Aft" | s"Object_Size" | s"Value_Size" | s"Storage_Size"
            | s"Scale"
            then self.subtype_attr_equation()
        elif rel_name in s"Access" | s"Unchecked_Access" | s"Unrestricted_Access" then self.access_equation()
        elif rel_name == s"Image" then self.image_equation(node.std_string_type())
        elif rel_name == s"Wide_Image" then self.image_equation(node.std_wide_string_type())
        elif rel_name == s"Wide_Wide_Image" then self.image_equation(node.std_wide_wide_string_type())
        elif rel_name == s"Enum_Rep" then self.enum_rep_equation()
        elif rel_name in s"Invalid_Value" | s"First_Valid" | s"Last_Valid" then self.self_type_equation()
        elif rel_name == s"Identity" then self.identity_equation()
        elif rel_name in s"Address" | s"Code_Address" then
            self.address_equation()
        elif rel_name in s"Small" | s"Model_Small" | s"Safe_Small" | s"Epsilon" | s"Model_Epsilon" | s"Large" | s"Safe_Large" | s"Delta" | s"Safe_First" | s"Safe_Last" then self.universal_real_equation()
        elif rel_name == s"Img" then self.img_equation(node.std_string_type())
        elif rel_name == s"Tag" then self.tag_attr_equation()
        elif rel_name == s"Result" then self.result_attr_equation()
        elif rel_name in s"Old" | s"Loop_Entry" then self.bind_to_prefix_eq()
        elif rel_name in s"Class" | s"Base" then self.prefix.sub_equation()
        elif rel_name in s"Valid" | s"Machine_Overflows" | s"Machine_Rounds"
            | s"Has_Access_Values" | s"Has_Discriminants" | s"Has_Tagged_Values"
            | s"Definite" | s"Constrained" | s"Initialized" | s"Valid_Scalars"
            | s"Unconstrained_Array" | s"Library_Level"
            | s"Preelaborable_Initialization" | s"Denorm" | s"Signed_Zeros"
            | s"Fast_Math" | s"Passed_By_Reference" then
            self.prefix.sub_equation() and %eq(node.type_var(), node.bool_type())
        # In the case of the ``Enabled`` attribute, the prefix is supposed
        # to be a check name, so it's not even an entity that has source
        # existence. In that case, we just bind the type of the expr to
        # bool.
        elif rel_name == s"Enabled" then %eq(node.type_var(), node.bool_type())
        elif rel_name in s"Width" | s"Component_Size" | s"Position" | s"Mantissa" | s"Model_Mantissa" | s"Machine_Mantissa" | s"Fore" | s"Aft" | s"Digits" | s"Modulus" | s"Word_Size" | s"Wchar_T_Size" | s"Max_Integer_Size" | s"Address_Size" | s"Maximum_Alignment" | s"System_Allocator_Alignment" | s"Finalization_Size" | s"Descriptor_Size" | s"Alignment" | s"First_Bit" | s"Last_Bit" | s"Default_Bit_Order" | s"Range_Length" | s"Storage_Unit" | s"Stream_Size" | s"Small_Numerator" | s"Small_Denominator" | s"Machine_Emin" | s"Machine_Emax" | s"Model_Emin" then self.prefix.sub_equation() and node.universal_int_bind(node.type_var())
        elif rel_name in s"External_Tag" | s"Type_Key" then self.prefix.sub_equation() and %eq(node.type_var(), node.std_string_type())
        elif rel_name == s"Target_Name" then %eq(node.type_var(), node.std_string_type())
        elif rel_name == s"Storage_Pool" then self.storage_pool_equation()
        elif rel_name in s"Bit_Order" | s"Scalar_Storage_Order" | s"Default_Scalar_Storage_Order" then self.order_equation()
        elif rel_name == s"Type_Class" then self.type_class_equation()
        # Task attributes (RM 9.9)
        elif rel_name in s"Callable" | s"Terminated" then self.prefix.sub_equation() and %eq(node.type_var(), node.bool_type())
        # Entry attributes (RM 9.9)
        elif rel_name == s"Count" then match self.prefix {
            # If prefix is a CallExpr, use sub_equation to resolve the
            # entry reference as it specifies a family member.
            case ce: CallExpr => ce.sub_equation()

            # On the other cases, prefix is a simple identifier
            case o => o.xref_no_overloading()
        } and node.universal_int_bind(node.type_var())
        elif rel_name == s"Caller" then self.prefix.xref_no_overloading() and %eq(node.type_var(), node.task_id_type())
        elif rel_name == s"Machine_Radix" then self.universal_int_equation()
        elif rel_name == s"To_Address" then self.to_address_equation()
        elif rel_name == s"Index" then self.index_equation()
        elif rel_name == s"Abort_Signal" then %eq(node.ref_var(), node.std_entity(s"abort_signal_")) and %eq(node.type_var(), null[Entity[BaseTypeDecl]])
        elif rel_name in s"Has_Same_Storage" | s"Overlaps_Storage" then self.storage_equation()
        elif rel_name == s"Deref" then self.deref_equation()
        elif rel_name == s"Mechanism_Code" then self.mechanism_code_equation()
        else raise[Equation] PropertyError("Unhandled attribute")
    }

    |" Equation for type attributes that denote functions.
    @with_dynvars(env, origin, entry_point)
    fun attribute_subprogram_equation(): Equation =
        self.prefix.xref_type_equation() and %eq(node.ref_var(), self.attribute_subprogram())

    |" Implementation of the Type_Class attribute, provided for compatibility
    |" with DEC 83.
    @with_dynvars(env, origin, entry_point)
    fun type_class_equation(): Equation = {
        val typ = self.get_unit_root_decl(
            [s"System", s"Aux_DEC"], AnalysisUnitKind.unit_specification
        )?.children_env().get_first(s"Type_Class", lookup=LookupKind.flat).as[BaseTypeDecl];

        self.prefix.xref_equation() and %eq(node.type_var(), typ)
    }

    |" Equation for the Storage_Pool attribute.
    @with_dynvars(env, origin, entry_point)
    fun storage_pool_equation(): Equation = {
        val typ = self.get_unit_root_decl(
            [s"System", s"Storage_Pools"], AnalysisUnitKind.unit_specification
        )?.children_env().get_first(
            s"Root_Storage_Pool", lookup=LookupKind.flat
        ).as[BaseTypeDecl].classwide_type();

        self.prefix.xref_equation() and %eq(node.type_var(), typ)
    }

    |" Equation for the Bit_Order/[Default_]Scalar_Storage_Order attributes.
    @with_dynvars(env, origin, entry_point)
    fun order_equation(): Equation = {
        val typ = self.get_unit_root_decl(
            [s"System"], AnalysisUnitKind.unit_specification
        )?.children_env().get_first(s"Bit_Order", lookup=LookupKind.flat).as[BaseTypeDecl];

        self.prefix.xref_equation() and %eq(node.type_var(), typ)
    }

    @with_dynvars(env, origin, entry_point)
    fun bind_to_prefix_eq(): Equation =
        %eq(node.prefix.expected_type_var(), node.expected_type_var()) and self.prefix.sub_equation() and %eq(node.type_var(), node.prefix.type_var())

    @with_dynvars(env, origin, entry_point)
    fun result_attr_equation(): Equation = {
        # We find the containing declaration (a function declaration or an
        # access-to-function type) starting the bound env's node instead of
        # self, as this attribute can appear in a pragma Post appearing
        # *after* the declaration.
        val containing_decl = env.env_node.parents().find(
            (p) => p is BasicSubpDecl | BaseSubpBody or p.as[ConcreteTypeDecl].do((v1) => v1.type_def is AccessToSubpDef)
        ).as_entity.as[BasicDecl];
        val returns = match containing_decl {
            case sd: ConcreteTypeDecl => sd.type_def.as[AccessToSubpDef].subp_spec
            case bd: BasicDecl => bd.subp_spec_or_null()
        }.do((ss) => ss.return_type());

        %eq(node.type_var(), returns) and %eq(self.prefix.ref_var(), containing_decl)
    }

    @with_dynvars(env, origin, entry_point)
    fun tag_attr_equation(): Equation = {
        val tag_type = self.get_unit_root_decl(
            [s"Ada", s"Tags"], AnalysisUnitKind.unit_specification
        )?.children_env().get_first(s"Tag", lookup=LookupKind.flat).as[BaseTypeDecl];

        (
            # Prefix is an expression, bind prefix's ref var to it
            self.prefix.xref_equation()
        ) and (
            # Type of self is String
            %eq(node.type_var(), tag_type)
        )
    }

    @with_dynvars(env, origin, entry_point)
    fun address_equation(): Equation =
        # Just like in access_equation, handle subprograms first, otherwise
        # paramless subprograms could match the normal path and therefore be
        # considered called.
        (
            (
                self.prefix.xref_no_overloading() and %predicate(BasicDecl.is_subprogram, node.prefix.ref_var())
            ) or self.prefix.sub_equation()
        ) and %eq(node.type_var(), self.system_address_type())

    @with_dynvars(env, origin, entry_point)
    fun identity_equation(): Equation =
        # NOTE: We don't verify that the prefix designates an exception
        # declaration, because that's legality, not name resolution.
        self.prefix.sub_equation() and %eq(node.type_var(), node.prefix.ref_var(), conv_prop=BasicDecl.identity_type)

    @with_dynvars(env, origin, entry_point)
    fun universal_real_equation(): Equation =
        node.universal_real_bind(node.type_var()) and self.prefix.sub_equation()

    @with_dynvars(env, origin, entry_point)
    fun universal_int_equation(): Equation = {
        val typ = self.prefix.name_designated_type();

        (
            self.prefix.sub_equation() and node.universal_int_bind(node.type_var())
        ) and self.args.logic_all(
            (arg) => (
                %eq(arg.expr().expected_type_var(), typ) and arg.expr().sub_equation()
            ) and arg.expr().matches_expected_type()
        )
    }

    @with_dynvars(env, origin, entry_point)
    fun image_equation(str_type: Entity[AdaNode]): Equation = {
        val typ = self.prefix.name_designated_type();

        if typ.is_null then (
            # If prefix is not a type, then it is an expression
            self.prefix.sub_equation() and %eq(node.type_var(), str_type)
        ) else self.prefix.xref_type_equation() and %eq(node.ref_var(), self.attribute_subprogram())
    }

    @with_dynvars(env, origin, entry_point)
    fun img_equation(str_type: Entity[AdaNode]): Equation = (
        # Prefix is an expression, bind prefix's ref var to it
        self.prefix.xref_equation()
    ) and (
        # Type of self is String
        %eq(node.type_var(), str_type)
    )

    @with_dynvars(env, origin, entry_point)
    fun enum_rep_equation(): Equation = {
        val typ = self.prefix.name_designated_type();

        if typ.is_null then (
            # If prefix is not a type, then it is an expression
            self.prefix.sub_equation() and %eq(node.type_var(), node.universal_int_type())
        ) else self.prefix.xref_type_equation() and %eq(node.ref_var(), self.attribute_subprogram())
    }

    |" Assuming the prefix of this attribute designates a type T, return
    |" an equation that binds the value of this attribute to that type T.
    @with_dynvars(env, origin, entry_point)
    fun self_type_equation(): Equation = {
        val typ = self.prefix.name_designated_type();

        self.prefix.xref_type_equation() and %eq(node.type_var(), typ)
    }

    @with_dynvars(env, origin, entry_point)
    fun access_equation(): Equation = (
        # Access to statically known subprogram
        self.prefix.xref_no_overloading(all_els=true)
        and %predicate(
            BaseTypeDecl.is_subp_access_of,
            node.type_var(), node.prefix.ref_var()
        )
        and %eq(node.type_var(), node.expected_type_var())
    ) or (
        # Access to object
        self.prefix.sub_equation() and (
            # If the expected type is known, use it to infer the prefix's
            # expected type, and also use it as the actual type of the
            # access attribute which avoids synthesizing an anonymous
            # access type.
            # Note: We use the `accessed_type_no_call` conversion property
            # here in case `self.type_var` holds an access-to-
            # subprogram type so that we don't propagate its
            # return type to the prefix of the 'Access attribute.
            %eq(node.expected_type_var(), node.type_var())
            and %eq(node.prefix.expected_type_var(), node.expected_type_var(),
                    conv_prop=BaseTypeDecl.accessed_type_no_call)
            and (
                # Either the expected type of the prefix is None, meaning
                # the conversion property above was applied on a subprogram
                # access (for which we cannot retrieve the dereferenced
                # type). In that case type should be None as well.
                %eq(node.prefix.expected_type_var(), node.prefix.type_var())
                and %eq(node.prefix.type_var(), null[Entity[BaseTypeDecl]])

                # Or it's an object access and so the actual type must
                # match the expected type we inferred above.
                or self.prefix.matches_expected_formal_type()
            )
            or
            # If this `X'Access` is the prefix of a DottedName, we may be
            # resolving an implicit dereference. In that case, our expected
            # type is also the expected type of the prefix `X`, and we
            # should synthesize an anonymous access type for the actual
            # type of `X'Access`.
            if node.parent is DottedName and node.is_prefix() then
                %eq(node.prefix.expected_type_var(), node.expected_type_var())
                and self.prefix.matches_expected_prefix_type()
                and %eq(node.type_var(), node.prefix.type_var(),
                        conv_prop=BaseTypeDecl.anonymous_access_type_or_null)
            elif node.parent is ExplicitDeref then
                %eq(node.type_var(), node.prefix.type_var(),
                    conv_prop=BaseTypeDecl.anonymous_access_type_or_null)
            else %false
        )
    )

    @with_dynvars(env, origin, entry_point)
    fun size_equation(): Equation = {
        val typ = self.prefix.name_designated_type();

        if not typ.is_null then %eq(node.prefix.ref_var(), typ) and node.universal_int_bind(node.type_var()) else self.prefix.sub_equation() and node.universal_int_bind(node.type_var())
    }

    @with_dynvars(env, origin, entry_point)
    fun array_attr_equation(): Equation = {
        val is_length = self.attribute.name_is(s"Length");
        val typ = self.prefix.name_designated_type();
        # If the range attribute has an argument, then it's a static expression
        # representing an int that we will use as a dimension.
        val dim = self.args?[0].do(
            (arg) => arg.expr().do(
                (expr) => {
                    val _ = expr.resolve_names_internal(false);

                    expr.eval_as_int().as_int()
                }, default_val=1
            ), default_val=1
        ) - 1;

        if not typ.is_null then (
            # Prefix is a type
            self.prefix.xref_type_equation() and (
                if typ.is_array_def_with_deref() and is_length then node.universal_int_bind(node.type_var())
                # If it's an array, take the appropriate index type
                elif typ.is_array_def_with_deref() then %eq(node.type_var(), typ.index_type(dim))
                # If it's a discrete type, then bind to the discrete type
                elif typ.is_discrete_type() or (typ.is_real_type() and not is_length) then %eq(node.type_var(), typ)
                else %false
            )
        ) else # Prefix is not a type: In that case we have permission to resolve
        # prefix separately.
        {
            val res = self.prefix.resolve_names_internal_with_eq(
                %predicate(BaseTypeDecl.is_array_def_with_deref, self.prefix.type_var())
            );
            val pfx_typ = self.prefix.type_val().as[BaseTypeDecl];

            if res then if is_length then node.universal_int_bind(node.type_var()) else %eq(node.type_var(), pfx_typ.index_type(dim)) else %false
        }
    }

    |" Generates the xref equation for a an attribute that is defined on any
    |" subtype and that evaluates to an universal integer.
    @with_dynvars(env, origin, entry_point)
    fun subtype_attr_equation(): Equation =
        %eq(node.prefix.ref_var(), self.prefix.name_designated_type()) and node.universal_int_bind(node.type_var())

    |" Return the xref equation for the ``To_Address`` attribute.
    @with_dynvars(env, origin, entry_point)
    fun to_address_equation(): Equation = {
        # TODO: this property can be completely removed once we support
        # attributes that return functions.
        val to_address_subp = self.get_unit_root_decl(
            [s"System", s"Storage_Elements"], AnalysisUnitKind.unit_specification
        )?.children_env().get_first(s"To_Address", lookup=LookupKind.minimal).as[BasicSubpDecl];

        self.prefix.sub_equation() and %eq(node.ref_var(), to_address_subp)
    }

    |" Return the xref equation for the ``Index`` attribute.
    @with_dynvars(env, origin, entry_point)
    fun index_equation(): Equation = {
        val typ = env.get_first(self.prefix.name_symbol()).as![EntryDecl].family_type();

        self.prefix.sub_equation() and %eq(node.type_var(), typ)
    }

    |" Return the xref equation for the ``Deref`` attribute.
    @with_dynvars(env, origin, entry_point)
    fun deref_equation(): Equation =
        self.prefix.xref_type_equation()
        and %eq(node.type_var(), node.prefix.ref_var())
        and self.args?[0].do(
            (arg) => arg.expr().sub_equation()
            and %eq(arg.expr().expected_type_var(), node.system_address_type())
            and arg.expr().matches_expected_type(),
            default_val=%false
        )

    |" Return the xref equation for the ``Mechanism_Code`` attribute.
    @with_dynvars(env, origin, entry_point)
    fun mechanism_code_equation(): Equation =
        self.prefix.xref_no_overloading()
        and self.universal_int_bind(node.type_var())
        and self.args?[0].do(
            (arg) => arg.expr().sub_equation()
            and self.universal_int_bind(arg.expr().expected_type_var())
            and arg.expr().matches_expected_type(),
            default_val=%true
        )

    |" Return the xref equation for the ``Has_Same_Storage`` and
    |" ``Overlaps_Storage`` attributes.
    @with_dynvars(env, origin, entry_point)
    fun storage_equation(): Equation = (
        # Prefix denotes an object
        self.prefix.sub_equation() and (
            # The attribute return a boolean value
            %eq(node.type_var(), node.bool_type())
        )
    ) and (
        # The only one argument of the attribute can be of any type
        self.args?[0].sub_equation()
    )

    fun called_formal_subp_spec(): Entity[BaseFormalParamHolder] = {
        val rel_name = self.attribute.name_symbol();

        if rel_name in s"Image" | s"Wide_Image" | s"Wide_Wide_Image" then self.prefix.expression_type().do(
            (typ) => typ.attribute_subprogram(rel_name).subp_spec_or_null()
        ) else null[Entity[BaseFormalParamHolder]]
    }
}

|" Represent a syntactic call expression.
|"
|" At the semantic level, this can be either a subprogram call, an array
|" subcomponent access expression, an array slice or a type conversion, all
|" described in :rmlink:`4.1`, except for subprogram call statements,
|" described in :rmlink:`6.4`.
class CallExpr: Name {
    @parse_field name: Name
    @parse_field suffix: AdaNode
    r_called_spec: LogicVar

    fun ref_var(): LogicVar = node.name.ref_var()

    fun subp_spec_var(): LogicVar = node.r_called_spec

    fun defines_subp_spec_var(): Bool = true

    fun relative_name(): Entity[Name] = self.name.relative_name()

    |" Return whether this expression is a subprogram call, an array
    |" subcomponent access expression, an array slice or a type conversion.
    @exported
    fun kind(): CallExprKind = if self.is_call() then CallExprKind.call
    elif self.is_array_slice() then CallExprKind.array_slice
    elif {
        bind origin = node.origin_node();

        not self.name.expression_type().do((typ) => typ.array_def_with_deref()).is_null
    } then CallExprKind.array_index
    # Case for type conversion: CallExpr has one
    # argument and its name denotes a type declaration.
    elif self.params().length() == 1 and self.name.referenced_decl() is BaseTypeDecl then CallExprKind.type_conversion
    # This is important to make this test *after* the check for
    # ``is_call`` so that real entry calls are correctly flagged as
    # such. We only want to catch family indexes here.
    elif self.name.referenced_decl() is EntryDecl then CallExprKind.family_index
    # Should not happen
    else raise[CallExprKind] PropertyError("undetermined CallExpr kind")

    fun is_constant(): Bool =
        if self.kind() == CallExprKind.type_conversion then match self.params()?[0].expr() {
            # View conversion: constant if the object is constant (value
            # conversion is always constant).
            case n: Name => n.is_constant()
            case _ => true
        }
        # A call is always constant
        elif self.kind() == CallExprKind.call then true
        # General case that handles, array subcomponent access expression
        # and array slice.
        else self.referenced_decl().is_constant_object()

    @with_dynvars(env, origin, no_visibility=false)
    fun designated_env(): LexicalEnv = {
        val typ = self.name.name_designated_type();

        if not typ.is_null then typ.defining_env() else (
            # Since we are in a CallExpr, we need to include user-defined
            # indexing in defining_env of the prefix, as it might actually be
            # used here.
            {
                bind include_ud_indexing = true;

                self.env_elements().map(
                    (e) => match e {
                        case bd: Entity[BasicDecl] => bd.defining_env()
                        case _ => null[LexicalEnv]
                    }
                ).env_group()
            }
        )
    }

    |" A call expression can never provide any dot-accessible entities in
    |" a "no overloading" context. In other words, it's never valid to have
    |" a ``CallExpr`` in the middle of a name that designates a type, so we
    |" can return an empty environment.
    @with_dynvars(env, origin, no_visibility=false)
    fun designated_env_no_overloading(): LexicalEnv =
        null[LexicalEnv]

    @with_dynvars(env)
    fun env_elements_impl(): Array[Entity[AdaNode]] =
        self.name.env_elements_impl()

    # CallExpr can appear in type expressions: they are used to create implicit
    # subtypes for discriminated records or arrays.
    @with_dynvars(env, origin)
    fun designated_type_impl(): Entity[BaseTypeDecl] = {
        # Retrieve the type designated by the prefix
        val prefix_tpe = self.name.designated_type_impl();
        # Check that this CallExpr is a valid type, which in this context
        # is the case if and only if the arguments of this CallExpr match
        # the discriminant list of the type designated by the prefix.
        val matches_formals = self.params().do(
            (ps) => node.match_formals(
                prefix_tpe?.discriminants_list(), ps, false
            ).all(
                (pm) => pm.has_matched and pm.formal.formal_decl().formal_type().matching_type(
                    pm.actual.assoc.expr().as[Name]?.name_designated_type()
                )
            ), default_val=true
        );

        # Make sure to not return the type designated by the prefix if this
        # CallExpr does not designate a type!
        if matches_formals then prefix_tpe else null[Entity[BaseTypeDecl]]
    }

    fun params(): Entity[AssocList] = self.suffix.as[AssocList]

    |" Return whether this CallExpr can correspond to taking a slice of the
    |" given array type.
    @with_dynvars(origin)
    fun check_array_slice(typ: Entity[BaseTypeDecl]): Bool = {
        val atd = typ.do((t) => t.array_def_with_deref());

        not atd.is_null and self.suffix.do(
            (sfx) => (
                # array slice using the ``(A .. B)`` notation
                sfx is BinOp
            ) or (
                # array slice using the ``(X'Range)`` notation
                sfx is AttributeRef
            ) or (
                # array slice using the ``(Subtype range ..)`` notation
                sfx is SubtypeIndication
            ) or (
                # array slice using the ``(Subtype)`` notation
                sfx.as[AssocList].do(
                    (al) => al.length() == 1 and al?[0].expr().as[Name].do(
                        (n) => not n.name_designated_type().is_null
                    )
                )
            )
        )
    }

    |" Return whether this CallExpr is actually an access to a slice of
    |" the array denoted by the prefix of this CallExpr.
    @exported
    fun is_array_slice(): Bool = {
        bind origin = node.origin_node();

        self.check_array_slice(self.name.expression_type())
    }

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = self.bottom_up_name_equation()

    |" Helper for xref_equation and stop_resolution_equation, handles the
    |" construction of the equation in type conversion cases, without the
    |" recursion on the argument.
    @with_dynvars(env, origin, entry_point)
    fun type_conv_self_xref_equation(): Equation =
        self.name.subtype_indication_equation() and %eq(node.type_var(), node.name.ref_var())

    |" Build the xref equation in case this node represents a call to the
    |" given entry declaration.
    @with_dynvars(env, origin, entry_point, logic_context)
    fun entry_equation(e: Entity[EntryDecl], root: Name): Equation = if e.has_family() then (
        # Handle calls to entry families
        e.family_type().do(
            (ft) => %eq(self.params()?[0].expr().expected_type_var(), ft) and self.params()?[0].expr().matches_expected_type(), default_val=%true
        ) and (
            # If the family type is None, it means it is an anonymous range
            # in which case we don't need to constrain it further.
            self.parent_name(root).as[CallExpr].do(
                (c) => c.params().logic_all((pa) => pa.expr().sub_equation()) and c.entity_equation(e, root), default_val=%true
            )
        )
    ) else (
        # The parent name can be null if the entry declaration has no
        # parameter section besides the family type section.
        # If this entry decl declares no family we can treat it the same
        # way as a subprogram call.
        self.entity_equation(e, root)
    )

    @with_dynvars(env, origin, entry_point, logic_context)
    fun entity_equation(s: Entity[BasicDecl], root: Name): Equation = # The called entity is the matched entity
    # If s does not have any parameters, then we construct the
    # chain of name equations starting from self, with the parent
    # component.
    if s.is_paramless() then self.parent_name_equation(s.expr_type(), root)
    # If S can be called in a paramless fashion, but can also be
    # called with parameters, we are forced to make a disjunction.
    elif s.can_be_paramless() then self.parent_name_equation(s.expr_type(), root) or (
        self.subprogram_equation(
            s.subp_spec_or_null(), s.info.md.dottable_subp
        ) and self.parent_name(root).do(
            (pn) => pn.parent_name_equation(s.expr_type(), root), default_val=%true
        )
    )
    elif not self.params().is_null then self.subprogram_equation(
        s.subp_spec_or_null(), s.info.md.dottable_subp
    ) and self.parent_name(root).do(
        (pn) => pn.parent_name_equation(s.expr_type(), root), default_val=%true
    )
    else %false

    |" Return whether this CallExpr actually represents a type conversion.
    @with_dynvars(env, origin)
    fun is_type_conversion(): Bool = not self.name is QualExpr and (
        # Directly call designated_type_impl instead of
        # name_designated_type to propagate self's origin.
        not self.name.designated_type_impl().is_null
    )

    @with_dynvars(env, origin)
    fun xref_stop_resolution(): Bool =
        self.super() or self.is_type_conversion()

    @with_dynvars(env, origin, entry_point)
    fun stop_resolution_equation(): Equation =
        if self.is_type_conversion() then self.type_conv_self_xref_equation() else self.super()

    |" Helper for xref_equation, handles construction of the equation in
    |" subprogram call cases.
    @with_dynvars(env, origin, entry_point)
    fun general_xref_equation(root: Name): Equation = if self.is_type_conversion() then (
        # Type conversion case
        (
            (
                self.type_conv_self_xref_equation() and %eq(self.params()?[0].expr().expected_type_var(), null[Entity[BaseTypeDecl]])
            ) and self.all_args_xref_equation(root)
        ) and self.parent_name(root).do(
            (pn) => pn.parent_name_equation(self.name.name_designated_type(), root), default_val=%true
        )
    )
    # Attribute ref case: we can always resolve the AttributeRef first
    # without ambiguity. This allows us to use its type in order to
    # solve the rest of the expression.
    elif self.name is AttributeRef then self.name.resolve_names_internal(false).do(
        (_) => self.all_args_xref_equation(root) and self.name.type_val().as[BaseTypeDecl].do(
            (typ) => self.parent_name_equation(typ, root), default_val={
                bind logic_context = LogicContext(
                    ref_node=self.name, decl_node=self.name.ref_var().get_value()
                );

                # If the attribute has no type, it must necessarily
                # reference a subprogram. Therefore, handle the rest as
                # if it was an entity call.
                self.entity_equation(
                    self.name.ref_var().get_value().as![BasicDecl], root
                )
            }
        ), default_val=%false
    )
    else {
        # If we are resolving this CallExpr from a DeltaAggregate, env is the
        # one of the aggregate type, so we need to bind env to self's env to
        # resolve the CallExpr params (array indicies).
        bind env = if entry_point.as[AggregateAssoc]?.as_entity
            .base_aggregate() is DeltaAggregate
        then
            self.children_env()
        else env;

        self.all_args_xref_equation(root)
    } and (
        # For each potential entity match, we want to express the
        # following constraints:
        {
            val subps = self.env_elements();

            if subps.is_null then %true else subps.logic_any(
                (s) => {
                    bind logic_context = LogicContext(ref_node=self.name, decl_node=s);

                    %eq(node.name.ref_var(), s.as[BasicDecl].corresponding_actual()) and s.as[EntryDecl].do(
                        (e) => self.entry_equation(e, root), default_val=self.entity_equation(s.as[BasicDecl], root)
                    )
                }
            )
        } and self.name.sub_equation()
        # TODO: Bug here: if operator equation, then parent equation is
        # not called!
    )

    |" Construct an equation verifying if self is conformant to the type
    |" designator passed in parameter.
    @with_dynvars(env, origin, entry_point)
    fun subscriptable_type_equation(typ: Entity[BaseTypeDecl]): Equation = {
        val atd = typ.do((t) => t.array_def_with_deref());
        val real_typ = typ.do(
            (t) => if t.is_implicit_deref() then t.accessed_type() else t
        );

        # First handle the case where this is an access to subprogram
        if typ.access_def() is AccessToSubpDef then typ.access_def().as[AccessToSubpDef].do(
            (asd) => {
                bind logic_context = LogicContext(ref_node=self.name, decl_node=typ);

                self.subprogram_equation(asd.subp_spec, false)
            }, default_val=%false
        )
        elif not atd.is_null and not atd.indices.is_null then match self.suffix {
            case _: AssocList => (
                # Either an array slice through subtype indication
                self.params()?[0].do(
                    (param) => param.expr().as[Name].do(
                        (name) => if name.name_designated_type().is_null then %false else name.xref_type_equation() and %eq(node.type_var(), real_typ), default_val=%false
                    ), default_val=%false
                )
            ) or (
                # Or a regular array access
                self.params()?.ilogic_all(
                    (pa, i) => atd.indices.constrain_index_expr(pa.expr(), i)
                ) and %eq(node.type_var(), atd.comp_type())
            )

            # Explicit slice access
            case bo: BinOp => (
                (
                    (
                        (
                            atd.indices.constrain_index_expr(bo.left, 0) and atd.indices.constrain_index_expr(bo.right, 0)
                        ) and %eq(bo.expected_type_var(), bo.right.expected_type_var())
                    ) and %eq(node.type_var(), real_typ)
                ) and bo.left.sub_equation()
            ) and bo.right.sub_equation()

            # Range attribute
            case ar: AttributeRef => (
                ar.sub_equation() and atd.indices.constrain_index_expr(ar, 0)
            ) and %eq(node.type_var(), real_typ)

            # Subtype indication
            case st: SubtypeIndication => st.sub_equation() and %eq(node.type_var(), real_typ)
            case _ => %false
        }
        # Type has user defined indexing
        elif not typ.is_null and typ.has_ud_indexing() then (
            typ.constant_indexing_fns() & typ.variable_indexing_fns()
        ).logic_any(
            (fn) => {
                val formals = fn.subp_spec_or_null().unpacked_formal_params();
                val ret_type = fn.subp_spec_or_null().return_type();
                val params = self.params();

                # The user indexing function that matches has one more
                # parameter than that call expression.
                if formals.length() == params.length() + 1 then %eq(node.type_var(), ret_type) and params.ilogic_all(
                    (param, i) => %eq(param.expr().expected_type_var(), formals?[i + 1].formal_decl().formal_type()) and param.expr().matches_expected_type()
                ) else %false
            }
        )
        else %false
    }

    @with_dynvars(env, origin, logic_context)
    fun subprogram_equation(subp_spec: Entity[BaseFormalParamHolder], dottable_subp: Bool): Equation = subp_spec.do(
        (subp_spec) => (
            # The type of the expression is the expr_type of the
            # subprogram.
            %eq(node.type_var(), subp_spec.as[BaseSubpSpec]?.return_type(), logic_ctx=logic_context) and (
                # This node represents a call to a subprogram which specification
                # is given by ``subp_spec``.
                %eq(node.subp_spec_var(), subp_spec)
            )
        ) and (
            # For each parameter, the type of the expression matches
            # the expected type for this subprogram.
            subp_spec.match_param_list(self.params(), dottable_subp).logic_all(
                (pm) => if pm.has_matched then subp_spec.call_argument_equation(
                    pm.formal.formal_decl(), pm.actual.assoc.expr()
                ) and (
                    # Bind actuals designators to parameters if there
                    # are designators.
                    if pm.actual.name.is_null then %true else %eq(pm.actual.name.ref_var(), {
                        val n = subp_spec.corresponding_actual_param(pm.formal).formal_decl();

                        self.entity_no_md(
                            n.node, n.info.rebindings, n.info.from_rebound
                        )
                    })
                ) else %false
            )
        ), default_val=%false
    )

    |" Check that self is an appropriate CallExpr for given type, which must
    |" be a subscriptable type (eg; a type for which it makes senses to do a
    |" call expr on an instance of the type, like an array type, or an access
    |" to subprogram type.
    @with_dynvars(env, origin)
    fun check_for_type(typ: Entity[BaseTypeDecl]): Bool = {
        # Algorithm: We're Recursing down call expression and component types
        # up to self, checking for each level that the call expression
        # corresponds.
        val atd = typ.do((t) => t.array_def_with_deref());

        {
            bind origin = node.origin_node();

            typ.do(
                (typ) => (
                    (
                        # Arrays
                        atd.do(
                            (_) => match node.suffix {
                                # Array indexing case
                                case al: AssocList => atd.array_ndims() == al.length()

                                # Array slice cases
                                case _: BinOp => atd.array_ndims() == 1
                                case _: SubtypeIndication => atd.array_ndims() == 1
                                case _: AttributeRef => atd.array_ndims() == 1
                                case _ => false
                            }, default_val=false
                        )
                    ) or (
                        # Accesses to subprograms
                        typ.access_def().as[AccessToSubpDef].do(
                            (sa) => sa.subp_spec.is_matching_param_list(self.params(), false)
                        )
                    ) or (
                        # Types with user defined indexing
                        typ.has_ud_indexing() and node.suffix.as[AssocList].do((al) => al.length() >= 1)
                    )
                ) and (
                    # All such `CallExpr`s shall have at least two parameters
                    # (:rmlink:`4.1.6`).
                    self.parent.as[CallExpr].do(
                        (ce) =>
                        # Since the result type of self is ``typ``, the result type of
                        # its parent CallExpr (if it exists) must be the component type
                        # of ``typ``, except in case of an array slice.
                        # Note: we use subscript=True because a CallExpr will
                        # dereference implicitly.
                        ce.check_for_type(
                            if self.check_array_slice(typ) then
                                typ
                            else
                                # TODO: see comment in Name.parent_name_equation
                                if typ.is_iterable_type() then
                                    typ.iterable_comp_type()
                                else
                                    typ.comp_type(is_subscript=true)
                        ),

                        # We are done if the parent is not a CallExpr. We could
                        # actually do more here by considering ExplicitDerefs,
                        # but this should be sufficient for the current purpose
                        # of check_for_type (e.g. to preemptively discard
                        # inadequate candidates in env_elements_impl).
                        default_val=true
                    )
                )
            )
        }
    }
}

|" Name that defines an entity (:rmlink:`3.1`).
@custom_short_image
class DefiningName: Name {
    @parse_field name: Name

    @with_dynvars(env)
    fun parent_scope(): LexicalEnv = node.name.parent_scope()

    @with_dynvars(env)
    fun scope(): LexicalEnv = node.name.scope()

    fun relative_name(): Entity[Name] = self.name.relative_name()

    fun ref_var(): LogicVar = node.name.ref_var()

    @with_dynvars(env)
    fun env_elements_impl(): Array[Entity[AdaNode]] =
        self.name.env_elements_impl()

    |" Return the parent ``BaseFormalParamDecl`` of this ``DefiningName``.
    |" Raise an error otherwise.
    fun formal_decl(): Entity[BaseFormalParamDecl] =
        self.parents().find((n) => n is BaseFormalParamDecl).as![BaseFormalParamDecl]

    |" Return the fully qualified name corresponding to this declaration, as
    |" an array of symbols.
    fun fully_qualified_name_impl(include_profile: Bool, suffix: String): Array[String] = {
        val def_name_array = match node {
            case scel: SyntheticDefiningName => [scel.name_symbol().image()]
            case n => n.as_single_tok_node_array().map((t) => t.text())
        };
        val bd = self.basic_decl();
        val self_name = def_name_array.imap((t, i) =>
            t
            & (if include_profile then bd.custom_id_text() else "")
            & (if i == def_name_array.length() - 1 then suffix else "")
        );
        val parent_decl = bd.parent_basic_decl();
        val is_instantiated = (bd is GenericDecl | Body)
            and parent_decl is GenericInstantiation;
        val fqn = if not is_instantiated and bd.is_compilation_unit_root() then
            self_name
        else
            parent_decl?.fully_qualified_name_string_array(
                include_profile=include_profile
            ).do((fqn) =>
                # If we were on an instantiated generic declaration, we don't
                # want to include the name of the generic but the name of the
                # instance (which is `fqn`).
                if is_instantiated then fqn else fqn & self_name
            );

        bd.parent.as[Subunit].do(
            (su) => su.name.as_single_tok_node_array()
        ).map((t) => t.text()) & fqn or? fqn
    }

    |" Implementation of canonical_fully_qualified_name.
    fun canonical_fully_qualified_name_impl(include_profile: Bool, suffix: String): String = ".".join(self.fully_qualified_name_impl(
        include_profile=include_profile, suffix=suffix
    )
    # Map to symbol & back to canonicalize
    .map((t) => t.to_symbol).map((t) => t.image()))

    |" Implementation for unique_identifying_name.
    fun unique_identifying_name_impl(suffix: String): String = match self.basic_decl() {
        case atd: AnonymousTypeDecl => atd.custom_id_text()
        case _ => self.canonical_fully_qualified_name_impl(include_profile=true, suffix=suffix)
    }

    |" Return a canonical representation of the fully qualified name
    |" corresponding to this defining name.
    @exported
    fun canonical_fully_qualified_name(): String =
        self.canonical_fully_qualified_name_impl(include_profile=false, suffix="")

    |" Return a unique identifying name for this defining name, provided this
    |" declaration is a public declaration. In the case of subprograms, this
    |" will include the profile.
    |"
    |" .. attention::
    |"     This will only return a unique name for public declarations.
    |"     Notably, anything nested in an unnamed declare block won't be
    |"     handled correctly.
    @exported
    fun unique_identifying_name(): String =
        self.unique_identifying_name_impl(suffix="")

    |" Return the fully qualified name corresponding to this defining name, as
    |" an array of symbols.
    @exported
    fun fully_qualified_name_array(): Array[Symbol] =
        self.fully_qualified_name_impl(include_profile=false, suffix="").map((t) => t.to_symbol)

    |" Return the fully qualified name corresponding to this defining name.
    @exported
    fun fully_qualified_name(): String =
        ".".join(self.fully_qualified_name_impl(include_profile=false, suffix=""))

    @with_dynvars(env, origin)
    fun all_env_els_impl(seq: Bool = true, seq_from: AdaNode = null[AdaNode], categories: RefCategories = RefCategories(_=true)): Array[Entity[AdaNode]] =
        self.name.all_env_els_impl(seq, seq_from, categories)

    |" Return this DefiningName's basic declaration, discarding internal nodes such as Generic*Internal wrappers
    @exported
    fun basic_decl(): Entity[BasicDecl] = self.basic_decl_internal().do(
        (bd) => if bd is GenericPackageInternal | GenericSubpInternal | SingleTaskTypeDecl then bd.parent.as![BasicDecl] else bd
    )

    |" Return this DefiningName's basic declaration, but do not bypass internal nodes (such as Generic*Internal wrappers)
    @memoized
    fun basic_decl_internal(): Entity[BasicDecl] =
        self.parents().find((p) => p is BasicDecl).as![BasicDecl]

    |" Find all references to this defining name in the given ``root`` and its
    |" children.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun find_refs(root: Entity[AdaNode]): Array[RefResult] =
        self.canonical_part().find_refs_impl(root, node)

    |" Internal implementation for find_refs. Find all references to self in
    |" the given ``root``. The ``skip_name`` is used to filter out a
    |" DefiningName from the result (typically, the name of self in order to
    |" avoid to report a reference to itself).
    @with_dynvars(imprecise_fallback)
    fun find_refs_impl(root: Entity[AdaNode], skip_name: DefiningName): Array[RefResult] =
        # TODO: Factor the traversal between this and `find_derived_types`
        root.children.do(
            (c) => c.filter(
                (n) => not (n.is_null or n.node == skip_name)
            ).mapcat((n) => self.find_refs_impl(n, skip_name))
        ) & root.as[BaseId].do(
            (id) => self.is_referenced_by(id).do(
                (ref_kind) => if ref_kind in RefResultKind.precise | RefResultKind.imprecise then [RefResult(ref=id, kind=ref_kind)] else null[Array[RefResult]]
            )
        )

    |" Return whether this is a name that defines an "=" operator which
    |" implicitly declares an "/=" operator giving the complementary result,
    |" which is True iff this "=" declaration returns a Boolean
    |" (:rmlink:`6.6` 6/3).
    @memoized
    fun is_derivable_equal(): Bool =
        node.name_is(s"\"=\"") and self.basic_decl().subp_spec_or_null().do(
            (s) => s.returns()?.designated_type_decl() == self.bool_type()
        )

    |" Return whether the given symbol could be a reference to this defining
    |" name.
    @memoized
    fun is_potential_reference(symbol: Symbol): Bool = node.name_is(symbol) or (
        self.is_derivable_equal() and symbol == s"\"/=\""
    )

    |" Returns True iff the given node is an identifier referring to self.
    |" Note that this takes into account both direct references as well as
    |" potential references.
    |"
    |" Potential references can occur in the context of dispatching calls: an
    |" identifier having for direct reference the declaration of an
    |" overridable subprogram is considered a potential reference to all
    |" subprograms that override it if the identifier appears in a dispatching
    |" call.
    @with_dynvars(imprecise_fallback=false)
    fun is_referenced_by(id: Entity[BaseId]): RefResultKind =
        if self.is_potential_reference(id.name_symbol()) then (
            if id.is_defining() then RefdDef(
                def_name=id.enclosing_defining_name(), kind=RefResultKind.precise
            ) else id.failsafe_referenced_def_name()
        ).do(
            (def_res) => {
                val canon = def_res.def_name?.canonical_part()?.node;

                if (
                    # Either `id` is a direct reference
                    node == canon
                ) or (
                    # Or `id` refers to one of the base subprograms of
                    # defined by self, and `x` appears in a dispatching
                    # call context.
                    self.basic_decl().base_subp_declarations().do(
                        (decls) => decls.any((d) => d.defining_name().node == canon) and id.is_dispatching_call()
                    )
                ) then def_res.kind else RefResultKind.no_ref
            }
        ) else RefResultKind.no_ref

    |" Searches all references to this defining name in the given list of
    |" units.
    |"
    |" If ``follow_renamings`` is True, also this also includes references
    |" that ultimately refer to this defining name, by unwinding renaming
    |" clauses.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun find_all_references(units: Array[AnalysisUnit], follow_renamings: Bool = false): Array[RefResult] = {
        val dn = self.canonical_part();
        # If `dn` defines a subprogram which overrides some subprogram P, we
        # need to do the unit filtering from the declaration of P so that we
        # don't omit units in which we may have potential references to self
        # through dispatching calls. This is valid because all units that would
        # import `dn` will necessarily import `base` as well, as `dn`
        # necessarily imports `base` to define its overriding subprogram.
        # This only works if filter_is_imported_by is called with transitive
        # set to True.
        val bases = {
            bind origin = node;

            dn.basic_decl().root_subp_declarations() or? [dn.basic_decl()]
        };
        val all_units = bases.mapcat(
            (base) => base.filter_is_imported_by(units, true)
        ).unique();
        val refs = all_units.mapcat(
            (u) => u.root.do(
                (r) => dn.find_refs_impl(r.as_bare_entity, node)
            )
        );

        if follow_renamings then refs & refs.filter(
            (f) => f.ref.parents().find((p) => p is RenamingClause).as[RenamingClause].do(
                (r) => r.renamed_object.referenced_defining_name().canonical_part().node == dn.node
            )
        ).mapcat(
            (f) => f.ref.parents().find((p) => p is RenamingClause).parent.as![BasicDecl].do(
                (bd) =>
                # Get the all renaming clauses *for which the renamed
                # entity is self* (it is possible to find a reference
                # inside a renaming clause but that this clause does not
                # rename self, such as `X` in  `... renames X.Y`, in which
                # case we don't want to recursively find its references!).
                # Since a renaming clause is always part of a BasicDecl,
                # retrieve the BasicDecl from the renaming clauses and
                # recursively find all references on those.
                bd.defining_name().find_all_references(units=units, follow_renamings=true)
            )
        ) else refs
    }

    |" Helper for navigation proxies. Will return the defining name matching
    |" self on the given BasicDecl.
    fun find_matching_name(bd: Entity[BasicDecl]): Entity[DefiningName] = bd?.defining_names().find(
        (di) => self.name.name_is(di.name_symbol())
    )

    |" Return the list of all possible calls to the subprogram which self is
    |" the defining name of.
    |"
    |" This will return the name corresponding to the call, excluding the
    |" parameters if there are any. For instance, it will return ``A`` for the
    |" ``A (B)`` call.
    |"
    |" .. note:: This does not yet support calls done inside generics.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun find_all_calls(units: Array[AnalysisUnit], follow_renamings: Bool = false): Array[RefResult] =
        self.find_all_references(units, follow_renamings).filter((r) => r.ref.is_direct_call())

    |" Like ``BasicDecl.next_part_for_decl`` on a defining name
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun next_part(): Entity[DefiningName] = self.find_matching_name(
        self.basic_decl().next_part_for_name(self.name_symbol())
    )

    |" Like ``BasicDecl.previous_part_for_decl`` on a defining name
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun previous_part(): Entity[DefiningName] = self.find_matching_name(
        self.basic_decl().previous_part_for_name(self.name_symbol())
    )

    |" Like ``BasicDecl.canonical_part`` on a defining name
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun canonical_part(): Entity[DefiningName] = self.find_matching_name(
        self.basic_decl().canonical_part_for_name(self.name_symbol())
    )

    |" Given an origin node and the entity represented by self, this property
    |" returns the most visible completion of self that can be seen by origin,
    |" according to Ada's visibility rules.
    @exported
    @with_dynvars(origin, imprecise_fallback=false)
    fun most_visible_part(): Entity[DefiningName] = self.find_matching_name(
        self.basic_decl().most_visible_part_for_name(self.name_symbol())
    )

    |" Return all previous parts of this entity, where the first part
    |" is at the beginning of the array.
    @with_dynvars(imprecise_fallback=false)
    fun all_previous_parts(): Array[Entity[DefiningName]] = self.previous_part().do(
        (pp) => if self == pp then null[Array[Entity[DefiningName]]] else pp.all_previous_parts() & [pp]
    )

    |" Return all next parts of this entity, where the last part is at the
    |" end of the array.
    @with_dynvars(imprecise_fallback=false)
    fun all_next_parts(): Array[Entity[DefiningName]] = self.next_part().do(
        (np) => if self == np then null[Array[Entity[DefiningName]]] else [np] & np.all_next_parts()
    )

    |" Return all parts that define this entity, sorted from first part to
    |" last part.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun all_parts(): Array[Entity[DefiningName]] = {
        val prevs = self.all_previous_parts();
        val nexts = self.all_next_parts();

        prevs & [self] & nexts
    }

    |" Return the aspect with the name ``name`` associated to this specific
    |" entity part.
    @with_dynvars(imprecise_fallback=false)
    fun get_aspect_impl(name: Symbol, inherited: Bool): Aspect = (
        (
            self.get_pragma(name).do((p) => p.as_aspect(inherited)) or? self.basic_decl_internal().get_aspect_assoc(name).do(
                (aa) => Aspect(
                    exists=true, node=aa, value=aa.expr, inherited=inherited
                )
            )
        ) or? self.get_representation_clause(name).do(
            (rc) => Aspect(
                exists=true, node=rc, value=rc.expr, inherited=inherited
            )
        )
    ) or? (
        if name == s"Address" then self.get_at_clause().do(
            (atc) => Aspect(
                exists=true, node=atc, value=atc.expr, inherited=inherited
            )
        ) else null[Aspect]
    )

    |" Return the aspect with name ``name`` associated to entity that this
    |" name defines.
    |"
    |" First, check for aspect on all parts of entity (``previous_parts_only``
    |" can be used to restrict the search to entity and its previous part to
    |" comply with visibility rules).
    |"
    |" If no aspect if found on entity, recursively check for it on its
    |" parents.
    @with_dynvars(imprecise_fallback=false)
    fun get_aspect_on_parts(name: Symbol, inherited: Bool, previous_parts_only: Bool): Aspect = {
        val parts_to_check = # SPARK_Mode has its own logic (see `is_spark`). For instance, if
        # defined on a body, it doesn't apply to the corresponding
        # specification, and conversely. Only consider the current part
        # when looking for it.
        if name == s"SPARK_Mode" then [self]
        elif previous_parts_only then [self] & self.all_previous_parts()
        else self.all_parts();
        val self_aspects = # The following aspects only support the Ada 2012 aspect
        # association syntax, so use a faster path to avoid looking
        # for pragmas and representation clauses for them as they are
        # often queried during name resolution.
        if name in s"Implicit_Dereference" | s"Constant_Indexing" | s"Variable_Indexing" | s"Iterable" | s"Iterator_Element" | s"Integer_Literal" | s"Real_Literal" | s"String_Literal" then parts_to_check.map(
            (p) => p.basic_decl_internal().get_aspect_assoc(name).do(
                (aa) => Aspect(
                    exists=true, node=aa, value=aa.expr, inherited=inherited
                )
            )
        )
        else parts_to_check.map(
            (p) => p.get_aspect_impl(name, inherited)
        );

        self_aspects.find((a) => a.exists) or? self.basic_decl().as[BaseTypeDecl].do(
            (bd) => {
                # If nothing has been found so far for entity, check out for
                # any inherited aspect.
                val typ = if bd is BaseSubtypeDecl then bd.as[BaseSubtypeDecl].get_type() else bd.base_type();

                if typ.is_null or typ == bd then null[Aspect] else typ.name.get_aspect_on_parts(
                    name, inherited=true, previous_parts_only=previous_parts_only
                )
            }
        )
    }

    |" Return the aspect with name ``name`` associated to entity that this
    |" name defines.
    |"
    |" Aspects are properties of entities that can be specified by the Ada
    |" program, either via aspect specifications, pragmas, or attributes.
    |"
    |" Note: by default, Libadalang will check if the aspect is defined on any
    |" part of the entity. However, the ``previous_parts_only`` parameter can
    |" be set to True to limit the search to the current entity and its
    |" previous parts in order to comply with visibilily rules. That way, if
    |" an aspect is defined on the private part of a type, calling this
    |" property on its corresponding public view won't return the aspect
    |" unlike the call on the private view.
    |"
    |" Moreover, since aspects can be inherited, if none was found for the
    |" current entity, Libadalang will also search for the aspect on the
    |" parents of entity (in that case the ``inherited`` field will be set
    |" to ``True`` in the returned result).
    @exported
    @memoized
    @with_dynvars(imprecise_fallback=false)
    fun get_aspect(name: Symbol, previous_parts_only: Bool = false): Aspect =
        self.get_aspect_on_parts(name, false, previous_parts_only)

    |" Returns whether the boolean aspect named ``name`` is set on the entity
    |" represented by this node.
    |"
    |" Note: The ``previous_parts_only`` parameter controls how aspects are
    |" retrieved. See ``DefiningName.get_aspect`` for more information.
    |"
    |" Aspects are properties of entities that can be specified by the Ada
    |" program, either via aspect specifications, pragmas, or attributes.
    |"
    |" "Aspect" is used as in RM terminology (see :rmlink:`13.1`).
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun has_aspect(name: Symbol, previous_parts_only: Bool = false): Bool = {
        val a = self.get_aspect(name, previous_parts_only);

        a.exists and (
            if node.is_contract_aspect(name) then (
                # We don't want to evaluate the predicate condition to determine
                # if its present.
                true
            ) else a.value.do(
                (value) => (
                    # Only check the value of the expression if it is determined to
                    # be of a boolean type, so we don't erroneously try to cast a
                    # value to bool when it would be wrong.
                    value.expression_type() != node.bool_type()
                ) or value.eval_as_int() == 1b, default_val=true
            )
        )
    }

    |" Helper property for ``get_pragma``. Used to check that ``decl`` is a
    |" pragma declaration that has the given name and is a valid pragma for
    |" the entity defined by this defining name.
    fun is_valid_pragma_for_name(name: Symbol, decl: Entity[AdaNode]): Bool = decl.as[Pragma].do(
        (p) => (
            # Check pragma's name
            p.id.name_is(name)
        ) and (
            # Check that it's associated to self
            not p.associated_entities().find((d) => self == d).is_null
        ) and (
            # Check that the pragma is after the decl
            node < p.node
        )
    )

    |" Given an array of regions in which to look for pragmas for this entity,
    |" search through all of them in sequence until finding a pragma of the
    |" given name. This is functionnally equivalent to flattening the array of
    |" regions and then finding the pragma, but this implementation avoids
    |" eagerly creating the big flattened array of nodes.
    fun find_valid_pragma_for_name(name: Symbol, regions: Array[Entity[ASTList[AdaNode]]], region_index: Int = 0): Entity[Pragma] = regions?[region_index].do(
        (r) => r.find(
            (d) => self.is_valid_pragma_for_name(name, d)
        ).as[Pragma] or? self.find_valid_pragma_for_name(name, regions, region_index + 1)
    )

    |" Return the pragma with name ``name`` associated to this entity.
    |"
    |" Please use the ``p_get_aspect`` property instead if you are interested
    |" in aspects, i.e. information that can be represented by either aspect
    |" specification nodes, pragma nodes or attribute definition nodes.
    @exported
    fun get_pragma(name: Symbol): Entity[Pragma] = {
        val bd = match self.basic_decl() {
            # If self is an EnumLiteralDecl, search the pragma from the enum
            # type declaration node.
            case eld: EnumLiteralDecl => eld.parent.parent.parent.as![BasicDecl]
            case o => o
        };

        # First look at library level pragmas if self is a library item
        bd.library_item_pragmas().do(
            (plist) => plist.find(
                # Check pragma's name
                (p) => p.id.name_is(name)
            )
        ) or? # Else check in the surrounding regions of this entity
        self.find_valid_pragma_for_name(name, bd.pragma_regions())
    }

    |" Return the representation clause associated to this entity that
    |" defines the given attribute name.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun get_representation_clause(name: Symbol): Entity[AttributeDefClause] = self.declarative_scope()?.decls.as_entity.find(
        (d) => d.as[AttributeDefClause].do(
            (p) => {
                val attr = p.attribute_expr.as![AttributeRef];

                attr.attribute.name_is(name) and attr.prefix.referenced_defining_name() == self
            }
        )
    ).as[AttributeDefClause]

    |" Return the at clause associated to this entity.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun get_at_clause(): Entity[AtClause] = self.declarative_scope()?.decls.as_entity.find(
        (d) => d.as[AtClause].do(
            (p) => p.name.referenced_defining_name() == self
        )
    ).as[AtClause]

    |" Return all the ``Annotate`` aspects associated to this specific entity
    |" part.
    @with_dynvars(imprecise_fallback=false)
    fun get_annotations_impl(): Array[Aspect] = {
        val bd = self.basic_decl_internal();
        # Gather aspects defined by pragmas
        val pragmas = match bd {
            # If self is an EnumLiteralDecl, search the pragma from the enum
            # type declaration node.
            case eld: EnumLiteralDecl => eld.parent.parent.parent.as![BasicDecl]
            case o => o
        }.pragma_regions().mapcat(
            (r) => r.filtermap(
                (d) => Aspect(
                    exists=true, node=d, value=d.as[Pragma].args?[0].assoc_expr(), inherited=false
                ), (d) => self.is_valid_pragma_for_name(s"Annotate", d)
            )
        );
        # But also those defined with aspect associations
        val aspects = bd.get_aspect_spec()?.aspect_assocs.filtermap(
            (asp) => Aspect(
                exists=true, node=asp, value=asp.expr.as[BaseAggregate].assocs?[0].expr(), inherited=false
            ), (asp) => asp.id.name_is(s"Annotate")
        );

        pragmas & aspects
    }

    |" Return all the ``Annotate`` aspects defined on this entity, both
    |" through pragmas and aspect specifications. For a type declaration,
    |" this also includes all annotations defined on its base type,
    |" when relevant (the field ``inherited`` will be set for those).
    |"
    |" The ``value`` field of each returned ``Aspect`` will be set to be the
    |" identifier that designates the tool which is concerned by the
    |" annotation.
    |"
    |" Note: Libadalang will look for the ``Annotate`` aspects on any part of
    |" the entity.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun get_annotations(): Array[Aspect] = {
        val self_annotations = self.all_parts().mapcat((p) => p.get_annotations_impl());
        val inherited_annotations = self.basic_decl().as[BaseTypeDecl].do(
            (bd) => {
                val typ = if bd is BaseSubtypeDecl then bd.as[BaseSubtypeDecl].get_type() else bd.base_type();

                if typ.is_null or typ == bd then null[Array[Aspect]] else typ.name.get_annotations().map(
                    (a) => Aspect(
                        exists=a.exists, node=a.node, value=a.value, inherited=true
                    )
                )
            }
        );
        val config_annotations = self.enclosing_compilation_unit().config_pragmas(s"Annotate").map(
            (p) => Aspect(
                exists=true, node=p, value=p.args?[0].assoc_expr(), inherited=false
            )
        );

        # We use `.unique` because for declarations split in multiple parts,
        # a pragma Annotate may be associated to all of them, and since
        # we concatenate aspects from all parts, we might end up with the
        # same pragma multiple times. Also, since we recursively look on base
        # types, we might end up with the same configuration pragmas.
        (
            self_annotations & inherited_annotations & config_annotations
        ).unique()
    }

    |" Whether this entity defined by this name is imported from another
    |" language.
    @exported
    fun is_imported(): Bool =
        self.has_aspect(s"Import") or self.has_aspect(s"Interface")

    |" Return whether the entity defined by this name is ghost or not.
    |" See SPARK RM 6.9.
    @exported
    @memoized
    fun is_ghost_code(): Bool = {
        val bd = self.basic_decl();

        self.has_aspect(s"Ghost") or bd.parent_basic_decl()?.is_ghost_code() or (
            # Instantiation of generic ghost entity is ghost code
            bd.as[GenericInstantiation].do(
                (gi) => gi.designated_bare_generic_decl().is_ghost_code()
            )
        ) or (
            # Renaming of ghost entity is ghost code
            match bd {
                case sr: SubpRenamingDecl => sr.renames.renamed_object
                case pr: PackageRenamingDecl => pr.renames.renamed_object
                case gr: GenericRenamingDecl => gr.renaming_name()
                case _ => null[Entity[Name]]
            }.do(
                (c) => c.referenced_defining_name()?.is_ghost_code()
            )
        )
    }

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        # The name field of a defining name must be an Identifier or a
        # DottedName. So we can special case the construction of the xref
        # equation here.
        self.name.as[DottedName].do(
            (dn) => {
                # In case this name denotes a package/library level
                # task/procedure name, it must be resolved as seen from the
                # standard package (same logic as for EndName).
                bind env = self.std_env();

                dn.prefix.xref_equation()
            }, default_val=%true
        )

    # There are names to resolve in a defining name only if its name field is
    # a dotted name, in which case we must resolve its prefix.
    fun xref_entry_point(): Bool = node.name is DottedName
}

|" Synthetic DefiningName.
@synthetic
class SyntheticDefiningName: DefiningName {
    # It is not possible to override Name.relative_name (which name_symbol is
    # defined in terms of), so we override name_symbol directly.
    fun name_symbol(): Symbol = node.name.name_symbol()

    fun as_symbol_array(): Array[Symbol] = [node.name_symbol()]
}

|" Subtype name for membership test expressions (:rmlink:`3.6`).
class DiscreteSubtypeName: Name {
    @parse_field subtype: DiscreteSubtypeIndication
}

|" Name to select a suffix in a prefix (:rmlink:`4.1.3`).
class DottedName: Name {
    @parse_field prefix: Name
    @parse_field suffix: BaseId

    fun ref_var(): LogicVar = node.suffix.ref_var()

    fun subp_spec_var(): LogicVar = node.suffix.subp_spec_var()

    fun defines_subp_spec_var(): Bool = true

    fun has_context_free_type(): Bool = not node.suffix is CharLiteral

    @with_dynvars(origin)
    fun complete_items(): Array[CompletionItem] = {
        bind origin = node.origin_node();
        bind env = node.node_env();
        val complete_env = {
            bind no_visibility = true;
            self.prefix.designated_env()
        };
        val visible_env = {
            bind no_visibility = false;
            self.prefix.designated_env()
        };
        # In completion we always want to return everything, and flag invisible
        # things as invisible, so we first query `complete_env` to discover all
        # possible items, and then check whether they are actually visible by
        # querying `visible_env`.
        node.env_get_public(
            complete_env, null[Symbol], LookupKind.flat
        ).filtermap(
            (n) => CompletionItem(
                decl=n.as[BasicDecl],
                is_dot_call=n.info.md.dottable_subp,
                is_visible=(
                    # Dottable subprograms are always visible
                    n.info.md.dottable_subp
                ) or (
                    # Else check visibility on the unit containing n
                    node.has_visibility(n)
                    and node.env_get_public(
                        visible_env,
                        n.as[BasicDecl].name_symbol(),
                        LookupKind.flat
                    ).contains(n)
                ),
                weight=self.complete_item_weight(n.as[BasicDecl])
            ), (n) => (
                # Filter elements that are coming from a body that is not
                # visible. This can happen with dottable subprograms
                # defined in bodies.
                # NOTE: We also filter `PrivatePart`s here as they are
                # useless from the completion point of view.
                # Order matters here, `has_visibility` below should not
                # be called with n being a PrivatePart.
                not n is PrivatePart
            ) and (
                n.owning_unit_kind() == AnalysisUnitKind.unit_specification
                or node.has_visibility(n)
            )
        )
    }

    @with_dynvars(origin)
    fun complete_item_weight(item: Entity[BasicDecl]): Int =
        # Give components and discriminants the highest weigth
        if item is ComponentDecl | DiscriminantSpec then 100
        # Then, promote primitives
        elif item is BasicSubpDecl | BaseSubpBody then 75
        # Treat everything else the default way
        else self.super(item)

    @with_dynvars(env, origin, no_visibility=false)
    fun designated_env_no_overloading(): LexicalEnv = {
        val pfx_env = self.prefix.designated_env_no_overloading();

        {
            bind env = pfx_env;

            self.suffix.designated_env_no_overloading()
        }
    }

    @with_dynvars(env, origin, no_visibility=false)
    fun designated_env(): LexicalEnv = {
        val pfx_env = self.prefix.designated_env();

        {
            bind env = pfx_env;

            self.suffix.designated_env()
        }
    }

    @with_dynvars(env, origin)
    fun all_env_els_impl(seq: Bool = true, seq_from: AdaNode = null[AdaNode], categories: RefCategories = RefCategories(_=true)): Array[Entity[AdaNode]] = {
        val pfx_env = self.prefix.designated_env();

        {
            bind env = pfx_env;

            self.suffix.all_env_els_impl(seq, seq_from, categories)
        }
    }

    @with_dynvars(env)
    fun scope(): LexicalEnv = node.suffix.do(
        (sfx) => {
            bind env = node.parent_scope();

            sfx.scope()
        }, default_val=null[LexicalEnv]
    )

    @with_dynvars(env)
    fun parent_scope(): LexicalEnv = node.prefix.scope()

    fun relative_name(): Entity[Name] = self.suffix.relative_name()

    @with_dynvars(env)
    fun env_elements_impl(): Array[Entity[AdaNode]] = {
        val pfx_env = {
            bind origin = node.origin_node();

            self.prefix.designated_env()
        };

        {
            bind env = pfx_env;

            self.suffix.env_elements_impl()
        }
    }

    @with_dynvars(env, origin)
    fun designated_type_impl(): Entity[BaseTypeDecl] = {
        bind env = self.prefix.designated_env_no_overloading();

        self.suffix.designated_type_impl()
    }

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        val base = self.prefix.sub_equation() and {
            bind env = self.prefix.designated_env();

            self.suffix.sub_equation()
        };

        if not self.designated_type_impl().is_null then base else (
            (
                base and %eq(node.expected_type_var(), node.suffix.expected_type_var())
            ) and %eq(node.type_var(), node.suffix.type_var())
        ) and self.env_elements().do(
            (env_els) => env_els.logic_any((e) => {
                val actual = e.as[BasicDecl].corresponding_actual();
                %eq(node.suffix.ref_var(), actual)
                and actual.constrain_prefix(node.prefix)
            }), default_val=self.undefined_reference_equation()
        )
    }

    fun is_constant(): Bool =
        # A dotted name references a constant object if the prefix or the
        # suffix does.
        self.prefix.is_constant() or self.suffix.is_constant()
}


|" Name for an array subcomponent choice of a deep delta aggregate.
class ArraySubcomponentChoiceName: Name {
    # This node can basically be seen as a CallExpr where `name` can be a null
    # node.

    # The name field can be null when the ArraySubcomponentChoiceName is of the
    # form "(suffix)" (where suffix is a list of expression: "expr{, expr}"
    # representing the indexes of a mono- or multi-dimentional array, or a
    # range). When the node is of the form of "name (suffix)", name can only be
    # another ArraySubcomponentChoiceName or a DottedName.
    @parse_field @nullable name: Name
    @parse_field suffix: AdaNode

    fun suffix_exprs(): Array[Entity[Expr]] =
        self.suffix.as![AssocList].map(
            (a) => a.as![ParamAssoc].expr()
        )

    |" Return the corresponding delta aggregate's ancestor expression type.
    @memoized
    fun delta_aggregate_ancestor_expr_type(): Entity[BaseTypeDecl] =
        node.parents(with_self=false).find(
            (p) => p is DeltaAggregate
        ).as[DeltaAggregate].ancestor_expr.as_bare_entity.expression_type()

    fun ref_var(): LogicVar =
        node.as_bare_entity.delta_aggregate_ancestor_expr_type().name.ref_var()

    fun name_symbol(): Symbol =
        node.name.do(
            (n) => n.name_symbol()
        )

    fun xref_equation(): Equation =
        # Resolve name if any
        self.name.do(
            (n) => n.sub_equation(), default_val=%true
        ) and (
            self.suffix_exprs().ilogic_all(
            # Resolve all suffix's indexes/range independently
            (a, i) => a.sub_equation()
            and %eq(a.expected_type_var(),
                    node.delta_aggregate_ancestor_expr_type().index_type(i))
            and a.matches_expected_type()
        )) and (
            # Self's type is bound to the component type of Self's name
            # designated type if any (if name is null, the type is given by the
            # delta aggregate itself).
            if self.name is DottedName
            then %eq(self.type_var(), self.name.type_var(),
                     conv_prop=BaseTypeDecl.comp_type)
            else %eq(self.type_var(),
                     self.name.do(
                         (n) => n.name_designated_type().comp_type(),
                         default_val=
                         node.delta_aggregate_ancestor_expr_type().comp_type()
                     )
                )
        )

    fun designated_type_impl(): Entity[BaseTypeDecl] =
        self.name.do(
            (n) => n.designated_type_impl(),
            default_val=node.delta_aggregate_ancestor_expr_type().comp_type()
        )

    fun designated_env(): LexicalEnv =
        self.name.do(
            (n) => n.name_designated_type().defining_env(),
            default_val={
                bind include_ud_indexing = false;

                node.delta_aggregate_ancestor_expr_type().defining_env()
            }
        )
}


|" self name in ``end ...;`` syntactic constructs.
class EndName: Name {
    @parse_field name: Name

    @with_dynvars(env)
    fun parent_scope(): LexicalEnv = node.name.parent_scope()

    @with_dynvars(env)
    fun scope(): LexicalEnv = node.name.scope()

    fun relative_name(): Entity[Name] = self.name.relative_name()

    fun ref_var(): LogicVar = node.name.ref_var()

    @with_dynvars(env)
    fun env_elements_impl(): Array[Entity[AdaNode]] =
        self.name.env_elements_impl()

    |" Returns this EndName's basic declaration
    @exported
    @memoized
    fun basic_decl(): Entity[BasicDecl] =
        node.parents().find((p) => p is BasicDecl | NamedStmt).do(
            (p) => if p is BasicDecl then p.as[BasicDecl].as_entity else p.as![NamedStmt].decl.as_entity
        )

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = self.parent.as[AcceptStmtWithStmts].do(
        (stmt) => %eq(node.ref_var(), stmt.designated_entry()), default_val=%eq(node.ref_var(), self.basic_decl())
    ) and self.name.as[DottedName].do(
        # Also resolve the prefix of the dotted name, in case this
        # subprogram/package is a child unit: the fully qualified name must
        # be resolved as seen from the standard package.
        (dn) => {
            bind env = self.std_env();

            dn.prefix.xref_no_overloading()
        }, default_val=%true
    )

    fun xref_entry_point(): Bool = true
}

|" Explicit dereference expression (``.all``) (:rmlink:`4.1`).
class ExplicitDeref: Name {
    @parse_field prefix: Name
    r_called_spec: LogicVar

    fun ref_var(): LogicVar = node.prefix.ref_var()

    fun subp_spec_var(): LogicVar = node.r_called_spec

    fun defines_subp_spec_var(): Bool = true

    fun relative_name(): Entity[Name] = self.prefix.relative_name()

    @with_dynvars(env, origin, no_visibility=false)
    fun designated_env(): LexicalEnv =
        # Since we have implicit dereference in Ada, everything is directly
        # accessible through the prefix, so we just use the prefix's env.
        self.prefix.designated_env()

    @with_dynvars(env)
    fun env_elements_impl(): Array[Entity[AdaNode]] =
        self.prefix.env_elements_impl()

    @with_dynvars(env, origin)
    fun eq_for_type(typ: Entity[BaseTypeDecl]): Equation = if typ.is_access_type() then (
        %eq(node.prefix.expected_type_var(), typ) and self.prefix.matches_expected_type()
    ) and %eq(node.type_var(), typ.accessed_type()) else %false

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = self.bottom_up_name_equation()

    @with_dynvars(env, origin, entry_point)
    fun general_xref_equation(root: Name = null[Name]): Equation =
        # Attribute ref case: we can always resolve the AttributeRef first
        # without ambiguity. This allows us to use its type in order to
        # solve the rest of the expression.
        self.all_args_xref_equation(root)
        and if self.prefix is AttributeRef then
            self.prefix.resolve_names_internal(false).do(
                (_) => self.prefix.type_val().as[BaseTypeDecl].do(
                    (typ) => (
                        %eq(node.prefix.expected_type_var(), typ)
                        and %eq(node.prefix.type_var(), typ)
                        and self.parent_name_equation(typ, root)
                    ),
                    default_val=%false
                ),
                default_val=%false
            )
        else (
            self.prefix.sub_equation()
            and self.env_elements().logic_any(
                (el) => {
                    val typ = el.as[BasicDecl].expr_type();
                    if typ?.is_access_type() then
                        %eq(node.prefix.ref_var(), el)
                        and self.parent_name_equation(typ, root)
                    else
                        %false
                }
            )
        )

    fun is_constant(): Bool =
        # The dereference expression is constant if its access type is
        # constant.
        {
            bind origin = node;

            self.prefix.expression_type()?.access_def().as[TypeAccessDef]?.has_constant.as_bool()
        }
}

|" Qualified expression (``...'(...)``) .(:rmlink:`4.7`).
class QualExpr: Name {
    @parse_field prefix: Name
    @parse_field suffix: Expr

    fun ref_var(): LogicVar = node.prefix.ref_var()

    fun relative_name(): Entity[Name] = self.prefix.relative_name()

    fun is_constant(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun general_xref_equation(root: Name = null[Name]): Equation =
        self.xref_equation() and self.all_args_xref_equation(root) and self.parent_name(root).do(
            (pn) => pn.parent_name_equation(self.prefix.designated_type_impl(), root), default_val=%true
        )

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = (
        (
            (
                self.prefix.xref_type_equation() and self.suffix.sub_equation()
            ) and %eq(node.suffix.expected_type_var(), node.prefix.ref_var())
        ) and self.suffix.matches_expected_type()
    ) and (
        # A qualified expression that appears as a statement
        # denotes a machine code insertion, in GNAT, it is parsed
        # as a parameterless procedure call. In that case,
        # self.type_var shouldn't denote any type. Note that we are
        # more flexible than Ada since we allow any type to be code
        # statements whereas Ada restricts that to types defined in
        # package `System.Machine_Code` (see :rmlink:`13.8`).
        if self.parent is CallStmt then %true else %eq(node.type_var(), node.prefix.ref_var())
    )

    @with_dynvars(env, origin, no_visibility=false)
    fun designated_env(): LexicalEnv =
        self.prefix.name_designated_type().defining_env()

    @with_dynvars(env)
    fun env_elements_impl(): Array[Entity[AdaNode]] =
        self.prefix.env_elements_impl()
}

|" Reduction expression (``Reduce`` attribute). Ada 2022, RM 4.5.10.
class ReduceAttributeRef: Name {
    @parse_field prefix: AdaNode
    @parse_field attribute: Identifier
    @parse_field args: AssocList
    r_ref_var: LogicVar

    fun ref_var(): LogicVar = node.r_ref_var

    |" Return the nameres equation for the Reduce attribute:
    |" ``Expr'Reduce (Reducer, InitVal)``
    |" where Expr is either a ``Name`` or a ``SequenceValue`` denoting a
    |" collection to reduce, ``Reducer`` is the subprogram to use to perform
    |" the reduction and ``InitVal`` is the initial value to be used by the
    |" reducer.
    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        val reducer = self.args?[0].expr();

        node.env_get(
            env=env, symbol=reducer.as[BaseId].sym(), from_node=node.origin_node()
        ).logic_any(
            (subp) => subp.as[BasicDecl].do(
                (bd) => bd.is_valid_reducer_candidate().do(
                    (_) => self.xref_equation_for_reducer_candidate(subp.as[BasicDecl]), default_val=%false
                ), default_val=%false
            )
        )
    }

    |" Build the equation for a reducer candidate.
    @with_dynvars(env, origin, entry_point)
    fun xref_equation_for_reducer_candidate(subp: Entity[BasicDecl]): Equation = {
        val reducer = self.args?[0].expr().as[BaseId];
        val initial_value_expression = self.args?[1].expr();
        # We don't need to take too many precautions here since we are sure the
        # subp parameter is a valid reducer candidate, its supb_spec isn't null
        # and it has parameters.
        val param_types = subp.subp_spec_or_null().param_types();
        val accum_type = param_types?[0];
        val value_type = param_types?[1];

        self.prefix.as[ValueSequence].do(
            (vs) => %eq(vs.iter_assoc.expr().expected_type_var(), value_type) and vs.iter_assoc.expr().matches_expected_type(), default_val=%true
        ) and self.prefix.sub_equation() and %eq(node.type_var(), accum_type) and %eq(reducer.ref_var(), subp) and %eq(initial_value_expression.expected_type_var(), accum_type) and initial_value_expression.sub_equation() and initial_value_expression.matches_expected_formal_type()
    }
}

|" Base class for nodes that are made up of a single token.
@abstract
class SingleTokNode: Name implements TokenNode {
    fun relative_name(): Entity[Name] = self

    @external()
    fun subp_spec_var(): LogicVar

    @external()
    fun ref_var(): LogicVar

    fun defines_subp_spec_var(): Bool = true

    |" Shortcut to get the symbol of this node. We keep this short form, even
    |" though the public property canonical_text is equivalent because it is
    |" very used inside of the internal properties
    fun sym(): Symbol = node.symbol

    fun name_symbol(): Symbol = node.symbol

    fun canonical_text(): Symbol = node.sym()

    |" Like env.get_first, but returning the first visible element in the Ada
    |" sense.
    |"
    |" If ``no_visibility``, discard visibility checks.
    @with_dynvars(no_visibility=false)
    fun env_get_first_visible(lex_env: LexicalEnv, lookup_type: LookupKind, from_node: AdaNode): Entity[AdaNode] = node.env_get(
        lex_env, node.symbol, lookup=lookup_type, from_node=from_node, categories=RefCategories(inherited_primitives=false, _=true)
    ).find(
        (el) => (
            # If no_visibility, then don't check visibility, (so return the
            # first).
            no_visibility
        ) or node.has_visibility(el)
    )
}

|" Base class for identifiers.
@abstract
@custom_short_image
class BaseId: SingleTokNode implements TokenNode {
    @memoized
    @with_dynvars(env)
    fun scope(): LexicalEnv = {
        val elt = env.get_first(
            node.symbol,
            lookup=if node.is_prefix() then LookupKind.recursive else LookupKind.flat,
            categories=RefCategories(inherited_primitives=false, _=true)
        );
        val ret = if not elt.is_null and elt.node is BasicDecl then elt.children_env() else null[LexicalEnv];

        # If this the corresponding decl is a generic, go grab the internal
        # package decl.
        ret.env_node.as[GenericPackageDecl].do(
            (gen_pkg_decl) => gen_pkg_decl.package_decl.children_env(), default_val=ret
        )
    }

    @with_dynvars(env, origin, no_visibility=false)
    fun designated_env_no_overloading(): LexicalEnv = node.env_get_first_visible(
        env, lookup_type=if node.is_prefix() then LookupKind.recursive else LookupKind.flat, from_node=node.origin_node()
    ).as[BasicDecl].do(
        # Getting back an ObjectDecl necessarily means we are dealing with
        # incorrect Ada code, because `designated_env_no_overloading` is
        # always called in context where we expect a package/type
        # declaration. In that case we now directly return an empty result,
        # in order to avoid cases of invalid code that trigger infinite
        # recursions (e.g. `Foo : Foo.T;`).
        (bd) =>
        if bd is ObjectDecl then node.empty_env()
        elif bd?.is_package() then self.pkg_env(bd)
        else {
            bind origin = node.origin_node();

            bd.defining_env()
        }
    )

    |" Decoupled implementation for designated_env, specifically used by
    |" DottedName when the parent is a library level package.
    @with_dynvars(env, origin, no_visibility=false)
    fun designated_env(): LexicalEnv = {
        val bd = node.parents().find((p) => p is GenericPackageInstantiation);
        val env_el = node.env_get_first_visible(
            env, lookup_type=if node.is_prefix() then LookupKind.recursive else LookupKind.flat, from_node=node.origin_node()
        ).as[BasicDecl];

        # If first element is a package, then return the pkg env
        if env_el?.is_package() and env_el.node != bd then self.pkg_env(env_el) else self.env_elements_impl().do(
            (all_env_els) => all_env_els.filter(
                (e) => (
                    # Exclude own generic package instantiation from the lookup
                    e.node != bd
                ) and node.has_visibility(e)
            )
        ).map((e) => e.as[BasicDecl].defining_env()).env_group()
    }

    |" Return the lexical environment for this identifier, should it be a
    |" package. This method handles resolving to the most visible part of a
    |" package - private or body - if necessary. It also unwinds package
    |" renamings if necessary.
    |"
    |" If ``inst_from_formal`` is True, we know that bd is a generic package
    |" instantiation coming from a rebound formal package, and that we need
    |" visibility on the formals.
    @with_dynvars(env, origin)
    fun pkg_env(from_pkg: Entity[BasicDecl]): LexicalEnv = {
        # If the given package is a renaming (after potentially several levels
        # of renamings) of another package P, do the rest of the work on P
        # instead.
        val pkg = from_pkg.as[PackageRenamingDecl].do(
            (r) => r.final_renamed_package(), default_val=from_pkg
        );
        # If pkg is a generic package (non instantiated) and it is
        # rebound somewhere in the context of self's rebindings, then
        # we want to put back those rebindings on it, because it means
        # we are inside a generic instantiation, so referring to the
        # generic package actually means referring to the
        # instantiation.
        val bd = pkg.unshed_rebindings(self.info.rebindings);
        # Check whether the package comes from a rebound env in order to
        # determine if we have visibility on its formal part. Look at both
        # ``from_pkg`` or ``pkg`` as we may have a renaming of a rebound
        # package, or a rebound package being a package renaming, and in
        # both cases we have visibility on the final renamed package's
        # formal part.
        val is_inst_from_formal = pkg is GenericPackageInstantiation and (
            from_pkg.info.from_rebound or pkg.info.from_rebound
        );
        val env = if bd is GenericPackageInstantiation and is_inst_from_formal then bd.as[GenericPackageInstantiation].defining_env_impl(true) else bd.defining_env();
        # If the basic_decl is a package decl with a private part, we get it.
        # Else we keep the defining env.
        val private_part_env = env.get(
            s"__privatepart", lookup=LookupKind.flat, categories=RefCategories(inherited_primitives=false, _=true)
        )?[0].do(
            (pp) => pp.children_env(), default_val=env
        );
        val package_body_env = private_part_env.get(
            s"__nextpart", lookup=LookupKind.flat, categories=RefCategories(inherited_primitives=false, _=true)
        )?[0].do(
            (pb) =>
            # If the package is implemented as a separate, we need to
            # jump through one more link to get to the body.
            if pb is PackageBodyStub then pb.children_env().get(
                s"__nextpart", lookup=LookupKind.flat, categories=RefCategories(inherited_primitives=false, _=true)
            )?[0].do((pb) => pb.children_env()) else pb.children_env(), default_val=null[LexicalEnv]
        );
        val formals_env = bd.as[GenericPackageDecl].do(
            (pkg_g) => pkg_g.formal_part.children_env(), default_val=null[LexicalEnv]
        );

        # If we're looking from the body, return a group of all the
        # relevant envs together.
        if package_body_env != null[LexicalEnv] and (
            # Since origin or self do not carry rebindings, `is_children_env`
            # would always return False in instantiated generics (since
            # `package_body_env` is a rebound environment). Fortunately, these
            # visibility rules are not instantiation-dependent, so we can use
            # `.env_node.children_env` on `package_body_env` to do the check on
            # the bare non-rebound lexical envs.
            node.is_children_env(
                package_body_env.env_node?.children_env(), (origin or? node).node_env()
            )
        ) then [package_body_env, private_part_env, env, formals_env].env_group()
        # If we're looking from the private part, return a group of private
        # part + public part.
        # See corresponding comment on `package_body_env` to understand why
        # we use `.env_node.children_env`.
        elif node.is_children_env(
            private_part_env.env_node?.children_env(), (origin or? node).node_env()
        ) then [private_part_env, env, formals_env].env_group()
        # If we're not looking from the private part, we could be looking
        # from the public part of a generic package decl. In such a case
        # the returned env should also include the formals environment for
        # that package.
        elif bd is GenericPackageDecl then [env, formals_env].env_group()
        # TODO: Probably some special handling for separates here, because
        # they'll have full visibility on the package body in which they're
        # defined.
        else env
    }

    @with_dynvars(env)
    fun parent_scope(): LexicalEnv = env

    @with_dynvars(env, origin)
    fun designated_type_impl(): Entity[BaseTypeDecl] =
        node.env_get_first_visible(
            env, from_node=node.origin_node(),
            lookup_type=if node.is_prefix()
                then LookupKind.recursive
                else LookupKind.minimal
        ).do(
            (env_el) => env_el.as[BaseTypeDecl].do(
                (t) => if origin.is_null then {
                    # When no origin is given (e.g. we are resolving from an
                    # aspect), try to find a more complete definition of `t`
                    # as seen from the reference if any, otherwise use `t`.
                    bind origin = node.origin_node();

                    t.most_visible_forward_part_for_name(
                        t.name_symbol(), seq=false
                    )
                }
                else if self.info.from_rebound then
                    # When the type was resolved from a formal using generic
                    # instance information, try to find a more complete
                    # definition from the origin if possible, otherwise `t`
                    # will be used.
                    t.most_visible_forward_part_for_name(
                        t.name_symbol(), seq=false
                    )
                else
                    # Otherwise, `t` itself might not actually be a visible
                    # part of the type as seen from `origin`. So, check amongst
                    # the previous and next part of `t` to find the most
                    # complete part, or return null if the type is not at all
                    # visible.
                    t.most_visible_part(),
                default_val=env_el
            ).do(
                (v1) => match v1 {
                    case t: BaseTypeDecl => t
                    case tb: TaskBody => tb.task_type()
                    case pb: ProtectedBody => pb.protected_type()
                    case tbs: TaskBodyStub =>
                        tbs.body_part_for_decl().as[TaskBody].task_type()
                    case pbs: ProtectedBodyStub =>
                        pbs.body_part_for_decl().as[ProtectedBody]
                        .protected_type()
                    case _ => null[Entity[BaseTypeDecl]]
                }
            )
        ).do(
            (type) =>
            # When the type is a generic formal type, if we are resolving it
            # from it's instantiation, that means that no actual has been given
            # for that formal (name resolution directly calls
            # resolve_generic_actual on actuals names), therefore the designated
            # type should be the default one if any. On the other hand, outside
            # it's own instantion context, the designated type is the formal
            # type, whether it has a default value or not.
            type.parent.as[GenericFormalTypeDecl].do(
                (formal_decl) =>
                    if formal_decl.generic_instantiations().any(
                        (inst) => inst.designated_generic_decl().node ==
                        formal_decl.parent_decl().node
                    )
                    then formal_decl.default_type() or? type
                    else type
            ) or? type
        )

    @with_dynvars(env, origin)
    fun all_env_els_impl(seq: Bool = true, seq_from: AdaNode = null[AdaNode], categories: RefCategories = RefCategories(_=true)): Array[Entity[AdaNode]] = node.env_get(
        env, node.name_symbol(), lookup=if node.is_prefix() then LookupKind.recursive else LookupKind.flat, from_node=if seq then if not seq_from.is_null then seq_from else node else null[AdaNode], categories=categories
    )

    @memoized
    @with_dynvars(env)
    fun env_elements_impl(): Array[Entity[AdaNode]] = {
        val items = node.env_get(
            env, node.symbol, lookup=if node.is_prefix() then LookupKind.recursive else LookupKind.flat, # If we are in an aspect, then lookup is not sequential
            from_node=node.origin_node(), categories=if node.can_designate_primitive() then RefCategories(_=true) else RefCategories(inherited_primitives=false, _=true)
        ).filter(
            (e) => e.as[AnonymousExprDecl].do(
                (aed) => self.parents().find((p) => p is GenericFormal).do(
                    # If we are in a generic formal part, we do not necessarily have
                    # visibility on all the actuals coming from the instantiation.
                    (_) => aed.get_formal().formal_decl().is_directly_reachable(self), default_val=true
                ), default_val=true
            )
        );
        # TODO: there is a big smell here: We're doing the filtering for parent
        # expressions in the baseid env_elements. We should solve that.
        val pc = self.parent_callexpr();
        val is_prefix = not node.is_suffix();

        {
            bind origin = node.origin_node();

            if pc.is_null then (
                # If it is not the main id in a CallExpr: either the name
                # designates something else than a subprogram, either it designates
                # a subprogram that accepts no explicit argument. So filter out
                # other subprograms.
                items.filter(
                    (e) => e.as![BasicDecl].can_be_paramless()
                ) & (
                    # If there is a subp_spec, check that it corresponds to
                    # a parameterless subprogram.
                    # Make sure that the enclosing body is in the list of items in
                    # case this name is the prefix of a qualified name refering to
                    # local variables.
                    if is_prefix then self.semantic_parents().find(
                        (n) => (n is TaskBody | BaseSubpBody).do(
                            (_) => n.as[BasicDecl].defining_name().name.name_is(node.symbol)
                        )
                    ).do(
                        (b) => [b], default_val=null[Array[Entity[AdaNode]]]
                    ) else null[Array[Entity[AdaNode]]]
                )
            )
            # This identifier is the name for a called subprogram, entry, or an
            # array.
            # So only keep:
            # * subprograms/entries for which the actuals match
            # * arrays for which the number of dimensions match
            # * any type that has a user defined indexing aspect.
            else pc.suffix.as[AssocList].do(
                (params) => items.filter(
                    (e) => match e {
                        # Type conversion case
                        case _: BaseTypeDecl => params.length() == 1
                        case b: BasicDecl => b.subp_spec_or_null().do(
                            (spec) => self.call_matches_spec(spec, pc, params, b),
                            # In the case of ObjectDecls/CompDecls in general,
                            # verify that the callexpr is valid for the given
                            # type designator.
                            default_val=pc.check_for_type(b.expr_type())
                        )
                        case _ => false
                    }
                ),

                # Discard BaseTypeDecls when resolving a CallExpr that cannot
                # be a type conversion.
                default_val=items.filter((e) => not e is BaseTypeDecl)
            )
        }
    }

    |" Return whether the BasicDecl ``b`` should be kept during
    |" ``env_elements_impl`` items filtering. This piece of code has been
    |" extracted from ``env_elements_impl`` to improve code readability.
    @with_dynvars(env, origin)
    fun call_matches_spec(spec: Entity[BaseSubpSpec], pc: Entity[CallExpr], params: Entity[AssocList], b: Entity[BasicDecl]): Bool = {
        val family_type = spec.as[EntrySpec]?.family_type;
        # If b is a `EntryDecl` with a specified family type, then the real
        # `CallExpr` is its parent, as in: `Task.Entry (Family) (Arg1, Arg2)`,
        # where `Entry (Family) (Arg1, Arg2)` is the real `CallExpr`, not just
        # `Entry (Family)`. Adjust `pc` and `params` accordingly:
        val real_pc = if family_type.is_null then pc else pc.parent.as[CallExpr];
        val real_params = if family_type.is_null then params else pc.parent.as[CallExpr].do((ce) => ce.suffix.as![AssocList]);

        (
            # ``real_pc`` can be null if we are handling a paramless entry decl
            # that has an entry family, in which case the subsequent checks are
            # not relevant.
            real_pc.is_null or (
                # Either the subprogram/entry is matching the CallExpr's parameters
                spec.is_matching_param_list(real_params, b.info.md.dottable_subp) and real_pc.parent.as[CallExpr].do(
                    (ce) => ce.check_for_type(b.expr_type()), default_val=true
                )
            )
        ) or (
            # Or the entity is parameterless, and the returned component (s)
            # matches the callexpr (s).
            real_pc.check_for_type(b.expr_type()) and spec.paramless(b.info.md.dottable_subp)
        )
    }

    fun denotes_the_property_function(subp_spec: Entity[BaseSubpSpec]): Bool = {
        # Return true whether this node can refer to a property function
        # denoted by `subp_spec`. (see RM 7.3.4 about stable properties of a
        # type). This equation has to be called in the scope of the
        # `Stable_Properties` aspect name resolution.
        val primitive_types = subp_spec.primitive_subp_types();

        # ``subp_decl`` is a property function of this node if it comes from a
        # `Stable_Properties` AspectAssoc and:
        (
            # It only has one single parameter (mode in but not checked here)
            subp_spec.params().length() == 1
        ) and (
            # It matches the type for which the Stable_Properties is defined.
            # There are two cases:
            match self.parent_basic_decl() {
                # Either the Stable_Properties aspect is defined within a
                # TypeDecl.
                case td: TypeDecl => not primitive_types.find((t) => t == td).is_null

                # Or within a SubpDecl
                case sd: SubpDecl => not sd.subp_spec.primitive_subp_types().filter(
                    (t1) => not primitive_types.find((t2) => t1 == t2).is_null
                ).is_null
                case _ => false
            }
        )
    }

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        val is_prefix = not node.is_suffix();

        self.env_elements().do(
            (env_els) => env_els.logic_any(
                (e) => %eq(node.ref_var(), e.as[BasicDecl].corresponding_actual()) and (
                    # If this BaseId refers to an enclosing subprogram and is
                    # the prefix of a dotted name, then it is not a call.
                    if is_prefix and e.as[BaseSubpBody]?.in_scope() then %eq(node.type_var(), null[Entity[BaseTypeDecl]]) else (
                        # If this BaseId represents a call, the called subprogram will
                        # be held in self.ref_var, in which case subp_spec_or_null will
                        # return the specification of the called subprogram. If ref_var
                        # does not contain a subprogram, this BaseId cannot be a call,
                        # and subp_spec_or_null would indeed return null in this case.
                        %eq(node.type_var(), node.ref_var(), conv_prop=BasicDecl.expr_type) and %eq(node.subp_spec_var(), e.as[BasicDecl].subp_spec_or_null())
                    )
                )
            ), default_val=self.undefined_reference_equation()
        )
    }
}

|" Character literal (:rmlink:`4.1`).
@repr_name("Chr")
class CharLiteral: BaseId implements TokenNode {
    |" Return the value that this literal denotes.
    @exported
    @external()
    fun denoted_value(): Char

    fun has_context_free_type(): Bool = false

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        %predicate(BaseTypeDecl.is_non_null_char_type, node.expected_type_var()) and %eq(node.expected_type_var(), node.type_var()) and (
            # Ada RM 4.2 (3): since the expected type of the `CharLiteral` is
            # known in this case (the predicates above let us through), we can
            # use it to determine what the literal refers to. Hackish: we use
            # the `origin` dynamic variable to pass an additional argument to
            # the conversion property ``corresponding_char_literal``.
            # TODO: fix this once we can pass explicit parameters to conversion
            # properties.
            {
                bind origin = node;

                %eq(node.ref_var(), node.type_var(), conv_prop=BaseTypeDecl.corresponding_char_literal)
            }
        )
}

|" Regular identifier (:rmlink:`2.3`).
@with_abstract_list
@repr_name("Id")
class Identifier: BaseId implements TokenNode {

    # Some attributes return functions in Ada. However, LAL incorrectly parses
    # an "AttributeRef with arguments" as something magical rather than a
    # regular call (which is why AttributeRef has an `args` field.
    #
    # Additionally, resolution for a number of them was implemented as "magic
    # attributes" rather than built-in functions. This is wrong and needs to be
    # fixed (see S910-057). However, for the moment, we parse them as
    # ``AttributeRef (pfx, attr, args)``, and resolve them specially
    # rather than  ``CallExpr (AttrRef (pfx, attr), args)``.
    #
    # For other args, we deactivate this parsing, so that they're correctly
    # parsed as ``CallExpr (AttrRef (pfx, attr), args)``.
    fun is_attr_with_args(): Bool =
        node.symbol in s"First" | s"Last" | s"Range" | s"Length"
        | s"Has_Same_Storage" | s"Overlaps_Storage" | s"Deref"
        | s"Mechanism_Code"

    @with_dynvars(origin)
    fun complete_items(): Array[CompletionItem] = self.parent.complete_items()

    fun is_constant(): Bool = {
        val rd = self.referenced_decl();

        (
            # If this identifier is defining, call is_constant_object on
            # the object it defines.
            if self.is_defining() then self.enclosing_defining_name().basic_decl().is_constant_object()
            # Check if the referenced declaration is constant (filter out
            # declarations that are not objects, as it makes no sense to
            # call is_constant_object on them).
            elif rd is ObjectDecl | ComponentDecl | EnumLiteralDecl | ParamSpec | NumberDecl then rd.is_constant_object()
            else false
        ) or (
            # An instance of a protected variable is constant within
            # a function body of the corresponding protected unit.
            self.parents().find(
                (n) => n.as[BaseSubpBody].do(
                    (v1) => v1.subp_spec.subp_kind is SubpKind.Function
                )
            ).do(
                (_) => (
                    # We just check that the variable is used within a
                    # function first, then we ensure that it is protected
                    # by looking at its declaration, which should be inside
                    # the private part of the corresponding protected unit.
                    rd.is_in_private_part()
                ) and not rd.parents().find((n) => n is ProtectedTypeDecl).is_null
            )
        )
    }
}

|" Operation in a binary expression.
|"
|" Note that the ARM does not consider "double_dot" ("..") as a binary
|" operator, but we process it this way here anyway to keep things simple.
enum class Op: BaseId implements TokenNode {
    case And,
    Or,
    OrElse,
    AndThen,
    Xor,
    In,
    NotIn,
    Abs,
    Not,
    Pow,
    Mult,
    Div,
    Mod,
    Rem,
    Plus,
    Minus, Concat, Eq, Neq, Lt, Lte, Gt, Gte, DoubleDot

    |" Return the symbol that needs to be used to define an overload of this
    |" operator.
    fun subprogram_symbol(): Symbol = match node {
        case _: Op.And => s"\"and\""
        case _: Op.Or => s"\"or\""
        case _: Op.Xor => s"\"xor\""
        case _: Op.Abs => s"\"abs\""
        case _: Op.Not => s"\"not\""
        case _: Op.Pow => s"\"**\""
        case _: Op.Mult => s"\"*\""
        case _: Op.Div => s"\"/\""
        case _: Op.Mod => s"\"mod\""
        case _: Op.Rem => s"\"rem\""
        case _: Op.Plus => s"\"+\""
        case _: Op.Minus => s"\"-\""
        case _: Op.Concat => s"\"&\""
        case _: Op.Eq => s"\"=\""
        case _: Op.Neq => s"\"/=\""
        case _: Op.Lt => s"\"<\""
        case _: Op.Lte => s"\"<=\""
        case _: Op.Gt => s"\">\""
        case _: Op.Gte => s"\">=\""
        case _ => s"<<>>"
    }

    |" Return the list of all operator definitions for the given operator
    |" symbol. Note that corresponding operators of root types are returned
    |" first in the list, so as to implement the "preference" behavior
    |" described in :rmlink:`8.6` - 29 in BinOp and UnOp xref_equation.
    fun subprograms_for_symbol(sym: Symbol, from_node: Entity[AdaNode]): Array[Entity[BasicDecl]] = node.root_type_ops(sym) & node.env_get(
        from_node.node_env(), sym, from_node=from_node.node
    ).filtermap(
        (e) => e.as![BasicDecl], (e) => e.as![BasicDecl].is_subprogram() and (
            # Note: here we explicitly filter out synthesized operators
            # (which correspond to built-in operators), because using them
            # for resolving arithmetic expressions would have a significant
            # performance impact. Instead, we use specific equations
            # tailored for the resolution of built-in operators. See
            # `BinOp.no_overload_equation`.
            # TODO: However these custom rules currently do not assign the
            # `ref_var` of operator references designating which built-in
            # operators have been called, which would be useful for users
            # and make this more transparent.
            not e is SyntheticSubpDecl
        )
    )

    |" Return the subprograms corresponding to this operator accessible in the
    |" lexical environment.
    fun subprograms(): Array[Entity[BasicDecl]] =
        node.subprograms_for_symbol(node.subprogram_symbol(), self)

    fun name_symbol(): Symbol = node.subprogram_symbol()

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        # An Op can only be a field of a BinOp or UnOp, so its ref var will
        # be bound in the xref equations of these two types.
        %false

    @with_dynvars(imprecise_fallback=false)
    fun is_dispatching_call(): Bool = self.referenced_decl().do((decl) =>
        # TODO: It's a bit of a shame to not have a base class for
        # operators?
        match self.parents().find((n) => n is BinOp | ConcatOp | UnOp).as![Expr] {
            # TODO: Not supported on ConcatOps yet. It would return false
            # anyway but this way it is obvious. See VC08-029.
            case _: ConcatOp => false
            case e => e.is_dispatching_call_impl(decl)
        }
    )
}

|" String literal (:rmlink:`2.6`).
@repr_name("Str")
class StringLiteral: BaseId implements TokenNode {
    |" Return the value that this literal denotes.
    @exported
    @external()
    fun denoted_value(): String

    fun has_context_free_type(): Bool = false

    |" Override of env_elements_impl for string literals, i.e. operators. We
    |" need to explicitly include operators on root types first, because those
    |" have precedence over the rest (see :rmlink:`8.6` - 29).
    @with_dynvars(env)
    fun env_elements_impl(): Array[Entity[AdaNode]] =
        node.root_type_ops(node.symbol).map((bd) => bd.as[AdaNode]) & self.super()

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        # StringLiteral can be in a name, if it is an operator, in which
        # case we don't want to constrain its type.
        if node.parent is Name then self.super() else (
            %eq(node.expected_type_var(), node.type_var()) and %predicate(BaseTypeDecl.is_not_any_type, node.expected_type_var(), error_location=node)
        ) and %predicate(BaseTypeDecl.allows_string_literal, node.expected_type_var(), error_location=node)
}

|" The ``null`` literal (:rmlink:`4.4`).
@repr_name("Null")
class NullLiteral: SingleTokNode implements TokenNode {
    fun has_context_free_type(): Bool = false

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        %predicate(BaseTypeDecl.is_access_type_predicate, node.expected_type_var()) and %eq(node.expected_type_var(), node.type_var())
}

|" Base class for number literals (:rmlink:`2.4`).
@abstract
@repr_name("Num")
class NumLiteral: SingleTokNode implements TokenNode {
    fun is_constant(): Bool = true
}

|" Literal for an integer (:rmlink:`2.4`).
@repr_name("Int")
class IntLiteral: NumLiteral implements TokenNode {
    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = node.universal_int_bind(node.type_var())

    |" Return the value that this literal denotes.
    @exported
    @external()
    fun denoted_value(): BigInt
}

|" Literal for a real number (:rmlink:`2.4`).
@repr_name("Real")
class RealLiteral: NumLiteral implements TokenNode {
    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = node.universal_real_bind(node.type_var())
}

|" Synthetic identifier.
@synthetic
class SyntheticIdentifier: Name {
    sym: Symbol

    fun name_symbol(): Symbol = node.sym

    fun relative_name(): Entity[Name] = self
}

|" Name for Ada 2020 ``@`` (:rmlink:`5.2.1`).
class TargetName: Name {
    r_ref_var: LogicVar

    fun ref_var(): LogicVar = node.r_ref_var

    fun assign_statement(): AssignStmt =
        node.parents().find((p) => p is AssignStmt).as![AssignStmt]

    fun relative_name(): Entity[Name] =
        node.assign_statement().dest.as_entity.relative_name()

    @with_dynvars(env, origin, no_visibility=false)
    fun designated_env(): LexicalEnv =
        node.assign_statement().dest.as_entity.designated_env()

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        # Since we are binding self's variables to the corresponding variables
        # of an outer node, we use the ``bind_to_non_local`` constructor, which
        # will handle correctly the case where the current node and the outer
        # node are across a stop_resolution boundary.
        val dest = self.assign_statement().dest;

        node.bind_to_non_local(node.type_var(), dest, dest.type_var()) and node.bind_to_non_local(node.ref_var(), dest, dest.ref_var())
    }
}

|" Reference to the ``Update`` attribute, which is a non standard GNAT
|" attribute.
class UpdateAttributeRef: Name {
    @parse_field prefix: Name
    @parse_field attribute: Identifier
    @parse_field values: BaseAggregate
    r_ref_var: LogicVar

    fun ref_var(): LogicVar = node.r_ref_var

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        # Assign the type of the inner aggregate (self's ``values`` field) to
        # the type of the updated value. This allows the aggregate associations
        # inside of it to be resolved independently.
        # (see AggregateAssoc.xref_equation).
        val _ = self.prefix.resolve_names_internal(false);
        val prefix_type = self.prefix.type_val().as[BaseTypeDecl];

        %eq(self.values.as![Aggregate].type_var(), prefix_type) and %eq(node.type_var(), prefix_type)
    }
}

|" Parenthesized expression.
class ParenExpr: Expr {
    @parse_field expr: Expr

    fun has_context_free_type(): Bool = node.expr.has_context_free_type()

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = (
        self.expr.sub_equation() and %eq(node.expr.expected_type_var(), node.expected_type_var())
    ) and %eq(node.expr.type_var(), node.type_var())
}

|" Quantified expression (:rmlink:`4.5.8`).
class QuantifiedExpr: Expr {
    @parse_field quantifier: Quantifier
    @parse_field loop_spec: ForLoopSpec
    @parse_field expr: Expr

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        # NOTE: we need to resolve the spec first so that the indexing variable
        # has a type.
        val spec_success = self.loop_spec.resolve_names();

        if spec_success then (
            (
                %eq(node.expr.expected_type_var(), node.bool_type()) and {
                    bind env = self.children_env();

                    self.expr.sub_equation()
                }
            ) and self.expr.matches_expected_formal_type()
        ) and %eq(node.type_var(), node.expr.type_var()) else %false
    }

    env_spec {
        add_env()
    }
}

|" Expression to raise an exception (:rmlink:`4.4`).
class RaiseExpr: Expr {
    @parse_field @nullable exception_name: Name
    @parse_field @nullable error_message: Expr

    fun has_context_free_type(): Bool = false

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.exception_name.sub_equation() and %eq(node.expected_type_var(), node.type_var()) and self.error_message.do(
            (er) => (
                # The expected type of that error message is always String,
                # according to RM 11.3 - 3.1/2.
                %eq(er.expected_type_var(), node.std_string_type())
            ) and er.sub_equation(), default_val=%true
        )
}

|" Unary expression.
|"
|" This encompasses several ARM expressions, because it is used for every
|" unary operator in Ada. Those expressions are all documented in
|" :rmlink:`4.4`.
class UnOp: Expr {
    @parse_field op: Op
    @parse_field expr: Expr

    fun has_context_free_type(): Bool = false

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = self.expr.sub_equation() and (
        if node.in_aspect(s"Depends") or node.in_aspect(s"Refined_Depends") then %true else self.overload_equation() or (
            %eq(node.expected_type_var(), node.expr.expected_type_var()) and %eq(node.type_var(), node.expr.type_var(), logic_ctx=LogicContext(
                ref_node=self.op, decl_node=null[Entity[AdaNode]]
            ))
        )
    )

    @with_dynvars(origin, env)
    fun overload_equation(): Equation = self.op.subprograms().logic_any(
        (subp) => {
            bind logic_context = LogicContext(ref_node=self.op, decl_node=subp);

            self.entity_eq(subp)
        }
    )

    @with_dynvars(origin, env, logic_context)
    fun entity_eq(subp: Entity[BasicDecl]): Equation = {
        val spec = subp.subp_spec_or_null();
        val ps = spec.unpacked_formal_params();

        if ps.length() == 1 then (
            # The subprogram's first argument must match self's left
            # operand.
            (
                (
                    spec.call_argument_equation(ps?[0].formal_decl(), self.expr) and (
                        # The subprogram's return type is the type of self
                        %eq(node.type_var(), spec.return_type(), logic_ctx=logic_context)
                    )
                ) and (
                    # The operator references the subprogram
                    %eq(node.op.ref_var(), subp)
                )
            ) and %eq(node.op.subp_spec_var(), spec)
        ) else %false
    }

    @with_dynvars(imprecise_fallback=false)
    fun potential_actuals_for_dispatch(spec: Entity[BaseSubpSpec]): Array[ExpectedTypeForExpr] = [ExpectedTypeForExpr(
        expected_type=spec.abstract_formal_params()?[0].type_expression(), expr=self.expr
    )]

    @with_dynvars(imprecise_fallback=false)
    fun is_dispatching_call(): Bool = self.op.is_dispatching_call()
}

|" Represent the ``when ...`` filter after a for loop specification. This
|" class has no RM existence, it is used internally to wrap the filtering
|" expression, so as to have a dedicated name resolution entry point for it
|" and make sure it is resolved separatly from the ``ForLoopSpec`` itself
|" (which it cannot influence anyway).
class ForLoopIterFilter: AdaNode {
    @parse_field expr: Expr

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        val _ = self.parent.as[ForLoopSpec].do(
            (spec) => if spec.is_iterated_assoc_spec() then spec.resolve_names_from_closest_entry_point() else true
        );

        %eq(node.expr.expected_type_var(), node.bool_type()) and self.expr.sub_equation() and self.expr.matches_expected_formal_type()
    }

    fun xref_entry_point(): Bool = true
}

|" Chunk of a format string literal.
class FormatStringChunk: AdaNode {
    @parse_field expr: Expr
    @parse_field string_tok: FormatStringTokNode

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = self.expr.sub_equation() and (
        # The RFC specifies that interpolated string expressions can be "of
        # any type", so we explicitly bind the expected type to null.
        %eq(node.expr.expected_type_var(), null[AdaNode])
    )
}

|" Node holding a format string token.
@abstract
class FormatStringTokNode: AdaNode implements TokenNode {
}

|" Node holding a formatting "end" token.
class FormatStringTokEnd: FormatStringTokNode implements TokenNode {
}

|" Node holding a formatting "middle" token.
class FormatStringTokMid: FormatStringTokNode implements TokenNode {
}

|" Node holding a formatting "start" token.
class FormatStringTokStart: FormatStringTokNode implements TokenNode {
}

|" Node holding a formatting "string" token. This token is used when the
|" corresponding interpolated string doesn't have any expression to expand.
class FormatStringTokString: FormatStringTokStart implements TokenNode {
}

|" List of statements, with optional exception handlers (:rmlink:`11.2`).
@snaps
class HandledStmts: AdaNode {
    @parse_field stmts: StmtList
    @parse_field exceptions: ASTList[AdaNode]

    |" Return whether this list of statement has SPARK mode set to On
    |" (assuming that we are in a library-level package body statements
    |" section).
    fun spark_mode_aspect(): Aspect =
        self.stmts.take_while((stmt) => stmt is Pragma).find(
            (stmt) => stmt.as[Pragma].id.name_is(s"SPARK_Mode")
        ).do(
            (spark_mode) => spark_mode.as[Pragma].as_aspect(),
            # Else, look at the body declarative part
            default_val=self.parent.as[PackageBody].do(
                (body) => body.decls.spark_mode_aspect(),
                default_val=self.semantic_parent().spark_mode_aspect()
            )
        )
}

|" Kind of interface type.
enum class InterfaceKind: AdaNode {
    case Limited, Task, Protected, Synchronized
}

|" Iteration type for ``for`` loops.
enum class IterType: AdaNode {
    case In, Of
}

|" Library item in a compilation unit (:rmlink:`10.1.1`).
class LibraryItem: AdaNode {
    @parse_field has_private: Private
    @parse_field item: BasicDecl
}

|" Qualifier for the ``limited`` keyword.
@qualifier
enum class Limited: AdaNode {
}

|" Base class for loop specifications (:rmlink:`5.5`).
@abstract
class LoopSpec: AdaNode {
}

|" Specification for a ``for`` loop (:rmlink:`5.5`).
class ForLoopSpec: LoopSpec {
    @parse_field var_decl: ForLoopVarDecl
    @parse_field loop_type: IterType
    @parse_field has_reverse: Reverse
    @parse_field iter_expr: AdaNode
    @parse_field @nullable iter_filter: ForLoopIterFilter

    |" Return whether this for loop spec is part of an iterated component
    |" association.
    fun is_iterated_assoc_spec(): Bool = node.parent is IteratedAssoc

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.var_decl.sub_equation() and match node.loop_type {
            # This is a for .. in
            case _: IterType.In =>
            # Let's handle the different possibilities
            match self.iter_expr {
                # Anonymous range case: for I in 1 .. 100
                case binop: BinOp => (
                    binop.sub_equation() and (
                        # The default type, if there is no other determined type, is
                        # Integer.
                        %predicate(BaseTypeDecl.is_not_root_int_type, binop.type_var())
                    )
                ) and %eq(node.var_decl.id.type_var(), binop.type_var())

                # Subtype indication case: the induction variable is of the
                # type.
                case t: SubtypeIndication => t.sub_equation() and %eq(node.var_decl.id.type_var(), t.designated_type().canonical_type())
                case r: AttributeRef => r.sub_equation() and %eq(node.var_decl.id.type_var(), r.type_var())

                # Name case: Either the name is a subtype indication, or an
                # attribute on a subtype indication, in which case the logic is
                # the same as above, either it's an expression that yields an
                # iterator.
                case t: Name => t.sub_equation() and t.name_designated_type().do(
                    (typ) => %eq(node.var_decl.id.type_var(), typ.canonical_type()), default_val=(
                        # Make sure null is not a possible value to avoid a
                        # null dereference in the subsequent predicate.
                        %predicate(AdaNode.is_not_null, t.type_var())
                    ) and %predicate(BaseTypeDecl.is_iterator_type, t.type_var()) and %eq(node.var_decl.id.type_var(), t.type_var(), conv_prop=BaseTypeDecl.cursor_type)
                )
                case _ => %true
            }

            # should never happen
            # This is a for .. of
            case _: IterType.Of => self.iter_expr.as[Expr].do(
                (iter_expr) => (
                    (
                        self.var_decl.id_type.do(
                            (typ) => %eq(iter_expr.expected_type_var(), typ.designated_type()), default_val=%true
                        ) and iter_expr.sub_equation()
                    ) and %predicate(AdaNode.is_not_null, iter_expr.type_var())
                ) and %eq(node.var_decl.id.type_var(), iter_expr.type_var(), conv_prop=BaseTypeDecl.iterable_comp_type_or_null), default_val=%false
            )
        }

    # This spec is not a complete resolution context when part of an iterated
    # component association: we must know the type of the enclosing aggregate
    # to determine the type of the iteration variable in case of a `for I in`.
    fun xref_entry_point(): Bool = not node.is_iterated_assoc_spec()
}

|" Specification for a ``while`` loop (:rmlink:`5.5`).
class WhileLoopSpec: LoopSpec {
    @parse_field expr: Expr

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.expr.sub_equation() and self.expr.expect_bool_derived_type()
}

|" Syntactic indicators for passing modes in formals (:rmlink:`6.1`).
enum class Mode: AdaNode {
    case In, Out, InOut, Default

    |" Return whether this mode allows the qualified entity to be written or
    |" not.
    fun is_writable(): Bool = node is Mode.Out | Mode.InOut
}

|" Node that holds several AbstractStateDecl nodes, which is necessary when
|" the Abstract_State aspect is associated with an aggregate in order to
|" declare a list of abstract states.
class MultiAbstractStateDecl: AdaNode {
    @parse_field decls: AbstractStateDeclList
}

|" Qualifier for the ``not null`` keywords.
@qualifier
enum class NotNull: AdaNode {
}

|" Placeholder for the ``null`` in lists of components (:rmlink:`3.8`).
class NullComponentDecl: AdaNode {
}

|" ``other`` designator.
class OthersDesignator: AdaNode {
    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = %true
}

|" Syntactic indicators for subprogram overriding modes.
enum class Overriding: AdaNode {
    case Overriding, NotOverriding, Unspecified
}

|" List of parameter specifications.
class Params: AdaNode {
    @parse_field params: ASTList[ParamSpec]
}

|" Holds an AbstractStateDecl between parentheses. Needed to support the
|" syntax:
|"
|" .. code:: ada
|"
|"     package Pkg
|"         with Abstract_State => (A, (B with Some_Aspect))
class ParenAbstractStateDecl: AdaNode {
    @parse_field decl: AdaNode
}

|" Base node for all preprocessor directives.
@abstract
class PpDirective: AdaNode {
}

|" ``else`` preprocessor directive.
class PpElseDirective: PpDirective {
}

|" ``elsif ... [then]`` preprocessor directive.
class PpElsifDirective: PpDirective {
    @parse_field expr: Expr
    @parse_field @nullable then_kw: PpThenKw
}

|" ``end if;`` preprocessor directive.
class PpEndIfDirective: PpDirective {
}

|" ``if ... [then]`` preprocessor directive.
class PpIfDirective: PpDirective {
    @parse_field expr: Expr
    @parse_field @nullable then_kw: PpThenKw
}

# Unparsers require to have a single sequence of tokens for a given node.
# We need parsers for ``PpIfDirective`` and ``PpElseDirective`` to accept
# both ``[els]if X then`` and ``[els]if X`` syntax forms, so we have to
# create a (possible null) ``then_kw`` field for both.
|" ``then`` keyword in preprocessor directives.
class PpThenKw: AdaNode {
}

|" Class for pragmas (:rmlink:`2.8`). Pragmas are compiler directives,
|" that can be language or compiler defined.
class Pragma: AdaNode {
    @parse_field id: Identifier
    @parse_field args: ASTList[BaseAssoc]

    fun xref_entry_point(): Bool = true

    |" Return whether this pragma is ghost code or not. See SPARK RM 6.9.
    @exported
    fun is_ghost_code(): Bool =
        # We only consider pragmas that can be in lists of statements for the
        # moment.
        self.id.sym() in s"Assert" | s"Assert_And_Cut" | s"Assume" | s"Loop_Invariant"

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        if self.id.name_is(s"Assert") or self.id.name_is(s"Loop_Invariant") or self.id.name_is(s"Compile_Time_Warning") or self.id.name_is(s"Compile_Time_Error") then {
            val expr = self.args?[0].assoc_expr();

            expr.sub_equation() and expr.expect_bool_derived_type()
        } and self.args?[1].do(
            (arg) => arg.assoc_expr().do(
                (msg) => (
                    %eq(msg.expected_type_var(), node.std_string_type()) and msg.sub_equation()
                ) and msg.matches_expected_type(), default_val=%true
            ), default_val=%true
        )
        elif self.id.name_is(s"Unreferenced") then self.args.logic_all(
            (assoc) => assoc.assoc_expr().as![Name].xref_no_overloading()
        )
        elif self.id.name_symbol() in s"Import" | s"Export" | s"Interface" | s"Convention" | s"Pack" | s"Pure" | s"Preelaborate" | s"Elaborate_Body" | s"Inline" | s"Volatile" then self.associated_entity_names().logic_all((n) => n.xref_no_overloading())
        elif self.id.name_is(s"Warnings") then self.args.logic_all(
            (arg) => arg.assoc_expr().do((expr) =>
                if expr is Identifier then (
                    if expr.as[Identifier].name_symbol() in
                        s"On" | s"Off" | s"GNAT" | s"GNATprove"
                    then %true
                    else expr.as[Identifier].xref_no_overloading()
                ) else (
                    %eq(expr.expected_type_var(), node.std_string_type())
                    and expr.sub_equation()
                    and expr.matches_expected_type()
                ),
                default_val=%true
            )
        )
        # Pragmas we want to deliberately not resolve, either because there
        # is nothing to resolve in there, or because we don't know how to
        # resolve them and don't want to spend effort implementing
        # resolution for them (for example, other compilers implementation
        # defined pragmas).
        elif self.id.name_symbol() in s"Style_Checks" | s"Import_Function" | s"Import_Procedure" then %true
        elif self.id.name_symbol() in s"Pre" | s"Post" | s"Pre'Class" | s"Post'Class" | s"Precondition" | s"Postcondition" | s"Precondition'Class" | s"Postcondition'Class" | s"Initial_Condition" then self.args?[0].assoc_expr().do(
            (expr) => (
                %eq(expr.expected_type_var(), node.bool_type()) and expr.sub_equation()
            ) and expr.matches_expected_formal_type(), default_val=%false
        )
        elif self.id.name_is(s"Test_Case") then self.args.filter(
            (arg) => arg.as[PragmaArgumentAssoc].do(
                (parg) => parg.name.name_symbol() in s"Requires" | s"Ensures"
            )
        ).logic_all(
            (arg) => (
                %eq(arg.assoc_expr().expected_type_var(), node.bool_type()) and arg.assoc_expr().sub_equation()
            ) and arg.assoc_expr().matches_expected_formal_type()
        )
        elif self.id.name_is(s"Contract_Cases") then self.args?[0].assoc_expr().as[BaseAggregate].assocs.logic_all(
            (assoc) => assoc.as[AggregateAssoc].contract_cases_assoc_equation()
        )
        elif self.id.name_is(s"Debug") then (
            # If we have two arguments, the first one is a conditional
            # expression.
            if self.args.length() == 2 then {
                val expr = self.args?[0].assoc_expr();

                (
                    %eq(expr.expected_type_var(), node.bool_type()) and expr.sub_equation()
                ) and expr.matches_expected_formal_type()
            } else %true
        ) and {
            val proc = self.args?[self.args.length() - 1]?.assoc_expr();

            %eq(proc.type_var(), null[Entity[BaseTypeDecl]]) and proc.sub_equation()
        }
        elif self.id.name_is(s"Annotate") then (
            # For the Annotate pragma, the first two identifiers are not
            # analyzed. The rest are arbitrary expressions (see
            # `Expr.annotate_argument_equation`). Optionally, a final
            # association `Entity => <name>` can be given, where `name`
            # must resolve to a local declaration.
            self.args.ilogic_all(
                (arg, i) => if i < 2 then %true
                elif arg.as[PragmaArgumentAssoc]?.name?.name_is(s"Entity") then arg.assoc_expr().as![Name].xref_no_overloading()
                else arg.assoc_expr().annotate_argument_equation()
            )
        )
        else self.args.logic_all(
            (a) => (
                # In the default case, we try to resolve every associated
                # expression, but we never fail, in order to not generate
                # diagnostics for unknown/implementation defined pragmas.
                a.assoc_expr().sub_equation()
            ) or %true
        )

    |" Return the expression representing the "value" of this pragma, which
    |" will be used to fill the ``value`` field of the ``Aspect`` struct
    |" returned by calls to ``get_aspect``. This property doesn't make sense
    |" for all pragmas but tries to give the most reasonable answer, and in
    |" particular tries to match what ``get_aspect`` would return if the
    |" pragma was replaced by its equivalent aspect.
    |" For example, on ``pragma Convention (C, X)``, the returned value is
    |" ``C`` because one would write ``X : Integer with Convention => C``.
    fun value_expr(): Entity[Expr] =
        if self.id.name_symbol() in s"Import" | s"Export" | s"Interface" | s"Convention" then self.args?[0].assoc_expr()
        # SPARK_Mode can have no associated value (in that case, the
        # default is `On`) but if a value is provided, it's in first
        # position.
        elif self.id.name_is(s"SPARK_Mode") then self.args?[0]?.assoc_expr()
        else self.args?[1]?.assoc_expr()

    fun associated_entity_names(): Array[Entity[Name]] =
        if self.id.name_symbol() in s"Import" | s"Export" | s"Interface" | s"Convention" then [self.args?[1].assoc_expr().as![Name]]
        elif self.id.name_is(s"Inline") then self.args.map((a) => a.assoc_expr().as[Name])
        elif self.id.name_symbol() in s"Pack" | s"Pure" | s"Preelaborate" | s"Elaborate_Body" | s"Volatile" | s"Volatile_Components" | s"Unchecked_Union" | s"Atomic" | s"Atomic_Components" | s"No_Return" | s"Discard_Names" | s"Independent" | s"Independent_Components" | s"Asynchronous" | s"Interrupt_Handler" | s"Attach_Handler" | s"Predicate" then self.args?[0]?.assoc_expr().as[Name].do((v1) => [v1])
        elif self.id.name_is(s"Obsolescent") then self.args?[0]?.assoc_expr().as[Name].do(
            # Pragma Obsolescent can have a StringLiteral as a first
            # argument, in which case there is no associated entity with
            # it.
            (name) => if not name is StringLiteral then [name] else null[Array[Entity[Name]]]
        )
        elif self.id.name_is(s"Annotate") then (
            # For pragma Annotate, the associated name is given by an
            # `Entity => <name>` association, if any.
            self.args.find(
                (a) => a.as[PragmaArgumentAssoc]?.name?.name_is(s"Entity")
            ).do(
                (a) => a.as[PragmaArgumentAssoc].expr.as[Name].do((v2) => [v2])
            )
        )
        else null[Array[Entity[Name]]]

    fun associated_entities_helper(): Array[Entity[DefiningName]] = self.associated_entity_names().mapcat(
        (name) => self.semantic_parent().do(
            (parent) => parent.children_env().get(
                name.name_symbol(), lookup=LookupKind.flat, categories=RefCategories(inherited_primitives=false, _=true)
            ).map(
                (decl) => decl.as[BasicDecl].wrap_public_reference().defining_names().find((dn) =>
                    # Find the scope in which this pragma lies by fetching the closest
                    # lexical scope. We don't use ``declarative_scope`` here, as some
                    # decls do not lie in a DeclarativePart, such as ComponentDecls.
                    # Get entities in it
                    # Map to the public view, to work on the instantiation nodes
                    # instead of the Generic*Internal nodes.
                    dn.name_is(name.name_symbol())
                )
            )
        ).filter(
            (ent) => (
                # Only get entities that are after self in the *same* source
                ent.unit() == node.unit()
            ) and ent.node < node
        )
    )

    |" Return an array of ``BasicDecl`` instances associated with this pragma,
    |" or an empty array if non applicable.
    @exported
    fun associated_entities(): Array[Entity[DefiningName]] = {
        val top_level_decl = node.parent.parent.as[CompilationUnit].do(
            (cu) => [cu.body.as![LibraryItem].item.as_entity.defining_name()], default_val=null[Array[Entity[DefiningName]]]
        );
        val enclosing_program_unit = node.parents(with_self=false).find((p) => p is BasicDecl).as[BasicDecl].as_entity;

        # TODO: This should be using a ._or, but is waiting on a fix for
        # R903-028.
        # NOTE: The whole reason we have to implement custom resolution for
        # decls associated to a pragma, is because there can be several
        # associated decls, so the regular crossref mechanism is not
        # sufficient, as in the following example::
        #
        #     procedure Foo;
        #     procedure Foo (A : Integer);
        #     pragma Inline (Foo);
        self.associated_entity_names().do(
            (names) => {
                val p = self.associated_entities_helper() or? top_level_decl;

                if p != null[Array[Entity[DefiningName]]] then p else enclosing_program_unit.do(
                    (epu) => if names.length() == 1 and names?[0].referenced_decl() == epu then [epu.defining_name()] else null[Array[Entity[DefiningName]]], default_val=top_level_decl
                )
            }, default_val=(
                # If no name
                if (
                    # either it's a contract pragma...
                    node.is_contract_aspect(self.id.name_symbol())
                ) or (
                    # or the Obsolescent pragma
                    self.id.name_is(s"Obsolescent")
                ) then (
                    # in which case they are attached to the closest declaration
                    # above it. We could have used a call to previous_sibling here
                    # to find the closest declaration above it but since
                    # declarations are in lists we can directly search it in the
                    # parent list to save time (previous_sibling has a linear
                    # complexity so it can be very inefficient if we have a long
                    # list of pragma to process before reaching the declaration
                    # associated to them).
                    node.parent.as[ASTList[AdaNode]].do(
                        (decls) => decls.filter(
                            (decl) => decl is BasicDecl and node > decl
                        ).do((decls) => decls?[decls.length() - 1]).as[BasicDecl].as_entity.do((v1) => [v1])
                    ) or? [enclosing_program_unit]
                ) else (
                    # Or else to the closest parent subprogram
                    # Or else it's necessarily a program unit pragma
                    [enclosing_program_unit]
                )
            ).map((bd) => bd.defining_name())
        )
    }

    |" Return the initial env name for a pragma clause. We use the
    |" Standard package for top level use clauses. For contract pragmas such
    |" as ``Precondition`` or ``Predicate``, we use the env of the entity the
    |" pragma is associated with in order to properly resolve references to
    |" formals or to the type's ``SyntheticObjectDecl`` instance.
    fun initial_env(): DesignatedEnv =
        if node.parent.parent is CompilationUnit then DesignatedEnv(
            kind=DesignatedEnvKind.named_env, env_name=s"Standard", direct_env=null[LexicalEnv]
        )
        elif node.as_bare_entity.id.name_symbol() in s"Pre" | s"Post" | s"Pre'Class" | s"Post'Class" | s"Precondition" | s"Postcondition" | s"Precondition'Class" | s"Postcondition'Class" | s"Test_Case" | s"Contract_Cases" | s"Predicate" then node.as_bare_entity.associated_entities()?[0].do(
            (ent) => DesignatedEnv(
                kind=DesignatedEnvKind.direct_env, env_name=null[Symbol], direct_env=ent.children_env()
            ), default_val=DesignatedEnv(
                kind=DesignatedEnvKind.current_env, env_name=null[Symbol], direct_env=null[LexicalEnv]
            )
        )
        else DesignatedEnv(
            kind=DesignatedEnvKind.current_env, env_name=null[Symbol], direct_env=null[LexicalEnv]
        )

    |" Return this pragma as an ``Aspect`` struct.
    fun as_aspect(inherited: Bool = false): Aspect = Aspect(
        exists=true, node=self, value=self.value_expr(), inherited=inherited
    )

    env_spec {
        set_initial_env(node.initial_env())
    }
}

|" Qualifier for the ``private`` keyword.
@qualifier
enum class Private: AdaNode {
}

|" Type definition for a protected object (:rmlink:`9.4`).
class ProtectedDef: AdaNode {
    @parse_field public_part: PublicPart
    @parse_field @nullable private_part: PrivatePart
    @parse_field @nullable end_name: EndName
}

|" Qualifier for the ``protected`` keyword.
@qualifier
enum class Protected: AdaNode {
}

|" Type for quantified expressions.
enum class Quantifier: AdaNode {
    case All, Some
}

|" Range specification (:rmlink:`3.5.7`).
class RangeSpec: AdaNode {
    @parse_field range: Expr

    @with_dynvars(env, origin)
    fun xref_stop_resolution(): Bool = node.parent is ComponentClause

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = self.range.xref_equation() and (
        # Ada RM says that for component clauses and signed int type
        # definitions, the expected type is any integer type.
        if node.parent is ComponentClause | SignedIntTypeDef then node.universal_int_bind(node.range.expected_type_var()) and self.range.matches_expected_type()
        # In the following cases, expressions from the range specification are
        # expected to be of any real type, the types need not be the same.
        elif node.parent is DeltaConstraint | DigitsConstraint | OrdinaryFixedPointDef | DecimalFixedPointDef then node.universal_real_bind(node.range.expected_type_var()) and self.range.matches_expected_type()
        else %true
    )
}

|" Renaming clause, used everywhere renamings are valid.
class RenamingClause: AdaNode {
    @parse_field renamed_object: Name
}

|" Synthetic renaming clause. Used to synthesize object decls with renamings.
|" (See to_anonymous_object_decl).
@synthetic
class SyntheticRenamingClause: RenamingClause {
}

|" Qualifier for the ``reverse`` keyword.
@qualifier
enum class Reverse: AdaNode {
}

|" Alternative part in a ``select`` statements block (:rmlink:`9.7`).
class SelectWhenPart: AdaNode {
    @parse_field @nullable cond_expr: Expr
    @parse_field stmts: StmtList

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = self.cond_expr.do(
        (c) => c.sub_equation() and c.expect_bool_derived_type(), default_val=%true
    )
}

|" Bass class for statements (:rmlink:`5.1`).
@abstract
class Stmt: AdaNode {
    fun xref_entry_point(): Bool = true

    |" Return whether this statement is ghost code or not. See SPARK RM 6.9.
    @exported
    fun is_ghost_code(): Bool = (
        # Either this statement is part of a ghost declaration like a ghost
        # package or function.
        self.parent_basic_decl().do((bd) => bd.is_ghost_code())
    ) or (
        # Either it's an implicitly ghost statement, because it's assigning
        # to a ghost variable, or calling a ghost procedure.
        match self {
            case ass: AssignStmt => ass.dest.failsafe_referenced_def_name()
            case call: CallStmt => call.call.failsafe_referenced_def_name()
            case _ => null[RefdDef]
        }.do((res) =>
            # Sometimes name resolution errors are materialized by None
            # being returned from the queries instead of a property error.
            # But None doesn't necessarily mean there was an error, so we
            # explicitly handle the error cases by raising an exception as
            # we don't want errors to be silently ignored, and we use the
            # null coalescing operator to handle the legitimate cases.
            if res.kind == RefResultKind.error then raise[Bool] PropertyError("Name resolution error") else res.def_name?.is_ghost_code()
        )
    )
}

|" Base class for composite statements (:rmlink:`5.1`).
@abstract
class CompositeStmt: Stmt {
}

|" ``accept`` statement (:rmlink:`9.5.2`).
class AcceptStmt: CompositeStmt {
    @parse_field body_decl: AcceptStmtBody
    @parse_field @nullable entry_index_expr: Expr
    @parse_field params: EntryCompletionFormalParams

    @with_dynvars(origin, env)
    fun designated_entry(): Entity[EntryDecl] = self.body_decl.name.all_env_els_impl().find(
        (e) => e.as[EntryDecl].do(
            (d) => d.spec.match_formal_params(self.params)
        )
    ).as[EntryDecl]

    |" Return the entry which corresponds to this accept statement.
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun corresponding_entry(): Entity[EntryDecl] = {
        bind env = self.node_env();

        self.designated_entry()
    }

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        %eq(node.body_decl.name.ref_var(), self.designated_entry()) and self.entry_index_expr.do(
            (e) => (
                # :rmlink:`9.5.2`: The expected type for entry_index_expr is
                # that of the type defined by the definition of the
                # corresponding entry declaration.
                %eq(e.expected_type_var(), self.designated_entry().family_type())
            ) and e.sub_equation(), default_val=%true
        )

    env_spec {
        add_to_env(
            [EnvAssoc(
                key=self.body_decl.name.relative_name().name_symbol(), value=node.body_decl, dest_env=DesignatedEnv(
                    kind=DesignatedEnvKind.current_env, env_name=null[Symbol], direct_env=null[LexicalEnv]
                ), metadata=null[Metadata]
            )]
        )
        add_env()
    }
}

|" Extended ``accept`` statement (:rmlink:`9.5.2`).
class AcceptStmtWithStmts: AcceptStmt {
    @parse_field stmts: HandledStmts
    @parse_field @nullable end_name: EndName
}

|" Base class for loop statements (:rmlink:`5.5`).
@abstract
class BaseLoopStmt: CompositeStmt {
    @parse_field @nullable spec: LoopSpec
    @parse_field stmts: StmtList
    @parse_field @nullable end_name: EndName

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = self.spec.do(
        (s) => s.xref_equation(), default_val=%true
    )
}

|" Statement for ``for`` loops (``for ... loop ... end loop;``)
|" (:rmlink:`5.5`).
class ForLoopStmt: BaseLoopStmt {
    env_spec {
        add_env()
    }
}

|" Statement for simple loops (``loop ... end loop;``) (:rmlink:`5.5`).
class LoopStmt: BaseLoopStmt {
}

|" Statement for ``while`` loops (``while ... loop ... end loop;``)
|" (:rmlink:`5.5`).
class WhileLoopStmt: BaseLoopStmt {
}

|" Base class for statement blocks (:rmlink:`5.6`).
@abstract
class BlockStmt: CompositeStmt {
    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = %true

    env_spec {
        add_env()
    }
}

|" Statement block with no declarative part (:rmlink:`5.6`).
class BeginBlock: BlockStmt {
    @parse_field stmts: HandledStmts
    @parse_field @nullable end_name: EndName
}

|" Statement block with a declarative part (:rmlink:`5.6`).
class DeclBlock: BlockStmt {
    @parse_field decls: DeclarativePart
    @parse_field stmts: HandledStmts
    @parse_field @nullable end_name: EndName

    fun immediate_declarative_region(): LexicalEnv =
        self.children_env()
}

|" ``case`` statement (:rmlink:`5.4`).
class CaseStmt: CompositeStmt {
    @parse_field expr: Expr
    @parse_field pragmas: ASTList[Pragma]
    @parse_field alternatives: ASTList[CaseStmtAlternative]

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = self.expr.sub_equation() and (
        (
            # First make sure null is not a possible value for the type of
            # the expression so as to avoid a null check in subsequent
            # predicates.
            %predicate(AdaNode.is_not_null, node.expr.type_var())
        ) and (
            # Then make sure it is a discrete type
            %predicate(BaseTypeDecl.is_discrete_type, node.expr.type_var())
        )
    )
}

|" Extended ``return`` statement (:rmlink:`6.5`).
class ExtendedReturnStmt: CompositeStmt {
    @parse_field decl: ExtendedReturnStmtObjectDecl
    @parse_field @nullable stmts: HandledStmts

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = %true

    env_spec {
        add_env()
    }
}

|" ``if`` statement block (:rmlink:`5.3`).
class IfStmt: CompositeStmt {
    @parse_field cond_expr: Expr
    @parse_field then_stmts: StmtList
    @parse_field alternatives: ASTList[ElsifStmtPart]
    @parse_field else_stmts: StmtList

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.cond_expr.sub_equation() and node.cond_expr.expect_bool_derived_type()
}

|" Wrapper class, used for composite statements that can be named (declare
|" blocks, loops). This allows to both have a BasicDecl for the named entity
|" declared, and a CompositeStmt for the statement hierarchy.
class NamedStmt: CompositeStmt {
    @parse_field decl: NamedStmtDecl
    @parse_field stmt: CompositeStmt

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = %true

    env_spec {
        add_to_env_kv(node.decl.name_symbol(), node.decl)
        add_env()
    }
}

|" ``select`` statements block (:rmlink:`9.7`).
class SelectStmt: CompositeStmt {
    @parse_field guards: ASTList[SelectWhenPart]
    @parse_field else_stmts: StmtList
    @parse_field abort_stmts: StmtList

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.guards.logic_all((wp) => wp.sub_equation())
}

|" Placeholder node for syntax errors in lists of statements.
class ErrorStmt: Stmt implements ErrorNode {
}

|" Base class for simple statements (:rmlink:`5.1`).
@abstract
class SimpleStmt: Stmt {
}

|" ``abort`` statement (:rmlink:`9.8`).
class AbortStmt: SimpleStmt {
    @parse_field names: ASTList[Name]

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = self.names.logic_all(
        (name) => name.sub_equation() and %predicate(BaseTypeDecl.is_task_type, name.type_var())
    )
}

|" Statement for assignments (:rmlink:`5.2`).
class AssignStmt: SimpleStmt {
    @parse_field dest: Name
    @parse_field expr: Expr

    @with_dynvars(origin)
    fun complete_item_weight(item: Entity[BasicDecl]): Int =
        node.complete_item_weight_matching_type(item, self.dest)

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = (
        (
            self.dest.sub_equation() and %eq(node.expr.expected_type_var(), node.dest.type_var(), conv_prop=BaseTypeDecl.derefed_type)
        ) and self.expr.sub_equation()
    ) and node.expr.matches_expected_assign_type()
}

|" Statement for entry or procedure calls (:rmlink:`6.4`).
class CallStmt: SimpleStmt {
    @parse_field call: Name

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = self.call.sub_equation() and (
        # Call statements can have no return value
        %eq(node.call.type_var(), null[Entity[AdaNode]])
    )
}

|" ``delay`` statement (:rmlink:`9.6`).
class DelayStmt: SimpleStmt {
    @parse_field has_until: Until
    @parse_field expr: Expr

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = self.expr.sub_equation() and (
        if node.has_until.as_bool() then %true else %eq(node.expr.expected_type_var(), node.std_entity(s"Duration")) and self.expr.matches_expected_type()
    )
}

|" ``exit`` statement (:rmlink:`5.7`).
class ExitStmt: SimpleStmt {
    @parse_field @nullable loop_name: Name
    @parse_field @nullable cond_expr: Expr

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = self.cond_expr.do(
        (cond) => cond.sub_equation() and cond.expect_bool_derived_type(), default_val=%true
    ) and self.loop_name.do(
        (ln) => ln.xref_no_overloading(), default_val=%true
    )
}

|" ``goto`` statement (:rmlink:`5.8`).
class GotoStmt: SimpleStmt {
    @parse_field label_name: Name

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.label_name.xref_no_overloading(sequential=false)
}

|" Statement to declare a code label (:rmlink:`5.1`).
class Label: SimpleStmt {
    @parse_field decl: LabelDecl

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = %true
}

|" ``null;`` statement (:rmlink:`5.1`).
class NullStmt: SimpleStmt {
    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = %true
}

|" ``raise`` statement (:rmlink:`11.3`).
class RaiseStmt: SimpleStmt {
    @parse_field @nullable exception_name: Name
    @parse_field @nullable error_message: Expr

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = self.exception_name.do(
        (en) => en.sub_equation(), default_val=%true
    ) and self.error_message.do(
        (er) => (
            # The expected type of that error message is always String,
            # according to RM 11.3 - 3.1/2.
            %eq(er.expected_type_var(), node.std_string_type())
        ) and er.sub_equation(), default_val=%true
    )
}

|" ``requeue`` statement (:rmlink:`9.5.4`).
class RequeueStmt: SimpleStmt {
    @parse_field call_name: Name
    @parse_field has_abort: Abort

    fun innermost_entry_or_accept_stmt_params(): Entity[BaseFormalParamHolder] = match self.parents().find(
        (p) => p is AcceptStmtWithStmts | EntryBody
    ) {
        case a: AcceptStmtWithStmts => a.params
        case b: EntryBody => b.params
        case _ => null[Entity[EntryCompletionFormalParams]]
    }.as[BaseFormalParamHolder]

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        val ce = self.call_name.as[CallExpr];
        val name = ce.do(
            (ce) => ce.name, default_val=self.call_name
        );
        val targets = name.all_env_elements_internal().filter(
            (n) => n.as[BasicDecl].do(
                (e) => (
                    # RM 9.5.4: the name shall resolve to denote a procedure or entry,
                    # where either:
                    # 1. The profile is empty
                    e.subp_spec_or_null().do(
                        (ss) => ss.nb_max_params() == 0 and ss.returns().is_null
                    )
                ) or (
                    # 2. The profile matches the profile of the enclosing
                    # entry/accept stmt.
                    e.subp_spec_or_null().do(
                        (ss) => ss.match_formal_params(
                            self.innermost_entry_or_accept_stmt_params(), match_names=not e is SubpRenamingDecl
                        )
                    )
                ) or (
                    # 3. The target denotes a prefixed view of a primitive
                    # subprogram of a synchronized interface, where the first
                    # parameter of the unprefixed view of the primitive subprogram
                    # shall be a controlling parameter, and the Synchronization
                    # aspect shall be specified with synchronization_kind By_Entry
                    # for the primitive subprogram.
                    if e.get_aspect_spec_expr(s"Synchronization").as[Name]?.name_is(s"By_Entry") then e.subp_spec_or_null().do(
                        (ss) => ss.match_formal_params(
                            self.innermost_entry_or_accept_stmt_params(), match_names=false, ignore_first_param=e.info.md.dottable_subp
                        )
                    ) else false
                )
            )
        );

        (
            # We call xref_no_overloading to make sure that sub-names are
            # bound.
            match name {
                # If name is a DottedName, prefix can be a CallExpr that should
                # be resolved using sub_equation.
                case dn: DottedName => (
                    if dn.prefix is CallExpr then dn.prefix.sub_equation() else dn.prefix.xref_no_overloading()
                ) and {
                    bind env = dn.prefix.designated_env();

                    dn.suffix.xref_no_overloading()
                }
                case o => o.xref_no_overloading()
            }
        ) and (
            # Then, bind the name to any entry that fits the bills
            targets.logic_any(
                (e) => {
                    # If we're binding to an entry from an entry family,
                    # resolve the expression in the call expr, knowing that it
                    # can be used to resolve overloads.
                    val fam_type = e.as[EntryDecl]?.spec.family_type.as[SubtypeIndication]?.designated_type();
                    val first_param = ce?.params()?[0]?.expr();

                    first_param.do(
                        (p) => p.sub_equation() and fam_type.do(
                            (eft) => %eq(p.expected_type_var(), eft) and p.matches_expected_type(), default_val=%true
                        ), default_val=%true
                    )
                }
            )
        )
    }
}

|" ``return`` statement (:rmlink:`6.5`).
class ReturnStmt: SimpleStmt {
    @parse_field @nullable return_expr: Expr

    |" Returns the subprogram this return statement belongs to
    fun subp(): Entity[SubpBody] =
        node.parents().find((p) => p is SubpBody).as[SubpBody].as_entity

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = self.return_expr.do(
        (rexpr) => (
            %eq(rexpr.expected_type_var(), self.subp().subp_spec.returns().designated_type()) and rexpr.sub_equation()
        ) and rexpr.matches_expected_assign_type(), default_val=%true
    )
}

|" Statement wrapping a simple object declaration.
class SimpleDeclStmt: SimpleStmt {
    @parse_field decl: ObjectDecl

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = %true
}

|" ``terminate`` alternative in a ``select`` statement (:rmlink:`9.7`).
class TerminateAlternative: SimpleStmt {
    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = %true
}

|" Qualifier for a subprogram kind.
enum class SubpKind: AdaNode {
    case Procedure, Function
}

|" Subunit (``separate``) (:rmlink:`10.1.3`).
class Subunit: AdaNode {
    @parse_field name: Name
    @parse_field body: Body

    |" Return the compilation unit in which this subunit is rooted.
    fun root_unit(): Entity[CompilationUnit] = node.designated_compilation_unit(
        node.name.as_symbol_array(), AnalysisUnitKind.unit_body, load_if_needed=true, not_found_is_error=true
    ).as_bare_entity

    |" Helper for AdaNode.env_hook. Handle sub-units (separates).
    fun env_hook_subunit(): Bool = {
        # Subunit handling is very simple: we just want to fetch the containing
        # unit.
        val _ = node.root_unit();

        false
    }

    |" Return the body in which this subunit is rooted.
    @exported
    fun body_root(): Entity[BasicDecl] =
        node.root_unit().decl().as_bare_entity

    |" Return all the bodies this subunit is rooted in, so that for:
    |"
    |" .. code::ada
    |"
    |"     separate (P1.P2.P3)
    |"     procedure P4 is ...
    |"
    |" ``bodies_root`` will return ``[P3, P2, P1]``, an array containing all
    |" the nested subunits (``P2``, ``P3``), as well as the body root ``P1``,
    |" in which ``P4`` has been recursively rooted in.
    fun bodies_root(): Array[Entity[BasicDecl]] = {
        val br = node.root_unit().decl().as_bare_entity;

        br.parent.as[Subunit].do(
            (su) => [br] & su.bodies_root(), default_val=[br]
        )
    }

    |" Return the stub corresponding to this subunit.
    |"
    |" This is an internal helper for ``AdaNode.can_reach``: since it is used
    |" in all lexical env lookups, its implementation cannot do lookups itself
    |" as it would trigger infinite recursions. Libadalang users can use
    |" ``BasicDecl.previous_part_for_decl`` instead.
    # At the time of its introduction, this property was used only by
    # AdaNode.can_reach, which was an external property.
    @ignored
    fun stub(): BodyStub = {
        # Look for the declaration list that is supposed to contain the stub
        # for this subunit. This must be in the unit in which this subunit is
        # rooted, and that unit can only be a package body, a subprogram body
        # or a subunit itself.
        val root = node.root_unit().node;
        val root_body = match root.body {
            case li: LibraryItem => li.item.as[Body]
            case su: Subunit => su.body
            case _ => null[Body]
        };
        val decls = match root_body {
            case subp: SubpBody => subp.decls.decls
            case pkg: PackageBody => pkg.decls.decls
            case _ => null[ASTList[AdaNode]]
        };

        # Look for the stub in this list: it is supposed to be the only stub
        # whose name matches self.body's defining name.
        decls.find(
            (d) => {
                # d may not be a body stub, so we have to use "._" after the
                # cast.
                val stub_name = d.as[BodyStub].as_bare_entity?.defining_name_or_raise().name;
                # By construction, self is a subunit, so for valid code, it is
                # supposed to have a unique defining name.
                val subunit_name = node.body.as_bare_entity.defining_name_or_raise().name;

                stub_name?.name_is(subunit_name.name_symbol())
            }
        ).as[BodyStub]
    }

    fun xref_entry_point(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        %eq(node.name.ref_var(), self.body_root()) and (
            # Bind the parent unit's name to the enclosing body for this
            # subunit.
            self.name.as[DottedName].do(
                (dn) => {
                    bind env = node.body.node_env();

                    dn.prefix.xref_no_overloading()
                }, default_val=%true
            )
        )
}

|" Qualifier for the ``synchronized`` keyword.
@qualifier
enum class Synchronized: AdaNode {
}

|" Qualifier for the ``tagged`` keyword.
@qualifier
enum class Tagged: AdaNode {
}

|" Type definition for a task type (:rmlink:`9.1`).
class TaskDef: AdaNode {
    @parse_field interfaces: ParentList
    @parse_field public_part: PublicPart
    @parse_field @nullable private_part: PrivatePart
    @parse_field @nullable end_name: EndName

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.interfaces.logic_all((ifc) => ifc.xref_equation())
}

|" Synthetic node that contains the lazy fields for the attribute subprograms
|" of a given type. The lazy fields are not directly on the BaseTypeDecl node
|" itself to minimize its size in memory: with this indirection, a type for
|" which no function attribute is ever synthesized will not waste any memory.
@synthetic
class TypeAttributesRepository: AdaNode {
    base_type: BaseTypeDecl

    @lazy
    base_type_expr: NodeBuilder[SyntheticTypeExpr] =
        SyntheticTypeExpr.builder(
            target_type=node.base_type.to_builder()
        )

    @lazy
    universal_int_type_expr: NodeBuilder[SyntheticTypeExpr] =
        SyntheticTypeExpr.builder(
            target_type=node.universal_int_type().node.to_builder()
        )

    @lazy
    universal_real_type_expr: NodeBuilder[SyntheticTypeExpr] =
        SyntheticTypeExpr.builder(
            target_type=node.universal_real_type().node.to_builder()
        )

    @lazy
    base_type_param: NodeBuilder[SyntheticFormalParamDecl] =
        SyntheticFormalParamDecl.builder(
            param_name=s"Value", param_type=node.base_type_expr
        )

    @lazy
    universal_int_param: NodeBuilder[SyntheticFormalParamDecl] =
        SyntheticFormalParamDecl.builder(
            param_name=s"Value", param_type=node.universal_int_type_expr
        )

    @lazy
    universal_real_param: NodeBuilder[SyntheticFormalParamDecl] =
        SyntheticFormalParamDecl.builder(
            param_name=s"Value", param_type=node.universal_real_type_expr
        )

    @lazy
    root_stream_param: NodeBuilder[SyntheticFormalParamDecl] =
        SyntheticFormalParamDecl.builder(
            param_name=s"S", param_type=SyntheticTypeExpr.builder(
                target_type=node.root_stream_type().anonymous_access_type().node.to_builder()
            )
        )

    @lazy
    succ: BasicSubpDecl = SyntheticSubpDecl.builder(
        spec=SyntheticUnarySpec.builder(
            subp_symbol=s"Succ", right_param=node.base_type_param, return_type_expr=node.base_type_expr
        )
    ).build(parent=node.base_type)

    @lazy
    pred: BasicSubpDecl = SyntheticSubpDecl.builder(
        spec=SyntheticUnarySpec.builder(
            subp_symbol=s"Pred", right_param=node.base_type_param, return_type_expr=node.base_type_expr
        )
    ).build(parent=node.base_type)

    @lazy
    min: BasicSubpDecl = SyntheticSubpDecl.builder(
        spec=SyntheticBinarySpec.builder(
            subp_symbol=s"Min", left_param=node.base_type_param, right_param=node.base_type_param, return_type_expr=node.base_type_expr
        )
    ).build(parent=node.base_type)

    @lazy
    max: BasicSubpDecl = SyntheticSubpDecl.builder(
        spec=SyntheticBinarySpec.builder(
            subp_symbol=s"Max", left_param=node.base_type_param, right_param=node.base_type_param, return_type_expr=node.base_type_expr
        )
    ).build(parent=node.base_type)

    @lazy
    round: BasicSubpDecl = # As defined in :rmlink:`3.5.10`
    SyntheticSubpDecl.builder(
        spec=SyntheticUnarySpec.builder(
            subp_symbol=s"Round", right_param=node.universal_real_param, return_type_expr=node.base_type_expr
        )
    ).build(parent=node.base_type)

    @lazy
    rounding: BasicSubpDecl = SyntheticSubpDecl.builder(
        spec=SyntheticUnarySpec.builder(
            subp_symbol=s"Rounding", right_param=node.base_type_param, return_type_expr=node.base_type_expr
        )
    ).build(parent=node.base_type)

    @lazy
    unbiased_rounding: BasicSubpDecl = SyntheticSubpDecl.builder(
        spec=SyntheticUnarySpec.builder(
            subp_symbol=s"Unbiased_Rounding", right_param=node.base_type_param, return_type_expr=node.base_type_expr
        )
    ).build(parent=node.base_type)

    @lazy
    ceiling: BasicSubpDecl = SyntheticSubpDecl.builder(
        spec=SyntheticUnarySpec.builder(
            subp_symbol=s"Ceiling", right_param=node.base_type_param, return_type_expr=node.base_type_expr
        )
    ).build(parent=node.base_type)

    @lazy
    floor: BasicSubpDecl = SyntheticSubpDecl.builder(
        spec=SyntheticUnarySpec.builder(
            subp_symbol=s"Floor", right_param=node.base_type_param, return_type_expr=node.base_type_expr
        )
    ).build(parent=node.base_type)

    @lazy
    truncation: BasicSubpDecl = SyntheticSubpDecl.builder(
        spec=SyntheticUnarySpec.builder(
            subp_symbol=s"Truncation", right_param=node.base_type_param, return_type_expr=node.base_type_expr
        )
    ).build(parent=node.base_type)

    @lazy
    machine: BasicSubpDecl = SyntheticSubpDecl.builder(
        spec=SyntheticUnarySpec.builder(
            subp_symbol=s"Machine", right_param=node.base_type_param, return_type_expr=node.base_type_expr
        )
    ).build(parent=node.base_type)

    @lazy
    machine_rounding: BasicSubpDecl = SyntheticSubpDecl.builder(
        spec=SyntheticUnarySpec.builder(
            subp_symbol=s"Machine_Rounding", right_param=node.base_type_param, return_type_expr=node.base_type_expr
        )
    ).build(parent=node.base_type)

    @lazy
    fraction: BasicSubpDecl = SyntheticSubpDecl.builder(
        spec=SyntheticUnarySpec.builder(
            subp_symbol=s"Fraction", right_param=node.base_type_param, return_type_expr=node.base_type_expr
        )
    ).build(parent=node.base_type)

    @lazy
    exponent: BasicSubpDecl = SyntheticSubpDecl.builder(
        spec=SyntheticUnarySpec.builder(
            subp_symbol=s"Exponent", right_param=node.base_type_param, return_type_expr=node.universal_int_type_expr
        )
    ).build(parent=node.base_type)

    @lazy
    copy_sign: BasicSubpDecl = SyntheticSubpDecl.builder(
        spec=SyntheticBinarySpec.builder(
            subp_symbol=s"Copy_Sign", left_param=node.base_type_param, right_param=node.base_type_param, return_type_expr=node.base_type_expr
        )
    ).build(parent=node.base_type)

    @lazy
    remainder: BasicSubpDecl = SyntheticSubpDecl.builder(
        spec=SyntheticBinarySpec.builder(
            subp_symbol=s"Remainder", left_param=node.base_type_param, right_param=node.base_type_param, return_type_expr=node.base_type_expr
        )
    ).build(parent=node.base_type)

    @lazy
    adjacent: BasicSubpDecl = SyntheticSubpDecl.builder(
        spec=SyntheticBinarySpec.builder(
            subp_symbol=s"Adjacent", left_param=node.base_type_param, right_param=node.base_type_param, return_type_expr=node.base_type_expr
        )
    ).build(parent=node.base_type)

    @lazy
    scaling: BasicSubpDecl = SyntheticSubpDecl.builder(
        spec=SyntheticBinarySpec.builder(
            subp_symbol=s"Scaling", left_param=node.base_type_param, right_param=node.universal_int_param, return_type_expr=node.base_type_expr
        )
    ).build(parent=node.base_type)

    @lazy
    compose: BasicSubpDecl = SyntheticSubpDecl.builder(
        spec=SyntheticBinarySpec.builder(
            subp_symbol=s"Compose", left_param=node.base_type_param, right_param=node.universal_int_param, return_type_expr=node.base_type_expr
        )
    ).build(parent=node.base_type)

    @lazy
    leading_part: BasicSubpDecl = SyntheticSubpDecl.builder(
        spec=SyntheticBinarySpec.builder(
            subp_symbol=s"Leading_Part", left_param=node.base_type_param, right_param=node.universal_int_param, return_type_expr=node.base_type_expr
        )
    ).build(parent=node.base_type)

    @lazy
    mod: BasicSubpDecl = SyntheticSubpDecl.builder(
        spec=SyntheticUnarySpec.builder(
            subp_symbol=s"Mod", right_param=node.universal_int_param, return_type_expr=node.base_type_expr
        )
    ).build(parent=node.base_type)

    @lazy
    value: BasicSubpDecl = SyntheticSubpDecl.builder(
        spec=SyntheticUnarySpec.builder(
            subp_symbol=s"Value", right_param=SyntheticFormalParamDecl.builder(
                param_name=s"Val", param_type=SyntheticTypeExpr.builder(
                    target_type=node.std_entity(s"String").as[BaseTypeDecl].node.to_builder()
                )
            ), return_type_expr=node.base_type_expr
        )
    ).build(parent=node.base_type)

    @lazy
    wide_value: BasicSubpDecl = SyntheticSubpDecl.builder(
        spec=SyntheticUnarySpec.builder(
            subp_symbol=s"Wide_Value", right_param=SyntheticFormalParamDecl.builder(
                param_name=s"Val", param_type=SyntheticTypeExpr.builder(
                    target_type=node.std_entity(s"Wide_String").as[BaseTypeDecl].node.to_builder()
                )
            ), return_type_expr=node.base_type_expr
        )
    ).build(parent=node.base_type)

    @lazy
    wide_wide_value: BasicSubpDecl = SyntheticSubpDecl.builder(
        spec=SyntheticUnarySpec.builder(
            subp_symbol=s"Wide_Wide_Value", right_param=SyntheticFormalParamDecl.builder(
                param_name=s"Val", param_type=SyntheticTypeExpr.builder(
                    target_type=node.std_entity(s"Wide_Wide_String").as[BaseTypeDecl].node.to_builder()
                )
            ), return_type_expr=node.base_type_expr
        )
    ).build(parent=node.base_type)

    @lazy
    fixed_value: BasicSubpDecl = SyntheticSubpDecl.builder(
        spec=SyntheticUnarySpec.builder(
            subp_symbol=s"Fixed_Value", right_param=node.universal_int_param, return_type_expr=node.base_type_expr
        )
    ).build(parent=node.base_type)

    @lazy
    integer_value: BasicSubpDecl = SyntheticSubpDecl.builder(
        spec=SyntheticUnarySpec.builder(
            subp_symbol=s"Integer_Value", right_param=node.universal_real_param, return_type_expr=node.base_type_expr
        )
    ).build(parent=node.base_type)

    @lazy
    pos: BasicSubpDecl = SyntheticSubpDecl.builder(
        spec=SyntheticUnarySpec.builder(
            subp_symbol=s"Pos", right_param=node.base_type_param, return_type_expr=node.universal_int_type_expr
        )
    ).build(parent=node.base_type)

    # We can't name it just `val` as this is a keyword in LKT
    @lazy
    val_attr: BasicSubpDecl = SyntheticSubpDecl.builder(
        spec=SyntheticUnarySpec.builder(
            subp_symbol=s"Val", right_param=node.universal_int_param, return_type_expr=node.base_type_expr
        )
    ).build(parent=node.base_type)

    @lazy
    enum_rep: BasicSubpDecl = SyntheticSubpDecl.builder(
        spec=SyntheticUnarySpec.builder(
            subp_symbol=s"Enum_Rep", right_param=node.base_type_param, return_type_expr=node.universal_int_type_expr
        )
    ).build(parent=node.base_type)

    @lazy
    enum_val: BasicSubpDecl = SyntheticSubpDecl.builder(
        spec=SyntheticUnarySpec.builder(
            subp_symbol=s"Enum_Val", right_param=node.universal_int_param, return_type_expr=node.base_type_expr
        )
    ).build(parent=node.base_type)

    @lazy
    read: BasicSubpDecl = SyntheticSubpDecl.builder(
        spec=SyntheticBinarySpec.builder(
            subp_symbol=s"Read", left_param=node.root_stream_param, right_param=node.base_type_param, return_type_expr=null[TypeExpr].to_builder()
        )
    ).build(parent=node.base_type)

    @lazy
    write: BasicSubpDecl = SyntheticSubpDecl.builder(
        spec=SyntheticBinarySpec.builder(
            subp_symbol=s"Write", left_param=node.root_stream_param, right_param=node.base_type_param, return_type_expr=null[TypeExpr].to_builder()
        )
    ).build(parent=node.base_type)

    @lazy
    input: BasicSubpDecl = SyntheticSubpDecl.builder(
        spec=SyntheticUnarySpec.builder(
            subp_symbol=s"Input", right_param=node.root_stream_param, return_type_expr=node.base_type_expr
        )
    ).build(parent=node.base_type)

    @lazy
    output: BasicSubpDecl = SyntheticSubpDecl.builder(
        spec=SyntheticBinarySpec.builder(
            subp_symbol=s"Output", left_param=node.root_stream_param, right_param=node.base_type_param, return_type_expr=null[TypeExpr].to_builder()
        )
    ).build(parent=node.base_type)

    @lazy
    image: BasicSubpDecl = SyntheticSubpDecl.builder(
        spec=SyntheticUnarySpec.builder(
            subp_symbol=s"Image", right_param=node.base_type_param, return_type_expr=SyntheticTypeExpr.builder(
                target_type=node.std_entity(s"String").as[BaseTypeDecl].node.to_builder()
            )
        )
    ).build(parent=node.base_type)

    @lazy
    wide_image: BasicSubpDecl = SyntheticSubpDecl.builder(
        spec=SyntheticUnarySpec.builder(
            subp_symbol=s"Wide_Image", right_param=node.base_type_param, return_type_expr=SyntheticTypeExpr.builder(
                target_type=node.std_entity(s"Wide_String").as[BaseTypeDecl].node.to_builder()
            )
        )
    ).build(parent=node.base_type)

    @lazy
    wide_wide_image: BasicSubpDecl = SyntheticSubpDecl.builder(
        spec=SyntheticUnarySpec.builder(
            subp_symbol=s"Wide_Wide_Image", right_param=node.base_type_param, return_type_expr=SyntheticTypeExpr.builder(
                target_type=node.std_entity(s"Wide_Wide_String").as[BaseTypeDecl].node.to_builder()
            )
        )
    ).build(parent=node.base_type)

    @lazy
    put_image: BasicSubpDecl = SyntheticSubpDecl.builder(
        spec=SyntheticBinarySpec.builder(
            subp_symbol=s"Put_Image", left_param=SyntheticFormalParamDecl.builder(
                param_name=s"Buffer", param_type=SyntheticTypeExpr.builder(
                    target_type=node.root_buffer_type().classwide_type().node.to_builder()
                )
            ), right_param=node.base_type_param, return_type_expr=null[TypeExpr].to_builder()
        )
    ).build(parent=node.base_type)

    @lazy
    asm_input: BasicSubpDecl = {
        val input_type = node.get_unit_root_decl(
            [s"System", s"Machine_Code"], AnalysisUnitKind.unit_specification
        )?.children_env().get_first(
            s"Asm_Input_Operand", lookup=LookupKind.flat
        ).node.as[BaseTypeDecl];

        SyntheticSubpDecl.builder(
            spec=SyntheticBinarySpec.builder(
                subp_symbol=s"Asm_Input", left_param=SyntheticFormalParamDecl.builder(
                    param_name=s"S", param_type=SyntheticTypeExpr.builder(
                        target_type=node.std_entity(s"String").as[BaseTypeDecl].node.to_builder()
                    )
                ), right_param=node.base_type_param, return_type_expr=SyntheticTypeExpr.builder(target_type=input_type.to_builder())
            )
        )
    }.build(parent=node.base_type)

    @lazy
    asm_output: BasicSubpDecl = {
        val output_type = node.get_unit_root_decl(
            [s"System", s"Machine_Code"], AnalysisUnitKind.unit_specification
        )?.children_env().get_first(
            s"Asm_Output_Operand", lookup=LookupKind.flat
        ).node.as[BaseTypeDecl];

        SyntheticSubpDecl.builder(
            spec=SyntheticBinarySpec.builder(
                subp_symbol=s"Asm_Output", left_param=SyntheticFormalParamDecl.builder(
                    param_name=s"S", param_type=SyntheticTypeExpr.builder(
                        target_type=node.std_entity(s"String").as[BaseTypeDecl].node.to_builder()
                    )
                ), right_param=node.base_type_param, return_type_expr=SyntheticTypeExpr.builder(target_type=output_type.to_builder())
            )
        )
    }.build(parent=node.base_type)

    @lazy
    model: BasicSubpDecl = SyntheticSubpDecl.builder(
        spec=SyntheticUnarySpec.builder(
            subp_symbol=s"Model", right_param=node.universal_real_param, return_type_expr=node.base_type_expr
        )
    ).build(parent=node.base_type)
}

|" Base class for type definitions (:rmlink:`3.2.1`).
@abstract
class TypeDef: AdaNode {
    |" Whether type is a real type or not.
    @with_dynvars(origin)
    fun is_real_type(): Bool = self.is_float_type() or self.is_fixed_point()

    fun predefined_equality_operators(): Array[EnvAssoc] = {
        val self_type = node.parent.as[TypeDecl];
        val bool_type = node.bool_type().node;

        [node.create_binop_assoc(
            s"\"=\"", self_type, self_type, bool_type
        ), node.create_binop_assoc(
            s"\"/=\"", self_type, self_type, bool_type
        )]
    }

    |" Return all the base types for this type (base type + base interfaces)
    @with_dynvars(origin)
    fun base_types(): Array[Entity[BaseTypeDecl]] =
        self.base_type().do((bt) => [bt]) & self.base_interfaces()

    @with_dynvars(origin, include_ud_indexing, dottable_type=null[AdaNode])
    fun defining_env(): LexicalEnv =
        # Regroup implementations for subclasses here instead of overriding to
        # avoid code duplication (multiple cases have the same implementation).
        # A "record" or "private" type def may be the completion of a
        # previous type declaration, so we need to include the defining
        # env of its previous part as well.
        if node is RecordTypeDef | PrivateTypeDef then [self.children_env(), self.dottable_subps_env(), self.previous_part_env()].env_group()
        # Same for "derived" and "interface" type definitions, but we also
        # need to include the defining environments of their base types.
        elif node is DerivedTypeDef | InterfaceTypeDef then (
            # Make sure to put own defining env before base types' defining
            # envs in the result, so that most-overridden subprograms will be
            # considered first during name resolution.
            (
                [self.children_env(), self.dottable_subps_env()] & {
                    bind dottable_type = dottable_type or? node.parent;

                    self.base_types().map((bt) => bt?.defining_env())
                } & [self.previous_part_env()]
            ).env_group()
        )
        # Continue propagating the original `dottable_type`, or start
        # propagating self if it's not set yet.
        elif node is ArrayTypeDef then [self.as[ArrayTypeDef].comp_type().defining_env(), self.dottable_subps_env()].env_group()
        elif node is AccessDef then [self.as[AccessDef].accessed_type()?.defining_env(), self.dottable_subps_env()].env_group()
        # An access to procedure will have a null accessed_type, hence
        # the use of the underscore.
        # In any case, include the type's `dottable_subps_env` so as to
        # fully support the universal dot notation feature.
        else self.dottable_subps_env()

    |" Return the TypeDecl containing this TypeDef
    fun containing_type(): Entity[TypeDecl] = self.parent.as![TypeDecl]

    fun previous_part(): Entity[BaseTypeDecl] =
        self.containing_type().previous_part(true)

    @with_dynvars(origin, dottable_type)
    fun previous_part_env(): LexicalEnv =
        self.previous_part()?.defining_env()

    @with_dynvars(origin, dottable_type)
    fun dottable_subps_env(): LexicalEnv =
        # Return the environment containing all subprograms that can be called
        # with the dot-notation on values of the type which this is defined.
        # It is important to rebind the env with our current rebindings,
        # so that subsequent calls to env.get on this env return those
        # subprograms with the adequate rebindings.
        # Note that we also set the ``primitive`` and ``primitive_real_type``
        # metadata field (without checking that they are actual primitives)
        # so that user queries such as ``primitive_subp_tagged_type`` return a
        # precise type. This is OK because those fields are not used for
        # name resolution in any case. (see TODO in ``real_designated_type``).
        [self.containing_type().dottable_subps_env.rebind_env(self.info.rebindings)].env_group(
            with_md=dottable_type.do(
                (t) => Metadata(
                    primitive=node.parent, primitive_real_type=t
                )
            )
        )

    |" Return the discrete range for this type def, if applicable.
    fun discrete_range(): DiscreteRange = null[DiscreteRange]

    |" If this designates an array type, return its number of dimensions.
    |" Return 0 otherwise.
    @with_dynvars(origin)
    fun array_ndims(): Int = 0

    |" Whether type is a float type or not.
    @with_dynvars(origin)
    fun is_float_type(): Bool = false

    |" Whether type is a fixed point type or not.
    @with_dynvars(origin)
    fun is_fixed_point(): Bool = false

    |" Return the list of predefined operators for this type definition.
    |" See TypeDecl.predefined_operators.
    |"
    |" This property is overridden by the various TypeDef concrete classes to
    |" implement type-specific logic.
    fun predefined_operators(): Array[EnvAssoc] = null[Array[EnvAssoc]]

    @with_dynvars(origin)
    fun is_discrete_type(): Bool = self.base_type().do(
        (bt) => bt.is_discrete_type(), default_val=self.is_int_type() or self.is_enum_type() or self.is_char_type()
    )

    |" Whether type is an integer type or not.
    @with_dynvars(origin)
    fun is_int_type(): Bool = false

    |" Whether type is an access type or not.
    @with_dynvars(origin)
    fun is_access_type(): Bool = false

    @with_dynvars(origin=null[AdaNode])
    fun is_char_type(): Bool = false

    @with_dynvars(origin=null[AdaNode])
    fun is_enum_type(): Bool = false

    @with_dynvars(origin)
    fun accessed_type(): Entity[BaseTypeDecl] = null[Entity[BaseTypeDecl]]

    |" Return whether this type is tagged.
    @with_dynvars(origin=null[AdaNode])
    fun is_tagged_type(): Bool = false

    @with_dynvars(origin=null[AdaNode])
    fun is_task_type(): Bool = false

    fun is_limited_type(): Bool = false

    |" Return the base type entity for this derived type definition.
    @with_dynvars(origin)
    fun base_type(): Entity[BaseTypeDecl] = null[Entity[BaseTypeDecl]]

    |" Return the interfaces this type derives from
    fun base_interfaces(): Array[Entity[BaseTypeDecl]] =
        null[Array[Entity[BaseTypeDecl]]]

    @with_dynvars(imprecise_fallback=false)
    fun is_static(): Bool = false
}

|" Base class for access type definitions (:rmlink:`3.10`).
@abstract
class AccessDef: TypeDef {
    @parse_field @nullable has_not_null: NotNull

    @with_dynvars(origin)
    fun is_access_type(): Bool = true

    @memoized
    fun predefined_operators(): Array[EnvAssoc] =
        node.predefined_equality_operators()
}

|" Type definition for accesses to subprograms (:rmlink:`3.10`).
class AccessToSubpDef: AccessDef {
    @parse_field has_protected: Protected
    @parse_field subp_spec: SubpSpec

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = %true

    @with_dynvars(origin)
    fun accessed_type(): Entity[BaseTypeDecl] = self.subp_spec.return_type()

    # We need to add an env to contain the subp_spec's parameters, so that they
    # don't leak in the external scope.
    env_spec {
        add_env()
    }
}

|" Base class for access type definitions (:rmlink:`3.10`).
@abstract
class BaseTypeAccessDef: AccessDef {
}

|" Synthetic type access, that will directly reference a type decl. It is used
|" to generate synthetic anonymous access types.
@synthetic
class AnonymousTypeAccessDef: BaseTypeAccessDef {
    @parse_field type_decl: BaseTypeDecl

    @with_dynvars(origin)
    fun accessed_type(): Entity[BaseTypeDecl] = self.type_decl
}

|" Syntactic type definition for accesses.
class TypeAccessDef: BaseTypeAccessDef {
    @parse_field has_all: All
    @parse_field has_constant: Constant
    @parse_field subtype_indication: SubtypeIndication

    @with_dynvars(origin)
    fun accessed_type(): Entity[BaseTypeDecl] =
        self.subtype_indication.designated_type()

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = self.subtype_indication.xref_equation()
}

|" Type definition for an array (:rmlink:`3.6`).
class ArrayTypeDef: TypeDef {
    @parse_field indices: ArrayIndices
    @parse_field component_type: ComponentDef

    |" Returns the type stored as a component in the array.
    @with_dynvars(origin)
    fun comp_type(): Entity[BaseTypeDecl] =
        self.component_type.type_expr.designated_type()

    @with_dynvars(origin)
    fun index_type(dim: Int): Entity[BaseTypeDecl] =
        self.indices.index_type(dim)

    @with_dynvars(origin)
    fun array_ndims(): Int = node.indices.ndims()

    fun is_limited_type(): Bool = {
        bind origin = null[AdaNode]; # We want full visibility

        self.comp_type().is_limited_type()
    }

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.indices.sub_equation() and self.component_type.sub_equation()

    @memoized
    fun predefined_operators(): Array[EnvAssoc] = {
        val self_type = node.parent.as[TypeDecl];
        val bool_type = node.bool_type().node;
        val comp_type_expr = node.component_type.type_expr;

        # Note: here, we define the `and`, `or`, `xor` and `not` operators
        # for all array types (even if they don't make sense) because we have
        # no way to know at this stage if the component type is a boolean type
        # or not (e.g. the component type designates a generic formal).
        # This does not seem to cause any problem for now in practice, but in
        # theory it could hide user-defined operators in certain circumstances.
        # TODO: This could be fixed by filtering out invalid operators when
        # resolving names, somewhere the self info is available.
        [node.create_binop_assoc(
            s"\"<\"", self_type, self_type, bool_type
        ), node.create_binop_assoc(
            s"\"<=\"", self_type, self_type, bool_type
        ), node.create_binop_assoc(
            s"\"=\"", self_type, self_type, bool_type
        ), node.create_binop_assoc(
            s"\"/=\"", self_type, self_type, bool_type
        ), node.create_binop_assoc(
            s"\">\"", self_type, self_type, bool_type
        ), node.create_binop_assoc(
            s"\">=\"", self_type, self_type, bool_type
        ), node.create_binop_assoc(
            s"\"and\"", self_type, self_type, self_type
        ), node.create_binop_assoc(
            s"\"or\"", self_type, self_type, self_type
        ), node.create_binop_assoc(
            s"\"xor\"", self_type, self_type, self_type
        ), node.create_unop_assoc(s"\"not\"", self_type, self_type), # The 4 predefined array concatenation operators
        node.create_binop_assoc_l_r_expr(
            s"\"&\"", comp_type_expr, comp_type_expr, self_type
        ), node.create_binop_assoc_l_expr(
            s"\"&\"", comp_type_expr, self_type, self_type
        ), node.create_binop_assoc_r_expr(
            s"\"&\"", self_type, comp_type_expr, self_type
        ), node.create_binop_assoc(
            s"\"&\"", self_type, self_type, self_type
        )]
    }

    @with_dynvars(imprecise_fallback=false)
    fun is_static(): Bool = self.indices.is_static()

    fun xref_entry_point(): Bool = true
}

|" Type definition for a derived type (:rmlink:`3.4`).
class DerivedTypeDef: TypeDef {
    @parse_field has_abstract: Abstract
    @parse_field has_limited: Limited
    @parse_field has_synchronized: Synchronized
    @parse_field subtype_indication: SubtypeIndication
    @parse_field interfaces: ParentList
    @parse_field @nullable record_extension: BaseRecordDef
    @parse_field has_with_private: WithPrivate

    @with_dynvars(origin)
    fun array_ndims(): Int = self.base_type().do(
        (bt) => bt.array_ndims(), default_val=self.super()
    )

    @with_dynvars(origin)
    fun base_type(): Entity[BaseTypeDecl] =
        self.subtype_indication.designated_type()

    fun base_interfaces(): Array[Entity[BaseTypeDecl]] =
        self.interfaces.map((i) => i.name_designated_type())

    @with_dynvars(origin=null[AdaNode])
    fun is_task_type(): Bool = self.base_type().is_task_type()

    @with_dynvars(origin)
    fun is_int_type(): Bool = self.base_type().is_int_type()

    @with_dynvars(origin)
    fun is_access_type(): Bool =
        node.as_bare_entity.base_type().is_access_type()

    @with_dynvars(origin=null[AdaNode])
    fun is_char_type(): Bool = self.base_type().is_char_type()

    @with_dynvars(origin)
    fun is_float_type(): Bool = self.base_type().is_float_type()

    @with_dynvars(origin)
    fun is_fixed_point(): Bool = self.base_type().is_fixed_point()

    @with_dynvars(origin)
    fun accessed_type(): Entity[BaseTypeDecl] =
        self.base_type()?.accessed_type()

    @with_dynvars(origin=null[AdaNode])
    fun is_tagged_type(): Bool =
        not self.record_extension.is_null or self.has_with_private.as_bool()

    @with_dynvars(origin=null[AdaNode])
    fun is_enum_type(): Bool = self.base_type().is_enum_type()

    fun is_limited_type(): Bool = (
        node.has_limited.as_bool() or self.record_extension?.comps()?.has_limited_component()
    ) or {
        bind origin = null[AdaNode];

        self.base_type().do(
            (bt) => (
                # We want full visibility
                # Note that we don't recurse on interfaces, because limitedness is
                # not inherited from those (ARM 7.5 6.2/2).
                not bt.is_interface_type()
            ) and bt.is_limited_type()
        )
    }

    @with_dynvars(imprecise_fallback=false)
    fun is_static(): Bool = self.subtype_indication.is_static_subtype()

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        # We want to make discriminants accessible, so need to evaluate this in
        # self's children_env.
        {
            bind env = self.children_env();

            self.subtype_indication.xref_equation() and self.interfaces.logic_all((ifc) => ifc.xref_equation())
        }

    fun discrete_range(): DiscreteRange =
        self.subtype_indication.discrete_range()
}

|" Type definition for enumerations (:rmlink:`3.5.1`).
class EnumTypeDef: TypeDef {
    @parse_field enum_literals: ASTList[EnumLiteralDecl]

    @with_dynvars(origin=null[AdaNode])
    fun is_char_type(): Bool =
        node.enum_literals.any((lit) => lit.name.name is CharLiteral)

    @with_dynvars(origin=null[AdaNode])
    fun is_enum_type(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = %true

    @with_dynvars(imprecise_fallback=false)
    fun is_static(): Bool = true

    fun is_std_char_type(): Bool = {
        val self_type = node.parent.as[TypeDecl];

        self_type in node.std_char_type().node | node.std_wide_char_type().node | node.std_wide_wide_char_type().node
    }

    @memoized
    fun predefined_operators(): Array[EnvAssoc] = {
        val self_type = node.parent.as[TypeDecl];
        val bool_type = node.bool_type().node;
        val defaults = [node.create_binop_assoc(
            s"\"<\"", self_type, self_type, bool_type
        ), node.create_binop_assoc(
            s"\"<=\"", self_type, self_type, bool_type
        ), node.create_binop_assoc(
            s"\"=\"", self_type, self_type, bool_type
        ), node.create_binop_assoc(
            s"\"/=\"", self_type, self_type, bool_type
        ), node.create_binop_assoc(
            s"\">\"", self_type, self_type, bool_type
        ), node.create_binop_assoc(
            s"\">=\"", self_type, self_type, bool_type
        )];
        # The boolean type has four additional builtin operations
        val specials = if self_type == bool_type then [node.create_binop_assoc(
            s"\"and\"", self_type, self_type, self_type
        ), node.create_binop_assoc(
            s"\"or\"", self_type, self_type, self_type
        ), node.create_binop_assoc(
            s"\"xor\"", self_type, self_type, self_type
        ), node.create_unop_assoc(s"\"not\"", self_type, self_type)] else null[Array[EnvAssoc]];

        defaults & specials
    }
}

|" Type definition for discrete types in generic formals
|" (:rmlink:`12.5.2`).
class FormalDiscreteTypeDef: TypeDef {
    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = %true

    @with_dynvars(origin)
    fun is_discrete_type(): Bool = true

    @memoized
    fun predefined_operators(): Array[EnvAssoc] = {
        val self_type = node.parent.as[TypeDecl];
        val bool_type = node.bool_type().node;

        [node.create_binop_assoc(
            s"\"<\"", self_type, self_type, bool_type
        ), node.create_binop_assoc(
            s"\"<=\"", self_type, self_type, bool_type
        ), node.create_binop_assoc(
            s"\"=\"", self_type, self_type, bool_type
        ), node.create_binop_assoc(
            s"\"/=\"", self_type, self_type, bool_type
        ), node.create_binop_assoc(
            s"\">\"", self_type, self_type, bool_type
        ), node.create_binop_assoc(
            s"\">=\"", self_type, self_type, bool_type
        )]
    }
}

|" Type definition for an interface (:rmlink:`3.9.4`).
class InterfaceTypeDef: TypeDef {
    @parse_field @nullable interface_kind: InterfaceKind
    @parse_field interfaces: ParentList

    @with_dynvars(origin=null[AdaNode])
    fun is_tagged_type(): Bool = true

    @with_dynvars(origin=null[AdaNode])
    fun is_task_type(): Bool = self.interface_kind is InterfaceKind.Task

    # All four interface kinds declare limited types. Also, limitedness is not
    # inherited from parent interfaces (ARM 7.5 6.2/2).
    fun is_limited_type(): Bool = not node.interface_kind.is_null

    fun base_interfaces(): Array[Entity[BaseTypeDecl]] =
        self.interfaces.map((i) => i.name_designated_type())

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.interfaces.logic_all((ifc) => ifc.xref_equation())
}

|" Type definition for a modular integer type (:rmlink:`3.5.4`).
class ModIntTypeDef: TypeDef {
    @parse_field expr: Expr

    @with_dynvars(origin)
    fun is_int_type(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = self.expr.sub_equation()

    @with_dynvars(imprecise_fallback=false)
    fun is_static(): Bool = self.expr.is_static_expr()

    fun discrete_range(): DiscreteRange = DiscreteRange(
        low_bound=null[Entity[Expr]], high_bound=self.expr
    )

    @memoized
    fun predefined_operators(): Array[EnvAssoc] = {
        val self_type = node.parent.as[TypeDecl];
        val bool_type = node.bool_type().node;
        val int_type = node.int_type().node;

        [node.create_binop_assoc(
            s"\"+\"", self_type, self_type, self_type
        ), node.create_binop_assoc(
            s"\"-\"", self_type, self_type, self_type
        ), node.create_binop_assoc(
            s"\"*\"", self_type, self_type, self_type
        ), node.create_binop_assoc(
            s"\"/\"", self_type, self_type, self_type
        ), node.create_binop_assoc(
            s"\"mod\"", self_type, self_type, self_type
        ), node.create_binop_assoc(
            s"\"rem\"", self_type, self_type, self_type
        ), node.create_binop_assoc(
            s"\"and\"", self_type, self_type, self_type
        ), node.create_binop_assoc(
            s"\"or\"", self_type, self_type, self_type
        ), node.create_binop_assoc(
            s"\"**\"", self_type, int_type, self_type
        ), node.create_binop_assoc(
            s"\"<\"", self_type, self_type, bool_type
        ), node.create_binop_assoc(
            s"\"<=\"", self_type, self_type, bool_type
        ), node.create_binop_assoc(
            s"\"=\"", self_type, self_type, bool_type
        ), node.create_binop_assoc(
            s"\"/=\"", self_type, self_type, bool_type
        ), node.create_binop_assoc(
            s"\">\"", self_type, self_type, bool_type
        ), node.create_binop_assoc(
            s"\">=\"", self_type, self_type, bool_type
        ), node.create_unop_assoc(s"\"+\"", self_type, self_type), node.create_unop_assoc(s"\"-\"", self_type, self_type), node.create_unop_assoc(s"\"abs\"", self_type, self_type), node.create_unop_assoc(s"\"not\"", self_type, self_type)]
    }
}

|" Type definition for a private type.
|"
|" Libadalang diverges from the ARM here, treating private types like regular
|" type declarations that have an embedded type definition. This type
|" definition hence corresponds to :rmlink:`7.3`.
class PrivateTypeDef: TypeDef {
    @parse_field has_abstract: Abstract
    @parse_field has_tagged: Tagged
    @parse_field has_limited: Limited

    @with_dynvars(origin=null[AdaNode])
    fun is_tagged_type(): Bool = node.has_tagged.as_bool()

    fun is_limited_type(): Bool = node.has_limited.as_bool()

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = %true

    @memoized
    fun predefined_operators(): Array[EnvAssoc] =
        if node.has_limited.as_bool() then null[Array[EnvAssoc]] else node.predefined_equality_operators()
}

|" Type definition for real numbers (:rmlink:`3.5.6`).
@abstract
class RealTypeDef: TypeDef {
    @with_dynvars(imprecise_fallback=false)
    fun is_static(): Bool = true

    @memoized
    fun predefined_operators(): Array[EnvAssoc] = {
        val self_type = node.parent.as[TypeDecl];
        val bool_type = node.bool_type().node;
        val int_type = node.int_type().node;
        val root_int_type = node.root_int_type().node;
        val defaults = [node.create_binop_assoc(
            s"\"+\"", self_type, self_type, self_type
        ), node.create_binop_assoc(
            s"\"-\"", self_type, self_type, self_type
        ), node.create_binop_assoc(
            s"\"*\"", self_type, self_type, self_type
        ), node.create_binop_assoc(
            s"\"/\"", self_type, self_type, self_type
        ), node.create_binop_assoc(
            s"\"**\"", self_type, int_type, self_type
        ), node.create_binop_assoc(
            s"\"<\"", self_type, self_type, bool_type
        ), node.create_binop_assoc(
            s"\"<=\"", self_type, self_type, bool_type
        ), node.create_binop_assoc(
            s"\"=\"", self_type, self_type, bool_type
        ), node.create_binop_assoc(
            s"\"/=\"", self_type, self_type, bool_type
        ), node.create_binop_assoc(
            s"\">\"", self_type, self_type, bool_type
        ), node.create_binop_assoc(
            s"\">=\"", self_type, self_type, bool_type
        ), node.create_unop_assoc(s"\"+\"", self_type, self_type), node.create_unop_assoc(s"\"-\"", self_type, self_type), node.create_unop_assoc(s"\"abs\"", self_type, self_type)];
        # The root_real type also defines the three following operators
        val specials = if self_type == node.root_real_type().node then [node.create_binop_assoc(
            s"\"*\"", root_int_type, self_type, self_type
        ), node.create_binop_assoc(
            s"\"*\"", self_type, root_int_type, self_type
        ), node.create_binop_assoc(
            s"\"/\"", self_type, root_int_type, self_type
        )] else null[Array[EnvAssoc]];

        defaults & specials
    }

    |" Return the predefined multiplication operators for the
    |" universal_fixed type (:rmlink:`4.5.5` 18-19).
    @memoized
    fun universal_fixed_predefined_operators(): Array[EnvAssoc] = {
        val uf = node.universal_fixed_type().node;

        [node.create_binop_assoc(s"\"*\"", uf, uf, uf), node.create_binop_assoc(s"\"/\"", uf, uf, uf)]
    }
}

|" Type definition for decimal fixed-point numbers (:rmlink:`3.5.9`).
class DecimalFixedPointDef: RealTypeDef {
    @parse_field delta: Expr
    @parse_field digits: Expr
    @parse_field @nullable range: RangeSpec

    @with_dynvars(origin)
    fun is_fixed_point(): Bool = true

    |" Build an equation for a decimal fixed point type definition.
    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = (
        # As per RM 3.5.9, the delta expression is expected to be of any
        # real type.
        self.universal_real_bind(self.delta.expected_type_var())
    ) and self.delta.sub_equation() and self.delta.matches_expected_type() and (
        # The digits expression is expected to be of any integer type
        self.universal_int_bind(self.digits.expected_type_var())
    ) and self.digits.sub_equation() and self.digits.matches_expected_type() and (
        if node.range.is_null then %true else self.range.sub_equation()
    )

    @memoized
    fun predefined_operators(): Array[EnvAssoc] = {
        val self_type = node.parent.as[TypeDecl];
        val bool_type = node.bool_type().node;
        val int_type = node.int_type().node;

        [node.create_binop_assoc(
            s"\"+\"", self_type, self_type, self_type
        ), node.create_binop_assoc(
            s"\"-\"", self_type, self_type, self_type
        ), node.create_binop_assoc(
            s"\"*\"", self_type, self_type, self_type
        ), node.create_binop_assoc(
            s"\"/\"", self_type, self_type, self_type
        ), node.create_binop_assoc(s"\"*\"", int_type, self_type, self_type), node.create_binop_assoc(s"\"*\"", self_type, int_type, self_type), node.create_binop_assoc(s"\"/\"", self_type, int_type, self_type), node.create_binop_assoc(
            s"\"**\"", self_type, int_type, self_type
        ), node.create_binop_assoc(
            s"\"<\"", self_type, self_type, bool_type
        ), node.create_binop_assoc(
            s"\"<=\"", self_type, self_type, bool_type
        ), node.create_binop_assoc(
            s"\"=\"", self_type, self_type, bool_type
        ), node.create_binop_assoc(
            s"\"/=\"", self_type, self_type, bool_type
        ), node.create_binop_assoc(
            s"\">\"", self_type, self_type, bool_type
        ), node.create_binop_assoc(
            s"\">=\"", self_type, self_type, bool_type
        ), node.create_unop_assoc(s"\"+\"", self_type, self_type), node.create_unop_assoc(s"\"-\"", self_type, self_type), node.create_unop_assoc(s"\"abs\"", self_type, self_type)]
    }
}

|" Type definition for floating-point numbers (:rmlink:`3.5.7`).
class FloatingPointDef: RealTypeDef {
    @parse_field num_digits: Expr
    @parse_field @nullable range: RangeSpec

    @with_dynvars(origin)
    fun is_float_type(): Bool = true

    |" Build an equation for a floating point type definition.
    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = (
        # As per RM 3.5.7, the num_digits expression is expected to be of
        # any integer type.
        self.universal_int_bind(self.num_digits.expected_type_var())
    ) and self.num_digits.sub_equation() and self.num_digits.matches_expected_type() and (
        # Expressions from the range specification are expected to be of
        # any real type, the types need not be the same.
        self.range.do(
            (r) => (
                self.universal_real_bind(r.range.expected_type_var()) and r.range.sub_equation()
            ) and r.range.matches_expected_type(), default_val=%true
        )
    )
}

|" Type definition for ordinary fixed-point numbers (:rmlink:`3.5.9`).
class OrdinaryFixedPointDef: RealTypeDef {
    @parse_field delta: Expr
    @parse_field @nullable range: RangeSpec

    @with_dynvars(origin)
    fun is_fixed_point(): Bool = true

    |" Build an equation for an ordinary fixed point type definition.
    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        # As per RM 3.5.9, the delta expression is expected to be of any
        # real type.
        self.universal_real_bind(self.delta.expected_type_var())
        and self.delta.sub_equation()
        and self.delta.matches_expected_type()
        and (if node.range.is_null then %true else self.range.sub_equation())

    @memoized
    fun predefined_operators(): Array[EnvAssoc] = {
        val self_type = node.parent.as[TypeDecl];
        val bool_type = node.bool_type().node;
        val int_type = node.int_type().node;

        [node.create_binop_assoc(
            s"\"+\"", self_type, self_type, self_type
        ), node.create_binop_assoc(
            s"\"-\"", self_type, self_type, self_type
        ), node.create_binop_assoc(
            s"\"*\"", self_type, self_type, self_type
        ), node.create_binop_assoc(
            s"\"/\"", self_type, self_type, self_type
        ), node.create_binop_assoc(s"\"*\"", int_type, self_type, self_type), node.create_binop_assoc(s"\"*\"", self_type, int_type, self_type), node.create_binop_assoc(s"\"/\"", self_type, int_type, self_type), node.create_binop_assoc(
            s"\"**\"", self_type, int_type, self_type
        ), node.create_binop_assoc(
            s"\"<\"", self_type, self_type, bool_type
        ), node.create_binop_assoc(
            s"\"<=\"", self_type, self_type, bool_type
        ), node.create_binop_assoc(
            s"\"=\"", self_type, self_type, bool_type
        ), node.create_binop_assoc(
            s"\"/=\"", self_type, self_type, bool_type
        ), node.create_binop_assoc(
            s"\">\"", self_type, self_type, bool_type
        ), node.create_binop_assoc(
            s"\">=\"", self_type, self_type, bool_type
        ), node.create_unop_assoc(s"\"+\"", self_type, self_type), node.create_unop_assoc(s"\"-\"", self_type, self_type), node.create_unop_assoc(s"\"abs\"", self_type, self_type)]
    }
}

|" Type definition for a record (:rmlink:`3.8`).
class RecordTypeDef: TypeDef {
    @parse_field has_abstract: Abstract
    @parse_field has_tagged: Tagged
    @parse_field has_limited: Limited
    @parse_field record_def: BaseRecordDef

    @with_dynvars(origin=null[AdaNode])
    fun is_tagged_type(): Bool = node.has_tagged.as_bool()

    fun is_limited_type(): Bool =
        node.has_limited.as_bool() or self.record_def.comps().has_limited_component()

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = %true

    @memoized
    fun predefined_operators(): Array[EnvAssoc] =
        if node.has_limited.as_bool() then null[Array[EnvAssoc]] else node.predefined_equality_operators()
}

|" Type definition for a signed integer type (:rmlink:`3.5.4`).
class SignedIntTypeDef: TypeDef {
    @parse_field range: RangeSpec

    @with_dynvars(origin)
    fun is_int_type(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = self.range.xref_equation()

    fun discrete_range(): DiscreteRange = self.range.range.discrete_range()

    @memoized
    fun predefined_operators(): Array[EnvAssoc] = {
        val self_type = node.parent.as[TypeDecl];
        val bool_type = node.bool_type().node;
        val int_type = node.int_type().node;
        val defaults = [node.create_binop_assoc(
            s"\"+\"", self_type, self_type, self_type
        ), node.create_binop_assoc(
            s"\"-\"", self_type, self_type, self_type
        ), node.create_binop_assoc(
            s"\"*\"", self_type, self_type, self_type
        ), node.create_binop_assoc(
            s"\"/\"", self_type, self_type, self_type
        ), node.create_binop_assoc(
            s"\"mod\"", self_type, self_type, self_type
        ), node.create_binop_assoc(
            s"\"rem\"", self_type, self_type, self_type
        ), node.create_binop_assoc(
            s"\"**\"", self_type, int_type, self_type
        ), node.create_binop_assoc(
            s"\"<\"", self_type, self_type, bool_type
        ), node.create_binop_assoc(
            s"\"<=\"", self_type, self_type, bool_type
        ), node.create_binop_assoc(
            s"\"=\"", self_type, self_type, bool_type
        ), node.create_binop_assoc(
            s"\"/=\"", self_type, self_type, bool_type
        ), node.create_binop_assoc(
            s"\">\"", self_type, self_type, bool_type
        ), node.create_binop_assoc(
            s"\">=\"", self_type, self_type, bool_type
        ), node.create_unop_assoc(s"\"+\"", self_type, self_type), node.create_unop_assoc(s"\"-\"", self_type, self_type), node.create_unop_assoc(s"\"abs\"", self_type, self_type)];

        defaults
    }

    @with_dynvars(imprecise_fallback=false)
    fun is_static(): Bool = self.range.range.is_static_expr()
}

|" A type expression is an abstract node that embodies the concept of a
|" reference to a type.
|"
|" Since Ada has both subtype_indications and anonymous (inline) type
|" declarations, a type expression contains one or the other.
|"
|" This node has no ARM correspondence.
@abstract
class TypeExpr: AdaNode {
    fun array_ndims(): Int = {
        bind origin = node.origin_node();

        self.designated_type().array_ndims()
    }

    |" Return the name node for this type expression, if applicable, else null
    @exported
    fun type_name(): Entity[Name] =
        self.as[SubtypeIndication].do((sti) => sti.name)

    @with_dynvars(origin, include_ud_indexing, dottable_type=null[AdaNode])
    fun defining_env(): LexicalEnv =
        self.designated_type().defining_env()

    |" Return the type designated by this type expression.
    @abstract
    @with_dynvars(origin)
    fun designated_type(): Entity[BaseTypeDecl]

    |" Returns the type declaration designated by this type expression.
    @exported
    fun designated_type_decl(): Entity[BaseTypeDecl] = {
        bind origin = node.origin_node();

        self.designated_type()
    }

    |" Return the type declaration designated by this type expression as
    |" viewed from the node given by origin_node.
    @exported
    fun designated_type_decl_from(origin_node: Entity[AdaNode]): Entity[BaseTypeDecl] = {
        bind origin = origin_node.node.origin_node();

        self.designated_type()
    }

    |" If self is an anonymous access, return the accessed type. Otherwise,
    |" return the designated type.
    @with_dynvars(origin)
    fun element_type(): Entity[BaseTypeDecl] = {
        val d = self.designated_type();

        if d is AnonymousTypeDecl and d.as[AnonymousTypeDecl].type_def is AccessDef then d.accessed_type() else d
    }

    @with_dynvars(origin)
    @ignored
    fun canonical_type(): Entity[BaseTypeDecl] =
        self.designated_type()?.canonical_type()

    |" Return the constraint that this type expression defines on its
    |" designated subtype, if any.
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun subtype_constraint(): Entity[Constraint] =
        self.as[SubtypeIndication].do((si) => si.constraint) or? self.designated_type().as[SubtypeDecl].do((st) => st.subtype.subtype_constraint())

    |" If this type expression designates a constrained discriminated type,
    |" return an array of pairs, associating each discriminant to its actual
    |" or default expression.
    @exported
    fun discriminant_constraints(): Array[ParamActual] =
        self.subtype_constraint().as[CompositeConstraint].do((cc) => cc.discriminant_params())

    |" Returns whether this designates a definite subtype.
    @exported
    fun is_definite_subtype(): Bool =
        self.designated_type_decl().is_definite_subtype()

    fun custom_id_text(): String = {
        bind origin = node;
        self.designated_type().canonical_fully_qualified_name()
    }
}

|" Container for inline anonymous array and access types declarations.
class AnonymousType: TypeExpr {
    @parse_field type_decl: AnonymousTypeDecl

    @with_dynvars(origin)
    fun designated_type(): Entity[BaseTypeDecl] = self.type_decl

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = self.type_decl.sub_equation()

    # TODO: This implementation is not satisfying, because the formatting will
    # be the original source formatting, but will do for the moment.
    # Ideally we would compute a properly formatted version of the anonymous
    # type declaration. Using unparsing in order to avoid duplicating logic
    # between parsing/unparsing.
    fun custom_id_text(): String = self.type_decl.text()
}

|" Synthetic node. Represents the type expression for an enum literal.
@synthetic
class EnumLitSynthTypeExpr: TypeExpr {
    @with_dynvars(origin)
    fun designated_type(): Entity[BaseTypeDecl] =
        self.parent.as[EnumLiteralDecl].enum_type()

    fun custom_id_text(): String = {
        bind origin = node;

        self.designated_type().canonical_fully_qualified_name() & "." & # The custom_id_text is the combination of the enum type name and of
        # the enum literal name.
        self.sym_join(
            self.parent.as[EnumLiteralDecl].defining_name().as_symbol_array(), ""
        )
    }
}

|" Reference to a type by name (:rmlink:`3.2.2`).
class SubtypeIndication: TypeExpr {
    @parse_field has_not_null: NotNull
    @parse_field name: Name
    @parse_field @nullable constraint: Constraint

    # The name for this type has to be evaluated in the context of the
    # SubtypeIndication node itself: we don't want to use whatever lexical
    # environment the caller is using. However we need to inherit the
    # visibility (origin node) of the caller.
    @with_dynvars(origin)
    fun designated_type(): Entity[BaseTypeDecl] = {
        bind env = self.node_env();

        self.name.designated_type_impl()
    }

    fun is_definite_subtype(): Bool =
        not self.constraint.is_null or self.designated_type_decl().is_definite_subtype()

    |" Return possible completions for a type indication at this point in the
    |" file. Completions for a type indication are more likely coming from a
    |" type declaration. PackageDecls have a medium weight in order to provide
    |" completion of fully qualified names.
    @with_dynvars(origin)
    fun complete_items(): Array[CompletionItem] = self.children_env().get(null[Symbol]).map(
        (n) => CompletionItem(
            decl=n.as[BasicDecl],
            is_dot_call=n.info.md.dottable_subp,
            is_visible=node.has_visibility(n),
            weight=match n {
                case btd: BaseTypeDecl =>
                # Do not promote self as a possible completion for
                # itself::
                #
                #     type My_Type is new M
                #                          ^ set My_Type's weight to 0
                if self.parent is DerivedTypeDef and self.parent.parent == btd then 0 else 100
                case _: PackageDecl => 50
                case _ => 0
            }
        )
    )

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        # Called by allocator.xref_equation, since the suffix can be either a
        # qual expr or a subtype indication.
        self.name.subtype_indication_equation() and self.constraint.do(
            (c) => c.sub_equation(), default_val=%true
        )

    fun discrete_range(): DiscreteRange = {
        val rc = self.constraint.as![RangeConstraint];

        rc.do(
            (r) => r.range.range.discrete_range(),
            # If no additional range constraint is specified, the range is
            # that of the indicated subtype.
            default_val=self.designated_type_decl().discrete_range()
        )
    }

    |" Returns whether self denotes a static subtype or not (i.e. determinable
    |" at compile time, see :rmlink:`4.9`).
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun is_static_subtype(): Bool = {
        bind origin = node.origin_node();

        not self.semantic_parent().as[BasicDecl].has_aspect(s"Dynamic_Predicate")
        and self.constraint.do(
            (c) => c.is_static(),
            default_val=self.designated_type().is_static_decl()
        )
    }
}

|" Reference to a type with a range constraint.
class ConstrainedSubtypeIndication: SubtypeIndication {
}

|" Reference to a type with a general constraint.
class DiscreteSubtypeIndication: SubtypeIndication {
}

|" Synthetic type expression. The designated type is already known at
|" instantiation time and is to be given in the ``target_type`` field.
@synthetic
class SyntheticTypeExpr: TypeExpr {
    @parse_field target_type: BaseTypeDecl

    @with_dynvars(origin)
    fun designated_type(): Entity[BaseTypeDecl] = {
        # The `target_type` field stores the bare designated BaseTypeDecl,
        # but self may be carrying rebindings that need to be put back on
        # the bare node.
        # However, all of self's rebinding may not be relevant. For example,
        # if `target_type` is the definition of `Standard.Boolean`, no
        # rebindings will ever be relevant.
        # Hence we use the built-in `shed_rebindings` construct from the type
        # definition's lexical environment so as to only keep relevant ones.
        val relevant_rebindings = node.target_type.children_env().shed_rebindings(self.info).rebindings;

        # Return a rebound `target_type`
        Entity[BaseTypeDecl](
            node=node.target_type, info=EntityInfo(
                md=null[Metadata], rebindings=relevant_rebindings, from_rebound=self.info.from_rebound
            )
        )
    }
}

|" List of unconstrained array indexes.
class UnconstrainedArrayIndex: AdaNode {
    @parse_field subtype_name: Name
    @parse_field @nullable lower_bound: Expr

    @with_dynvars(origin)
    fun designated_type(): Entity[BaseTypeDecl] =
        self.subtype_name.name_designated_type()
}

|" Qualifier for the ``until`` keyword.
@qualifier
enum class Until: AdaNode {
}

|" Base class for use clauses (:rmlink:`10.1.2`).
@abstract
class UseClause: AdaNode {
    fun xref_entry_point(): Bool = true

    |" Return the environment grouping all environments that are referred
    |" to by this use clause.
    fun used_envs(): LexicalEnv = match self {
        case upc: UsePackageClause => upc.designated_envs().env_group()
        case utc: UseTypeClause => utc.types.map((n) => n.name_designated_type_env()).env_group()
    }

    |" Return the initial env for a use clause. Always the standard package
    |" for top level use clauses.
    fun initial_env(): DesignatedEnv =
        if node.parent.parent is CompilationUnit then DesignatedEnv(
            kind=DesignatedEnvKind.named_env, env_name=s"Standard", direct_env=null[LexicalEnv]
        ) else DesignatedEnv(
            kind=DesignatedEnvKind.current_env, env_name=null[Symbol], direct_env=null[LexicalEnv]
        )
}

|" Use clause for packages (:rmlink:`8.4`).
class UsePackageClause: UseClause {
    @parse_field packages: ASTList[Name]

    |" Return the lexical env designated by the index'th package name in this
    |" use clause.
    fun designated_env(index: Int): LexicalEnv = {
        val pkg = node.packages?[index];

        {
            bind env = self.node_env();
            bind origin = pkg.origin_node();

            pkg.as_bare_entity.designated_env()
        }
    }

    |" Return the array of designated envs corresponding to each package name.
    |"
    |" It is very important for this property to be memoized, as it is used a
    |" lot during lexical environment lookups.
    fun designated_envs(): Array[LexicalEnv] =
        node.packages.imap((_, i) => self.designated_env(i))

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.packages.logic_all((p) => p.xref_no_overloading())

    env_spec {
        set_initial_env(node.initial_env())
        # Run PLE on the children (i.e. the names of USE'd packages) so that we
        # can run name resolution on them in the call to reference() below.
        handle_children()
        reference(
            node.packages.map((n) => n.as[AdaNode]), Name.use_package_name_designated_env, cond=not node.parent.parent is CompilationUnit
        )
    }
}

|" Use clause for types (:rmlink:`8.4`).
class UseTypeClause: UseClause {
    @parse_field has_all: All
    @parse_field types: ASTList[Name]

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.types.logic_all((p) => p.xref_type_equation())

    env_spec {
        set_initial_env(node.initial_env())
        # Run PLE on the children (i.e. the names of USE'd packages) so that we
        # can run name resolution on them in the call to reference() below.
        handle_children()
        reference(
            node.types.map((n) => n.as[AdaNode]), Name.name_designated_type_env, cond=not node.parent.parent is CompilationUnit
        )
    }
}

|" The value sequence of a reduction expression (see ``ReduceAttributeRef``).
|" Ada 2022, RM 4.5.10.
class ValueSequence: AdaNode {
    # NOTE: add chunk and aspect specification fields when parallel keyword is
    # supported.
    @parse_field iter_assoc: IteratedAssoc

    |" Return the nameres equation for this ValueSequence.
    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = self.iter_assoc.xref_equation_for_reduce()
}

|" Single variant in a discriminated type record declaration.
|"
|" This corresponds to a ``when ... => ...`` section in a variant part.
class Variant: AdaNode {
    @parse_field choices: AlternativesList
    @parse_field components: ComponentList

    |" Return the default expression of the discriminant this Variant
    |" depends on, if any.
    fun default_discriminant_expr(): Entity[Expr] = {
        # First, get the record type declaration to extract the
        # discriminant specifications.
        val discr_specs = self.parents(with_self=false).find((p) => p is ConcreteTypeDecl).as![ConcreteTypeDecl].discriminants.as![KnownDiscriminantPart].discr_specs;
        val discr_symbol = self.parent.parent.as![VariantPart].discr_name.symbol;

        # Then, get the default expression that applies to self's variant
        # part discriminant.
        discr_specs.find(
            (d) => d.defining_names().any((n) => n.name_is(discr_symbol))
        ).default_expr
    }

    |" Check if any choice in the choice list matches expr's value.
    fun matches(expr: Entity[Expr]): Bool = {
        # Statically evaluate expr

        val expr_val = (
            # If expr is a box expr, `expr_val` is the value of the default
            # expression of the given discriminant (:rmlink:`4.3.1`).
            if expr is BoxExpr then self.default_discriminant_expr() else expr
        ).eval_as_int();

        self.choices.any((c) => c.choice_match(expr_val))
    }
}

|" Variant part in a discriminated type record declaration
|" (:rmlink:`3.8.1`).
|"
|" This corresponds to the whole ``case ... is ... end case;`` block.
class VariantPart: AdaNode {
    @parse_field discr_name: Identifier
    @parse_field variant: ASTList[Variant]

    fun xref_entry_point(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        val _ = self.discr_name.resolve_names_internal(false);

        self.variant.logic_all(
            (var) => var.choices.logic_all(
                (c) => match c {
                    # Expression case
                    case e: Expr => if e is Name and not e.as[Name].name_designated_type().is_null then e.as[Name].xref_type_equation() else %eq(e.expected_type_var(), node.discr_name.type_val()) and e.sub_equation() and e.matches_expected_type()

                    # SubtypeIndication case (``when Color range Red .. Blue``)
                    case t: SubtypeIndication => t.xref_equation()
                    case _: OthersDesignator => %true
                    case _ => raise[Equation] PropertyError("Should not happen")
                }
            )
        )
    }

    |" Get components for this variant part, depending on the values of
    |" discriminants.
    fun get_components(discriminants: Array[ParamMatch]): Array[Entity[BaseFormalParamDecl]] = {
        # Get the specific discriminant this variant part depends upon
        val discr = discriminants.find(
            (d) => d.formal.name.name_is(node.discr_name.symbol)
        ).do(
            (d) => d.actual.assoc.expr(), default_val=self.parents().find((n) => n is ConcreteTypeDecl).as[ConcreteTypeDecl].discriminants.abstract_formal_params().find(
                (d) => not d.as[DiscriminantSpec].defining_names().filter(
                    # If the discriminant is found in aggregate params we are looking
                    # for, then take its actual's expression.
                    # Else, take the default expression of the this variant's related
                    # discriminant specification.
                    (n) => n.name.name_is(node.discr_name.symbol)
                ).is_null
            ).as[DiscriminantSpec].default_expr
        );
        # Get the variant branch with a choice that matches the discriminant's
        # value.
        val variant = self.variant.find((v) => v.matches(discr));

        # Get the components for this variant branch. We're passing down
        # discriminants, because there might be a nested variant part in this
        # variant branch.
        variant.components.abstract_formal_params_impl(discriminants, false, false)
    }
}

|" With clause (:rmlink:`10.1.2`).
class WithClause: AdaNode {
    @parse_field has_limited: Limited
    @parse_field has_private: Private
    @parse_field packages: ASTList[Name]

    |" Given a name that fully qualified a library-level declaration (i.e.
    |" a name in a with clause), return an xref equation that binds every
    |" part of the name to its corresponding library-level declarations.
    fun child_unit_xref_equation(name: Name): Equation = {
        val self_eq = %eq(name.ref_var(), node.withed_unit_helper(name)?.decl());

        self_eq and name.as[DottedName].do(
            (dn) => self.child_unit_xref_equation(dn.prefix), default_val=%true
        )
    }

    fun xref_entry_point(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        node.packages.logic_all((p) => self.child_unit_xref_equation(p))

    env_spec {
        set_initial_env(
            DesignatedEnv(
                kind=DesignatedEnvKind.named_env, env_name=s"Standard", direct_env=null[LexicalEnv]
            )
        )
    }
}

|" Qualifier for the ``private`` keyword in ``with private`` record clauses.
@qualifier
enum class WithPrivate: AdaNode {
}

@metadata
struct Metadata {
    |" Whether the stored element is a subprogram accessed through
    |" the dot notation
    dottable_subp: Bool = false
    |" The type for which this subprogram is a primitive, if any
    @used_in_equality primitive: AdaNode = null[AdaNode]
    |" The type for which this subprogram is a primitive, if any
    @used_in_equality primitive_real_type: AdaNode = null[AdaNode]
}

|" Composite field representing the aspect of an entity (:rmlink:`13`).
struct Aspect {
    |" Whether the aspect is defined or not
    exists: Bool
    |" Syntactic node that defines the aspect
    node: Entity[AdaNode]
    |" Expr node defining the value of the aspect
    value: Entity[Expr]
    |" Whether the aspect is inherited (it has been defined by a parent)
    inherited: Bool
}

struct CompletionItem {
    decl: Entity[BasicDecl]
    is_dot_call: Bool = false
    is_visible: Bool = true
    |" The higher the weight, the more relevant the completion item is
    weight: Int = 0
    # See `AdaNode.complete_item_weight` for implementation details.
}

|" Represent the range of a discrete type or subtype. The bounds are not
|" evaluated, you need to call ``eval_as_int`` on them, if they're static, to
|" get their value.
struct DiscreteRange {
    low_bound: Entity[Expr]
    high_bound: Entity[Expr]
}

|" Represent a set of values (as a list of choices) on a discriminant.
struct DiscriminantValues {
    discriminant: Entity[Identifier]
    values: Entity[AlternativesList]
}

|" Documentation annotation.
struct DocAnnotation {
    |" Annotation key
    key: String
    |" Annotation value
    value: String
}

|" Represent the range of a discrete type or subtype. The bounds are already
|" evaluated, so the type of the fields is BigInt.
struct EvalDiscreteRange {
    low_bound: BigInt
    high_bound: BigInt
}

|" Struct used by ``potential_actuals_for_dispatch`` to store an expression
|" together with the type that is expected for it.
struct ExpectedTypeForExpr {
    expected_type: Entity[TypeExpr]
    expr: Entity[Expr]
}

|" Represent the result of a call to logic_val. ``success`` is True iff
|" solving the logic equation was successful, and ``value`` holds the value of
|" the logic variable.
struct LogicValResult {
    success: Bool
    value: Entity[AdaNode]
}

|" Struct enclosing information about aggregates for multidimensional array
|" types.
struct MultidimAggregateInfo {
    |" the top level aggregate
    agg: Entity[BaseAggregate]
    |" the type of the array
    typ: Entity[BaseTypeDecl]
    |" the rank of the original sub-aggregate
    rank: Int
}

|" Data structure used by zip_with_params, Name.call_params,
|" GenericInstantiation.inst_params, BaseAggregate.aggregate_params,
|" SubtypeIndication.subtype_constraints, and EnumRepClause.params
|" properties. Associates an expression (the actual) to a formal param
|" declaration (the parameter).
struct ParamActual {
    param: Entity[DefiningName]
    actual: Entity[Expr]
}

struct SingleActual {
    name: BaseId
    assoc: Entity[BasicAssoc]
}

|" Helper data structure to implement SubpSpec/ParamAssocList matching.
|"
|" Each value relates to one ParamAssoc.
struct ParamMatch {
    |" Whether the matched ParamAssoc a ParamSpec.
    has_matched: Bool
    actual: SingleActual
    formal: Entity[DefiningName]
}

|" Result for a cross reference query returning a reference.
struct RefResult {
    ref: Entity[BaseId]
    kind: RefResultKind = RefResultKind.no_ref
}

|" Result for a cross reference query returning a referenced decl.
struct RefdDecl {
    decl: Entity[BasicDecl] = null[Entity[BasicDecl]]
    kind: RefResultKind = RefResultKind.no_ref
}

|" Result for a cross reference query returning a referenced defining name.
struct RefdDef {
    def_name: Entity[DefiningName] = null[Entity[DefiningName]]
    kind: RefResultKind = RefResultKind.no_ref
}

|" Represent one of the shapes that a variant record can have, as a list of
|" the available components.
struct Shape {
    components: Array[Entity[BaseFormalParamDecl]]
    discriminants_values: Array[DiscriminantValues]
}

|" Represent a substitution of a BasicDecl by a given value. This can then
|" be used as part of an environment in the eval_as_*_in_env property. See
|" the declaration of those properties for more details.
struct Substitution {
    |" The declaration to substitute.
    from_decl: Entity[BasicDecl]

    # TODO: once we can call expr_eval from the DSL and get an actual
    # discriminated type, use that type instead of BigInt.
    # For now however, we only ever need to do BigInt substitutions.
    |" The value by which to substitute the declaration.
    to_value: BigInt
    |" The type of the substituted value.
    value_type: Entity[BaseTypeDecl]
}

|" Structure to hold an expected subprogram specification (parameters and
|" return types only) denoted by an user defined function.
struct UserDefinedFunctionSubpSpec {
    subp_params_types: Array[Entity[BaseTypeDecl]]
    subp_return_type: Entity[BaseTypeDecl]
}
