import parser
import tokens

dynvar env: LexicalEnv
|" Origin for this property's request. See :ref:`The origin parameter` for more
|" details

dynvar origin: AdaNode
dynvar no_visibility: Bool
dynvar include_ud_indexing: Bool
dynvar dottable_type: AdaNode
dynvar imprecise_fallback: Bool
dynvar entry_point: AdaNode

|" Kind for the result of a cross reference operation.
|"
|" - ``no_ref`` is for no reference, it is the null value for this enum.
|" - ``precise`` is when the reference result is precise.
|" - ``imprecise`` is when there was an error computing the precise result,
|"   and a result was gotten in an imprecise fashion.
|" - ``error`` is for unrecoverable errors (either there is no imprecise path
|"   for the request you made, or the imprecise path errored out too).
@with_default(no_ref)
enum RefResultKind {
    case no_ref, precise, imprecise, error
}

|" Kind of CallExpr type.
|"
|" - ``call`` is when the CallExpr is a procedure or function call.
|" - ``array_slice``, ``array_index`` is when the CallExpr is in fact an
|"   array slice or an array subcomponent access expression, respectively.
|" - ``type_conversion`` is when the CallExpr is a type conversion.
|" - ``family_index`` is for entry calls using a family index.
enum CallExprKind {
    case call, array_slice, array_index, type_conversion, family_index
}

|" Root node class for the Ada syntax tree.
@abstract
@generic_list_type("AdaList")
class AdaNode implements Node[AdaNode] {
    @external()
    fun can_reach(from_node: AdaNode): Bool

    |" Return the scope of definition of this basic declaration.
    @exported
    fun declarative_scope(): DeclarativePart =
        node.parents().find((p) => p is DeclarativePart).as[DeclarativePart]

    |" Return the kind of the compilation unit owning this node.
    fun owning_unit_kind(): AnalysisUnitKind =
        node.unit.root.as![CompilationUnit].unit_kind()

    |" Static method helper. Fetch the unit designated by unit_name. Return
    |" the compilation unit node.
    |"
    |" This is designed in a way that will emit a
    |" ``unit_requested(not_found_is_error=True, ...)`` event when not
    |" finding the unit is supposed to be an error within Ada semantics.
    fun withed_unit_helper(unit_name: Name): CompilationUnit = {
        # Try to fetch the spec and the body for ``unit_name``, but do not emit
        # a unit_requested event yet.
        val unit_name_array = unit_name.as_symbol_array();
        val spec =
            node.designated_compilation_unit(
                unit_name_array,
                kind=AnalysisUnitKind.unit_specification,
                not_found_is_error=false
            );
        val body =
            if spec.is_null
            then
                node.designated_compilation_unit(
                    unit_name_array,
                    kind=AnalysisUnitKind.unit_body,
                    not_found_is_error=false
                )
            else null[CompilationUnit];
        # Emit an event if one missing unit is actually required by Ada's
        # semantics: either when we have a package body but got no spec, or
        # when we have no body and no spec.
        val _ =
            if
                (body.do((v1) => v1.decl() is PackageBody) and spec.is_null)
                or (spec.is_null and body.is_null)
            then
                node.designated_compilation_unit(
                    unit_name_array,
                    kind=AnalysisUnitKind.unit_specification,
                    not_found_is_error=true
                )
            else null[CompilationUnit];

        # Return the requested unit (the spec takes precedence)
        spec or? body
    }

    fun is_contract_aspect(name: Symbol): Bool =
        name in s"Pre"
            | s"Pre'Class"
            | s"Post"
            | s"Post'Class"
            | s"Refined_Post"
            | s"Precondition"
            | s"Postcondition"
            | s"Precondition'Class"
            | s"Postcondition'Class"
            | s"Invariant"
            | s"Invariant'Class"
            | s"Type_Invariant"
            | s"Type_Invariant'Class"
            | s"Predicate"
            | s"Static_Predicate"
            | s"Dynamic_Predicate"
            | s"Default_Initial_Condition"
            | s"Initial_Condition"
            | s"Contract_Cases"
            | s"Test_Case"
            | s"Global"
            | s"Refined_Global"
            | s"Refined_State"
            | s"Stable_Properties"
            | s"Depends"
            | s"Refined_Depends"
            | s"Predicate_Failure"
            | s"SPARK_Mode"

    |" Return True if the given ``name`` is that of an Ada aspect in which
    |" references can designate entities declared *after* the entity on which
    |" this aspect is defined.
    fun aspect_has_forward_visibility(name: Symbol): Bool =
        node.is_contract_aspect(name)
        or name in s"Iterator_Element" | s"Default_Iterator"

    fun in_aspect_with_forward_visibility(): Bool =
        not node.parents().find(
            (p) =>
            p.as[AspectAssoc].do(
                (a) =>
                node.aspect_has_forward_visibility(
                    a.id.as_bare_entity.name_symbol()
                )
            )
            or? p.as[Pragma].do(
                (p) =>
                node.aspect_has_forward_visibility(
                    p.id.as_bare_entity.name_symbol()
                )
            )
        )
        .is_null

    |" Return whether self is contained by an aspect whose name is ``name``.
    fun in_aspect(name: Symbol): Bool =
        node.parents().any(
            (p) => p.as[AspectAssoc].do((a) => a.id.name_is(name))
        )

    fun empty_env(): LexicalEnv =
        node.parents().find((p) => p is CompilationUnit)
        .as[CompilationUnit]
        .get_empty_env()

    |" Return True iff this node is not null.
    fun is_not_null(): Bool =
        # TODO: Remove this once we have better logic predicates: it is
        # currently not possible to pass an arbitrary DSL expression to a
        # predicate, so we must have a property for every expression that we
        # might want to pass to a predicate.
        not self.is_null

    |" Static method. Evaluate the bounds of ``dr``.
    fun eval_discrete_range(dr: DiscreteRange): EvalDiscreteRange =
        if dr == null[DiscreteRange]
        then
            raise[EvalDiscreteRange] PreconditionFailure(
                "Attempting to evaluate a null discrete range"
            )
        else
            EvalDiscreteRange(
                low_bound=dr.low_bound.do(
                    (lb) => lb.eval_as_int(),
                    default_val=0b
                ),
                high_bound=dr.high_bound.eval_as_int()
            )

    |" Static method. Return the array of symbols joined by separator ``sep``.
    fun sym_join(syms: Array[Symbol], sep: String): String =
        sep.join(syms.map((s) => s.image()))

    |" Return the compilation unit containing this node.
    |"
    |" .. note:: This returns the :typeref:`CompilationUnit` node, which is
    |"    different from the ``AnalysisUnit``. In particular, an analysis unit
    |"    can contain multiple compilation units.
    @exported
    fun enclosing_compilation_unit(): CompilationUnit =
        node.parents().find((n) => n is CompilationUnit).as![CompilationUnit]

    |" Static property. Will return True if current_env is a children of
    |" parent.
    fun is_children_env(parent: LexicalEnv, current_env: LexicalEnv): Bool =
        if parent == null[LexicalEnv] then false
        elif current_env == parent then true
        elif current_env.is_null then false
        else node.is_children_env(parent, current_env.env_parent)

    |" Return self with an empty metadata field.
    fun without_md(): Entity[AdaNode] =
        Entity[AdaNode](
            node=self.node,
            info=EntityInfo(
                md=null[Metadata],
                rebindings=self.info.rebindings,
                from_rebound=self.info.from_rebound
            )
        )

    |" Assuming this node comes from an instantiated generic declaration,
    |" return its non-instantiated counterpart lying in the generic
    |" declaration.
    @exported
    fun get_uninstantiated_node(): Entity[AdaNode] = node.as_bare_entity

    |" Return possible completions at this point in the file.
    @exported
    fun complete(): Iterator[CompletionItem] = {
        bind origin = node.origin_node();

        self.complete_items().filter(
            # This property filters out `SyntheticSubpDecl` and
            # `SyntheticObjectDecl` items because they are of no use for
            # completion. This is not entirely true for `SyntheticObjectDecl`
            # since they can be useful in type predicate aspects (yet not
            # implemented since no likely helpful). Additional filtering can be
            # done in `complete_items`.
            (n) => not n.decl is SyntheticSubpDecl | SyntheticObjectDecl
        )
        .to_iterator()
    }

    |" Specialization of ``complete_item_weight``.
    |"
    |" Set the weight according to the type of the ``item``'s return value in
    |" comparison to the type of the declaration designated by ``name``.
    @with_dynvars(origin)
    fun complete_item_weight_matching_type(
        item: Entity[BasicDecl],
        name: Entity[Name]
    ): Int = {
        val te_not_null = not item.type_expression().is_null;
        val td = item.type_expression()?.designated_type_decl();

        # Promote declarations that returns a value
        item.expr_type().do(
            (_) =>
            # Return value type of item matches name's type
            if (
                name.referenced_decl()?.type_expression()
                ?.designated_type_decl()
                .matching_assign_type(td)
                and te_not_null
            )
            then 100
            # Re-try with best-effort resolution (for incomplete code)

            elif {
                bind imprecise_fallback = true;

                name.referenced_decl()?.type_expression()
                ?.designated_type_decl()
                .matching_assign_type(td)
                and te_not_null
            } then 70
            # Types don't match but item returns a value
            else 50,
            default_val=0
        )
    }

    |" Return the list of keywords that are valid at this point in the file.
    |"
    |" .. note::
    |"     This is work in progress. It will return all keywords for now,
    |"     without looking at the context.
    @exported
    fun valid_keywords(): Array[Symbol] =
        [
            s"abort",
            s"abs",
            s"abstract",
            s"accept",
            s"access",
            s"aliased",
            s"all",
            s"and",
            s"array",
            s"at",
            s"begin",
            s"body",
            s"case",
            s"constant",
            s"declare",
            s"delay",
            s"delta",
            s"digits",
            s"do",
            s"else",
            s"elsif",
            s"end",
            s"entry",
            s"exception",
            s"exit",
            s"for",
            s"function",
            s"generic",
            s"goto",
            s"if",
            s"in",
            s"interface",
            s"is",
            s"limited",
            s"loop",
            s"mod",
            s"new",
            s"not",
            s"null",
            s"others",
            s"out",
            s"of",
            s"or",
            s"overriding",
            s"package",
            s"pragma",
            s"private",
            s"procedure",
            s"protected",
            s"raise",
            s"range",
            s"record",
            s"rem",
            s"renames",
            s"requeue",
            s"return",
            s"reverse",
            s"select",
            s"separate",
            s"some",
            s"subtype",
            s"synchronized",
            s"tagged",
            s"task",
            s"terminate",
            s"then",
            s"type",
            s"until",
            s"use",
            s"when",
            s"while",
            s"with",
            s"xor"
        ]

    |" Assuming that self is the error location of a semantic diagnostic and
    |" that ``ctx`` is one of its logic contexts indicating which subprogram
    |" was tried, return a node that indicates with more precision which part
    |" of the subprogram caused a mismatch. For example, if self corresponds
    |" to the second actual in the ``CallExpr``, this returns the second
    |" parameter of the candidate subprogram.
    @ignored
    fun call_context(ctx: LogicContext): AdaNode = {
        val bd = ctx.decl_node.as[BasicDecl];

        bd?.subp_spec_or_null().do(
            (spec) =>
            ctx.ref_node.as[Name]?.parent_callexpr().do(
                (ce) =>
                if node == ce.node then spec.returns().node
                else
                    node.match_formals(
                        spec.abstract_formal_params(),
                        ce.params(),
                        bd.info.md.dottable_subp
                    )
                    .find((pm) => pm.actual.assoc.expr().node == node)
                    .do(
                        (pm) => pm.formal.formal_decl().type_expression().node,
                        default_val=bd.defining_name().node
                    ),
                default_val=bd.defining_name().node
            ),
            default_val=ctx.decl_node.node
        )
    }

    |" Return the potentially empty list of generic package/subprogram
    |" instantiations that led to the creation of this entity. Outer-most
    |" instantiations appear last.
    @exported
    fun generic_instantiations(): Array[Entity[GenericInstantiation]] =
        node.generic_instantiations_internal(self.info.rebindings)

    fun generic_instantiations_internal(
        r: EnvRebindings
    ): Array[Entity[GenericInstantiation]] =
        if r == null[EnvRebindings]
        then null[Array[Entity[GenericInstantiation]]]
        else {
            val head = (
                r.new_env.env_node.as![GenericInstantiation].as_bare_entity
            );
            val tail = node.generic_instantiations_internal(r.get_parent);

            [head] & tail
        }

    |" If the rebindings in ``base`` end with ``suffix``, ``base`` is
    |" returned without it. Otherwise ``base`` is returned as-is.
    fun remove_rebindings(
        base: EnvRebindings,
        suffix: EnvRebindings
    ): EnvRebindings =
        if base.is_null or suffix.is_null then base
        elif base.old_env == suffix.old_env and base.new_env == suffix.new_env
        then node.remove_rebindings(base.get_parent, suffix.get_parent)
        else base

    |" Append a new entry ``old_env -> new_env`` to ``base``. This also takes
    |" care of collapsing a subset of the rebindings if ``new_env`` is
    |" actually inside an envinonment which is rebound by an existing entry.
    |" In other words, this collapses generic formal package instantiations
    |" done in a generic context where the actual package is known.
    |" For example in the following snippet:
    |"
    |" .. code:: ada
    |"
    |"     generic
    |"     package Interface_G is
    |"     end Interface_G;
    |"
    |"     generic
    |"         with package I is new Interface_G (<>);
    |"     package Pkg_G is
    |"     end Pkg_G;
    |"
    |"     package My_Interface is new Interface_G;
    |"     package My_Pkg is new Pkg_G (My_Interface);
    |"
    |" Navigating inside ``My_Pkg`` leads us in ``Pkg_G`` with rebindings
    |" ``[My_Pkg]``. From here, navigating inside the instantiation of the
    |" formal package ``I`` would lead us in ``Interface_G`` with rebindings
    |" ``[My_Pkg, I]``. However, ``add_rebinding`` sees that ``I`` is
    |" rebound by the instantiation of ``My_Pkg`` and therefore collapses
    |" the two rebindings from ``[My_Pkg, I]`` to ``[My_Interface]``.
    fun add_rebinding(
        base: EnvRebindings,
        old_env: LexicalEnv,
        new_env: LexicalEnv
    ): EnvRebindings = {
        val parent_env = new_env.env_node.node_env;

        if (
            base.is_null or not parent_env.env_node is GenericDecl
            or not node.is_rebound(base, parent_env)
        )
        then base.append_rebinding(old_env, new_env)
        elif base.old_env == parent_env
        then
            base.new_env.get_first(
                new_env
                .env_node
                .as[GenericPackageInstantiation]
                .name
                .name_symbol(),
                lookup=LookupKind.minimal
            )
            .as[GenericPackageInstantiation]
            .do(
                (gpi) => {
                    val gen_env =
                        gpi.nonbound_generic_decl_from_self()
                        .node
                        .children_env;
                    val info =
                        EntityInfo(
                            md=null[Metadata],
                            rebindings=node.add_rebinding(
                                base.get_parent,
                                gen_env,
                                gpi.instantiation_env
                            ),
                            from_rebound=false
                        );
                    # Collapsing may make some entries irrelevant, so shed
                    # rebindings at this point to remove those.
                    gen_env.shed_rebindings(info).rebindings
                },
                default_val=base.append_rebinding(old_env, new_env)
            )
        else node.add_rebinding(base.get_parent, old_env, new_env)
    }

    |" Return whether ``old_env`` is rebound somewhere inside the given
    |" rebindings.
    fun is_rebound(base: EnvRebindings, old_env: LexicalEnv): Bool =
        not base.is_null
        and (
            base.old_env == old_env
            or node.is_rebound(base.get_parent, old_env)
        )

    |" Append rebindings from ``to_insert`` to ``base``, stopping as soon as
    |" an entry from ``to_insert`` is already rebound in ``base``, such that
    |" for example ``insert_rebindings([A, C], [B, C, D]) = [A, C, D]``.
    fun insert_rebindings(
        base: EnvRebindings,
        to_insert: EnvRebindings
    ): EnvRebindings =
        if to_insert.is_null then base
        elif base.is_null then to_insert
        elif node.is_rebound(base, to_insert.old_env) then base
        else
            node.add_rebinding(
                node.insert_rebindings(base, to_insert.get_parent),
                to_insert.old_env,
                to_insert.new_env
            )

    |" Return whether ``parent`` is a parent of ``base``. This considers
    |" the chain as a whole, i.e. ``has_parent_rebindings([A, B, C], [A, B])``
    |" returns True, but both ``has_parent_rebindings([A, B, C], [B, C])`` as
    |" well as ``has_parent_rebindings([A, C], [A, B])`` return False.
    fun has_parent_rebindings(
        base: EnvRebindings,
        parent: EnvRebindings
    ): Bool =
        base == parent or parent.is_null
        or (
            not base.is_null
            and node.has_parent_rebindings(base.get_parent, parent)
        )

    # We mark this property as memoizable because for the moment, we only ever
    # get the first result of logic resolution, so we only ever want the result
    # of the first evaluation of this property. When we change that, we'll
    # probably change the solving API anyway.
    @call_memoizable
    fun logic_val(
        from_node: Entity[AdaNode],
        lvar: LogicVar
    ): LogicValResult = {
        val success = from_node.resolve_names_from_closest_entry_point();

        LogicValResult(
            success=success,
            value=if success then lvar.get_value() else null[Entity[AdaNode]]
        )
    }

    fun semantic_parent_helper(env: LexicalEnv): Entity[AdaNode] =
        env.do(
            (env) =>
            env.env_node.as_entity
            or? self.semantic_parent_helper(env.env_parent)
        )

    |" Return the semantic parent for this node, if applicable, null
    |" otherwise.
    |"
    |" .. note:: A node lying outside of a library item's declaration or
    |"     subunit's body does not have a parent environment, meaning that
    |"     this property will return null.
    @exported
    fun semantic_parent(): Entity[AdaNode] =
        self.semantic_parent_helper(self.node_env)

    |" Recursively call ``semantic_parent`` to get all the semantic parents
    |" of this node.
    fun semantic_parents(): Array[Entity[AdaNode]] =
        self.semantic_parent().do((sp) => [sp] & sp.semantic_parents())

    |" Return the parent basic decl for this node, if applicable, null
    |" otherwise.
    |"
    |" .. note:: If the parent BasicDecl of the given node is a generic
    |"     declaration, this call will return the instantiation from which
    |"     the node was retrieved instead, if any. This also applies to bodies
    |"     of generic declarations.
    |"
    |" .. note:: When called on a subunit's body, this property will return
    |"     its corresponding body stub.
    |"
    |" .. note:: When called on a node lying outside of a library item's
    |"     declaration or subunit's body this property will return null.
    @exported
    fun parent_basic_decl(): Entity[BasicDecl] =
        # On synthetic types that are rooted in their parents, we want to
        # call parent_basic_decl on the parent type, to avoid getting the
        # type itself as a parent_basic_decl (since some types introduce a
        # scope).
        if
            self is ClasswideTypeDecl
            | DiscreteBaseSubtypeDecl
            | SynthAnonymousTypeDecl
        then self.semantic_parent().parent_basic_decl()
        else {
            val gen_decl = self.as[GenericDecl];
            val gen_body =
                self.as[Body]?.decl_part().do(
                    (dp) => dp.as[GenericDecl] or? dp.parent.as[GenericDecl]
                );
            (gen_decl or? gen_body).do((gd) => gd.decl().get_instantiation())
            or? self.semantic_parent().do(
                (sp) =>
                if sp is GenericSubpInternal | GenericPackageInternal
                then sp.parent_basic_decl()
                else sp.as[BasicDecl] or? sp.parent_basic_decl()
            )
        }

    |" Helper for the properties ``has_spark_mode_on`` and
    |" ``is_subject_to_proof``.
    |"
    |" This property will determine if the decl or body has SPARK mode on,
    |" with some special paths for bodies.
    |"
    |" It will also, for bodies only, determine whether there are
    |" ``Skip_Proof`` or ``Skip_Flow_And_Proof`` annotations, if the parameter
    |" ``include_skip_proof_annotations`` is True.
    fun is_spark_impl(include_skip_proof_annotations: Bool): Bool = {
        val spark_mode = self.spark_mode_aspect();

        # For bodies, and if `include_skip_proof_annotations` is True,
        # check `Skip_Proof`/`Skip_Flow_And_Proof`.
        if (
            include_skip_proof_annotations
            and not self.as[Body].do(
                (b) => b,
                default_val=self.semantic_parents().find((n) => n is Body)
                .as[Body]
            )
            .do(
                (b) =>
                b.gnatprove_annotations().find(
                    (a) =>
                    a.as[Name].name_symbol() in s"Skip_Proof"
                        | s"Skip_Flow_And_Proof"
                )
            )
            .is_null
        )
        then false
        elif not spark_mode.exists then false
        else
            spark_mode.value.do(
                (mode) => mode.as[Name].name_is(s"On"),
                # `SPARK_Mode` without value is `On` by default
                default_val=true
            )
    }

    |" Returns whether this subprogram has explicitly been set as having
    |" ``Spark_Mode`` to ``On``, directly or indirectly.
    |"
    |" Doesn't include subprograms that can be inferred by GNATprove as being
    |" SPARK.
    @exported
    fun has_spark_mode_on(): Bool = self.is_spark_impl(false)

    |" Returns whether this subprogram body is subject to proof in the context
    |" of the SPARK/GNATprove tools.
    @exported
    fun is_subject_to_proof(): Bool = self.is_spark_impl(true)

    # TODO (S917-027): re-enable this protection or remove it once we
    # moved forward on memoization soundness issues in Langkit.
    # This comment was associated with the following previous libadalang DSL::
    #    call_non_memoizable_because=(
    #        None and
    #        'Getting an analysis unit cannot appear in a memoized context'
    #    )
    |" Return the analysis unit for the given ``kind`` corresponding to this
    |" Name. Return null if ``load_if_needed`` is false and the unit is not
    |" loaded yet.
    |"
    |" For nested library units, this will trigger the processing of parent
    |" library units, so for example, if you ``get_unit('A.B.C')``, this will
    |" load units ``A.B.C``, ``A.B`` and ``A``, except if ``process_parents``
    |" is False.
    |"
    |" ``not_found_is_error`` will condition the parameter of the same name in
    |" the ``Unit_Requested`` callback. The client of ``get_unit`` is supposed
    |" to pass ``True`` if the unit not being found is an error in the Ada
    |" sense.
    @external()
    fun get_unit(
        name: Array[Symbol],
        kind: AnalysisUnitKind,
        load_if_needed: Bool,
        not_found_is_error: Bool,
        process_parents: Bool = true
    ): AnalysisUnit

    |" Fetch the compilation unit designated by the given name defined in an
    |" analysis unit of the given kind.
    fun designated_compilation_unit(
        name: Array[Symbol],
        kind: AnalysisUnitKind,
        load_if_needed: Bool = true,
        not_found_is_error: Bool = true,
        process_parents: Bool = true
    ): CompilationUnit = {
        val designated_analysis_unit =
            node.get_unit(
                name,
                kind,
                load_if_needed,
                not_found_is_error,
                process_parents
            );

        node.compilation_unit_with_name(designated_analysis_unit, name)
    }

    |" Helper for ``designated_compilation_unit``. From a given analysis unit,
    |" that might contain several compilation units, and a name, return the
    |" corresponding compilation unit.
    fun compilation_unit_with_name(
        unit: AnalysisUnit,
        name: Array[Symbol]
    ): CompilationUnit =
        unit?.root.do(
            (v1) =>
            match v1 {
                # If the root of the analysis unit is a single compilation
                # unit, it is necessarily the one we look for.
                case single: CompilationUnit => single

                # If the root of the analysis unit comprises multiple
                # compilation units, look for the one with a matching fully
                # qualified name.
                case multi: ASTList[CompilationUnit] =>
                    multi.find(
                        (c) => c.syntactic_fully_qualified_name() == name
                    )

                # If the root is a PragmaNodeList (`pragma No_Body` case),
                # there is no compilation unit for `name`.
                case _: ASTList[Pragma] => null[CompilationUnit]
                case _ =>
                    raise[CompilationUnit] PropertyError(
                        "Unexpected analysis unit root"
                    )
            }
        )

    |" If the corresponding analysis unit is loaded, return the root decl
    |" node for the given analysis unit ``kind`` and corresponding to the
    |" name ``name``. If it's not loaded, return none.
    fun get_unit_root_decl(
        name: Array[Symbol],
        kind: AnalysisUnitKind,
        load_if_needed: Bool = true,
        not_found_is_error: Bool = true,
        process_parents: Bool = true
    ): BasicDecl = {
        val cu =
            node.designated_compilation_unit(
                name,
                kind,
                load_if_needed,
                not_found_is_error,
                process_parents
            );

        cu?.decl()
    }

    |" Filters out among the list of given units those that cannot refer to
    |" the unit in which this node lies. If transitive is True, the whole
    |" transitive closure of imports will be used to find a reference to the
    |" unit of this node.
    @exported
    @external()
    fun filter_is_imported_by(
        units: Array[AnalysisUnit],
        transitive: Bool
    ): Array[AnalysisUnit]

    |" Return the environment to bind initially during the construction of the
    |" xref equation for this node. Note that this only makes sense if this
    |" node is an xref entry point.
    fun xref_initial_env(): LexicalEnv = self.children_env

    |" This property can be used when an xref_equation needs to bind one of
    |" self's logic vars (given in ``dest``) to one of ``outer_node``'s logic
    |" vars given in ``node_var``, when ``outer_node`` is a node that is not a
    |" children of self. Indeed, due to the stop_resolution mechanism, binding
    |" to such a variable directly may not have the expected effect: if there
    |" is a "stop_resolution" boundary between the current node and the outer
    |" node, then the outer node's variable already has a value when we
    |" construct the current node's equation, hence using it in an equation
    |" will reset its content instead of binding to its value. This property
    |" basically checks whether this is the case or not in order to create an
    |" equation that either assigns ``dest`` to the known value or that binds
    |" it to the given variable.
    @with_dynvars(entry_point)
    fun bind_to_non_local(
        dest: LogicVar,
        outer_node: AdaNode,
        node_var: LogicVar
    ): Equation =
        if outer_node.parents().contains(entry_point) then dest <-> node_var
        else dest <- node_var.get_value()

    |" Wrapper for xref_equation, meant to be used inside of xref_equation
    |" when you want to get the sub equation of a sub expression. It is
    |" used to change the behavior when xref_equation is called from
    |" another xref_equation call, or from the top level, so that we can do
    |" resolution in several steps.
    @with_dynvars(env, origin, entry_point)
    fun sub_equation(): Equation =
        if self.xref_stop_resolution() then self.stop_resolution_equation()
        else self.xref_equation()

    |" Internal helper for resolve_names. Resolve names for this node up to
    |" xref_entry_point and xref_stop_resolution boundaries.
    @external(uses_entity_info=true, uses_envs=true)
    @call_memoizable
    @with_dynvars(env, origin, entry_point)
    fun resolve_own_names(generate_diagnostics: Bool): Bool

    |" Internal helper for resolve_names, implementing the recursive logic
    |" needed to resolve names across xref_stop_resolution boundaries.
    @with_dynvars(env, origin)
    fun resolve_children_names(generate_diagnostics: Bool): Bool =
        node.children.all(
            (c) =>
            c.do(
                # Only resolve nodes that have xref_stop_resolution set, and do
                # not recursively explore nodes that are xref entry points.
                (c) =>
                if c.xref_entry_point() then true
                else
                    (
                        if c.as_entity.xref_stop_resolution()
                        then {
                            bind entry_point = c;
                            bind env = self.xref_initial_env();

                            c.as_entity.resolve_own_names(generate_diagnostics)
                        }
                        else true
                    )
                    and c.as_entity.resolve_children_names(
                        generate_diagnostics
                    ),
                default_val=true
            )
        )

    |" Resolves names for this node up to xref_entry_point boundaries.
    @with_dynvars(env, origin)
    fun resolve_names_internal(generate_diagnostics: Bool): Bool = {
        bind entry_point = node;

        self.resolve_own_names(generate_diagnostics)
        and self.resolve_children_names(generate_diagnostics)
    }

    |" Resolves names in this node with an additional constraint given by
    |" ``additional_equation``, up to xref_entry_point boundaries.
    @with_dynvars(env, origin)
    fun resolve_names_internal_with_eq(additional_equation: Equation): Bool = {
        val eq =
            {
                bind entry_point = node;

                self.xref_equation()
            }
            %and additional_equation;

        eq.solve() and self.resolve_children_names(false)
    }

    |" This will resolve names for this node. If the operation is successful,
    |" then type_var and ref_var will be bound on appropriate subnodes of the
    |" statement.
    @exported
    @memoized
    @call_memoizable
    fun resolve_names(): Bool = {
        bind env = self.xref_initial_env();
        bind origin = node.origin_node();

        self.resolve_names_internal(false)
    }

    |" Resolve names from the closest entry point up to this node. Note that
    |" unlike ``resolve_names``, this will *not* trigger resolution of every
    |" node with stop_resolution that lie in the sub-tree formed by the
    |" closest entry point. It will only resolve those that are in the path to
    |" resolving self. Consider for example the following entry point:
    |"
    |" .. code::
    |"
    |"     R := (A, B);
    |"
    |" Since aggregate association nodes have ``stop_resolution`` set to True,
    |" calling ``resolve_names_from_closest_entry_point`` on ``B`` will
    |" resolve nodes ``R`` and ``B`` but not ``A``, because ``A`` does not lie
    |" on the path to ``B``.
    |"
    |" This can be useful for resolving aggregates of variant records, because
    |" resolution of a component association can safely call the resolution
    |" of a discriminant association without triggering an infinite recursion,
    |" as both are on different "paths".
    fun resolve_names_from_closest_entry_point(): Bool =
        # This is the closest entry point: resolve its names and stop the
        # recursion.
        if self.xref_entry_point()
        then {
            bind env = self.xref_initial_env();
            bind origin = node.origin_node();
            bind entry_point = node;

            self.resolve_own_names(false)
        }

        # Otherwise, recurse on the parent
        else
            self.parent?.resolve_names_from_closest_entry_point().do(
                (_) => {
                    bind env = self.xref_initial_env();
                    bind origin = node.origin_node();

                    # Resolution succeeded for the parent and this is a
                    # stop resolution, so resolve own names as well.
                    if self.xref_stop_resolution()
                    then {
                        bind entry_point = node;

                        self.resolve_own_names(false)
                    }

                    # Resolution succeeded and there is nothing to do
                    # on that particular node: return successfully.
                    else true
                }
            )

    |" Return all the diagnostics produced by ``resolve_own_names`` on this
    |" node. If it was never called on this node, or if it was called without
    |" diagnostic generation enabled, return an empty array.
    @external(uses_entity_info=true, uses_envs=true)
    @call_memoizable
    fun own_nameres_diagnostics(): Array[SolverDiagnostic]

    |" Accumulates all the diagnostics emitted on the children of this node,
    |" up to ``xref_entry_point`` boundaries. This considers all children
    |" nodes and not only those for which ``xref_stop_resolution`` is True,
    |" so as to handle calls to ``resolve_names_internal`` that are done
    |" during the construction of xref equations.
    @with_dynvars(env, origin)
    fun children_nameres_diagnostics(): Array[SolverDiagnostic] =
        self.children.mapcat(
            (c) =>
            c.do(
                (c) =>
                if c.is_null or c.xref_entry_point()
                then null[Array[SolverDiagnostic]]
                else
                    c.own_nameres_diagnostics()
                    & c.children_nameres_diagnostics()
            )
        )

    |" If name resolution on this xref entry point fails, this returns all the
    |" diagnostics that were produced while resolving it.
    @exported
    fun nameres_diagnostics(): Array[SolverDiagnostic] = {
        bind env = self.xref_initial_env();
        bind origin = node.origin_node();

        val _ = self.resolve_names_internal(true);

        self.own_nameres_diagnostics() & self.children_nameres_diagnostics()
    }

    |" Used as a predicate during name resolution to emit a diagnostic
    |" when an entity is not found.
    @predicate_error("no such entity")
    fun missing_entity_error(): Bool = not node.is_null

    |" Static method. Return the analysis unit corresponding to the Standard
    |" package.
    @exported
    @external()
    fun standard_unit(): AnalysisUnit

    |" Static method. Return whether the given token is considered a keyword
    |" in the given version of Ada. Supported values for the language version
    |" argument are: "Ada_83", "Ada_95", "Ada_2005", "Ada_2012", "Ada_2022".
    @exported
    @external()
    fun is_keyword(token: Token, language_version: Symbol): Bool

    |" Retrieves the package corresponding to the Standard unit. Used to
    |" access standard types.
    fun std(): Entity[BasicDecl] =
        node.standard_unit()
        .root
        .as[CompilationUnit]
        .body
        .as[LibraryItem]
        .item
        .as_bare_entity

    |" Get the children env of the Standard package.
    fun std_env(): LexicalEnv = node.std().children_env

    |" Static property. Return an entity from the standard package with name
    |" ``sym``.
    @exported
    fun std_entity(sym: Symbol): Entity[AdaNode] =
        node.unit.root.std_entity_implem(sym)

    @memoized
    fun std_entity_implem(sym: Symbol): Entity[AdaNode] =
        node.std_env().get_first(
            sym,
            categories=RefCategories(inherited_primitives=false, _=true)
        )

    |" Static method. Return the standard Boolean type.
    @exported
    fun bool_type(): Entity[BaseTypeDecl] =
        node.std_entity(s"Boolean").as[BaseTypeDecl]

    |" Static method. Return the standard Integer type.
    @exported
    fun int_type(): Entity[BaseTypeDecl] =
        node.std_entity(s"Integer").as[BaseTypeDecl]

    |" Static method. Return the standard Universal Integer type.
    @exported
    fun universal_int_type(): Entity[BaseTypeDecl] =
        node.std_entity(s"Universal_Int_Type_").as[BaseTypeDecl]

    |" Static method. Return the standard Universal Real type.
    @exported
    fun universal_real_type(): Entity[BaseTypeDecl] =
        node.std_entity(s"Universal_Real_Type_").as[BaseTypeDecl]

    |" Static method. Return the standard Universal Fixed type.
    fun universal_fixed_type(): Entity[BaseTypeDecl] =
        node.std_entity(s"Universal_Fixed_Type_").as[BaseTypeDecl]

    |" Static method. Return the standard Character type.
    @exported
    fun std_char_type(): Entity[BaseTypeDecl] =
        node.std_entity(s"Character").as[BaseTypeDecl]

    |" Static method. Return the standard Wide_Character type.
    @exported
    fun std_wide_char_type(): Entity[BaseTypeDecl] =
        node.std_entity(s"Wide_Character").as[BaseTypeDecl]

    |" Static method. Return the standard Wide_Wide_Character type.
    @exported
    fun std_wide_wide_char_type(): Entity[BaseTypeDecl] =
        node.std_entity(s"Wide_Wide_Character").as[BaseTypeDecl]

    |" Static method. Return the standard String type.
    @exported
    fun std_string_type(): Entity[BaseTypeDecl] =
        node.std_entity(s"String").as[BaseTypeDecl]

    |" Static method. Return the standard Wide_String type.
    @exported
    fun std_wide_string_type(): Entity[BaseTypeDecl] =
        node.std_entity(s"Wide_String").as[BaseTypeDecl]

    |" Static method. Return the standard Wide_Wide_String type.
    @exported
    fun std_wide_wide_string_type(): Entity[BaseTypeDecl] =
        node.std_entity(s"Wide_Wide_String").as[BaseTypeDecl]

    |" Static method. Return the package containing the definitions of the
    |" root types.
    fun std_root_types(): LexicalEnv =
        node.std_entity(s"root_types_").as[PackageDecl]?.children_env

    |" Static method. Return the root_integer type.
    fun root_int_type(): Entity[BaseTypeDecl] =
        node.std_root_types().get_first(
            s"root_integer",
            lookup=LookupKind.minimal,
            categories=RefCategories(inherited_primitives=false, _=true)
        )
        .as[BaseTypeDecl]

    |" Static method. Return the root_real type.
    fun root_real_type(): Entity[BaseTypeDecl] =
        node.std_root_types().get_first(
            s"root_real",
            lookup=LookupKind.minimal,
            categories=RefCategories(inherited_primitives=false, _=true)
        )
        .as[BaseTypeDecl]

    |" Static method. Return the System.Address type.
    fun system_address_type(): Entity[BaseTypeDecl] =
        node.get_unit_root_decl(
            [s"System"],
            AnalysisUnitKind.unit_specification
        )
        ?.children_env
        .get_first(s"Address", lookup=LookupKind.flat)
        .as[BaseTypeDecl]

    |" See ``root_type_ops``.
    @memoized
    fun root_type_ops_impl(sym: Symbol): Array[Entity[BasicDecl]] =
        node.std_root_types().get(
            sym,
            lookup=LookupKind.minimal,
            categories=RefCategories(inherited_primitives=false, _=true)
        )
        .filtermap(
            (n) => n.as[BasicDecl],
            (n) => n.as![BasicDecl].is_subprogram()
        )

    |" Lookup the given symbol in the builtin ``root_types`` package. This is
    |" used for fast-access to predefined operator on root types.
    fun root_type_ops(sym: Symbol): Array[Entity[BasicDecl]] =
        # Typical strategy for memoizing "static" functions
        node.unit.root.root_type_ops_impl(sym)

    |" Return the type Ada.Exceptions.Exception_Id.
    fun exc_id_type(): Entity[BaseTypeDecl] =
        node.get_unit_root_decl(
            [s"Ada", s"Exceptions"],
            AnalysisUnitKind.unit_specification
        )
        ?.children_env
        .get_first(s"Exception_Id", lookup=LookupKind.flat)
        .as[BaseTypeDecl]

    |" Return the type Ada.Task_Identification.Task_Id.
    fun task_id_type(): Entity[BaseTypeDecl] =
        node.get_unit_root_decl(
            [s"Ada", s"Task_Identification"],
            AnalysisUnitKind.unit_specification
        )
        ?.children_env
        .get_first(s"Task_Id", lookup=LookupKind.flat)
        .as[BaseTypeDecl]

    |" Return the type Ada.Strings.Text_Buffers.Root_Buffer_Type
    fun root_buffer_type(): Entity[BaseTypeDecl] =
        node.get_unit_root_decl(
            [s"Ada", s"Strings", s"Text_Buffers"],
            AnalysisUnitKind.unit_specification
        )
        ?.children_env
        .get_first(s"Root_Buffer_Type", lookup=LookupKind.flat)
        .as[BaseTypeDecl]

    |" Return the type Ada.Streams.Root_Stream_Type
    fun root_stream_type(): Entity[BaseTypeDecl] =
        node.get_unit_root_decl(
            [s"Ada", s"Streams"],
            AnalysisUnitKind.unit_specification
        )
        ?.children_env
        .get_first(s"Root_Stream_Type", lookup=LookupKind.flat)
        .as[BaseTypeDecl]
        .classwide_type()
        .as[BaseTypeDecl]

    |" Return the type Ada.Numerics.Big_Numbers.Big_Integers.Big_Integer
    fun big_integer_type(): Entity[BaseTypeDecl] =
        node.get_unit_root_decl(
            [s"Ada", s"Numerics", s"Big_Numbers", s"Big_Integers"],
            AnalysisUnitKind.unit_specification,
            load_if_needed=false
        )
        ?.children_env
        .get_first(s"Big_Integer", lookup=LookupKind.flat)
        .as[BaseTypeDecl]

    |" Return the type Ada.Numerics.Big_Numbers.Big_Integers_Ghost.Big_Integer
    fun big_integer_ghost_type(): Entity[BaseTypeDecl] =
        node.get_unit_root_decl(
            [s"Ada", s"Numerics", s"Big_Numbers", s"Big_Integers_Ghost"],
            AnalysisUnitKind.unit_specification,
            load_if_needed=false
        )
        ?.children_env
        .get_first(s"Big_Integer", lookup=LookupKind.flat)
        .as[BaseTypeDecl]

    |" Return the type SPARK.Big_Integers.Big_Integer
    fun spark_big_integer_type(): Entity[BaseTypeDecl] =
        node.get_unit_root_decl(
            [s"SPARK", s"Big_Integers"],
            AnalysisUnitKind.unit_specification,
            load_if_needed=false
        )
        ?.children_env
        .get_first(s"Big_Integer", lookup=LookupKind.flat)
        .as[BaseTypeDecl]

    |" Return whether the parent unit of this node has with visibility on
    |" the given analysis unit. In particular, this takes into account
    |" private visibility: for a given node which is inside a body or a
    |" private part, it will forward to the query in the parent unit the
    |" fact that the origin node has visibility on the ``private with``
    |" clauses of the parent unit.
    fun parent_has_with_visibility(
        refd_unit: AnalysisUnit,
        self_cu: CompilationUnit,
        has_private_view: Bool
    ): Bool = {
        val should_have_private_view =
            has_private_view or self_cu.has_private_view(node);

        self_cu.decl().as_bare_entity.semantic_parent().do(
            (parent) =>
            # In our implementation, the semantic parent of a child package
            # is always the private part of the parent package (see note in
            # ``PackageDecl``'s ``env_spec``). But if we are not supposed
            # to have view on the private part, we must perform the query
            # outside of it, here from the parent of the private part.
            if parent is PrivatePart and not should_have_private_view
            then
                parent.parent.has_with_visibility(
                    refd_unit,
                    omit_privacy_check=false
                )
            else
                parent.has_with_visibility(
                    refd_unit,
                    omit_privacy_check=should_have_private_view
                )
        )
    }

    |" Return whether this node has a private part amongst its parent. This
    |" implementation uses environments instead of syntactic parents in order
    |" to jump over irrelevant nodes (since we know that a private part has a
    |" lexical environment). Don't go further than ``barrier``. Also return
    |" True for nodes in the prelude of compilation units, as they have the
    |" same visibility privileges of private parts (i.e. they can see "private
    |" with"s).
    fun has_private_part_parent(barrier: AdaNode): Bool =
        node is PrivatePart
        or (
            node != barrier
            and node.node_env.env_node.do(
                (parent) => parent.has_private_part_parent(barrier),
                default_val=true
            )
        )

    |" Here we assume that ``refd_unit.is_referenced_from(self.unit)`` is
    |" already True, but we now want to check if the clause that made
    |" ``refd_unit`` visible is private and if it is, whether we are in the
    |" private part.
    fun has_private_with_visibility(
        self_cu: CompilationUnit,
        refd_unit: AnalysisUnit
    ): Bool =
        # If the referenced unit is ourself, we don't need further checks
        node.unit
        == refd_unit

        # If we have view on "private with"s, we don't need further checks
        or self_cu.has_private_view(node)

        # But if we don't, so we must return False if the referenced unit
        # is only visible from private parts.
        or not self_cu.privately_imported_units().contains(refd_unit)

    |" Return whether self's unit has ``with visibility`` on ``refd_unit``.
    |"
    |" In other words, whether self's unit has a WITH clause on ``refd_unit``,
    |" or if its spec, or one of its parent specs has one.
    fun has_with_visibility(
        refd_unit: AnalysisUnit,
        omit_privacy_check: Bool = false
    ): Bool = {
        val cu = node.enclosing_compilation_unit();

        (
            # First, check whether this unit "with"s the referenced unit
            refd_unit.is_referenced_from(node.unit)
            and (
                omit_privacy_check
                or node.has_private_with_visibility(cu, refd_unit)
            )
        )
        or (
            # If it doesn't, check whether its parent unit does
            node.parent_has_with_visibility(
                refd_unit,
                cu,
                has_private_view=omit_privacy_check
            )
        )
        or (
            # With clauses from a library level subprogram declaration are
            # visible by its corresponding body. Since the decl is not the
            # parent of the body, we must specifically take this case into
            # account.
            cu.decl().as_bare_entity.as[BaseSubpBody].do(
                (b) =>
                if b.is_library_item()
                then
                    b.defining_name().referenced_unit(
                        AnalysisUnitKind.unit_specification,
                        not_found_is_error=false
                    )
                    .do(
                        # A subprogram renaming can appear as a top-level
                        # library item of a unit specification, in which case
                        # the `referenced_unit` call above will return `cu`.
                        # In that case, we must not perform the recursive call,
                        # otherwise we will get an infinite recursion.
                        (u) =>
                        if cu == u then false
                        else
                            u?.has_with_visibility(
                                refd_unit,
                                omit_privacy_check=true
                            )
                    )
                else false
            )
        )
        or (
            # because of the GNAT kludge around the child packages of
            # Ada.Text_IO, always consider those to be visible. Otherwise it
            # will break any access to P.Integer_IO & co. for any package P
            # that is a renaming of Ada.Text_IO. Indeed, since Integer_IO & co.
            # must behave as nested packages even though they are implemented
            # as child packages, we must consider them visible as soon as P
            # is visible.
            refd_unit.root.as[CompilationUnit]?.is_text_io_child()
        )
    }

    fun has_visibility(other_entity: Entity[AdaNode]): Bool =
        # We found a synthetic type predicate object decl, check if we are
        # allowed to see it.
        other_entity.as[SyntheticObjectDecl].do(
            (sod) => sod.is_referred_by(node),
            default_val=true
        )
        and (
            (
                # The node is a generic package instantiation coming from a
                # formal package.
                other_entity.as[GenericPackageInstantiation]?.info.from_rebound
            )
            or other_entity.as[PackageRenamingDecl]?.info.from_rebound
            or (
                # The node is not an unit root
                not other_entity.as[BasicDecl]?.is_compilation_unit_root()
            )
            or (
                # Else, check with visibility
                node.has_with_visibility(other_entity.node.unit)
            )
        )

    |" Helper property to resolve the actuals of generic instantiations.
    fun resolve_generic_actual(): Entity[AdaNode] = match self {
        case aod: Entity[AnonymousExprDecl] => aod

        # Depending on the formal that matches this actual, this name
        # can be either an object, a type or a subprogram.
        # TODO: the code below should execute a specific logic
        # depending on the corresponding kind of the formal (type, object,
        # subprogram, etc.), so we should find a way to make it available.
        case n: Entity[Name] =>
            (
                n.name_designated_type().as[AdaNode]
                or? n.as[AttributeRef]?.attribute_subprogram()
            )
            or? n.all_env_elements()?[0]

        # We first try to find a type.  If it's an attribute, it might be a
        # reference to a function.  If all that didn't work, find something
        # else.
        case _ => null[Entity[AdaNode]]
    }

    |" If self is a library item or a subunit, return a flat list of all names
    |" for top-level UsePackageClause nodes. See
    |" UsePackageClause.env_spec.ref_envs for more details.
    fun top_level_use_package_clauses(): Array[AdaNode] =
        node.parent.parent.as![CompilationUnit].prelude.filter(
            (p) => p is UsePackageClause
        )
        .mapcat(
            (p) => p.as![UsePackageClause].packages.map((n) => n.as[AdaNode])
        )

    |" If self is a library item or a subunit, return a flat list of all names
    |" for top-level UseTypeClause nodes. See UseTypeClause.env_spec
    |" for more details.
    fun top_level_use_type_clauses(): Array[AdaNode] =
        node.parent.parent.as![CompilationUnit].prelude.filter(
            (p) => p is UseTypeClause
        )
        .mapcat((p) => p.as![UseTypeClause].types.map((n) => n.as[AdaNode]))

    |" If self is a library item or a subunit, return a flat list of all names
    |" for top-level UseClause nodes.
    fun top_level_use_clauses(): Array[UseClause] = {
        val cu = node.parent.parent.as![CompilationUnit];

        cu.prelude.filtermap((p) => p.as[UseClause], (p) => p is UseClause)
    }

    |" Return a flat list of all package names that are with'ed by top-level
    |" WithClause nodes of the compilation unit this node lies in.
    |" Omit "private with" clauses if ``include_privates`` is False.
    fun top_level_with_package_clauses(
        include_privates: Bool = true
    ): Array[Name] =
        node.enclosing_compilation_unit().prelude.mapcat(
            (clause) =>
            clause.as[WithClause].do(
                (with_clause) =>
                if with_clause.has_private.as_bool() and not include_privates
                then null[Array[Name]]
                else with_clause.packages.as_array()
            )
        )

    |" If self is a library-level SubpBody, fetch the environments USE'd in
    |" its declaration.
    fun use_clauses_in_spec_of_subp_body(): LexicalEnv = {
        val fqn =
            node.enclosing_compilation_unit().syntactic_fully_qualified_name();
        val spec =
            node.designated_compilation_unit(
                name=fqn,
                kind=AnalysisUnitKind.unit_specification,
                not_found_is_error=false
            );

        spec?.decl()?.top_level_use_clauses().map(
            (clause) => clause.as_bare_entity.used_envs()
        )
        .env_group()
    }

    |" Assuming self is a generic entity's body that is nested (not a library
    |" item), return the grouped lexical environment containing all the
    |" environments that are referred by use clauses inside formal part of
    |" its generic declaration. Return an empty environment if this is not
    |" the body of a generic decl.
    fun use_clauses_in_generic_formal_part(): LexicalEnv = {
        val gen_decl = self.as[Body]?.safe_generic_decl_part();

        gen_decl.do(
            (gd) => gd.formal_part.use_clauses_envs(),
            default_val=node.empty_env()
        )
    }

    |" Assuming self is a generic entity's body that is nested (not a library
    |" item), return the lexical environment for the corresponding
    |" GenericPackageDecl (or GenericSubpDecl) node. Return an empty
    |" environment in all other cases.
    |"
    |" This is a helper for generic formals visibility in generic bodies. See
    |" the use in the child_unit macro.
    |"
    |" The following property is evaluated each time we make a recursive
    |" lexical environment lookup on a child unit. As it does itself a lot of
    |" lookups, memoizing it is very important.
    fun nested_generic_formal_part(): LexicalEnv = {
        val gen_decl = node.as_bare_entity.as[Body]?.safe_generic_decl_part();

        gen_decl.do((gd) => gd.node.children_env, default_val=node.empty_env())
    }

    |" Property helper to determine if an entity is a package or not.
    fun is_package(): Bool =
        node is PackageDecl
        | PackageBody
        | GenericPackageInstantiation
        | PackageRenamingDecl
        | GenericPackageDecl

    |" Provide the default lexical environment to use in EnvSpec's
    |" initial_env.
    fun default_initial_env(): LexicalEnv =
        node.parent.do((p) => p.children_env, default_val=node.children_env)

    |" Static method. Get the top-level decl in ``unit``.  This is the body of
    |" a Subunit, or the item of a ``LibraryItem``.
    @exported
    fun top_level_decl(unit: AnalysisUnit): BasicDecl =
        unit?.root.as![CompilationUnit].decl()

    |" Static method. DefiningName for all parameters.
    fun unpack_formals(
        formal_params: Array[Entity[BaseFormalParamDecl]]
    ): Array[Entity[DefiningName]] =
        node.unit.root.unpack_formals_impl(formal_params)

    fun unpack_formals_impl(
        formal_params: Array[Entity[BaseFormalParamDecl]]
    ): Array[Entity[DefiningName]] =
        formal_params.mapcat((spec) => spec.defining_names())

    |" Static method. For each ParamAssoc in a AssocList, return whether we
    |" could find a matching formal in self, and whether this formal is
    |" optional (i.e. has a default value). When match_others is true, try to
    |" match unmatched formals with OthersDesignator if any.
    fun match_formals(
        formal_params: Array[Entity[BaseFormalParamDecl]],
        params: Entity[AssocList],
        is_dottable_subp: Bool,
        match_others: Bool = true
    ): Array[ParamMatch] = {
        val unpacked_formals = node.unpack_formals(formal_params);

        val matched_formals =
            params.do(
                (p) =>
                p.unpacked_params().imap(
                    (a, i) =>
                    if a.name.is_null
                    then {
                        val idx = if is_dottable_subp then i + 1 else i;

                        # Positional parameter case: if this parameter has no
                        # name association, make sure we have enough formals.
                        unpacked_formals?[idx].do(
                            (sp) =>
                            ParamMatch(has_matched=true, actual=a, formal=sp)
                        )
                    }
                    else (
                        # Named parameter case: make sure the designator is
                        # actually a name and that there is a corresponding
                        # formal.
                        a.name.do(
                            (id) =>
                            unpacked_formals.find((p) => p.name.matches(id))
                            .do(
                                (sp) =>
                                ParamMatch(
                                    has_matched=true,
                                    actual=a,
                                    formal=sp
                                )
                            )
                        )
                    )
                )
            );

        # If some matches are missing, search for OthersDesignator and
        # match all unmatched formals to it.
        if match_others and matched_formals.any((m) => not m.has_matched)
        then {
            val od_assoc =
                params.find((p) => p.names()?[0] is OthersDesignator);

            od_assoc.do(
                (od) => {
                    val unmatched_formals =
                        unpacked_formals.filter(
                            (f) =>
                            matched_formals.find(
                                (m) => f.name.matches(m.actual.name)
                            )
                            .is_null
                        );

                    matched_formals.filter((mf) => mf.has_matched)
                    & unmatched_formals.map(
                        (uf) =>
                        ParamMatch(
                            has_matched=true,
                            actual=SingleActual(
                                name=null[Identifier],
                                assoc=od
                            ),
                            formal=uf
                        )
                    )
                },
                default_val=matched_formals
            )
        }
        else
        # All formals have matched, nothing more to do
            matched_formals
    }

    |" Assuming that self is a choice expression (such as what can appear in
    |" an alternative of a case statement or in the RHS of a membership
    |" expression, this property returns whether the given value satisfies it.
    |"
    |" .. ATTENTION::
    |"     This is an experimental feature, so even if it is exposed to allow
    |"     experiments, it is totally unsupported and the API and behavior are
    |"     very likely to change in the future.
    @exported
    fun choice_match(value: BigInt): Bool = match self {
        # If choice is a binop, it is either a range, or a static
        # arithmetic expression.
        case bo: BinOp =>
        # If choice is a range, then check that val is in the range
            if bo.op is Op.DoubleDot
            then
                value >= bo.left.eval_as_int()
                and value <= bo.right.eval_as_int()
            else value == bo.eval_as_int()

        # If choice is a name, it is either a subtype name, either a
        # constant number name.
        case n: Name =>
            n.name_designated_type().do(
                (dt) =>
                dt.discrete_range().do(
                    (dr) => {
                        val edr = node.eval_discrete_range(dr);

                        value >= edr.low_bound and value <= edr.high_bound
                    },
                    default_val=true
                )
                and {
                    bind origin = node;
                    bind imprecise_fallback = false;

                    dt.satisfies_type_predicates(value)
                },
                default_val=value == n.eval_as_int()
            )

        # If choice is a subtype indication, then get the range
        case st: SubtypeIndication =>
            st.discrete_range().do(
                (dr) => {
                    val edr = node.eval_discrete_range(dr);

                    value >= edr.low_bound and value <= edr.high_bound
                },
                default_val=true
            )
            and {
                bind origin = node;
                bind imprecise_fallback = false;

                st.designated_type().satisfies_type_predicates(value)
            }

        # If it is an expr, then just check for equality
        case e: Expr => value == e.eval_as_int()

        # If 'others', always return true
        case _: OthersDesignator => true
        case _ => false
    }

    |" Return a cross reference from this name to a defining identifier,
    |" trying to mimic GNAT's xrefs as much as possible.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun gnat_xref(): Entity[DefiningName] = {
        val bd =
            self.as[Name].enclosing_defining_name().do(
                (dn) => dn.basic_decl()
            );

        {
            bind origin = node;

            if
                bd is ParamSpec
                and (
                    bd.semantic_parent() is BasicSubpDecl
                    | ExprFunction
                    | BaseTypeDecl
                    | SubpBodyStub
                    | NullSubpDecl
                    or bd.semantic_parent().as[SubpBody].do(
                        (body) => body.previous_part_for_decl().is_null
                    )
                )
            then bd.semantic_parent().as[BasicDecl].defining_name()
            elif bd.do((v1) => v1.parent is GenericFormal)
            then
                bd.parents().find((p) => p is GenericDecl)
                .as[GenericDecl]
                .decl()
                .defining_name()
            # Deferred constants case

            elif
                (
                    bd is ObjectDecl
                    and not bd.as[ObjectDecl].has_constant.is_null
                )
                and bd.is_in_private_part()
            then self.as[Name].enclosing_defining_name().previous_part()
            # Discriminants case. There are two kinds of GNAT xrefs that apply
            # to discrimimants. The 'd' kind, which points to the type this
            # discriminant belongs to, and the 'r' kind, which, for a private
            # type completion, points to the corresponding discriminant in the
            # public view of that type. Note that 'r' references are simply
            # documented as "reference" in GNAT and might apply to other nodes,
            # but the discriminants case is the single occurence of that kind
            # we found so far.

            elif bd is DiscriminantSpec
            then {
                val pd = bd.as[DiscriminantSpec].parent_decl();

                if pd.is_in_private_part()
                then
                    self.as[Name].enclosing_defining_name().previous_part()
                    or? pd.defining_name()
                else pd.defining_name()
            }
            elif bd is AbstractSubpDecl
            then
                bd.as[AbstractSubpDecl].subp_decl_spec()
                .primitive_subp_first_type()
                .defining_name()
            elif bd is BasicSubpDecl
            then
                bd.as[BasicSubpDecl].subp_decl_spec()
                .primitive_subp_first_type()
                .do(
                    (prim_typ) =>
                    prim_typ.is_tagged_type().do(
                        (_) =>
                        prim_typ.private_completion().do(
                            (pc) => pc.defining_name()
                        )
                        or? prim_typ.defining_name()
                    )
                )
            elif bd is BaseSubpBody
            then bd.as[BaseSubpBody].subp_spec.subp_name
            else
                self.as[Name]?.gnat_xref_decl().do(
                    (ret) => {
                        val dbd = ret.basic_decl();

                        if dbd is ParamSpec
                        then dbd.as[ParamSpec].decl_param(ret)
                        elif dbd is ObjectDecl
                        then (
                            # Since dbd can refer to an object declaration with
                            # multiple defining names, do not call
                            # `public_part_decl` but directly call
                            # `previous_part_for_name(self)`.
                            dbd.as[ObjectDecl].previous_part_for_name(
                                self.as[Name].name_symbol()
                            )
                            .do((ppn) => ppn.defining_name())
                            or? ret
                        )
                        elif dbd is Body
                        then (dbd.as[Body].decl_part() or? dbd).defining_name()
                        else ret
                    }
                )
        }
    }

    |" Static property. Finds the closest parent which is a ``BaseSubpSpec`` /
    |" ``GenericInstantiation`` / ``ComponentDecl`` / ``RenamingClause``.
    |" Is used by ``env_get`` to implement correct visibility rules for those.
    |" See documentation on that property.
    fun env_get_real_from_node(from_node: AdaNode): AdaNode =
        if from_node.is_null then from_node
        else {
            val c =
                from_node.parents().find(
                    (n) =>
                    n is GenericInstantiation
                    | BaseSubpSpec
                    | ComponentDecl
                    | RenamingClause
                );

            if c.is_null then from_node
            elif c is GenericInstantiation
            then
            # A generic instantiation may have referenced environments,
            # therefore we don't want the lookup origin to be done on
            # the instantiation node directly, otherwise these references
            # will not be visited, as they won't be considered reachable.
                c
                .as[GenericInstantiation]
                .as_bare_entity
                .defining_name()
                .node
            elif c is BaseSubpSpec
            then c.as[BaseSubpSpec].as_bare_entity.name().node
            elif c is RenamingClause
            then
            # By querying from the parent of the renaming clause, we
            # prevent a SubpRenamingDecl's renamed object from  having
            # visibility over its own parameters.
                c
                .as[RenamingClause]
                .parent
            else c
        }

    |" Static property. Create an entity from the arguments with a null
    |" metadata.
    fun entity_no_md(
        n: AdaNode,
        rebindings: EnvRebindings,
        from_rebound: Bool
    ): Entity[AdaNode] =
        Entity[AdaNode](
            node=n,
            info=if n.is_null then null[EntityInfo]
            else
                EntityInfo(
                    md=null[Metadata],
                    rebindings=rebindings,
                    from_rebound=from_rebound
                )
        )

    |" Static method. Create an env mapping array from a list of BaseId to be
    |" used as keys, and a node to be used as value in the mappings.
    fun env_mappings(
        defining_names: ASTList[DefiningName],
        value: AdaNode
    ): Array[EnvAssoc] =
        defining_names.map(
            (n) =>
            EnvAssoc(
                key=n.name_symbol(),
                value=value,
                dest_env=DesignatedEnv(
                    kind=DesignatedEnvKind.current_env,
                    env_name=null[Symbol],
                    direct_env=null[LexicalEnv]
                ),
                metadata=null[Metadata]
            )
        )

    @with_dynvars(origin)
    fun comp_bind(left: LogicVar, right: LogicVar): Equation =
        right <- BaseTypeDecl.comp_type%(left)

    |" Static method. Return an equation that will bind type_var to any
    |" integer value, corresponding to the notion of universal_integer in the
    |" Ada RM (see :rmlink:`3.4.1`).
    @with_dynvars(origin)
    fun universal_int_bind(type_var: LogicVar): Equation =
        type_var <- node.universal_int_type()

    |" Static method. Return an equation that will bind type_var to any real
    |" value, corresponding to the notion of universal_real in the Ada RM (see
    |" :rmlink:`3.4.1`).
    @with_dynvars(origin)
    fun universal_real_bind(type_var: LogicVar): Equation =
        type_var <- node.universal_real_type()

    |" Return a null node iff we are in the definition of an aspect clause
    |" where sequential lookup needs to be deactivated. Return self otherwise.
    fun origin_node(): AdaNode =
        if node.in_aspect_with_forward_visibility() then null[AdaNode]
        elif node is ExprFunction then node.as[ExprFunction].expr
        else node

    |" Hook for the EnvSpec of units.
    |"
    |" Return value is not significant: the only purpose of this property lies
    |" in its side effects.
    fun env_hook(): Bool = match node.parent {
        case _: LibraryItem =>
            match node {
                case b: Body => b.env_hook_body()
                case bd: BasicDecl => bd.env_hook_basic_decl()
                case _ => false
            }
        case su: Subunit => su.env_hook_subunit()
        case _ => false
    }

    |" Wrapper for ``env.get``. Refines the results so that Ada visibility
    |" rules for subprogram specifications, generic instantiations and
    |" component declarations are correctly handled: names inside the three
    |" aforementioned constructs do not have visibility on their enclosing
    |" declaration, such that the following is legal:
    |"
    |" .. code:: ada
    |"
    |"     type T is null record;
    |"     procedure T (X : T) is null;
    |"
    |" Here, calling ``env_get("T")`` in the subp spec of subprogram ``T``
    |" must not return the subprogram ``T`` itself, because according to Ada
    |" the subprogram is not yet visible.
    |"
    |" Likewise, in the following snippet:
    |"
    |" .. code:: ada
    |"
    |"     type Rec is record
    |"         Set : access Set.T;
    |"     end record;
    |"
    |" Calling ``env_get("Set")`` inside the type expression of the component
    |" should not include the ``ComponentDecl`` itself in the result.
    fun env_get(
        env: LexicalEnv,
        symbol: Symbol,
        lookup: LookupKind = LookupKind.recursive,
        from_node: AdaNode = null[AdaNode],
        categories: RefCategories = RefCategories(_=true)
    ): Array[Entity[AdaNode]] = {
        val real_from_node = node.env_get_real_from_node(from_node);
        val results =
            env.get(
                symbol,
                lookup=lookup,
                from=real_from_node,
                categories=categories
            );

        # Fetch the BasicDecl corresponding to ``real_from_node``, so that
        # we can filter it out from ``results`` if its name matches the symbol
        # on which we want to perform an env lookup.
        real_from_node.do(
            (rfn) =>
            match rfn {
                case bd: BasicDecl =>
                    if bd.as_bare_entity.defining_name()?.name_is(symbol)
                    then bd
                    else null[BasicDecl]
                case dn: DefiningName =>
                    if dn.name_is(symbol)
                    then dn.as_bare_entity.basic_decl().node
                    else null[BasicDecl]
                case _ => null[BasicDecl]
            }
            .do(
                (enclosing_bd) =>
                # We found that our enclosing basic decl's defining name
                # matches the symbol on which we are doing an env lookup:
                # filter it out of the `results` array since it cannot be
                # legal Ada.
                results.filter((r) => r.node != enclosing_bd),
                default_val=results
            ),
            default_val=results
        )
    }

    |" Like ``env_get`` but should be used when the results are to be returned
    |" to users: this wrapper takes care of removing internal structures
    |" which are of no use for users.
    fun env_get_public(
        env: LexicalEnv,
        symbol: Symbol,
        lookup: LookupKind = LookupKind.recursive,
        from_node: AdaNode = null[AdaNode],
        categories: RefCategories = RefCategories(_=true)
    ): Array[Entity[AdaNode]] =
        node.env_get(env, symbol, lookup, from_node, categories).filter(
            (x) =>
            x.as[PackageDecl].do(
                (pkg) => pkg.name_symbol() != s"root_types_",
                default_val=true
            )
        )

    |" Synthesizes a defining name and its inner identifier using the given
    |" symbol.
    @memoized
    fun synthesize_defining_name(sym: Symbol): DefiningName =
        SyntheticDefiningName(
            logic_vars=null[Address],
            name=SyntheticIdentifier(logic_vars=null[Address], sym=sym)
        )

    |" Synthesizes a subprogram declaration named after the given symbol,
    |" with a "Right" parameter having the ``rhs`` type, and the given
    |" return type.
    @memoized
    fun create_unop_assoc(
        op: Symbol,
        rhs: BaseTypeDecl,
        ret: BaseTypeDecl
    ): EnvAssoc =
        EnvAssoc(
            key=op,
            value=SyntheticSubpDecl(
                spec=SyntheticUnarySpec(
                    subp_symbol=op,
                    right_param=SyntheticFormalParamDecl(
                        param_name=s"right",
                        param_type=SyntheticTypeExpr(target_type=rhs)
                    ),
                    return_type_expr=SyntheticTypeExpr(target_type=ret)
                )
            ),
            dest_env=DesignatedEnv(
                kind=DesignatedEnvKind.current_env,
                env_name=null[Symbol],
                direct_env=null[LexicalEnv]
            ),
            metadata=null[Metadata]
        )

    |" Implementation for the various ``create_binop_assoc*`` variants. The
    |" shorthands take care of synthesizing type expressions when necessary.
    @memoized
    fun create_binop_assoc_impl(
        op: Symbol,
        lhs: TypeExpr,
        rhs: TypeExpr,
        ret: TypeExpr
    ): EnvAssoc =
        EnvAssoc(
            key=op,
            value=SyntheticSubpDecl(
                spec=SyntheticBinarySpec(
                    subp_symbol=op,
                    left_param=SyntheticFormalParamDecl(
                        param_name=s"left",
                        param_type=lhs
                    ),
                    right_param=SyntheticFormalParamDecl(
                        param_name=s"right",
                        param_type=rhs
                    ),
                    return_type_expr=ret
                )
            ),
            dest_env=DesignatedEnv(
                kind=DesignatedEnvKind.current_env,
                env_name=null[Symbol],
                direct_env=null[LexicalEnv]
            ),
            metadata=null[Metadata]
        )

    |" Synthesizes a subprogram declaration named after the given symbol,
    |" with a "Left" parameter having the ``lhs`` type, a "Right" parameter
    |" having the ``rhs`` type, and the given return type.
    @memoized
    fun create_binop_assoc(
        op: Symbol,
        lhs: BaseTypeDecl,
        rhs: BaseTypeDecl,
        ret: BaseTypeDecl
    ): EnvAssoc =
        node.create_binop_assoc_impl(
            op,
            SyntheticTypeExpr(target_type=lhs),
            SyntheticTypeExpr(target_type=rhs),
            SyntheticTypeExpr(target_type=ret)
        )

    |" Like ``create_binop_assoc`` but the left parameter's type is given as a
    |" type expression.
    @memoized
    fun create_binop_assoc_l_expr(
        op: Symbol,
        lhs: TypeExpr,
        rhs: BaseTypeDecl,
        ret: BaseTypeDecl
    ): EnvAssoc =
        node.create_binop_assoc_impl(
            op,
            lhs,
            SyntheticTypeExpr(target_type=rhs),
            SyntheticTypeExpr(target_type=ret)
        )

    |" Like ``create_binop_assoc`` but the right parameter's type is given as
    |" a type expression.
    @memoized
    fun create_binop_assoc_r_expr(
        op: Symbol,
        lhs: BaseTypeDecl,
        rhs: TypeExpr,
        ret: BaseTypeDecl
    ): EnvAssoc =
        node.create_binop_assoc_impl(
            op,
            SyntheticTypeExpr(target_type=lhs),
            rhs,
            SyntheticTypeExpr(target_type=ret)
        )

    |" Like ``create_binop_assoc`` but the left and right parameters' types
    |" are given as type expressions.
    @memoized
    fun create_binop_assoc_l_r_expr(
        op: Symbol,
        lhs: TypeExpr,
        rhs: TypeExpr,
        ret: BaseTypeDecl
    ): EnvAssoc =
        node.create_binop_assoc_impl(
            op,
            lhs,
            rhs,
            SyntheticTypeExpr(target_type=ret)
        )

    |" Custom Unique identifying text used to recognize this node. Not
    |" applicable to all nodes, but on AdaNode because it spans more than one
    |" hierarchy of node types.
    @ignored
    fun custom_id_text(): String = ""

    |" Internal method used by ``complete`` to get the array of possible
    |" completions for the current node. This method has to be overridden in
    |" order to specialize the completion.
    @with_dynvars(origin)
    fun complete_items(): Array[CompletionItem] =
        node.env_get_public(node.children_env, null[Symbol]).map(
            (n) =>
            CompletionItem(
                decl=n.as[BasicDecl],
                is_dot_call=n.info.md.dottable_subp,
                is_visible=node.has_visibility(n),
                weight=self.complete_item_weight(n.as[BasicDecl])
            )
        )

    |" Internal method used by ``complete_items`` that can be used to
    |" specialize the completion weight field only.
    |"
    |" Weight is an integer, the higher it is, the more relevant it is in the
    |" given context. In practice, the weight varies from 0 to 100, so that
    |" one has just to sort the completion items by their weight, in
    |" decreasing order, to get the more relevant items first.
    @with_dynvars(origin)
    fun complete_item_weight(
        @ignored
        item: Entity[BasicDecl]
    ): Int = 0

    |" Helper for the ``has_spark_mode_on`` and ``is_subject_to_proof``
    |" properties.
    |"
    |" This property will get the applicable aspect defining the SPARK_Mode
    |" for the given node, recursing syntactically and taking into account
    |" configuration files.
    |"
    |" This only implements the base logic for recursing up the tree: nodes
    |" that need a specific logic must override it. See for example
    |" ``BasicDecl.spark_mode_aspect``.
    @exported
    fun spark_mode_aspect(): Aspect =
        if not self.parent.is_null then self.parent.spark_mode_aspect()

        # Handle cases where this property is called on a node that is outside
        # of a compilation unit.
        else
            raise[Aspect] PreconditionFailure("SPARK Mode does not apply here")

    |" Return the immediate declarative region (:rmlink:`8.1`)
    |" corresponding to this node, that is, the concatenation of the
    |" declarative parts of itself and all its completion. This does not
    |" include the declarative regions of the enclosed declarations.
    |"
    |" This is mainly used to restrict the scope in which to search for the
    |" previous part of a declaration.
    fun immediate_declarative_region(): LexicalEnv = null[LexicalEnv]

    |" This is the base property for constructing equations that, when solved,
    |" will resolve names and types for every sub expression of the expression
    |" you call it on. Note that if you call that on any expression, in some
    |" context it might lack full information and return multiple solutions.
    |" If you want completely precise resolution, you must call that on the
    |" outermost node that supports xref_equation.
    @with_dynvars(env, origin, entry_point)
    # xref_equation is only called from the external property
    # resolve_own_names, so we need to ignore the warning.
    @ignored
    fun xref_equation(): Equation =
        raise[Equation] PropertyError(
            "Property AdaNode.xref_equation not implemented"
        )

    @with_dynvars(env, origin)
    fun xref_stop_resolution(): Bool = false

    @with_dynvars(env, origin, entry_point)
    fun stop_resolution_equation(): Equation = %true

    |" Designates entities that are entry point for the xref solving
    |" infrastructure. If this returns true, then resolve_names can be called
    |" on it.
    |"
    |" .. note::
    |"     For convenience, and unlike what is defined in the ARM wrt.
    |"     complete contexts for name resolution, ``xref_entry_points`` can be
    |"     nested.
    @exported
    fun xref_entry_point(): Bool = false

    |" Return whether this node is a ``UsePackageClause`` that follows a
    |" ``WithClause`` for the same unit.
    @exported
    fun matching_with_use_clause(): Bool =
        node.as[UsePackageClause].do(
            (uc) =>
            self.previous_sibling.as[WithClause].do(
                (wc) =>
                uc.packages.length() == wc.packages.length()
                and uc.packages[0].as_symbol_array()
                == wc.packages[0].as_symbol_array()
            )
        )
}

|" Qualifier for the ``abort`` keyword.
@qualifier
enum class Abort: AdaNode {
}

|" Qualifier for the ``abstract`` keyword.
@qualifier
enum class Abstract: AdaNode {
}

|" List of AbstractStateDecls.
class AbstractStateDeclList: ASTList[AdaNode] {
}

|" List of alternatives in a ``when ...`` clause.
class AlternativesList: ASTList[AdaNode] {
    |" If this AlternativesList belongs to a case statement, return the type
    |" of the enum this case statement operates on. Null otherwise.
    fun enum_type(): Entity[BaseTypeDecl] =
        self.parent.parent.parent.as[CaseStmt].do(
            (cs) => cs.expr.expression_type()
        )

    |" Return possible completions at this point in the file.
    @with_dynvars(origin)
    fun complete_items(): Array[CompletionItem] =
        node.children_env.get(null[Symbol]).map(
            (n) =>
            CompletionItem(
                decl=n.as[BasicDecl],
                is_dot_call=n.info.md.dottable_subp,
                is_visible=node.has_visibility(n),
                weight=match n {
                    case eld: EnumLiteralDecl =>
                        if self.enum_type() == eld.enum_type() then 100 else 0
                    case _ => 0
                }
            )
        )
}

|" List of constraints.
class ConstraintList: ASTList[AdaNode] {
}

|" List of declarations.
class DeclList: ASTList[AdaNode] {
}

|" List of statements.
class StmtList: ASTList[AdaNode] {
}

|" List of associations.
class AssocList: ASTList[BasicAssoc] {
    |" Return the actual expression for ``param`` if any, ``default_expr``
    |" otherwise.
    fun actual_for_param_at(
        param: Entity[DefiningName],
        pos: Int,
        default_expr: Entity[Expr] = null[Entity[Expr]]
    ): Entity[Expr] = {
        val up = self.unpacked_params();

        up.find(
            # Search expression for parameter `param` if a named one exists
            (p) => p.name?.matches(param.name.node)
        )
        .do(
            (a) => a.assoc.expr(),
            # Otherwise, get the parameter using its position if any
            default_val=if
                up?[pos].is_null or not up?[pos].assoc.names().is_null
            then (
                # None was found, either by name or by position, return
                # default expression.
                default_expr
            )
            else (
                # Use expression for param by position
                up?[pos].assoc.expr()
            )
        )
    }

    |" Given the list of ParamAssoc, that can in certain case designate
    |" several actual parameters at once, create an unpacked list of
    |" SingleActual instances.
    @memoized
    fun unpacked_params(): Array[SingleActual] =
        self.mapcat(
            (pa) => {
                val names = pa.names();

                if names.length() == 0
                then [SingleActual(name=null[Identifier], assoc=pa)]
                else
                    names.filtermap(
                        (i) => SingleActual(name=i.as[BaseId], assoc=pa),
                        (i) => i is BaseId
                    )
            }
        )

    |" Returns an array of pairs, associating formal parameters to actual
    |" expressions. The formals to match are retrieved by resolving the call
    |" which this AssocList represents the actuals of.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun zip_with_params(): Array[ParamActual] = {
        # Bind imprecise_fallback to False for now because
        # first_corresponding_decl is not implemented on CallExpr.
        val is_dottable_subp = {
            bind imprecise_fallback = false;

            self.parent.as[Name].do((e) => e.is_dot_call())
        };
        val params =
            self.parent.do(
                (v1) =>
                match v1 {
                    case e: CallExpr =>
                        e.called_subp_spec()?.abstract_formal_params()
                    case i: GenericInstantiation =>
                        i.designated_generic_decl()
                        ?.formal_part
                        .abstract_formal_params()
                    case c: CompositeConstraint =>
                        c.subtype()?.discriminants_list()
                    case a: BaseAggregate =>
                        {
                            bind origin = node;
                            bind env = node.node_env;

                            a.expression_type().record_def()
                            ?.components
                            .abstract_formal_params_for_assocs(
                                self,
                                # Do not get ancestor_expr's components if `a`
                                # is an extended aggregate.
                                stop_recurse_at=a.ancestor_expr_type()
                            )
                        }
                    case _ => null[Array[Entity[BaseFormalParamDecl]]]
                }
            );
        val others_assoc =
            self.find(
                (assoc) => assoc.names().any((n) => n is OthersDesignator)
            );
        val explicit_matches =
            params.do(
                (_) =>
                node.match_formals(params, self, is_dottable_subp).map(
                    (m) =>
                    ParamActual(param=m.formal, actual=m.actual.assoc.expr())
                )
            );
        val default_subp_matches =
            params.do(
                (_) =>
                params.filtermap(
                    (p) => {
                        # Append implicit actuals of formal subprograms that
                        # have a default value (box expression of explicit
                        # reference).
                        val decl = p.as[GenericFormalSubpDecl];
                        val subp =
                            p
                            .as[GenericFormalSubpDecl]
                            .decl
                            .as[FormalSubpDecl];

                        ParamActual(
                            param=decl.defining_name(),
                            actual=if subp.default_expr is Name
                            then subp.default_expr
                            else
                                subp.designated_subprogram_from(
                                    inst=self.parent.as[GenericInstantiation]
                                )
                                ?.defining_name()
                        )
                    },
                    (p) =>
                    p.as[GenericFormalSubpDecl].do(
                        (fd) =>
                        fd.decl.as[FormalSubpDecl].do(
                            (subp) =>
                            # Generate a new match for formal subprogram
                            # which have a default value.
                            subp.default_expr is BoxExpr
                            | Name
                            # unless they have already have an explicit match
                            and not explicit_matches.any(
                                (m) => m.param == subp.defining_name()
                            )
                        )
                    )
                )
            );
        val given_matches = explicit_matches & default_subp_matches;
        val others_matches =
            others_assoc.do(
                (oa) =>
                node.unpack_formals(params).filtermap(
                    (p) => ParamActual(param=p, actual=oa.expr()),
                    (p) => not given_matches.any((m) => m.param == p)
                )
            );

        given_matches & others_matches
    }
}

|" List of alternatives in a membership test expression.
class ExprAlternativesList: ASTList[Expr] {
}

|" List of discriminant associations.
class DiscriminantChoiceList: ASTList[Identifier] {
}

|" List of parents in a type declaration.
class ParentList: ASTList[Name] {
}

|" Qualifier for the ``aliased`` keyword.
@qualifier
enum class Aliased: AdaNode {
}

|" Qualifier for the ``all`` keyword.
@qualifier
enum class All: AdaNode {
}

|" Specification for array indexes (:rmlink:`3.6`).
@abstract
class ArrayIndices: AdaNode {
    |" Number of dimensions described in this node.
    @abstract
    fun ndims(): Int

    |" Add a constraint on an expression passed as the index of an array
    |" access expression.
    |"
    |" For example::
    |"
    |"     type A is array (Integer range 1 .. 10) of Integer;
    |"
    |"     A_Inst : A;
    |"
    |"     A_Inst (2);
    |"     --      ^ Will add constraint on lit that it needs to be of type
    |"     --      Integer.
    @abstract
    @with_dynvars(origin)
    fun constrain_index_expr(index_expr: Entity[Expr], dim: Int): Equation

    @abstract
    @with_dynvars(origin)
    fun index_type(dim: Int): Entity[BaseTypeDecl]

    |" Return True iff all index types are static.
    @abstract
    @with_dynvars(imprecise_fallback=false)
    fun is_static(): Bool
}

|" Constrained specification for array indexes (:rmlink:`3.6`).
class ConstrainedArrayIndices: ArrayIndices {
    @parse_field
    list: ConstraintList

    fun ndims(): Int = node.list.length()

    @with_dynvars(origin)
    fun constrain_index_expr(index_expr: Entity[Expr], dim: Int): Equation =
        index_expr.expected_type_var() <- self.index_type(dim)
        %and index_expr.matches_expected_type()

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.list.logic_all(
            (index) =>
            index.sub_equation()
            %and index.as[Expr].do(
                (expr) =>
                (
                    AdaNode.is_not_null%(expr.type_var())
                    %and BaseTypeDecl.is_discrete_type%(expr.type_var())
                )
                %and BaseTypeDecl.is_not_root_int_type%(expr.type_var()),
                default_val=%true
            )
        )

    @with_dynvars(origin)
    fun index_type(dim: Int): Entity[BaseTypeDecl] = {
        # We might need to solve self's equation to get the index type
        val _ =
            node.parents().find((p) => p.xref_entry_point())
            .as_entity
            .resolve_names();

        self.list?[dim].do(
            (v1) =>
            match v1 {
                case st: SubtypeIndication => st.designated_type()
                case e: Expr => e.type_val().as[BaseTypeDecl]
                case _ => null[Entity[BaseTypeDecl]]
            }
        )
    }

    @with_dynvars(imprecise_fallback=false)
    fun is_static(): Bool =
        self.list.all(
            (t) =>
            match t {
                case st: SubtypeIndication => st.is_static_subtype()
                case e: BinOp =>
                    e.left.is_static_expr() and e.right.is_static_expr()
                case _ => false
            }
        )
}

|" Unconstrained specification for array indexes (:rmlink:`3.6`).
class UnconstrainedArrayIndices: ArrayIndices {
    @parse_field
    types: ASTList[UnconstrainedArrayIndex]

    fun ndims(): Int = node.types.length()

    @with_dynvars(origin)
    fun constrain_index_expr(index_expr: Entity[Expr], dim: Int): Equation =
        index_expr.expected_type_var() <- self.index_type(dim)
        %and index_expr.matches_expected_type()

    @with_dynvars(origin)
    fun index_type(dim: Int): Entity[BaseTypeDecl] =
        self.types?[dim]?.designated_type()

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.types.logic_all(
            (typ) =>
            typ.subtype_name.xref_type_equation()
            %and (
                if typ.lower_bound.is_null then %true
                else typ.lower_bound.sub_equation()
            )
        )

    @with_dynvars(imprecise_fallback=false)
    fun is_static(): Bool =
        self.types.all((t) => t.subtype_name.is_static_subtype())
}

|" Name/expression association in an aspect.
class AspectAssoc: AdaNode {
    @parse_field
    id: Name
    @parse_field
    @nullable
    expr: Expr

    fun xref_entry_point(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        val target = node.parent.parent.parent;

        # Iterable aspect
        if self.id.name_symbol() in s"Aggregate" | s"Iterable"
        then
            self.expr.as[Aggregate].assocs.unpacked_params().logic_all(
                (sa) =>
                sa.assoc.expr().as![Name].xref_no_overloading(sequential=false)
            )

        # Contracts
        elif
            self.id.name_symbol() in s"Pre"
                | s"Post"
                | s"Refined_Post"
                | s"Type_Invariant"
                | s"Invariant"
                | s"Predicate"
                | s"Static_Predicate"
                | s"Dynamic_Predicate"
                | s"Initial_Condition"
        then {
            # Ada 2022 allows Pre and Post aspects for
            # access-to-subprogram types. In such case, visibility
            # rules change. The TypeDecl environment should be
            # considered for name resolution.
            bind env =
                if
                    self.id.name_symbol() in s"Pre" | s"Post"
                    and target.as[TypeDecl]?.type_def is AccessToSubpDef
                then target.as[TypeDecl].type_def.children_env
                else self.node_env;


            node.expr.expected_type_var() <- node.bool_type()
            %and self.expr.sub_equation()
            %and node.expr.matches_expected_formal_type()
        }
        elif self.id.name_symbol() in s"Contract_Cases" | s"Subprogram_Variant"
        then self.expr.sub_equation()

        # Put_Image aspect
        elif self.id.name_is(s"Put_Image")
        then
            self.expr.as![Name].xref_no_overloading(
                sequential=false,
                all_els=true
            )
            %and BasicDecl.is_put_image_subprogram_for_type%(self
            .expr
            .as[Name]
            .ref_var(),
            target.as![BaseTypeDecl].as_entity)

        # Global aspect. Depends is always an aggregate, so doesn't need an
        # entry.
        elif self.id.name_is(s"Global") or self.id.name_is(s"Refined_Global")
        then
            if self.expr is NullLiteral then %true
            else self.expr.sub_equation()

        # Do not resolve anything inside those aspect, as identifiers act
        # as reserved words. For example, we do not want to resolve `C`
        # in `Convention => C` to the first visible entity named C.
        elif self.id.name_is(s"Convention") then %true
        elif self.id.name_is(s"Stable_Properties")
        then self.stable_properties_assoc_equation()
        elif
            self.id.name_symbol() in s"Integer_Literal"
                | s"Real_Literal"
                | s"String_Literal"
        then self.user_defined_literals_equation(target.as[TypeDecl])

        # Constant_Indexing and Variable_Indexing aspects name expression
        # can denotes one or more functions. Since name resolution can set
        # only one reference for a name, only keep the first function
        # returned by constant_indexing_fns and variable_indexing_fns.
        elif self.id.name_is(s"Constant_Indexing")
        then
            self.expr.as![Identifier].ref_var()
            <- target.as[TypeDecl].as_entity.constant_indexing_fns()?[0]
        elif self.id.name_is(s"Variable_Indexing")
        then
            self.expr.as![Identifier].ref_var()
            <- target.as[TypeDecl].as_entity.variable_indexing_fns()?[0]

        # For the Annotate aspect, the first two identifiers are not
        # analyzed. The rest are arbitrary expressions (see
        # `Expr.annotate_argument_equation`).
        elif self.id.name_is(s"Annotate")
        then
            self.expr.as[BaseAggregate].assocs.unpacked_params().ilogic_all(
                (sa, i) =>
                if i < 2 then %true
                else sa.assoc.expr().annotate_argument_equation()
            )
        elif self.id.name_is(s"Implicit_Dereference")
        then self.implicit_dereference_equation(target.as[TypeDecl])

        # For the Model_Of aspect, the RHS must either denote a type
        # declaration or a subprogram with a matching profile, depending
        # on the kind of entity this aspect is attached to.
        elif self.id.name_is(s"Model_Of")
        then
            if target is BaseTypeDecl
            then self.expr.as![Name].xref_type_equation()
            else
                self.expr.as![Name].xref_no_overloading(all_els=true)
                %and BasicDecl.subp_decl_match_signature%(self
                .expr
                .as![Name]
                .ref_var(),
                target.as[BasicDecl].as_entity)

        # Default resolution: For the moment we didn't encode specific
        # resolution rules for every aspect, so by default at least try to
        # name resolve the expression.
        else self.expr.do((e) => e.sub_equation(), default_val=%true) %or %true
    }

    |" Equation for the case where this is an aspect assoc for an
    |" Implicit_Dereference aspect.
    @with_dynvars(env, origin, entry_point)
    fun implicit_dereference_equation(target: TypeDecl): Equation = {
        val id = self.expr.as![Identifier];
        val discr =
            target.as_entity.discriminants_list().find(
                (l) => l.defining_names().any((n) => n.name_is(id.symbol))
            );

        id.ref_var() <- discr
    }

    |" Equation for the case where this is an aspect assoc for a
    |" Stable_Properties aspect.
    @with_dynvars(env, origin, entry_point)
    fun stable_properties_assoc_equation(): Equation = {
        # Get the list of names defined by the aspect
        val identifiers =
            match self.expr {
                # AspectAssoc is of the form: (name1, name2, ...)
                case a: Aggregate => a.assocs.map((i) => i.expr())

                # AspectAssoc is of the form: (name)
                case pe: ParenExpr => [pe.expr]
                case _ => [null[Entity[Expr]]]
            }
            .map(
                (e) =>
                e.as[UnOp].do(
                    # Ignore the `not` keyword (useless for nameres)
                    (uo) => if uo.op is Op.Not then uo.expr else e,
                    default_val=e
                )
            )
            .map((e) => e.as![Identifier]);
        # Names defined by the assoc can only be `Identifier`s

        identifiers.logic_all(
            (i) =>
            node.env_get(
                env,
                i.sym(),
                lookup=LookupKind.recursive,
                from_node=node.origin_node(),
                categories=RefCategories(_=true)
            )
            .filter(
                (f) =>
                (
                    # It can only refer to a SubpDecl or an ExprFunction
                    f is SubpDecl | ExprFunction
                )
                and i.denotes_the_property_function(
                    f.as[BasicDecl].subp_spec_or_null()
                )
            )
            .logic_any((f) => i.ref_var() <- f)
        )
    }

    |" Equation for the case where this is an aspect assoc for a
    |" user-defined literal.
    @with_dynvars(env, origin, entry_point)
    fun user_defined_literals_equation(target: TypeDecl): Equation =
        self.expr.as![Identifier].ref_var()
        <- target.as_entity.user_defined_literal_fns(self.id.name_symbol())?[
        # First result in the list is the last override if any
            0
        ]

    |" Return the string representation of the given name, which must be a
    |" Name that can appear in an aspect association id.
    fun aspect_name(n: Entity[Name]): String =
    # TODO: would be cleaner to implement a general "image" function in
    # class Name directly.
    match n {
        case bid: BaseId => bid.sym().image()
        case ar: AttributeRef =>
            node.aspect_name(ar.prefix) & "'" & ar.attribute.sym().image()
        case _ =>
            raise[String] PreconditionFailure(
                "aspect_name called on an invalid aspect name"
            )
    }

    |" Return whether this aspect is ghost code or not. See SPARK RM 6.9.
    @exported
    fun is_ghost_code(): Bool =
        self.id.name_symbol() in s"Pre" | s"Post" | s"Contract_Cases"
}

|" Base class for aspect clauses.
@abstract
class AspectClause: AdaNode {
    fun xref_entry_point(): Bool = true
}

|" Representation clause (``for .. use at ...;``) (:rmlink:`13.5.1`).
class AtClause: AspectClause {
    @parse_field
    name: BaseId
    @parse_field
    expr: Expr

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.name.sub_equation() %and self.expr.sub_equation()
}

|" Clause for an attribute definition (``for ...'Attribute use ...;``)
|" (:rmlink:`13.3`).
class AttributeDefClause: AspectClause {
    @parse_field
    attribute_expr: Name
    @parse_field
    expr: Expr

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        val attr = self.attribute_expr.as![AttributeRef];
        val rel_name = attr.attribute.name_symbol();

        if rel_name in s"Read" | s"Write" | s"Input" | s"Output"
        then
            (
                self.expr.as![Name].xref_no_overloading(all_els=true)
                %and BasicDecl.is_stream_subprogram_for_type%(self
                .expr
                .as[Name]
                .ref_var(),
                attr.prefix.name_designated_type(),
                rel_name == s"Input")
            )
            %and attr.prefix.sub_equation()
        elif rel_name in s"Put_Image"
        then
            (
                self.expr.as![Name].xref_no_overloading(all_els=true)
                %and BasicDecl.is_put_image_subprogram_for_type%(self
                .expr
                .as[Name]
                .ref_var(),
                attr.prefix.name_designated_type())
            )
            %and attr.prefix.sub_equation()
        else
            (self.expr.sub_equation() %and attr.sub_equation())
            %and (
                if rel_name == s"External_Tag"
                then
                    node.expr.expected_type_var() <- node.std_entity(s"String")
                elif rel_name == s"Address"
                then
                    node.expr.expected_type_var() <- self.system_address_type()
                else %true
            )
    }
}

|" Representation clause for enumeration types (:rmlink:`13.4`).
class EnumRepClause: AspectClause {
    @parse_field
    type_name: Name
    @parse_field
    aggregate: BaseAggregate

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = # TODO: resolve names in ``aggregate``
        self
        .type_name
        .xref_type_equation()

    |" Returns an array of pairs, associating enum literals to representation
    |" clause actuals.
    @exported
    fun params(): Array[ParamActual] = {
        # Get the enum literals
        val el =
            self.type_name.referenced_decl().as[BaseTypeDecl].root_type()
            .as[TypeDecl]
            .type_def
            .as[EnumTypeDef]
            .enum_literals;
        # Get the representation clause actuals
        val ra = self.aggregate.assocs;

        el.imap(
            (l, i) =>
            ParamActual(param=l.name, actual=ra.actual_for_param_at(l.name, i))
        )
    }
}

|" Representation clause for a record type (:rmlink:`13.5.1`).
class RecordRepClause: AspectClause {
    @parse_field
    name: Name
    @parse_field
    @nullable
    at_expr: Expr
    @parse_field
    components: ASTList[AdaNode]

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.name.xref_type_equation()
        %and self.at_expr.do((e) => e.sub_equation(), default_val=%true)
}

|" List of aspects in a declaration (:rmlink:`13.1.1`).
class AspectSpec: AdaNode {
    @parse_field
    aspect_assocs: ASTList[AspectAssoc]
}

|" Abstract class for a key/value association, where the value is an
|" expression.
@abstract
class BaseAssoc: AdaNode {
    |" Returns the expression side of this assoc node.
    @exported
    @abstract
    fun assoc_expr(): Entity[Expr]
}

|" Single association for the ``Contract_Case`` aspect.
class ContractCaseAssoc: BaseAssoc {
    @parse_field
    guard: AdaNode
    @parse_field
    consequence: Expr

    fun assoc_expr(): Entity[Expr] = self.consequence
}

|" Argument association in a pragma.
class PragmaArgumentAssoc: BaseAssoc {
    @parse_field
    @nullable
    name: Name
    @parse_field
    expr: Expr

    fun assoc_expr(): Entity[Expr] = self.expr
}

|" Base class for lists of formal parameters. This is used in every case a
|" list of "formals" can be called or instantiated, so in all the following
|" cases:
|"
|" * Subprogram specifications (and subprogram calls).
|" * Component lists (and aggregates).
|" * Generic formals (and generic instantiations).
|"
|" This allows to share the parameter unpacking/matching logic.
|"
|" This is a Libadalang abstraction that has no existence in the Ada reference
|" manual.
@abstract
class BaseFormalParamHolder: AdaNode {
    |" Return the list of abstract formal parameters for this holder.
    @exported
    @abstract
    fun abstract_formal_params(): Array[Entity[BaseFormalParamDecl]]

    |" Return ``DefiningName`` for all parameters.
    fun unpacked_formal_params(): Array[Entity[DefiningName]] =
        node.unpack_formals(self.abstract_formal_params())

    |" Return all parameters as a ``DefiningName`` array. This property
    |" doesn't return record discriminants nor variants when called on a
    |" record component list.
    @exported
    fun formal_params(): Array[Entity[DefiningName]] = match self {
        case r: ComponentList =>
            node.unpack_formals(r.components.keep[BaseFormalParamDecl])
        case _ => self.unpacked_formal_params()
    }

    fun match_param_list(
        params: Entity[AssocList],
        is_dottable_subp: Bool
    ): Array[ParamMatch] =
        node.match_formals(
            self.abstract_formal_params(),
            params,
            is_dottable_subp
        )

    |" Return the minimum number of parameters this subprogram can be called
    |" while still being a legal call.
    @exported
    fun nb_min_params(): Int =
        node.as_bare_entity.unpacked_formal_params().filter(
            (p) => p.formal_decl().is_mandatory()
        )
        .length()

    |" Return the maximum number of parameters this subprogram can be called
    |" while still being a legal call.
    @exported
    fun nb_max_params(): Int =
        node.as_bare_entity.unpacked_formal_params().length()

    |" Utility function. Given a subprogram spec and whether the subprogram
    |" was referenced using the dot notation, determine if it can be called
    |" without parameters (and hence without a callexpr).
    fun paramless(dottable_subp: Bool, can_be: Bool = true): Bool = {
        val nb_params =
            if can_be then node.nb_min_params() else node.nb_max_params();

        (dottable_subp and nb_params == 1) or nb_params == 0
    }

    |" Return whether a AssocList is a match for this SubpSpec, i.e.
    |" whether the argument count (and designators, if any) match.
    @with_dynvars(env)
    fun is_matching_param_list(
        params: Entity[AssocList],
        is_dottable_subp: Bool
    ): Bool = {
        val bare = node.as_bare_entity;
        val match_list = bare.match_param_list(params, is_dottable_subp);
        # Compute the min and max number of parameters this subprogram takes
        # and adjust that number in case the subprogram is dottable:
        # - Remove 1 to the maximum value if the subprogram is dottable.
        # - Remove 1 to the minimum value iff the subprogram is dottable and
        # its first parameter (the one used for the prefixed notation) is
        # mandatory, because the call to ``bare.nb_min_params`` already takes
        # care of optional parameters, so we won't count it twice.
        val nb_max_params =
            if is_dottable_subp then bare.nb_max_params() - 1
            else bare.nb_max_params();
        val nb_min_params =
            if
                is_dottable_subp
                and (
                    # If is dottable and the first parameter is mandatory,
                    # remove 1 to the minumum number of parameter. In the
                    # other case, ``bare.nb_min_params`` has already counted
                    # it.
                    node.as_bare_entity.unpacked_formal_params()?[0]
                    .formal_decl()
                    .is_mandatory()
                )
            then bare.nb_min_params() - 1
            else bare.nb_min_params();

        params.length() <= nb_max_params
        and match_list.all((m) => m.has_matched)
        and match_list.filter((m) => m.formal.formal_decl().is_mandatory())
        .length()
        == nb_min_params
    }

    |" Returns the type of each parameter of self.
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun param_types(): Array[Entity[BaseTypeDecl]] =
        self.unpacked_formal_params().map(
            (fp) =>
            self.real_designated_type(fp.formal_decl().type_expression())
        )

    |" Returns the mode of each parameter of self.
    fun param_modes(): Array[Entity[Mode]] =
        self.unpacked_formal_params().map(
            (fp) => fp.formal_decl().as[ParamSpec].mode
        )

    |" Scrap all surface-level rebindings pairs that correspond to generic
    |" subprogram instantiations from the given chain of rebindings.
    fun shed_subp_rebindings(r: EnvRebindings): EnvRebindings =
        if r?.new_env.do((v1) => v1.env_node is GenericSubpInstantiation)
        then node.shed_subp_rebindings(r.get_parent)
        else r

    |" Given the name of a parameter defined in a specification of a generic
    |" formal parameter, return its corresponding name in the actual that was
    |" used in the instantiation.
    fun corresponding_actual_param(
        name: Entity[DefiningName]
    ): Entity[DefiningName] = {
        val actual_spec = self.corresponding_actual();

        if self == actual_spec then name
        else
            self.unpacked_formal_params().imapcat(
                (param, i) =>
                if param.node == name.node
                then [actual_spec.unpacked_formal_params()?[i]]
                else null[Array[Entity[DefiningName]]]
            )?[
                0
            ]
    }

    |" Return the real type denoted by ``typ``, taking into account that
    |" ``typ`` might be the type of a derived primitive. In that case, return
    |" the derived primitive type.
    @with_dynvars(origin=null[AdaNode])
    fun real_type(typ: Entity[BaseTypeDecl]): Entity[BaseTypeDecl] = {
        # Compute the type entity of which self is a primitive
        val prim_type =
            self.entity_no_md(
                self.info.md.primitive,
                self.info.rebindings,
                self.info.from_rebound
            )
            .as[BaseTypeDecl];

        if prim_type.node.is_null then typ
        elif prim_type?.canonical_type().node == typ?.canonical_type().node
        then
            match
                self.entity_no_md(
                    self.info.md.primitive_real_type or? typ.node,
                    # This primitive might come from a subprogram
                    # instantiation, in which case we don't want to plug its
                    # rebindings to the type itself. So simply remove all
                    # rebindings at the surface that correspond to subprogram
                    # instantiations. We cannot mistakenly remove relevant
                    # rebindings, since a derived type cannot come from a
                    # subprogram instantiation.
                    node.shed_subp_rebindings(self.info.rebindings),
                    self.info.from_rebound
                )
            {
                # Since `primitive_real_type` is a node and not an entity, it
                # may refer to a formal type, so we need to manually resolve it
                # to an actual type using the current rebindings in case they
                # are relevant.
                case ft: Entity[FormalTypeDecl] => ft.get_actual()
                case other => other.as[BaseTypeDecl]
            }
        # Handle the case where the primitive is defined on an anonymous
        # access type, by returning an anonymous access type over the
        # real_type of the accessed type.

        elif
            typ.as[AnonymousTypeDecl].do(
                (td) => not td.type_def is AccessToSubpDef
            )
        then
            typ.accessed_type().do(
                (at) =>
                self.real_type(at).do(
                    (rat) =>
                    if at == rat then typ else rat.anonymous_access_type()
                )
            )
        else typ
    }

    |" Given a type expression that is part of this subprogram specification
    |" (for example, appearing in a parameter specification), return the real
    |" type it designates, taking into account the fact that self might be
    |" the specification of an inherited subprogram. Overall, we can
    |" distinguish the following cases:
    |"
    |" - self is a primitive subprogram inherited from a base type and
    |"   ``typ`` designates that base type, in which case we should return
    |"   the inheriting type.
    |"
    |" - self is a primitive subprogram inherited from a base type but
    |"   ``typ`` does not designate that base type, in which case we must
    |"   compute the actual designated type by taking into account the
    |"   rebindings associated with the base type. This is done by
    |"   traversing the inheritance hierarchy starting from the inheriting
    |"   type up to the inherited type and extracting the rebindings that we
    |"   got along the way.
    |"
    |" - self is not an inherited primitive subprogram, in which case we
    |"   simply return the designated type using the normal path.
    |"
    |" The first two points are illustrated with the following example.
    |"
    |" .. code::
    |"
    |"     generic
    |"        type G is private;
    |"     package Pkg is
    |"        type T is null record;
    |"
    |"        function Foo (Self : T) return G;      --  A
    |"     end Pkg;
    |"
    |"     package My_Pkg is new Pkg (Integer);      --  B
    |"
    |"     type My_T is new My_Pkg.T;
    |"
    |"     X : My_T    := (null record);
    |"     Y : Integer := Foo (X);                    -- C
    |"
    |" Resolving the reference to ``Foo`` at line C gets us the function
    |" declaration at line A with the appropriate metadata indicating it is a
    |" primitive subprogram of T inherited by My_T.
    |"
    |" Calling this property on the ``T`` node from the ``Self : T`` parameter
    |" specification is an instance of the first case. We should obviously
    |" return ``My_T`` in that case.
    |"
    |" Calling it on ``G`` from the return type specification is an instance
    |" of the second case. We traverse up the inheritance hierarchy starting
    |" from ``My_T`` and get to ``T [B]``, where ``[B]`` indicates the
    |" rebindings corresponding to the instantiation at line B. We can now use
    |" those rebindings to compute the actual designated type (the type
    |" designated by ``G [B]``) which correctly yields ``Integer``.
    |"
    |" This property is used during the construction of xref equations for
    |" call expressions in order to match the right parameter and return
    |" types.
    @with_dynvars(origin)
    fun real_designated_type(typ: Entity[TypeExpr]): Entity[BaseTypeDecl] = {
        val md = self.info.md;

        typ.designated_type()?.without_md().as[BaseTypeDecl].do(
            (t) =>
            # Subprograms retrieved through ``dottable_subps_env``
            # already have their base type rebindings set, so we don't
            # need to adjust it.
            # TODO: we should however compute the real_type just like we
            # do for regular primitives, but this can't be done yet because
            # their ``primitive_real_type`` metadata is not precise enough
            # as it is set on all dottable subprograms, even those which
            # are not actual primitives.
            if md.dottable_subp then t
            else {
                val rt = self.real_type(t);
                val base_rebindings =
                    md
                    .primitive_real_type
                    .as[BaseTypeDecl]
                    .as_bare_entity
                    ?.find_base_type_rebindings(md.primitive.as[BaseTypeDecl]);

                if t == rt
                then
                    if base_rebindings.is_null then t
                    else
                        Entity[TypeExpr](
                            node=typ.node,
                            info=EntityInfo(
                                md=null[Metadata],
                                rebindings=node.insert_rebindings(
                                    typ.info.rebindings,
                                    base_rebindings
                                ),
                                from_rebound=typ.info.from_rebound
                            )
                        )
                        .designated_type()
                else rt
            }
        )
    }

    |" Generate the equation that binds the type_var of this expression
    |" given its corresponding parameter in the context of a subprogram call.
    |" This takes into account the fact that the called subprogram might
    |" be an inherited primitive.
    @with_dynvars(origin, logic_context)
    fun call_argument_equation(
        param: Entity[BaseFormalParamDecl],
        arg: Entity[Expr]
    ): Equation = {
        val param_type = self.real_designated_type(param.type_expression());

        arg.expected_type_var() <- param_type
        %and arg.matches_expected_formal_type()
    }

    |" Check whether self's params match other's.
    @with_dynvars(origin)
    fun match_formal_params(
        other: Entity[BaseFormalParamHolder],
        match_names: Bool = true,
        ignore_first_param: Bool = false
    ): Bool = {
        # Check that there is the same number of formals and that each
        # formal matches.
        val self_params =
            self.unpacked_formal_params().do(
                (params) =>
                if ignore_first_param then params.ifilter((e, i) => i != 0)
                else params
            );
        val other_params = other.unpacked_formal_params();
        val self_types =
            self.param_types().do(
                (types) =>
                if ignore_first_param then types.ifilter((e, i) => i != 0)
                else types
            );
        val other_types = other.param_types();

        self_params.length() == other_params.length()
        and self_types.length() == other_types.length()
        and self_params.iall(
            (p, i) =>
            (not match_names or p.name.matches(other_params?[i].name.node))
            and self_types?[i]?.matching_type(other_types?[i])
        )
    }

    |" For a ``BaseFormalParamHolder`` (e.g. a ``SubpSpec``), we simply go
    |" to its parent (e.g. a ``FormalSubpDecl``), retrieve its corresponding
    |" actual (e.g. a ``BasicSubpDecl``), and then grab the formal param
    |" holder of that node (e.g. a ``SubpSpec``).
    fun corresponding_actual(): Entity[BaseFormalParamHolder] =
        self.parent.as[BasicDecl].do(
            (bd) => bd.corresponding_actual()?.formal_param_holder_or_null(),
            default_val=self
        )

    |" Base method of any BaseFormalParamHolder that checks whether the
    |" other given BaseFormalParamHolder matches. In practice, this will call
    |" match_formal_params, except for BaseSubpSpecs for which it will call
    |" match_signature.
    @with_dynvars(origin)
    fun match_other(
        other: Entity[BaseFormalParamHolder],
        match_names: Bool = true
    ): Bool = self.match_formal_params(other, match_names)
}

|" Base class for subprogram specifications (:rmlink:`6.1`).
@abstract
class BaseSubpSpec: BaseFormalParamHolder {
    |" Syntax property. Return the name of the subprogram defined by this
    |" specification.
    @exported
    @abstract
    fun name(): Entity[DefiningName]

    |" Syntax property. Return the type expression node corresponding to the
    |" return of this subprogram spec.
    @exported
    @abstract
    fun returns(): Entity[TypeExpr]

    fun abstract_formal_params(): Array[Entity[BaseFormalParamDecl]] =
        self.params().map((p) => p.as[BaseFormalParamDecl])

    @with_dynvars(origin)
    fun match_return_type(other: Entity[BaseSubpSpec]): Bool = {
        # Check that the return type is the same. Caveat: it's not because
        # we could not find the canonical type that it is null!
        #
        # TODO: simplify this code when SubpSpec provides a kind to
        # distinguish functions and procedures.
        val self_ret = self.return_type();
        val other_ret = other.return_type();

        (self.returns().is_null and other.returns().is_null)
        or (
            not self.returns().is_null and not other.returns().is_null
            and {
                bind origin = node.origin_node();

                self_ret?.matching_type(other_ret)
            }
        )
    }

    |" Return whether SubpSpec's signature matches self's.
    |"
    |" Note that the comparison for types isn't just a name comparison: it
    |" compares the canonical types.
    |"
    |" If match_name is False, then the name of subprogram will not be
    |" checked.
    |"
    |" If use_entity_info is True and self's metadata has values for fields
    |" ``primitive`` and ``primitive_real_type`` (e.g. if it was retrieved
    |" from a primitive_env), those will be taken into account and
    |" match_signature will return True if ``other`` overrides ``self``.
    |"
    |" If ignore_first_param is True, do the signature match by ignoring the
    |" self's first parameter. This can be used for example when matching a
    |" TaskType's procedure with one of its parent interface primitives,
    |" because the subprogram from the task has an implicit self parameter
    |" which does not appear in the subprogram specification.
    @with_dynvars(origin)
    fun match_signature(
        other: Entity[BaseSubpSpec],
        match_name: Bool,
        use_entity_info: Bool = true,
        ignore_first_param: Bool = false
    ): Bool = {
        val ent = if use_entity_info then self else node.as_bare_entity;

        (
            # Check that the names are the same
            not match_name or ent.name().node.matches(other.name().node)
        )
        and ent.match_return_type(other)
        and ent.match_formal_params(other, match_name, ignore_first_param)
    }

    @with_dynvars(origin)
    fun match_other(
        other: Entity[BaseFormalParamHolder],
        match_names: Bool = true
    ): Bool = self.match_signature(other.as![BaseSubpSpec], match_names)

    |" Return whether UserDefinedFunctionSubpSpec's signature matches self's.
    fun match_expected_user_defined_function(
        fn: UserDefinedFunctionSubpSpec
    ): Bool =
        self.return_type().matching_type(fn.subp_return_type)
        and self.unpacked_formal_params().do(
            (params) =>
            params.length() == fn.subp_params_types.length()
            and params.ifilter(
                (p, i) =>
                not p.formal_decl().formal_type().matching_type(
                    fn.subp_params_types?[i]
                )
            )
            .is_null
        )

    |" Helper for BasicDecl.defining_env.
    @with_dynvars(origin)
    fun defining_env(): LexicalEnv =
        if self.returns().is_null then null[LexicalEnv]
        else self.return_type().defining_env()

    |" If self meets the criteria for being a subprogram callable via the dot
    |" notation, return the type of dottable elements.
    @with_dynvars(origin)
    fun potential_dottable_type(): Entity[BaseTypeDecl] =
        self.abstract_formal_params()?[0].do(
            (p) => p.type_expression()?.element_type()
        )

    |" If the given type expression designates a type of which self is a
    |" primitive, return that designated type. Otherwise return null.
    |"
    |" If ``canonicalize`` is true, then the returned type will be
    |" canonicalized first. Else, the most complete part of the type will be
    |" returned.
    fun get_candidate_type_for_primitive(
        type_expr: Entity[TypeExpr],
        canonicalize: Bool = true
    ): Entity[BaseTypeDecl] = {
        val decl_scope =
            (
                if node.parent is GenericSubpInternal
                then (
                    # Get the scope of the generic instantiation (if any) when
                    # self comes from a generic subprogram.
                    self.generic_instantiations()?[0]?.parent?.parent
                )
                else node.parent.parent.parent.as_entity
            )
            .as[DeclarativePart]
            .node;
        val typ = {
            bind origin = node.origin_node();

            match type_expr {
                case at: AnonymousType =>
                    at.element_type().do(
                        (et) => (not et.is_classwide()).do((_) => et)
                    )

                # TODO: remove this check once S918-021 is done, since it will
                # be checked below in any case.
                case other => other.designated_type()
            }
        };
        # Canonicalize if requested
        val canon_type =
            if canonicalize
            then {
                bind origin = node.origin_node();

                typ?.canonical_type()
            }
            else typ;
        val final_type =
            canon_type.as[IncompleteTypeDecl].do(
                (i) => i.next_part(),
                default_val=canon_type
            );
        val type_scope =
            final_type.do((typ) => typ.node.parent.parent.as[DeclarativePart]);

        if
            (
                (
                    # Either both the subprogram and the type are declared in
                    # in a package declaration...
                    type_scope.do((v1) => v1.parent is BasePackageDecl)
                    and decl_scope.do((v2) => v2.parent is BasePackageDecl)
                )
                or (
                    # Or, in case of a derived tagged type, a subprogram
                    # defined in the same scope may be a primitive even in a
                    # non-package scope if that subprogram overrides a previous
                    # primitive.
                    # Therefore the correct behavior here would be to compute
                    # the primitives of `final_type` and check if one of its
                    # primitives matches the signature of this subprogram.
                    # Unfortunately we cannot do that here, because it would
                    # trigger infinite recursions if the parent is defined
                    # in the same scope. Therefore, the final filtering is done
                    # in `direct_primitive_subps` and the result of this
                    # property is not 100% accurate.
                    final_type.as[TypeDecl]?.is_derived_tagged_type()
                )
            )
            and (
                # A subprogram may not be a primitive of a classwide type
                not final_type?.is_classwide()
            )
            and (
                # A subprogram may not be a primitive of a type which is not
                # declared in the same declarative scope as self, or in the
                # private part of the package in which self is defined.
                type_scope.do(
                    (ds) =>
                    ds in decl_scope
                        | decl_scope?.parent.as[BasePackageDecl]?.public_part
                )
            )
        then final_type
        else null[Entity[BaseTypeDecl]]
    }

    |" Return the types of which this subprogram is a candidate primitive of.
    |" If ``canonicalize`` is true, then the returned types will be
    |" canonicalized.
    @memoized
    fun candidate_primitive_subp_types(
        canonicalize: Bool = true
    ): Array[Entity[BaseTypeDecl]] = {
        # TODO: This might be improved by checking for spelling before looking
        # up every type.
        val params = self.unpacked_formal_params();
        val types =
            params.map((p) => p.formal_decl().type_expression())
            & self.returns().do((v1) => [v1]);

        types.map(
            (t) =>
            self.get_candidate_type_for_primitive(t, canonicalize=canonicalize)
        )
        .filter((t) => not t.is_null)
        .map(
            (t) =>
            t.as[IncompleteTypeDecl].do((i) => i.next_part(), default_val=t)
        )
        .unique()
    }

    |" Return the first type of which this subprogram is a candidate
    |" primitive of.
    fun candidate_primitive_subp_first_type(): Entity[BaseTypeDecl] =
        self.candidate_primitive_subp_types().do((p) => p?[0])

    |" If this subprogram is a primitive for a tagged type, then return this
    |" type. If ``canonicalize`` is true, then the returned types will be
    |" canonicalized.
    @memoized
    fun candidate_primitive_subp_tagged_type(
        canonicalize: Bool = true
    ): Entity[BaseTypeDecl] = {
        bind origin = node;

        self.candidate_primitive_subp_types(canonicalize).find(
            (t) => t.full_view().is_tagged_type()
        )
    }

    |" If this subp spec is that of the body of an entity, this property
    |" returns the subp spec of the declaration of that entity. It returns
    |" itself otherwise.
    |"
    |" If ``follow_generic`` is set to False, we explicitly return null if
    |" this spec is part of a generic subprogram declaration. See
    |" ``primitive_decl_spec``.
    @with_dynvars(imprecise_fallback=false)
    fun decl_spec(follow_generic: Bool): Entity[BaseSubpSpec] = {
        # The ``name`` field can be null, for example if this subp spec is part
        # of an access-to-subprogram type declaration.
        val bd = self.name()?.basic_decl();

        bd.do(
            (bd) =>
            bd.canonical_part().do(
                (dp) =>
                if not follow_generic and dp is GenericSubpInternal
                then null[Entity[BaseSubpSpec]]
                else dp.subp_spec_or_null(follow_generic=follow_generic),
                default_val=self
            ),
            default_val=self
        )
    }

    |" Return the subp spec of the declaration of this potential primitive.
    |" Since a generic subprogram cannot be a primitive, we explicitly
    |" set ``follow_generic`` to False to filter out those early.
    @with_dynvars(imprecise_fallback=false)
    fun primitive_decl_spec(): Entity[BaseSubpSpec] =
        self.decl_spec(follow_generic=false)

    |" Given a type that was retrieved by one of the ``candidate_primitive_*``
    |" properties, return itself if the subp spec actually corresponds to a
    |" primitive of this type, otherwise return null. This is needed because
    |" the result of the ``candidate_primitive_*`` properties is an
    |" approximation.
    fun as_primitive_subp_type(
        typ: Entity[BaseTypeDecl]
    ): Entity[BaseTypeDecl] =
        # `self.name` can be null for access-to-subprogram specifications
        self.name().do(
            (name) =>
            typ?.primitives_env().get(name.name_symbol()).any(
                (b) => b.node == name.basic_decl().node
            )
            .do(
                # This is node is indeed a primitive if we can find it in
                # `typ`'s primitives env.
                #
                # If seen from an inherited primitive, make sure the returned
                # type corresponds to the derived type and not the base type by
                # using `real_type`.
                (_) => self.real_type(typ)
            )
        )

    |" Return the types of which this subprogram is a primitive of.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun primitive_subp_types(): Array[Entity[BaseTypeDecl]] =
        self.primitive_decl_spec().do(
            (spec) =>
            spec.candidate_primitive_subp_types().filter(
                (c) => not spec.as_primitive_subp_type(c).is_null
            )
        )

    |" Return the first type of which this subprogram is a primitive of.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun primitive_subp_first_type(): Entity[BaseTypeDecl] =
        self.primitive_decl_spec().do(
            (spec) =>
            spec.as_primitive_subp_type(
                spec.candidate_primitive_subp_first_type()
            )
        )

    |" If this subprogram is a primitive for a tagged type, then return this
    |" type.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun primitive_subp_tagged_type(): Entity[BaseTypeDecl] =
        self.primitive_decl_spec().do(
            (spec) =>
            spec.as_primitive_subp_type(
                spec.candidate_primitive_subp_tagged_type()
            )
        )

    |" Return whether this subprogram has a controlling result, i.e. that
    |" it is the primitive of a tagged type ``T`` and its return type is
    |" ``T`` as well.
    @with_dynvars(imprecise_fallback=false)
    fun has_controlling_result(): Bool = {
        val typ = self.candidate_primitive_subp_tagged_type();

        not typ.is_null and typ == self.return_type()
    }

    |" Returns whether the subprogram containing this spec is a subprogram
    |" callable via the dot notation.
    |"
    |" This property doesn't implement Ada standard but the GNAT experimental
    |" feature allowing dot-notation for untagged types.
    @memoized
    fun dottable_subp_of(): Entity[BaseTypeDecl] =
    # See also comments in BaseTypeDecl.dottable_subps
    {
        bind origin = node.origin_node();

        if self.nb_max_params() > 0
        then self.potential_dottable_type()?.specific_type()
        else null[Entity[BaseTypeDecl]]
    }

    |" Returns the return type of self, if applicable (e.g. if self is a
    |" subprogram). Else, returns null.
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun return_type(): Entity[BaseTypeDecl] =
        self.returns().do((rt) => self.real_designated_type(rt))

    fun xref_entry_point(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.returns().do((r) => r.sub_equation(), default_val=%true)

    |" Returns the array of parameters specification for this subprogram spec.
    @exported
    fun params(): Array[Entity[ParamSpec]] =
        raise[Array[Entity[ParamSpec]]] PropertyError(
            "Property BaseSubpSpec.params not implemented"
        )
}

|" Entry specification.
|"
|" This node does not have ARM existence, because in the RM subprogram
|" specifications don't encompass the ad-hoc specifications that happen in
|" entry declarations. Entry declarations are described in
|" :rmlink:`9.5.2`.
class EntrySpec: BaseSubpSpec {
    @parse_field
    entry_name: DefiningName
    @parse_field
    @nullable
    family_type: AdaNode
    @parse_field
    @nullable
    entry_params: Params

    fun name(): Entity[DefiningName] = self.entry_name

    fun params(): Array[Entity[ParamSpec]] =
        self.entry_params.do(
            (p) => p.params.map((p) => p),
            default_val=null[Array[Entity[ParamSpec]]]
        )

    fun returns(): Entity[TypeExpr] = null[Entity[TypeExpr]]

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.family_type.do((r) => r.sub_equation(), default_val=%true)
}

|" Synthetic node for the abstract subprogram spec of an enum literal.
|"
|" NOTE: This has no existence in the ARM. While enum literals are functions
|" semantically, they're not such syntactically.
@synthetic
class EnumSubpSpec: BaseSubpSpec {
    fun enum_decl(): Entity[EnumLiteralDecl] =
        node.parent.as[EnumLiteralDecl].as_entity

    fun name(): Entity[DefiningName] = self.enum_decl().enum_decl_name()

    fun returns(): Entity[TypeExpr] = self.enum_decl().synth_type_expr()

    fun params(): Array[Entity[ParamSpec]] = null[Array[Entity[ParamSpec]]]
}

|" Subprogram specification (:rmlink:`6.1`).
class SubpSpec: BaseSubpSpec {
    @parse_field
    subp_kind: SubpKind
    @parse_field
    @nullable
    subp_name: DefiningName
    @parse_field
    @nullable
    subp_params: Params
    @parse_field
    @nullable
    subp_returns: TypeExpr

    fun name(): Entity[DefiningName] = self.subp_name

    fun params(): Array[Entity[ParamSpec]] =
        self.subp_params?.params.map((p) => p)

    fun returns(): Entity[TypeExpr] = self.subp_returns
}

|" Synthetic subprogram specification for binary operators.
@synthetic
class SyntheticBinarySpec: BaseSubpSpec {
    subp_symbol: Symbol
    @parse_field
    left_param: SyntheticFormalParamDecl
    @parse_field
    right_param: SyntheticFormalParamDecl
    @parse_field
    @nullable
    return_type_expr: TypeExpr

    fun name(): Entity[DefiningName] =
        node.synthesize_defining_name(node.subp_symbol).as_entity

    fun returns(): Entity[TypeExpr] = self.return_type_expr

    fun corresponding_actual(): Entity[BaseFormalParamHolder] = self

    fun abstract_formal_params(): Array[Entity[BaseFormalParamDecl]] =
        [
            self.left_param.as[BaseFormalParamDecl],
            self.right_param.as[BaseFormalParamDecl]
        ]
}

|" Synthetic subprogram specification for unary operators.
@synthetic
class SyntheticUnarySpec: BaseSubpSpec {
    subp_symbol: Symbol
    @parse_field
    right_param: SyntheticFormalParamDecl
    @parse_field
    return_type_expr: SyntheticTypeExpr

    fun name(): Entity[DefiningName] =
        node.synthesize_defining_name(node.subp_symbol).as_entity

    fun returns(): Entity[TypeExpr] = self.return_type_expr

    fun corresponding_actual(): Entity[BaseFormalParamHolder] = self

    fun abstract_formal_params(): Array[Entity[BaseFormalParamDecl]] =
        [self.right_param.as[BaseFormalParamDecl]]
}

|" List of component declarations (:rmlink:`3.8`).
class ComponentList: BaseFormalParamHolder {
    @parse_field
    components: ASTList[AdaNode]
    @parse_field
    @nullable
    variant_part: VariantPart

    fun type_def(): Entity[TypeDef] = node.parent.parent.as[TypeDef].as_entity

    fun type_decl(): Entity[TypeDecl] = self.type_def().parent.as[TypeDecl]

    fun parent_component_list(): Entity[ComponentList] = {
        bind origin = node;

        self.type_def().as[DerivedTypeDef]?.base_type().record_def()?.comps()
    }

    @with_dynvars(env, origin=null[AdaNode])
    fun abstract_formal_params_for_assocs(
        assocs: Entity[AssocList],
        stop_recurse_at: Entity[BaseTypeDecl] = null[Entity[BaseTypeDecl]]
    ): Array[Entity[BaseFormalParamDecl]] = {
        val td = self.type_decl();
        val discriminants = td.discriminants_list(stop_recurse_at);
        # Get param matches for discriminants only
        val discriminants_matches =
            node.match_formals(
                discriminants,
                assocs,
                false,
                # All discriminants should be matched before calling
                # abstract_formal_params_impl below.
                match_others=true
            )
            .filter(
                (pm) =>
                not pm.formal.is_null
                and discriminants.contains(pm.formal.formal_decl())
            );

        # Get param matches for all aggregates' params. Here, we use and pass
        # down the discriminant matches, so that abstract_formal_params_impl is
        # able to calculate the list of components belonging to variant parts,
        # depending on the static value of discriminants.
        td.record_def().comps().abstract_formal_params_impl(
            discriminants=discriminants_matches,
            stop_recurse_at=stop_recurse_at,
            assocs=assocs
        )
    }

    |" Return all the components lists of this ComponentList, which includes
    |" the current and parent components, and all the components lists of the
    |" variant part, recursively, regardless of the discriminants values. This
    |" list is used for DeltaAggregate name resolution.
    fun abstract_formal_params_for_delta_assocs(

    ): Array[Entity[BaseFormalParamDecl]] = {
        val variant_part_components =
            self.variant_part?.variant.mapcat(
                (v) => v.components.abstract_formal_params_for_delta_assocs()
            );
        val self_components = self.components.keep[BaseFormalParamDecl];
        val parent_components =
            self.parent_component_list()
            ?.abstract_formal_params_for_delta_assocs();

        variant_part_components & self_components & parent_components
    }

    |" Implementation for abstract_formal_params. Warning: this property
    |" is for internal use.
    |"
    |" This property returns the formal parameter declarations of a given
    |" aggregate components list, regarding its ``discriminants`` values.
    |"
    |" * If ``include_discriminants`` is True, discriminants are also returned
    |"   by the property.
    |"
    |" * When ``recurse`` is set, parent's components are appended to the
    |"   result, recursively. In some cases, ``stop_recurse_at`` can be used
    |"   to stop the recursion. This is used for extended aggregates in order
    |"   to not consider the ancestor when looking for parents components. See
    |"   also ``BaseTypeDecl.all_discriminants``.
    |"
    |" * ``assoc`` is the AssocList of the aggregate that can be used to
    |"   get parents components regarding their discriminants values.
    fun abstract_formal_params_impl(
        discriminants: Array[ParamMatch],
        include_discriminants: Bool = true,
        recurse: Bool = true,
        stop_recurse_at: Entity[BaseTypeDecl] = null[Entity[BaseTypeDecl]],
        assocs: Entity[AssocList] = null[Entity[AssocList]]
    ): Array[Entity[BaseFormalParamDecl]] = {
        # Get self's components. We pass along discriminants, to get variant
        # part's components too.
        val self_comps =
            self
            .components
            .keep[BaseFormalParamDecl]
            & self.variant_part?.get_components(discriminants);
        # Append parent's components: the parent could have a variant part too,
        # which discriminants can be constrained by the subtype indication from
        # our DerivedTypeDef. The code below retrieves the relevant components
        # from the parent record taking that into account.
        val ret =
            if recurse
            then
                self.parent_component_list().do(
                    (pcl) =>
                    if pcl.type_decl().matching_type(stop_recurse_at)
                    then self_comps
                    else
                        pcl.abstract_formal_params_impl(
                            pcl.match_formals(
                                pcl.type_decl().discriminants_list(
                                    stop_recurse_at
                                ),
                                self.type_def()
                                .as[DerivedTypeDef]
                                .subtype_indication
                                .constraint
                                .as[CompositeConstraint]
                                .do(
                                    (cc) => cc.constraints,
                                    default_val=assocs
                                ),
                                # In case of extension aggregate, discriminants
                                # are not constrained by any subtype
                                # indication, then match the discriminants with
                                # the AssocList of the aggregate.
                                is_dottable_subp=false
                            ),
                            include_discriminants=false,
                            stop_recurse_at=stop_recurse_at
                        )
                        & self_comps,
                    default_val=self_comps
                )
            else self_comps;

        if include_discriminants
        then
            self.type_decl().do(
                (decl) => decl.discriminants_list(stop_recurse_at)
            )
            & ret
        else ret
    }

    fun abstract_formal_params(): Array[Entity[BaseFormalParamDecl]] =
        self.abstract_formal_params_impl(null[Array[ParamMatch]])

    |" Return all the possible shapes that this component list spans.
    fun shapes(): Array[Shape] = {
        val self_comps = self.components.keep[BaseFormalParamDecl];

        self.variant_part.do(
            (vpart) =>
            vpart.variant.mapcat(
                (v) =>
                v.components.shapes().map(
                    (s) =>
                    Shape(
                        components=self_comps & s.components,
                        discriminants_values=[
                            DiscriminantValues(
                                discriminant=vpart.discr_name,
                                values=v.choices
                            )
                        ]
                        & s.discriminants_values
                    )
                )
            ),
            default_val=[
                Shape(
                    components=self_comps,
                    discriminants_values=null[Array[DiscriminantValues]]
                )
            ]
        )
    }

    |" Return whether this component list declares at least one component
    |" which is limited. This also looks in all branches of a variant part.
    fun has_limited_component(): Bool = {
        bind origin = null[AdaNode];

        self.components.any(
            (c) => c.as[BaseFormalParamDecl]?.formal_type()?.is_limited_type()
        )
        or self.variant_part?.variant.any(
            (v) => v.components.has_limited_component()
        )
    }
}

|" Specification for discriminants in type declarations.
@abstract
class DiscriminantPart: BaseFormalParamHolder {
    fun abstract_formal_params(): Array[Entity[BaseFormalParamDecl]] =
        null[Array[Entity[BaseFormalParamDecl]]]
}

|" Known list of discriminants in type declarations (:rmlink:`3.7`).
class KnownDiscriminantPart: DiscriminantPart {
    @parse_field
    discr_specs: ASTList[DiscriminantSpec]

    fun abstract_formal_params(): Array[Entity[BaseFormalParamDecl]] =
        node.discr_specs.map((e) => e.as[BaseFormalParamDecl].as_entity)
}

|" Unknown list of discriminants in type declarations (:rmlink:`3.7`).
class UnknownDiscriminantPart: DiscriminantPart {
}

|" Formal parameters for the completion of an ``EntryDecl`` (either an
|" ``EntryBody`` or an ``AcceptStmt``).
class EntryCompletionFormalParams: BaseFormalParamHolder {
    @parse_field
    @nullable
    params: Params

    fun abstract_formal_params(): Array[Entity[BaseFormalParamDecl]] =
        self.params?.params.map((p) => p.as[BaseFormalParamDecl])
}

|" List of declaration for generic formals (:rmlink:`12.1`).
class GenericFormalPart: BaseFormalParamHolder {
    @parse_field
    decls: ASTList[AdaNode]

    fun abstract_formal_params(): Array[Entity[BaseFormalParamDecl]] =
        self
        .decls
        .keep[BaseFormalParamDecl]

    |" Returns the envs for all the use clauses declared in this generic
    |" formal part.
    fun use_clauses_envs(): LexicalEnv =
        self.decls.filtermap(
            (u) => u.as[UseClause].used_envs(),
            (u) => u is UseClause
        )
        .env_group()
}

|" Base class for record definitions (:rmlink:`3.8`).
@abstract
class BaseRecordDef: AdaNode {
    @parse_field
    components: ComponentList

    # TODO: If base subtype is from a formal type, then False
    fun comps(): Entity[ComponentList] = self.components
}

|" Record definition for ``null record``.
class NullRecordDef: BaseRecordDef {
}

|" Record definition that contains components (``record ... end record``).
class RecordDef: BaseRecordDef {
}

|" Association of one or several names to an expression.
@abstract
@with_abstract_list
class BasicAssoc: AdaNode {
    @abstract
    fun expr(): Entity[Expr]

    @abstract
    fun names(): Array[AdaNode]

    |" Return the list of parameters that this association refers to.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun get_params(): Array[Entity[DefiningName]] =
        self.parent.as![AssocList].zip_with_params().filtermap(
            (m) => m.param,
            (m) => m.actual == self.expr()
        )
}

|" Association (X => Y) used for aggregates associations (:rmlink:`4.3`).
class AggregateAssoc: BasicAssoc {
    @parse_field
    designators: AlternativesList
    @parse_field
    r_expr: Expr

    fun expr(): Entity[Expr] = self.r_expr

    fun names(): Array[AdaNode] = node.designators.map((d) => d)

    @with_dynvars(env, origin)
    fun xref_stop_resolution(): Bool = true

    fun base_aggregate(): Entity[BaseAggregate] =
        self.parent.parent.as![BaseAggregate]

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        val agg = self.base_aggregate();
        val mra = agg.multidim_root_aggregate();
        # If we're part of a multidim aggregate, then take the root aggregate's
        # type. Else, this is a regular aggregate. In this case grab the type
        # in type_val.
        val td =
            if not mra.is_null then mra.typ
            else self.base_aggregate().type_val().as[BaseTypeDecl];

        val atd = td?.array_def();

        if agg.in_aspect(s"Global") or agg.in_aspect(s"Refined_Global")
        then self.globals_assoc_equation()
        elif agg.in_aspect(s"Depends") or agg.in_aspect(s"Refined_Depends")
        then self.depends_assoc_equation()
        elif agg.in_aspect(s"Test_Case") then self.test_case_assoc_equation()
        elif agg.in_aspect(s"Refined_State")
        then (
            # Simply resolve all names present in the Refined_State aspect,
            # as they must all refer to existing declarations.
            self.exprs_assoc_equation()
        )
        # In the case of Contract_Cases aspect, only the top level
        # aggregate should be resolved by the special equation here. All
        # other agreggates included in the latter should use the regular
        # resolution path.

        elif agg.parent.as[AspectAssoc]?.id.name_is(s"Contract_Cases")
        then self.contract_cases_assoc_equation()
        elif agg.parent.as[AspectAssoc]?.id.name_is(s"Subprogram_Variant")
        then self.r_expr.spark_variant_equation(
            self.designators[0].as[BaseId]
        )
        elif agg is BracketAggregate and td?.has_aspect(s"Aggregate")
        then self.container_aggregate_equation(td)
        elif agg.parent is AspectClause | AspectAssoc | PragmaArgumentAssoc
        then %true
        elif agg is DeltaAggregate then self.delta_aggregate_assoc_equation()
        elif atd.is_null then self.record_assoc_equation()
        else self.array_assoc_equation(atd, mra)
    }

    |" Equation for the case where this is an aggregate assoc for a
    |" container type. This is an Ada 2022 feature (:rmlink:`4.3.5`).
    @with_dynvars(env, origin, entry_point)
    fun container_aggregate_equation(td: Entity[BaseTypeDecl]): Equation = {
        val aggregate_aspect = td.get_aspect(s"Aggregate").value.as[Aggregate];
        val entity_name = self.names()?[0].as[Name];
        val element_type = aggregate_aspect.element_type();
        val key_type = aggregate_aspect.key_type();

        self.expr().expected_type_var() <- element_type
        %and self.expr().sub_equation()
        %and self.expr().matches_expected_type()
        %and (
            if entity_name.is_null then %true
            else
                entity_name.expected_type_var() <- key_type
                %and entity_name.as_entity.sub_equation()
                %and entity_name.matches_expected_type()
        )
    }

    |" Equation for the case where this is an aggregate assoc for a delta
    |" aggregate. This is an Ada 2022 feature (:rmlink:`4.3.4`). This equation
    |" also supports the so called "deep" delta aggregates, a GNAT
    |" experimental feature.
    @with_dynvars(env, origin, entry_point)
    fun delta_aggregate_assoc_equation(): Equation = {
        val agg = self.base_aggregate();
        val agg_type = agg.type_val().as[BaseTypeDecl];

        # Determine whether this is a delta array aggregate rather than a deep
        # delta aggregate by checking whether any alternative designates a
        # position in an array.
        val positional_assoc =
            agg_type.is_array()
            and not self.names().any(
                # leftmost_name returns null if n starts with
                # ArraySubcomponentChoiceName (which denotes a deep aggregate).
                (n) => n.as[Name]?.leftmost_name().is_null
            );

        val agg_components =
            (not agg_type.is_array()).do(
                (_) => node.unpack_formals(agg.all_components())
            );

        # If this is a record delta aggregate, try to match the components
        # corresponding to these names in order to correctly set the
        # environments from which they should be resolved.
        val matches =
            self.names().map(
                (n) =>
                if n is Name
                then
                # Get the leftmost name to match a component with if any
                    n
                    .as[Name]
                    .leftmost_name()
                    .do((id) => agg_components.find((c) => c.name.matches(id)))
                # If not a Name, there can be no component match (can be a
                # BinOp denoting a range in an array for example).
                else null[Expr].as_entity
            );

        self.names().ilogic_all(
            (n, i) =>
            {
                # Resolve the name from the matched component if any
                bind env =
                    matches[i].do((l) => l.children_env, default_val=env);

                n.as[Expr].as_entity.sub_equation()
            }
            %and (
                # Check that all alternatives resolve to the same type
                if i > 0
                then {
                    bind error_location = node;
                    BaseTypeDecl.matching_type%(n.as[Expr].type_var(),
                    self.names()[0].as[Expr].type_var())
                }
                else %true
            )
            %and (
                # We cannot set the expected type of the alternative in case
                # the aggregate is a record aggregate or a deep one (both
                # record and array) because the expected type of the
                # alternative can be any one of the record components
                # (including those from parents).  Only simple array aggregate
                # associations's alternatives can have an expected type (i.e.,
                # the alternative designates a position or a range).
                if positional_assoc
                then
                    n.as[Expr].expected_type_var() <- agg_type.index_type(0)
                    %and n.as[Expr].matches_expected_type()
                else %true
            )
        )
        %and (
            # Set the expected type of the expression only once since all the
            # alternatives should have the same type.
            if positional_assoc
            then self.expr().expected_type_var() <- agg_type.comp_type()
            else
                self.expr().expected_type_var()
                <-> self.names()[0].as[Expr].type_var()
        )
        %and (
            # Build the equation for the expression
            self.expr().sub_equation() %and self.expr().matches_expected_type()
        )
    }


    |" Equation for the case where this is an aggregate assoc for a record
    |" type.
    @with_dynvars(env, origin, entry_point)
    fun record_assoc_equation(): Equation = {
        val agg = self.base_aggregate();
        # First, try to find all the discriminants matched by this assoc
        val discr_matches =
            agg.matched_discriminants().filter(
                (pm) => pm.actual.assoc == self
            );
        # If there are none, this assoc matches one or several components of
        # the record, so gather them.
        # WARNING: It is important to gather these components ONLY IF this
        # association is not for specifying a discriminant. Indeed,
        # discriminants can (and must) be resolved separately once the type of
        # the aggregate is known. Otherwise, name resolution will enter an
        # infinite loop when trying to match an available component for this
        # association, as it requires statically evaluating discriminants which
        # involves doing name resolution on them, thus introducing a cycle.
        val matches =
            if not discr_matches.is_null then discr_matches
            else
                agg.matched_components().filter(
                    (pm) => pm.actual.assoc == self
                );
        # Whether this is the `others => ...` association
        val is_others_assoc = self.names().any((n) => n is OthersDesignator);
        # Whether this is the `component_choice_list => <>` association (in
        # that case the component_choice_list's components can not be of the
        # same type).
        val is_box_expr = self.expr() is BoxExpr;

        if not is_others_assoc
        then
            matches.logic_all(
                (match_var) =>
                (
                    # If expr is a box expr do not resolve it since it doesn't
                    # have a name nor type.
                    if is_box_expr then %true
                    else
                        (
                            match_var.actual.assoc.expr().expected_type_var()
                            <- match_var.formal.formal_decl().type_expression()
                            .designated_type()
                            %and match_var.actual.assoc.expr().sub_equation()
                        )
                        %and match_var.actual.assoc.expr()
                        .matches_expected_assign_type()
                )
                %and match_var.actual.name.do(
                    (n) => n.ref_var() <- match_var.formal.formal_decl(),
                    default_val=%true
                )
            )
        else (
            # Since all the formals designated by "others" should have the same
            # type (iff expr is not a box expr), we look for the first formal
            # that was not yet matched and use its type as the type of the
            # expression associated to "others".
            if is_box_expr then %true
            else
                agg.first_unmatched_formal().do(
                    (unmatched_formal) =>
                    (
                        self.expr().expected_type_var()
                        <- unmatched_formal.formal_decl().type_expression()
                        .designated_type()
                        %and self.expr().sub_equation()
                    )
                    %and self.expr().matches_expected_type(),
                    default_val=%true
                )
        )
    }

    |" Equation for the case where this is an aggregate assoc for an array
    |" type.
    @with_dynvars(env, origin, entry_point)
    fun array_assoc_equation(
        atd: Entity[ArrayTypeDef],
        mra: MultidimAggregateInfo
    ): Equation =
        (
            # If the array is monodimensional, or we're on the last
            # dimension of a multidimensional array ..
            if mra.is_null or mra.rank == atd.array_ndims() - 1
            then (
                # .. Then we want to match the component type
                (
                    self.expr().expected_type_var() <- atd.comp_type()
                    %and self.expr().sub_equation()
                )
                %and self.expr().matches_expected_type()
            )
            else (
                # .. Else we're on an intermediate dimension of a
                # multidimensional array: do nothing.
                %true
            )
        )
        %and self.designators.logic_all(
            (n) =>
            n.sub_equation()
            %and (
                if n is Name and not n.as[Name].name_designated_type().is_null
                then n.as[Name].xref_type_equation()
                else
                    n.as[Expr].do(
                        (n) =>
                        n.expected_type_var() <- atd.index_type(mra.rank)
                        %and n.matches_expected_type(),
                        default_val=%true
                    )
            )
        )

    |" Equation for the case where this is an aggregate assoc for a Globals
    |" aspect.
    @with_dynvars(env, origin, entry_point)
    fun globals_assoc_equation(): Equation =
        # Assoc expr can either be a name or an aggregate. If a name, then
        # resolve. If an aggregate, resolution will be handled recursively
        # by solve.
        self.expr().sub_equation()

    |" Equation for the case where this is an aggregate assoc for a Depends
    |" aspect.
    @with_dynvars(env, origin, entry_point)
    fun depends_assoc_equation(): Equation =
        (
            # For both the name and the expr, same as in `globals_equation`, we
            # call sub_equation: If it's a name it will resolve the name. If
            # it's an aggregate it will return LogicTrue() and the content will
            # be resolved separately.
            # The ``null`` literal is a possible value for ```expr``. Do
            # not resolve it.
            if
                self.expr() is NullLiteral
                or self.expr().as[UnOp]?.expr.do((v1) => v1 is NullLiteral)
            then %true
            else self.expr().sub_equation()
        )
        %and # Here, we go fetch the first element of the list of names. Since
        # we parse this as an aggregate, the list is elements separated by
        # pipes (alternatives_list), which will ever only have one element
        # in this case. As above, we make sure to not resolve the ``null``
        # literal.
        {
            val n = self.names()?[0];

            if n.is_null or n is NullLiteral then %true
            else n.as_entity.sub_equation()
        }

    |" Equation for the case where this is an aggregate assoc for a Test_Case
    |" aspect.
    @with_dynvars(env, origin, entry_point)
    fun test_case_assoc_equation(): Equation =
        # Only resolve the right-hand side of `Requires` and `Ensures`,
        # the other associations (Name and Mode) need not be resolved.
        if
            self.names()?[0].as[BaseId].do(
                (name) => name.name_symbol() in s"Requires" | s"Ensures"
            )
        then self.expr().sub_equation()
        else %true

    |" Equation for the case where this is an aggregate assoc for a
    |" Contract_Cases aspect. Both the ``guard`` and the ``consequence`` must
    |" be of type Boolean.
    @with_dynvars(env, origin, entry_point)
    fun contract_cases_assoc_equation(): Equation =
        self.designators.logic_all(
            (d) =>
            d.as[Expr].do(
                (e) =>
                (
                    e.expected_type_var() <- node.bool_type()
                    %and e.sub_equation()
                )
                %and e.matches_expected_formal_type(),
                default_val=%true
            )
        )
        %and (
            # Nothing to do for `others =>`
            self.expr().expected_type_var() <- node.bool_type()
        )
        %and self.expr().sub_equation()
        %and self.expr().matches_expected_formal_type()

    |" Return the xref equation for the case where this is an aggregate assoc
    |" in which all the designator as well as the RHS are usual expressions
    |" which can be recursively resolved.
    @with_dynvars(env, origin, entry_point)
    fun exprs_assoc_equation(): Equation =
        self.designators.logic_all((d) => d.sub_equation())
        %and self.expr().as[Name].do(
            (n) => n.sub_equation(),
            default_val=%true
        )
}

|" Association used for multi-dimension array aggregates.
class MultiDimArrayAssoc: AggregateAssoc {
}

|" Association of discriminant names to an expression (:rmlink:`3.7.1`).
class CompositeConstraintAssoc: BasicAssoc {
    @parse_field
    ids: DiscriminantChoiceList
    @parse_field
    constraint_expr: AdaNode

    fun expr(): Entity[Expr] = self.constraint_expr.as![Expr]

    fun names(): Array[AdaNode] = node.ids.map((i) => i.as[AdaNode])
}

|" Iterated association (Ada 2020, :rmlink:`4.3.3`).
class IteratedAssoc: BasicAssoc {
    @parse_field
    spec: ForLoopSpec
    @parse_field
    @nullable
    key_expr: Expr
    @parse_field
    r_expr: Expr

    fun expr(): Entity[Expr] = self.r_expr

    fun names(): Array[AdaNode] = null[Array[AdaNode]]

    fun base_aggregate(): Entity[BaseAggregate] =
        self.parent.parent.as![BaseAggregate]

    @with_dynvars(env, origin)
    fun xref_stop_resolution(): Bool = self.parent.parent is BaseAggregate

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        val aggregate = self.base_aggregate();
        val root_agg = aggregate.multidim_root_aggregate();
        # If we're part of a multidim aggregate, then take the root aggregate's
        # type. Else, this is a regular aggregate. In this case grab the type
        # in type_val.
        val type_decl =
            if not root_agg.is_null then root_agg.typ
            else aggregate.type_val().as[BaseTypeDecl];
        val array_type_def = type_decl?.array_def();
        # The iterated assoc can also be in a container aggregate
        val container_aggregate =
            type_decl.get_aspect(s"Aggregate").value.as[Aggregate];
        # Get the "component" type of the array or container
        val comp_type =
            array_type_def.do(
                (atd) => atd.comp_type(),
                default_val=container_aggregate.element_type()
            );
        # Get the index type of the array or container
        val index_type =
            array_type_def.do(
                (atd) => atd.index_type(root_agg.rank),
                default_val=container_aggregate.key_type()
            );
        # NOTE: we need to resolve the spec first so that the indexing variable
        # has a type when resolving `r_expr`.
        # NOTE: if the form of the iterated_component_association is
        # `for I in ..`, Ada requires the type of I to be the index type of the
        # array (taking dimension into account) which we are building an
        # aggregate for.
        val spec_success =
            self.spec.resolve_names_internal_with_eq(
                if node.spec.loop_type is IterType.In
                then
                    self.spec.iter_expr.as[Expr].expected_type_var()
                    <- index_type
                    %and self.spec.iter_expr.as[Expr].matches_expected_type()
                else %true
            );

        if spec_success
        then # If the array is monodimensional, or we're on the last
        # dimension of a multidimensional array ..
            if
                root_agg.is_null
                or root_agg.rank == array_type_def.array_ndims() - 1
            then (
                # .. Then we want to match the component type
                (
                    (
                        self.expr().sub_equation()
                        %and self.expr().expected_type_var() <- comp_type
                    )
                    %and self.expr().matches_expected_type()
                )
                %and (
                    # .. As well as the key expression if it exists
                    self.key_expr.do(
                        (ke) =>
                        (
                            ke.sub_equation()
                            %and ke.expected_type_var() <- index_type
                        )
                        %and ke.matches_expected_type(),
                        default_val=%true
                    )
                )
            )
            else (
                # .. Else we're on an intermediate dimension of a
                # multidimensional array: do nothing.
                %true
            )
        else %false
    }

    |" Equation specialization for ``ValueSequence`` name resolution (part of
    |" ``ReduceAttributeRef``).
    @with_dynvars(env, origin, entry_point)
    fun xref_equation_for_reduce(): Equation = {
        # The expected type is the expected type of the ReduceAttributeRef
        # holding this iterated assoc.
        val expected_typ =
            self.parent.as[ValueSequence].iter_assoc.expr()
            .expected_type_var();
        # See self.xref_equation for more details
        val spec_success =
            self.spec.resolve_names_internal_with_eq(
                if node.spec.loop_type is IterType.In
                then
                    self.spec.iter_expr.as[Expr].expected_type_var()
                    <-> expected_typ
                    %and self.spec.iter_expr.as[Expr].matches_expected_type()
                else %true
            );

        if spec_success
        then
            (
                self.expr().sub_equation()
                %and self.expr().expected_type_var() <-> expected_typ
            )
            %and self.expr().matches_expected_type()
        else %false
    }
}

|" Association (X => Y) used for parameter associations (:rmlink:`6.4`).
class ParamAssoc: BasicAssoc {
    @parse_field
    @nullable
    designator: AdaNode
    @parse_field
    r_expr: Expr

    fun expr(): Entity[Expr] = self.r_expr

    fun names(): Array[AdaNode] =
        if node.designator.is_null then null[Array[AdaNode]]
        else [node.designator]

    fun xref_entry_point(): Bool = node.is_static_attribute_assoc()

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        if node.xref_entry_point() then self.expr().sub_equation() else %false

    fun is_static_attribute_assoc(): Bool =
        node.parent.parent.as[AttributeRef].do(
            (ar) =>
            ar.attribute.name_symbol() in s"First"
                | s"Last"
                | s"Range"
                | s"Length"
                | s"Has_Same_Storage"
                | s"Overlaps_Storage"
        )
}

|" Root class for an Ada declaration (:rmlink:`3.1`). A declaration
|" associates a name with a language entity, for example a type or a variable.
@abstract
@custom_short_image
class BasicDecl: AdaNode {
    @abstract
    @parse_field
    @nullable
    aspects: AspectSpec

    |"
    @memoized
    fun spark_mode_aspect(

    ): Aspect = # Check for direct `SPARK_Mode` aspect definition
        if self.has_aspect(s"SPARK_Mode")
        then self.get_aspect(s"SPARK_Mode")
        # If there is no aspect on this subprogram, it's `On` if the
        # enclosing subprogram or declarative region is `On`.
        else
            (
                if self.previous_part_for_decl().do((v1) => v1 is BodyStub)
                then self.previous_part_for_decl()
                else self
            )
            .declarative_scope()
            .as_entity
            ?.spark_mode_aspect()
            .do(
                (asp) => asp,
                # Finally, check for configuration pragmas
                default_val=self.enclosing_compilation_unit()
                .spark_config_pragma()
                .do(
                    (p) => p.as_aspect(),
                    # No configuration pragma were found
                    default_val=null[Aspect]
                )
            )

    |" Implementation for ``BasicDecl.constrain_prefix`` but for subprograms.
    |"
    |" Since subprograms can't have a base class, this is shared here.
    @with_dynvars(origin)
    fun subp_constrain_prefix(prefix: Expr): Equation =
        # If self is a dottable subprogram, then we want to constrain the
        # prefix so that it's type is the type of the first parameter of
        # self.
        if self.info.md.dottable_subp
        then
            prefix.expected_type_var()
            <- self.subp_spec_or_null().unpacked_formal_params()?[0]
            ?.formal_decl()
            .formal_type()
            %and prefix.matches_expected_prefix_type()
        else %true

    |" Helper for AdaNode.env_hook. Handle library-level unit decl nodes.
    fun env_hook_basic_decl(): Bool =
        # For library-level subprogram/package declarations, process the
        # parent spec.
        if
            node is PackageDecl
            | BasicSubpDecl
            | PackageRenamingDecl
            | GenericPackageDecl
            | GenericPackageInstantiation
            | GenericSubpInstantiation
            | GenericSubpDecl
            | SubpBody
        then
            node.as_bare_entity.defining_name().name.as[DottedName].do(
                (dn) =>
                node.get_unit(
                    dn.prefix.as_symbol_array(),
                    AnalysisUnitKind.unit_specification,
                    load_if_needed=true,
                    not_found_is_error=not node is SubpBody
                )
                .do((_) => false)
            )
        else false

    |" For library-level subprogram declarations, we always want to populate
    |" the unit containing the body, so that the lexical envs always contain
    |" the spec and the body, no matter which was initially requested.
    fun populate_body_unit(): Bool =
        if node.is_library_item()
        then
            node.get_unit(
                node.as_bare_entity.defining_name().name.as_symbol_array(),
                AnalysisUnitKind.unit_body,
                load_if_needed=true,
                not_found_is_error=false
            )
            .do((_) => false)
        else false

    |" Helper for ``has_top_level_env_name``. See its docstring for more
    |" information.
    fun has_top_level_env_name_impl(allow_bodies: Bool): Bool = {
        val is_decl =
            node is BasePackageDecl
            | BasicSubpDecl
            | GenericDecl
            | TaskTypeDecl
            | ProtectedTypeDecl
            | SingleTaskDecl
            | SingleProtectedDecl;
        val is_body = node is Body;

        node.is_compilation_unit_root()
        or (
            (is_decl or (allow_bodies and is_body))
            and node.node_env.env_node.do(
                (env_node) =>
                env_node.as[BasicDecl].do(
                    (p) =>
                    if node == p then true
                    else
                        p.has_top_level_env_name_impl(
                            allow_bodies=allow_bodies
                            and not node is BaseSubpBody
                            and not p is BaseSubpBody
                        ),
                    default_val=env_node is PrivatePart
                    and env_node.parent.as[BasicDecl].do(
                        (bd) => bd.has_top_level_env_name_impl(allow_bodies)
                    )
                ),
                default_val=true
            )
        )
    }

    |" Return True if this declaration is exposed to other compilation units.
    |" This is equivalent to asking if this declaration's env should be named.
    |"
    |" Find a few examples below.
    |"
    |" .. code::
    |"
    |"     package A is                     -- True
    |"         package B is                 -- True
    |"             procedure Foo;           -- True
    |"         end B;
    |"     end A;
    |"
    |"     package body A is                -- True
    |"         package B is                 -- True
    |"             procedure Foo;           -- True
    |"         end B;
    |"     end A;
    |"
    |"     package body A is                -- True
    |"         package body B is            -- True
    |"             procedure Foo;           -- False
    |"         end B;
    |"     end A;
    |"
    |"     package body A is                -- True
    |"         package body B is            -- True
    |"             procedure Foo is null;   -- True
    |"         end B;
    |"     end A;
    |"
    |"     package body A is                -- True
    |"         procedure B is               -- True
    |"             procedure Foo is null;   -- False
    |"         begin
    |"             ...
    |"         end B;
    |"     end A;
    |"
    |"     procedure A is                   -- True
    |"         procedure Foo;               -- True
    |"     begin
    |"         ...
    |"     end A;
    |"
    |"     procedure A is                   -- True
    |"         package body B is            -- False
    |"             procedure Foo is null;   -- False
    |"         end B;
    |"     begin
    |"         ...
    |"     end A;
    |"
    |"     procedure A is                   -- True
    |"         package B is                 -- True
    |"         end B;
    |"
    |"         package body B is            -- True
    |"         end B;
    |"     begin
    |"     end A;
    fun has_top_level_env_name(): Bool =
        # Gotcha: at this point, self.children_env actual refers to its parent
        # env. That's because self does not have yet have a children env (this
        # property is typically called in env specs before add_env() in order
        # to understand where we should create this children_env).
        node.children_env.env_node.do(
            (env_node) =>
            env_node.as[BasicDecl].do(
                (bd) => bd.has_top_level_env_name_impl(allow_bodies=true),
                default_val=env_node is PrivatePart
                and env_node.parent.as[BasicDecl].do(
                    (bd) => bd.has_top_level_env_name_impl(allow_bodies=true)
                )
            ),
            default_val=true
        )

    |" Helper to implement ``env_spec_fully_qualified_name``.
    fun env_spec_fully_qualified_name_impl(self_env: LexicalEnv): String =
        # For a compilation unit root, simply use the existing syntactic
        # fully qualified name property, which does not rely on envs.
        if node.is_compilation_unit_root()
        then
            node.sym_join(
                node.enclosing_compilation_unit()
                .syntactic_fully_qualified_name(),
                "."
            )
        # For internal nodes, ignore them and recurse on their parent,
        # which are the real declarations.

        elif node is GenericPackageInternal | GenericSubpInternal
        then
            node.parent.as[BasicDecl].env_spec_fully_qualified_name_impl(
                self_env=node.parent.node_env
            )
        # Find the enclosing BasicDecl
        else
            (
                self_env.env_node.as[BasicDecl]
                or? self_env.env_node.as[PrivatePart]?.parent.as[BasicDecl]
            )
            .do(
                # Recurse and append the basic decl's name
                (bd) =>
                bd.env_spec_fully_qualified_name_impl(self_env=bd.node_env)
                & "."
                & node.name_symbol().image()
            )

    |" Return a the fully qualified name of this declaration to be used by
    |" env specs. This should not be used elsewhere, as it does some
    |" assumption about envs that are not True anymore after envs are
    |" populated.
    fun env_spec_fully_qualified_name(): String =
        # Gotcha: at this point, self.children_env actual refers to its parent
        # env. See similar notice in BasicDecl.has_top_level_env_name.
        node.env_spec_fully_qualified_name_impl(node.children_env)

    |" Return the name that this BasicDecl should use to create its lexical
    |" environment. An empty name is returned if it shouldn't use a named
    |" env.
    fun top_level_env_name(): String =
        if node.has_top_level_env_name()
        then node.env_spec_fully_qualified_name()
        else null[String]

    |" Return the initial env for this basic declaration. This is used
    |" to set the parent environment of a child declaration to its actual
    |" parent in terms of Ada semantics.
    |"
    |" If ``private_part`` is True, return the env of the private part of its
    |" parent.
    fun child_decl_initial_env(private_part: Bool = false): DesignatedEnv =
        node.child_decl_initial_env_name(private_part).do(
            (name) =>
            DesignatedEnv(
                kind=DesignatedEnvKind.named_env,
                env_name=name,
                direct_env=null[LexicalEnv]
            ),
            default_val=DesignatedEnv(
                kind=DesignatedEnvKind.direct_env,
                env_name=null[Symbol],
                direct_env=node.default_initial_env()
            )
        )

    |" Return an array of env assocs that should be added in the environment
    |" designated by ``dest_env``. In the general case, it simply adds an
    |" entry for self using this declaration's name as key. However, if self
    |" corresponds to the declaration of a ``"="`` operator, we also generate
    |" an order to add an entry for the ``"/="`` operator, as described in
    |" :rmlink:`4.5.2` 25.a.
    fun basic_decl_env_assocs(dest_env: DesignatedEnv): Array[EnvAssoc] = {
        val name = self.name_symbol();
        val base_assoc =
            [
                EnvAssoc(
                    key=self.name_symbol(),
                    value=node,
                    dest_env=dest_env,
                    metadata=null[Metadata]
                )
            ];
        val implicit_neq_assoc =
            if name == s"\"=\""
            then [EnvAssoc(
                key=s"\"/=\"",
                value=node,
                dest_env=dest_env,
                metadata=null[Metadata]
            )]
            else null[Array[EnvAssoc]];

        base_assoc & implicit_neq_assoc
    }

    |" Return the env association that describes where to register this
    |" basic declaration. For a child declaration in particular, this orders
    |" adding itself inside its parent declaration's environment.
    |"
    |" .. note::
    |"     This intercepts user-defined "=" operators so as to introduce an
    |"     implicit "/=" operator, as per :rmlink:`4.5.2` 25.a.
    fun child_decl_env_assocs(): Array[EnvAssoc] = {
        val dest_env =
            node.child_decl_initial_env_name(false).do(
                (non_null_name) =>
                DesignatedEnv(
                    kind=DesignatedEnvKind.named_env,
                    env_name=non_null_name,
                    direct_env=null[LexicalEnv]
                ),
                default_val=DesignatedEnv(
                    kind=DesignatedEnvKind.current_env,
                    env_name=null[Symbol],
                    direct_env=null[LexicalEnv]
                )
            );

        self.basic_decl_env_assocs(dest_env)
    }

    |" Whether this decl is the nested decl of a generic formal declaration.
    @exported
    fun is_formal(): Bool = node.parent is GenericFormal

    |" Return the documentation annotations associated with this decl.
    |" Annotations are any comment line of the form::
    |"
    |"     --% [annotation_name]: [annotation]
    |"
    |" Raises a property error if the doc is incorrectly formatted.
    |"
    |" .. ATTENTION:: This is an experimental feature, so even if it is
    |"    exposed to allow experiments, it is totally unsupported and the API
    |"    and behavior are very likely to change in the future.
    @exported
    @external()
    fun doc_annotations(): Array[DocAnnotation]

    |" Return the documentation associated with this decl. Raises a property
    |" error if the doc is incorrectly formatted.
    |"
    |" .. ATTENTION:: This is an experimental feature, so even if it is
    |"    exposed to allow experiments, it is totally unsupported and the API
    |"    and behavior are very likely to change in the future.
    @exported
    @external()
    fun doc(): String

    |" Return the canonical part for this decl. In the case of decls composed
    |" of several parts, the canonical part will be the first part.
    @exported
    @memoized
    @with_dynvars(imprecise_fallback=false)
    fun canonical_part(): Entity[BasicDecl] =
        self.previous_part_for_decl().do(
            (pp) => pp.canonical_part(),
            default_val=self
        )

    |" Return all previous parts of this entity, where the first part
    |" is at the beginning of the array.
    @with_dynvars(imprecise_fallback=false)
    fun all_previous_parts(): Array[Entity[BasicDecl]] =
        self.previous_part_for_decl().do(
            (pp) =>
            if self == pp then null[Array[Entity[BasicDecl]]]
            else pp.all_previous_parts() & [pp]
        )

    |" Return all next parts of this entity, where the last part is at the
    |" end of the array.
    @with_dynvars(imprecise_fallback=false)
    fun all_next_parts(): Array[Entity[BasicDecl]] =
        self.next_part_for_decl().do(
            (np) =>
            if self == np then null[Array[Entity[BasicDecl]]]
            else [np] & np.all_next_parts()
        )

    |" Return all parts that define this entity, sorted from first part to
    |" last part.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun all_parts(): Array[Entity[BasicDecl]] = {
        val prevs = self.all_previous_parts();
        val nexts = self.all_next_parts();

        prevs & [self] & nexts
    }

    |" Put ``rebindings`` back on ``self`` if ``self`` is rebound
    |" somewhere in the chain of rebindings. Ensure coherency, e.g. that if
    |" self already has some rebindings, the one that we add are a superset
    |" of the one it already has.
    fun unshed_rebindings(rebindings: EnvRebindings): Entity[BasicDecl] =
        if rebindings == null[EnvRebindings] then self
        elif rebindings.old_env.env_node == node
        then self.unshed_rebindings_helper(rebindings)
        else self.unshed_rebindings(rebindings.get_parent)

    |" Put ``rebindings`` on ``self`` if needed. Ensure coherency, e.g. that
    |" if self already has some rebindings, the one that we add are a
    |" superset of the one it already has.
    fun unshed_rebindings_helper(
        rebindings: EnvRebindings
    ): Entity[BasicDecl] =
        # If the rebindings are already the same, just return the entity as
        # is.
        if self.info.rebindings == rebindings then self
        elif node.has_parent_rebindings(rebindings, self.info.rebindings)
        then
            Entity[BasicDecl](
                node=node,
                info=EntityInfo(
                    md=self.info.md,
                    rebindings=rebindings,
                    from_rebound=self.info.from_rebound
                )
            )
        else raise[Entity[BasicDecl]] PropertyError("Incorrect rebindings")

    fun decl_private_part(): Entity[PrivatePart] = match self {
        case bpd: BasePackageDecl => bpd.private_part
        case ttd: TaskTypeDecl => ttd.definition.private_part
        case td: SingleTaskDecl => td.task_type.definition.private_part
        case ptd: ProtectedTypeDecl => ptd.definition.private_part
        case spd: SingleProtectedDecl => spd.definition.private_part
        case _ => null[Entity[PrivatePart]]
    }

    @memoized
    fun immediate_declarative_region(): LexicalEnv =
        (self.all_previous_parts() & [self]).mapcat(
            (part) => part.declarative_parts().map((p) => p.children_env)
        )
        .env_group()

    |" Return an array of AdaNode list corresponding to declarative parts in
    |" which to look for pragmas associated to this entity.
    fun pragma_regions(): Array[Entity[ASTList[AdaNode]]] = {
        # First look in the scope where self is declared. We don't use
        # ``declarative_scope`` here, as this BasicDecl may not necessarily
        # be in a DeclarativePart, as is the case for ComponentDecls.
        # Instead, we simply look among this node's siblings.
        val enclosing_scope =
            self.parent.as[ASTList[AdaNode]].do((v1) => [v1]);
        # Then, if entity is declared in the public part of a package or
        # protected def, corresponding pragma might be in the private part.
        val private_scope =
            self.declarative_scope().as[PublicPart].do(
                (pp) =>
                match pp.parent {
                    case pkg: BasePackageDecl => pkg.private_part
                    case ptd: ProtectedDef => ptd.private_part
                    case _ => null[PrivatePart]
                }
                .do((v2) => [v2.decls.as_entity])
            );
        # Finally, look inside decl, in the first declarative region of decl
        val inner_scope = self.declarative_parts()?[0].do((v3) => [v3.decls]);

        enclosing_scope & private_scope & inner_scope
    }

    |" Return the aspect with name ``name`` for this entity.
    @exported
    fun get_aspect_assoc(name: Symbol): Entity[AspectAssoc] =
        self.get_aspect_spec()?.aspect_assocs.find(
            (asp) => asp.aspect_name(asp.id) == name.image()
        )

    |" Return the expression associated to the aspect with name ``name`` for
    |" this entity.
    @exported
    fun get_aspect_spec_expr(name: Symbol): Entity[Expr] =
        self.get_aspect_assoc(name)?.expr

    |" If this entity is a library item, return the compilation unit pragmas.
    fun library_item_pragmas(): Entity[ASTList[Pragma]] =
        if self.parent is LibraryItem
        then self.parent.parent.as[CompilationUnit].pragmas
        elif self.parent.parent is LibraryItem
        then self.parent.parent.parent.as[CompilationUnit].pragmas
        else null[Entity[ASTList[Pragma]]]

    |" Return the aspect with name ``name`` associated to this entity.
    |"
    |" Aspects are properties of entities that can be specified by the Ada
    |" program, either via aspect specifications, pragmas, or attributes.
    |"
    |" See ``DefiningName.P_Get_Aspect`` for more details.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun get_aspect(name: Symbol, previous_parts_only: Bool = false): Aspect =
        self.defining_name_or_raise()?.get_aspect(name, previous_parts_only)

    |" Returns whether the boolean aspect named ``name`` is set on the entity
    |" represented by this node.
    |"
    |" Aspects are properties of entities that can be specified by the Ada
    |" program, either via aspect specifications, pragmas, or attributes.
    |"
    |" "Aspect" is used as in RM terminology (see :rmlink:`13`).
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun has_aspect(name: Symbol, previous_parts_only: Bool = false): Bool =
        self.defining_name_or_raise()?.has_aspect(name, previous_parts_only)

    |" Return the pragma with name ``name`` associated to this entity.
    |"
    |" Please use the ``p_get_aspect`` property instead if you are interested
    |" in aspects, i.e. information that can be represented by either aspect
    |" specification nodes, pragma nodes or attribute definition nodes.
    @exported
    fun get_pragma(name: Symbol): Entity[Pragma] =
        self.defining_name_or_raise()?.get_pragma(name)

    |" Return the representation clause associated to this type decl that
    |" defines the given attribute name.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun get_representation_clause(name: Symbol): Entity[AttributeDefClause] =
        self.defining_name_or_raise()?.get_representation_clause(name)

    |" Return the at clause associated to this declaration.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun get_at_clause(): Entity[AtClause] =
        self.defining_name_or_raise()?.get_at_clause()

    |" Return all the ``Annotate`` aspects defined on this entity, both
    |" through pragmas and aspect specifications. For a type declaration,
    |" this also includes all annotations defined on its from a base type,
    |" when relevant (the field ``inherited`` will be set for those).
    |" See ``DefiningName.P_Get_Annotations`` for more details.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun get_annotations(): Array[Aspect] =
        self.defining_name_or_raise()?.get_annotations()

    |" Return whether this declaration is ghost code or not. See SPARK RM 6.9.
    @exported
    fun is_ghost_code(): Bool = self.defining_name_or_raise()?.is_ghost_code()

    |" Assuming self is a Generic*Internal node (BasicDecl is their greatest
    |" common parent), return the GenericInstantiation node from which this
    |" Generic*Internal node is derived.
    |"
    |" .. ATTENTION:: If this Generic*Internal is not part of an
    |"     instantiation, but has been fetched through the formal generic
    |"     subprogram, this will return None. None is also returned if the
    |"     rebindings do not correspond to the instantiation of this generic
    |"     declaration.
    fun get_instantiation(): Entity[GenericInstantiation] = {
        val inst_node =
            self.info.rebindings.do(
                (r) => r.new_env.env_node.as![GenericInstantiation]
            );
        val designated_decl =
            inst_node.as_bare_entity?.designated_generic_decl();

        if designated_decl.node == node.parent
        then
            Entity[GenericInstantiation](
                node=inst_node,
                info=EntityInfo(
                    md=Metadata(),
                    # Since we return the instantiation itself, remove
                    # it from its rebindings.
                    rebindings=node.remove_rebindings(
                        self.info.rebindings,
                        designated_decl.info.rebindings
                    ),
                    from_rebound=self.info.from_rebound
                )
            )
        else null[Entity[GenericInstantiation]]
    }

    |" Whether a BasicDecl is the root decl for its unit.
    @exported
    fun is_compilation_unit_root(): Bool =
        node.parent.do(
            (p) =>
            match p {
                case _: LibraryItem => true
                case gen_pkg_decl: GenericPackageDecl =>
                    gen_pkg_decl.parent.do((p) => p is LibraryItem)
                case _: Subunit => true
                case _ => false
            }
        )

    fun populate_dependent_units(): Array[CompilationUnit] =
        if node.is_compilation_unit_root()
        then
            node.top_level_with_package_clauses().map(
                (package_name) => node.withed_unit_helper(package_name)
            )
        else null[Array[CompilationUnit]]

    |" Helper property used to determine whether we should add a
    |" referenced_env to the generic formal part of a given entity.
    fun should_ref_generic_formals(

    ): Bool =
        # We want to reference the generic formal env if:
        #
        # 1. This potential generic body is not a compilation unit root. In
        # that case, the parent is the lexical parent of the body (eg the
        # containing entity), and we need to reference the formals.
        not node.is_compilation_unit_root()

        # 2. This potential generic body is a subunit. In that case, similarly,
        # the parent is the lexical parent of the stub part, and we need to
        # reference the generic formals.
        or node.parent is Subunit

        # 3. This is the declaration of a subprogram body. In that case, we
        # should add a reference to the generic formals even for library-level
        # subprograms, because their parent is not their declaration.
        or node is BaseSubpBody

    |" Return whether self can be found in a single env query from the given
    |" ``origin`` node.
    fun is_directly_reachable(origin: Entity[AdaNode]): Bool =
        origin.node.node_env.get(
            node.name_symbol(),
            categories=RefCategories(inherited_primitives=false, _=true)
        )
        .contains(node.as_bare_entity)

    |" Return whether this declaration is visible from the point of view of
    |" the given ``origin`` node.
    |"
    |" .. ATTENTION::
    |"
    |"     Only package-level (public or private) declarations are supported
    |"     for now.
    @exported
    fun is_visible(from_node: Entity[AdaNode]): Bool =
        # If entity comes from resolving an actual of the current generic
        # context, we necessarily have visibility on it.
        if self.info.from_rebound then true
        # For synthetic type decls, forward the computation on their
        # specific type.

        elif self is ClasswideTypeDecl | DiscreteBaseSubtypeDecl
        then self.parent.as[BaseTypeDecl].is_visible(from_node)
        # If self is declared in a private part, check that we can find it
        # from origin's env.

        elif self.is_in_private_part()
        then
            node.is_directly_reachable(from_node)
            and (
                # Even if the above expression is True, we may not have
                # visibility according to Ada rules: in LAL, library-level
                # child packages' parent environments are defined to be their
                # parent packages' private part. The expression below filters
                # out cases where self is declared in the private part of a
                # library-level package and from_node lies in the public part
                # of a child package.
                from_node.enclosing_compilation_unit().has_private_view(
                    from_node.node
                )
            )
        # If self is declared in a public part, origin has visibility on it
        # iff it has visibility on the parent of self: do a recursive call
        # on the parent scope.

        elif self.is_in_public_part() or self.parent is GenericFormalPackage
        then
            node.is_directly_reachable(from_node)
            or self.parent_basic_decl().is_visible(from_node)
        # If self is declared at the top-level (but is not a subunit), we
        # necessarily have visibility on it.

        elif
            self.is_compilation_unit_root() and not self.as[Body]?.is_subunit()
        then true
        # If self is in any other kind of declarative part, we can perform
        # an env query to figure out if we can reach it.

        elif self.parent.do((v1) => v1.parent is DeclarativePart)
        then node.is_directly_reachable(from_node)
        # Unhandled case: raise PropertyError
        else
            raise[Bool] PropertyError(
                |" Only package-level declaration support visibility checks for
                |" now."
            )

    @with_dynvars(origin)
    fun subp_decl_match_signature(other: Entity[BasicDecl]): Bool =
        self.subp_spec_or_null().do(
            (spec) =>
            spec.match_signature(
                other.subp_spec_or_null().as![SubpSpec],
                false
            ),
            default_val=false
        )

    |" Predicate to check whether ``other``, is a valid renaming of ``self``,
    |" an explicit dereference of an access to a subprogram object.
    @with_dynvars(origin)
    fun access_to_subp_decl_match_signature(other: Entity[BasicDecl]): Bool =
        self.expr_type().access_def().as[AccessToSubpDef].subp_spec.do(
            (spec) =>
            spec.match_signature(
                other.subp_spec_or_null().as![SubpSpec],
                false
            ),
            default_val=false
        )

    |" Predicate to check whether ``other`` is a valid subprogram renaming
    |" of ``self``.
    |"
    |" In case ``other`` is a subprogram renaming of a prefixed view call of
    |" ``self``, subprograms profiles are not fully conformant. The first
    |" parameter of ``self`` has to be ignored when comparing it to
    |" ``other``, and the object designated by ``prefix`` shall be of the type
    |" of the first parameter of ``self``.
    |"
    |" If ``prefix`` doesn't designate an object (but a package for example),
    |" the ``subp_decl_match_signature`` predicate will match.
    |"
    |"   .. code::
    |"
    |"     procedure Entity (X, Y : T);
    |"
    |"     procedure Other (A, B : T) renames Entity; -- Regular subp renaming
    |"
    |"     procedure Other (B : T) renames A.Entity; -- Prefixed view renaming
    @with_dynvars(origin)
    fun subp_renaming_decl_match_signature(
        prefix: Entity[BasicDecl],
        other: Entity[BasicDecl]
    ): Bool =
        # Check first for a regular subprogram renaming
        self.subp_decl_match_signature(other)

        # Then, check for a renaming of a prefixed view call
        or self.subp_spec_or_null().do(
            (spec) =>
            not prefix
            .is_null
            # ``self`` shall be a dottable subprogram for the
            # object's type designated by ``prefix``.
            and (
                prefix.expr_type().do((typ) => typ.accessed_type())
                or? prefix.expr_type()
            )
            == spec.dottable_subp_of()
            # Then signature profiles shall match by ignoring the first
            # parameter of ``self``.
            and spec.match_signature(
                other.subp_spec_or_null().as![SubpSpec],
                false,
                ignore_first_param=true
            ),
            default_val=false
        )

    |" Actual implementation of ``base_subp_declarations`` that already
    |" assumes self is a subprogram.
    @with_dynvars(imprecise_fallback)
    fun base_subp_declarations_impl(): Array[Entity[BasicDecl]] = {
        val parent = self.canonical_part().parent_basic_decl();
        val task_or_protected = parent is ProtectedTypeDecl | TaskTypeDecl;
        # We use `without_md` below because we don't want to take into
        # account self's metadata, as the result of this property
        # shouldn't depend upon how this node was retrieved.
        val spec = self.without_md().as[BasicDecl].subp_spec_or_null();
        # Retrieve an environment that contains all the candidate subprograms
        # that can be base declarations of this one.

        # Note that we don't want the canonicalized primitive type, but the
        # most visible, as it might be a private type that has a more specific
        # derivation than the canonical (public) type:
        #
        # type A is tagged private;
        # type B is new A with private;
        # type P is new A with private;
        # private
        # type P is new B with record ...
        val prims_env =
            if task_or_protected
            then
                # If we are in a task or protected type, accumulate the
                # primitives of the parent interfaces, and add the subprogram
                # defined in the scope of the protected or task type.
                (
                    parent.as[BaseTypeDecl].base_types().map(
                        (bt) => bt.full_view().primitives_env()
                    )
                    & [parent.children_env]
                ).env_group()
            else (
                # For classical types, we can simply fetch the primitives_env.
                # We can call the `candidate_` version because the over-
                # approximation will get cancelled by the following logic.
                spec.candidate_primitive_subp_tagged_type(canonicalize=false)
                .do((t) => t.full_view().primitives_env())
            );

        # Now, simply filter in primitive subprograms that self overrides
        bind origin = node.origin_node();

        prims_env.get(self.name_symbol(), lookup=LookupKind.minimal).filtermap(
            (bd) => bd.as[BasicDecl].canonical_part(),
            (bd) => bd.as[BasicDecl]?.subp_spec_or_null().do(
                # Since `s` is retrieved from `t`'s primitives env,
                # its metadata fields `primitive` and
                # `primitive_real_type` are set and therefore
                # the following `match_signature` call will return
                # true if `s` is overridable by `spec`.
                (s) => s.match_signature(
                    spec,
                    match_name=false,
                    use_entity_info=true,
                    ignore_first_param=task_or_protected
                )
            )
        ).unique()
    }

    |" If self declares a primitive subprogram of some tagged type T, return
    |" the set of all subprogram declarations that it overrides (including
    |" itself).
    |"
    |" .. note:: for the moment this only works for tagged types. Remains to
    |"     be seen if we need to extend it.
    @exported
    @memoized
    @with_dynvars(imprecise_fallback=false)
    fun base_subp_declarations(): Array[Entity[BasicDecl]] =
        if self.is_subprogram() then self.base_subp_declarations_impl()
        else null[Array[Entity[BasicDecl]]]

    |" Actual implementation of ``root_subp_declarations`` that already
    |" assumes self is a subprogram.
    @with_dynvars(origin, imprecise_fallback)
    fun root_subp_declarations_impl(): Array[Entity[BasicDecl]] = {
        # Get all the parent overrides defined for this subprogram. That is,
        # if this subprogram is a primitive of some type T and overrides some
        # subprogram P, get all the other overrides of P which are primitives
        # of parent types of T.
        val raw_base_decls = self.base_subp_declarations();
        # If this subprogram is defined in a protected type or task type,
        # we must do things a bit different since the `primitive` metadata
        # field is not set on those subprograms. Fortunately, the reasoning is
        # quite trivial for those cases: since one cannot override a subprogram
        # defined in a protected type or task type, the root subprogram cannot
        # be self unless there is no other base subprogram. So, simply filter
        # self out of the base subp declarations in that case.
        val parent = self.canonical_part().parent_basic_decl();
        val task_or_protected = parent is ProtectedTypeDecl | TaskTypeDecl;
        val base_decls =
            if task_or_protected and raw_base_decls.length() > 1
            then raw_base_decls.filter((bd) => bd.node != node)
            else raw_base_decls;
        # Compute the set of all such types for which an override is declared
        val base_types =
            base_decls.map(
                (d) => d.info.md.primitive.as[BaseTypeDecl].as_bare_entity
            )
            .unique();

        # Among this set of type, find the ones which are not derived from any
        # of the others, i.e. the base-most types on which the original
        # subprogram is declared.
        base_types.filter(
            (t) => not base_types.any((u) => t != u and t.is_derived_type(u))
        )
        .map(
            # Get back the subprograms declared on the base types
            (root_type) =>
            base_decls.find((d) => d.info.md.primitive == root_type.node)
        )
    }

    |" If self declares a primitive subprogram of some tagged type T, return
    |" the root subprogram declarations that it overrides. There can be
    |" several, as in the following scenario:
    |"
    |" - package Root defines the root tagged type T and subprogram Foo.
    |" - package Itf defines interface I and abstract subprogram Foo.
    |" - package D defines "type U is new Root.T and Itf.I" and an overriding
    |"   subprogram Foo.
    |"
    |" Here, root_subp_declarations of Foo defined in package D will return
    |" both Foo from package Root and Foo from package Itf.
    @exported
    @with_dynvars(origin=null[AdaNode], imprecise_fallback=false)
    fun root_subp_declarations(): Array[Entity[BasicDecl]] =
        if self.is_subprogram() then self.root_subp_declarations_impl()
        else null[Array[Entity[BasicDecl]]]

    |" If self is the declaration of a primitive of some type T, return
    |" the list of all subprogram that override this subprogram among the
    |" given units.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun find_all_overrides(
        units: Array[AnalysisUnit]
    ): Array[Entity[BasicDecl]] = {
        val spec = self.subp_spec_or_null();
        # We can call the `candidate_` version because the over-approximation
        # will get cancelled by the following logic.
        val prim_type = spec?.candidate_primitive_subp_tagged_type();
        val derivations = prim_type?.find_all_derived_types(units);

        derivations.mapcat(
            (t) => {
                # Get all primitives that are named just like self
                val prims =
                    t.primitives_env().get(self.name_symbol()).map(
                        (p) => p.as![BasicDecl]
                    );

                # Retrieve self among the primitives, so that it carries
                # the adequate real_primitive_type metadata field.
                {
                    val base_p = prims.find((p) => p.node == node);

                    prims.filter(
                        (p) =>
                        (
                            # Among all the primitives ``p`` available on type
                            # ``t``, keep ``p`` if it both:
                            # is a primitive "owned" by ``t`` (i.e. not an
                            # inherited one).
                            p.info.md.primitive == t.node
                        )
                        and (
                            # overrides self
                            {
                                bind origin = base_p.origin_node();

                                base_p.subp_spec_or_null().match_signature(
                                    p.subp_spec_or_null(),
                                    match_name=false,
                                    use_entity_info=true
                                )
                            }
                        )
                    )
                    .map((p) => p.canonical_part().without_md().as![BasicDecl])
                }
            }
        )
        .unique()
    }

    |" Get all the names of this basic declaration.
    @exported
    @abstract
    fun defining_names(): Array[Entity[DefiningName]]

    |" Get the name of this declaration. If this declaration has several
    |" names, it will return the first one.
    @exported
    fun defining_name(): Entity[DefiningName] = self.defining_names()?[0]

    |" Return the defining name of this ``BasicDecl``, if and only if there
    |" is a unique defining name for it. Otherwise, raise a property error.
    fun defining_name_or_raise(): Entity[DefiningName] = {
        val dns = self.defining_names();

        if dns.length() > 1
        then
            raise[Entity[DefiningName]] PreconditionFailure(
                "BasicDecl with multiple defining names"
            )
        else dns?[0]
    }

    @with_dynvars(origin)
    fun identity_type(): Entity[BaseTypeDecl] = match self {
        case _: ExceptionDecl => node.exc_id_type()
        case _: SingleTaskDecl => node.task_id_type()

        # An object decl on which you can call 'Identity implies that its
        # type is a task type.
        case _: ObjectDecl => node.task_id_type()

        # As well as for for loop variable declarations and parameter
        # specifications.
        case _: ForLoopVarDecl => node.task_id_type()
        case _: BaseFormalParamDecl => node.task_id_type()
        case _ => null[Entity[BaseTypeDecl]]
    }

    @with_dynvars(origin)
    fun is_array(): Bool = self.array_ndims() > 0

    |" If self is a Subp, returns the specification of this subprogram.
    |"
    |" If ``follow_generic`` is True, will also work for instances of
    |" ``GenericSubpDecl``.
    @exported
    fun subp_spec_or_null(
        follow_generic: Bool = true
    ): Entity[BaseSubpSpec] = match self {
        case subp: BasicSubpDecl => subp.subp_decl_spec()
        case subp: BaseSubpBody => subp.subp_spec
        case subp: SubpBodyStub => subp.subp_spec
        case gsp: GenericSubpDecl =>
            if follow_generic then gsp.subp_decl.subp_spec
            else null[Entity[SubpSpec]]
        case gsi: GenericSubpInstantiation =>
            if follow_generic then gsi.designated_subp()?.subp_spec_or_null()
            else null[Entity[SubpSpec]]
        case gsr: GenericSubpRenamingDecl =>
            if follow_generic then gsr.resolve()?.subp_spec_or_null()
            else null[Entity[SubpSpec]]
        case _ => null[Entity[SubpSpec]]
    }

    fun formal_param_holder_or_null(): Entity[BaseFormalParamHolder] = match
        self
    {
        case t: TypeDecl => t.discriminants
        case e: EntryBody => e.params
        case _ => self.subp_spec_or_null()
    }

    |" Return True if self is a subprogram node in the general sense (which
    |" is, an entity that can be called). This includes separates and entries.
    |"
    |" .. attention: This is a purely syntactic query and will return True for
    |"     everything that is a syntactic entity that can be called like a
    |"     subprogram in some contexts, even generic formal subprograms for
    |"     example.
    @exported
    fun is_subprogram(): Bool =
        node is BasicSubpDecl
        | BaseSubpBody
        | SubpBodyStub
        | EntryDecl
        | GenericSubpDecl
        | GenericSubpInstantiation
        | GenericSubpRenamingDecl

    |" Return True if self is a subprogram node that is a valid reducer
    |" candidate as per RM 4.5.10 definition of the reducer program used by
    |" the ``'Reduce`` attribute (Ada 2022).
    fun is_valid_reducer_candidate(): Bool =
        # A reducer candidate can be a function or a procedure
        self.is_subprogram().do(
            (_) =>
            self.subp_spec_or_null().do(
                (spec) => {
                    val param_types = spec.param_types();
                    val return_type = spec.return_type();

                    (
                        # It should have two params
                        param_types.length() == 2
                    )
                    and (
                        if return_type.is_null
                        then {
                            # If it is a procedure, the first param mode should
                            # be `in out` while the second one should be `in`.
                            val param_modes = spec.param_modes();

                            param_modes?[0] is Mode.InOut
                            and param_modes?[1] is Mode.In | Mode.Default
                        }
                        else (
                            # Else, it is a function, and its return type
                            # should be identical to its first param type.
                            return_type == param_types?[0]
                        )
                    )
                }
            )
        )

    fun is_stream_subprogram_for_type(
        typ: Entity[BaseTypeDecl],
        return_obj: Bool
    ): Bool = {
        val root_stream_type =
            self.get_unit_root_decl(
                [s"Ada", s"Streams"],
                AnalysisUnitKind.unit_specification
            )
            ?.children_env
            .get_first(s"Root_Stream_Type", lookup=LookupKind.flat)
            .as[BaseTypeDecl]
            .classwide_type()
            .as[BaseTypeDecl];
        val params = self.subp_spec_or_null()?.unpacked_formal_params();

        bind origin = node.origin_node();

        node.is_subprogram()
        and params?[0].formal_decl().formal_type().is_access_to(
            root_stream_type
        )
        and (
            if return_obj
            then
                self.subp_spec_or_null().return_type().matching_formal_type(
                    typ
                )
            else
                params?[1].formal_decl().formal_type().matching_formal_type(
                    typ
                )
        )
    }

    |" Return whether this subprogram has the correct profile to be given
    |" as argument to the ``Put_Image`` aspect.
    fun is_put_image_subprogram_for_type(typ: Entity[BaseTypeDecl]): Bool = {
        val root_buffer_type =
            node.root_buffer_type().classwide_type().as[BaseTypeDecl];
        val params = self.subp_spec_or_null()?.unpacked_formal_params();

        {
            bind origin = node.origin_node();

            (
                node.is_subprogram()
                and params?[0].formal_decl().formal_type()
                .matching_formal_type(root_buffer_type)
            )
            and params?[1].formal_decl().formal_type().matching_formal_type(
                typ
            )
        }
    }

    |" Return true if entity can be a paramless subprogram entity, when used
    |" in an expression context.
    fun can_be_paramless(): Bool =
        self.subp_spec_or_null().do(
            (ss) => ss.paramless(self.info.md.dottable_subp, can_be=true),
            default_val=true
        )

    |" Return true if entity is a paramless subprogram entity, when used
    |" in an expression context.
    fun is_paramless(): Bool =
        self.subp_spec_or_null().do(
            (ss) => ss.paramless(self.info.md.dottable_subp, can_be=false),
            default_val=true
        )

    |" Return the relative name for self. If self's defining name is
    |" ``A.B.C``, return ``C`` as a node.
    @exported
    fun relative_name(): Entity[Name] = self.defining_name()?.relative_name()

    |" Return the relative name for self, as text.
    @exported
    fun relative_name_text(): Symbol = self.relative_name()?.name_symbol()

    fun name_symbol(): Symbol =
        node.as_bare_entity.relative_name().name_symbol()

    |" Return the body corresponding to this declaration, if applicable.
    |"
    |" .. note:: It is not named body_part, subclasses have more precise
    |"     versions named body_part and returning a more precise result.
    |"     Probably, we want to rename the specific versions, and have the
    |"     root property be named body_part. (TODO R925-008)
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun body_part_for_decl(): Entity[Body] =
        self.next_part_for_decl().do(
            (np) =>
            match np {
                case stub: BodyStub => stub.next_part_for_decl()
                case other => other
            }
        )
        .as[Body]

    |" Return the canonical part for this decl. In the case of decls composed
    |" of several parts, the canonical part will be the first part.
    @with_dynvars(imprecise_fallback=false)
    fun canonical_part_for_name(sym: Symbol): Entity[BasicDecl] =
        self.previous_part_for_name(sym).do(
            (pp) => pp.canonical_part_for_name(sym),
            default_val=self
        )

    |" Given an origin node and the entity represented by self, this property
    |" returns the most visible completion of self that can be seen by origin,
    |" according to Ada's visibility rules.
    @exported
    @with_dynvars(origin, imprecise_fallback=false)
    fun most_visible_part(): Entity[BasicDecl] =
        self.most_visible_part_for_name(
            self.defining_name_or_raise().name_symbol()
        )

    |" Internal method for computing the most visible part (going forward or
    |" backwards) of a basic decl according to one of its defining names.
    @with_dynvars(origin, imprecise_fallback)
    fun most_visible_part_for_name(
        sym: Symbol,
        only_backwards: Bool = false
    ): Entity[BasicDecl] = {
        # Note that for optimization purposes, we only try to go backwards if
        # this part is in a private part, because that's what is required to
        # implement correct name resolution. Making it work in any
        # circumstances would be more useful for users but does slowdown
        # name resolution, so should probably be done in a wrapper property
        # which we can bypass internally. The complete behavior can be enabled
        # by removing the condition on ``is_in_private_part`` below.
        val self_is_visible =
            (origin.is_null or not self.is_in_private_part())
            or self.is_visible(origin.as_bare_entity);

        # If this part is not visible, check if the previous part is, If
        # there is no previous part, return a null node.
        if not self_is_visible
        then
            self.previous_part_for_name(sym).do(
                (pp) => pp.most_visible_part_for_name(sym, only_backwards=true)
            )
        # This part is visible but we only want to go backwards, so stop
        # here.

        elif only_backwards then self
        # This part is visible, now check if the next part is as well
        else self.most_visible_forward_part_for_name(sym, seq=true)
    }

    |" Internal method for computing the most visible part (only looking
    |" forward) of a basic decl according to one of its defining names.
    |" If ``seq`` is True, the visibility check is sequential: if a next
    |" part is in the same unit as the origin but defined after it, it will
    |" not be considered visible.
    @with_dynvars(origin, imprecise_fallback=false)
    fun most_visible_forward_part_for_name(
        sym: Symbol,
        seq: Bool
    ): Entity[BasicDecl] = {
        val np = self.next_part_for_name(sym);

        # This is already the most visible part
        if np.is_null then self
        # A null origin means any "find the most complete part"

        elif origin.is_null
        then np.most_visible_forward_part_for_name(sym, seq)
        # The query is sequential and origin can't see the next part

        elif (seq and origin.unit == np.unit) and origin <= np.node then self
        # If the entity is not a package declaration, we only need to check
        # if its lexical env is one of the parents of origin's env.

        elif not (np.is_in_private_part() or np.is_in_public_part())
        then
            if
                origin.node_env.get(
                    sym,
                    categories=RefCategories(
                        inherited_primitives=false,
                        _=true
                    )
                )
                .contains(node.as_bare_entity)
            then np.most_visible_forward_part_for_name(sym, seq)
            else self
        # Otherwise this is a package declaration, so we can use the
        # is_visible property.

        elif np.is_visible(origin.as_bare_entity)
        then np.most_visible_forward_part_for_name(sym, seq)
        # Otherwise this was the most visible part
        else self
    }

    |" Return the extra suffix that should be appended to the fully qualified
    |" name of this declaration, for example to append ``'Class`` to classwide
    |" type declarations, etc.
    fun fqn_extra_suffix(): String =
        if self is ClasswideTypeDecl then "'Class"
        elif self is DiscreteBaseSubtypeDecl then "'Base"
        # For the moment, SynthAnonymousTypeDecl is used solely to
        # generate anonymous access types. We give those a name.
        # NOTE: this is not an Ada type as per the RM, and is used
        # for the GNAT specific 'Unrestricted_Access attribute, so
        # we give this type a name that doesn't exist in the RM
        # either.

        elif self is SynthAnonymousTypeDecl then "'Anonymous_Access"
        else ""

    |" Return the fully qualified name corresponding to this declaration, as
    |" an array of symbols.
    fun fully_qualified_name_string_array(
        include_profile: Bool = false
    ): Array[String] =
        self.defining_name_or_raise().fully_qualified_name_impl(
            include_profile=include_profile,
            suffix=self.fqn_extra_suffix()
        )

    |" Return the fully qualified name corresponding to this declaration, as
    |" an array of symbols.
    @exported
    fun fully_qualified_name_array(
        include_profile: Bool = false
    ): Array[Symbol] =
        self.fully_qualified_name_string_array(include_profile=include_profile)
        .map((t) => t.to_symbol)

    |" Return the fully qualified name corresponding to this declaration.
    @exported
    fun fully_qualified_name(): String =
        ".".join(self.fully_qualified_name_string_array())

    |" Return a canonical representation of the fully qualified name
    |" corresponding to this declaration.
    @exported
    fun canonical_fully_qualified_name(): String =
        self.defining_name_or_raise().canonical_fully_qualified_name_impl(
            include_profile=false,
            suffix=self.fqn_extra_suffix()
        )

    |" Return a unique identifying name for this declaration, provided this
    |" declaration is a public declaration. In the case of subprograms, this
    |" will include the profile.
    |"
    |" .. attention::
    |"     This will only return a unique name for public declarations.
    |"     Notably, anything nested in an unnamed declare block won't be
    |"     handled correctly.
    @exported
    fun unique_identifying_name(): String =
        self.defining_name_or_raise().unique_identifying_name_impl(
            suffix=self.fqn_extra_suffix()
        )

    fun custom_id_text(): String =
        self.subp_spec_or_null().do(
            # For subprograms, we'll compute their profiles as the unique
            # identifying text.
            (ss) =>
            "(" & ss.returns().do((_) => "(")
            & ss.unpacked_formal_params().do(
                (ufp) =>
                ", ".join(
                    ufp.map(
                        (p) =>
                        p.formal_decl().type_expression().custom_id_text()
                    )
                )
            )
            & ss.returns().do((_) => ")")
            & ss.returns().do((r) => " -> " & r.custom_id_text())
            & ")",
            default_val=""
        )

    |" Implementation helper for ``CompilationUnit.is_preelaborable``.
    |"
    |" Return whether ``self`` has aspects that make it preelaborable.
    |"
    |" If ``from_body``, consider that ``self`` is a spec and that we are
    |" computing whether its body is preelaborable.
    fun does_aspects_make_preelaborable(from_body: Bool): Bool = {
        bind imprecise_fallback = false;

        (
            # The following aspects apply to bodies...
            self.has_aspect(s"Pure")
        )
        or self.has_aspect(s"Preelaborate")
        or self.has_aspect(s"Shared_Passive")
        or (
            not from_body
            and (
                (
                    # ... but the ones below apply only to specs
                    self.has_aspect(s"Remote_Types")
                )
                or self.has_aspect(s"Remote_Call_Interface")
            )
        )
    }

    |" Return a public-friendly view of this entity. For now this only needs
    |" to handle the case where self is a ``GenericSubpInternal``, in which
    |" case we prefer to return its parent ``GenericSubpInstantiation`` node.
    |"
    |" .. attention:: Properties typically use ``wrap_public_reference`` to
    |"     sanitize their return value for users. Sometimes however, those
    |"     properties end up being used by internal properties for practical
    |"     reasons, meaning those properties will work on biased values,
    |"     which could become problematic. Moreover, as of yet this property
    |"     only exists to handle the ``GenericSubpInternal`` case, which could
    |"     actually be addressed cleanly in at least two different ways:
    |"
    |"     - By adding interfaces to langkit, so that a
    |"       ``GenericSubpInstantiation`` could be both a
    |"       ``GenericInstantiation`` and a ``BasicSubpDecl``.
    |"
    |"     - By also working with ``GenericSubpInstantiation`` nodes
    |"       internally. This mostly means getting rid of
    |"       ``GenericSubpInternal`` nodes in the envs.
    fun wrap_public_reference(): Entity[BasicDecl] =
        if self is GenericSubpInternal | GenericPackageInternal
        then self.get_instantiation() or? self
        else self

    |" If this is a child declaration, return the lexical environment name of
    |" its parent declaration. Otherwise return an empty string.
    |"
    |" If ``private_part`` is True, return the env name of the private part
    |" of its parent.
    fun child_decl_initial_env_name(private_part: Bool = false): Symbol = {
        val defining_name = node.as_bare_entity.defining_name();
        val child_name = defining_name.name.as[DottedName];

        # The standard package is the only library item that does not have
        # a named parent.
        if defining_name.text.to_symbol == s"standard" then null[Symbol]
        elif node.is_library_item()
        then
            child_name.do(
                (n) =>
                # If this declaration's name is a dotted name, use the prefix
                # to retrieve the name of its parent.
                if private_part
                then (n.prefix.text & ".__privatepart").to_symbol
                else n.prefix.text.to_symbol,
                default_val=s"standard"
            )
        # If it's not a dotted name, its parent is the standard package This
        # declaration.
        else null[Symbol]
    }

    |" Return the previous part for this decl, if applicable.
    |"
    |" .. note:: It is not named previous_part, because BaseTypeDecl has a
    |"     more precise version of previous_part that returns a BaseTypeDecl.
    |"     Probably, we want to rename the specific versions, and have the
    |"     root property be named previous_part. (TODO R925-008)
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun previous_part_for_decl(): Entity[BasicDecl] = match self {
        case btd: BaseTypeDecl => btd.previous_part(true).as[BasicDecl]
        case bd: Body => bd.previous_part_internal()
        case _ => null[Entity[BasicDecl]]
    }

    |" Return whether this declaration is static.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun is_static_decl(): Bool = false

    |" Given a generic formal entity inside a generic context, return the
    |" actual that was used to instantiate it.
    fun corresponding_actual(): Entity[BasicDecl] = self

    |" Return whether this is a top-level element.
    fun is_library_item(): Bool = node.parent is LibraryItem

    |" Return the declarative parts directly associated to this BasicDecl, if
    |" any.
    fun declarative_parts(): Array[Entity[DeclarativePart]] =
        null[Array[Entity[DeclarativePart]]]

    |" Return the actual AspectSpec to use for this entity. This is typically
    |" overriden by internal nodes that act as wrappers around the concrete
    |" nodes on which the aspects are defined.
    fun get_aspect_spec(): Entity[AspectSpec] = self.aspects

    |" Whether this declaration is imported from another language.
    @exported
    fun is_imported(): Bool = self.defining_name_or_raise()?.is_imported()

    fun is_in_public_part(): Bool = node.parent.parent is PublicPart

    fun is_in_private_part(): Bool = node.parent.parent is PrivatePart

    |" Return a lexical environment that contains entities that are accessible
    |" as suffixes when self is a prefix.
    @with_dynvars(
        origin, include_ud_indexing=false, dottable_type=null[AdaNode]
    )
    fun defining_env(): LexicalEnv = null[LexicalEnv]

    @with_dynvars(origin)
    fun array_ndims(): Int = self.expr_type().array_ndims()

    |" Return the type declaration corresponding to this basic declaration
    |" has when it is used in an expression context. For example, for this
    |" basic declaration::
    |"
    |"     type Int is range 0 .. 100;
    |"
    |"     A : Int := 12;
    |"
    |" the declaration of the Int type will be returned. For this
    |" declaration::
    |"
    |"     type F is delta 0.01 digits 10;
    |"
    |"     function B return F;
    |"
    |" expr_type will return the declaration of the type F.
    @with_dynvars(origin)
    fun expr_type(): Entity[BaseTypeDecl] =
        self.type_expression().do((te) => te.designated_type())

    |" Return the type expression for this BasicDecl if applicable, a null
    |" otherwise.
    @exported
    fun type_expression(): Entity[TypeExpr] = null[TypeExpr].as_entity

    |" This method is used when self is a candidate suffix in a dotted
    |" expression, to express the potential constraint that the suffix could
    |" express on the prefix.
    |"
    |" For example, given this code::
    |"
    |"     1 type P is record
    |"     2     A, B : Integer;
    |"     3 end record;
    |"     4
    |"     5 P_Inst : P;
    |"     7
    |"     8 P_Inst.A;
    |"       ^^^^^^^^
    |"
    |" A references the A ComponentDecl at line 2, and the constraint that we
    |" want to express on the prefix (P_Inst), is that it needs to be of type
    |" P.
    @with_dynvars(origin)
    fun constrain_prefix(
        @ignored
        prefix: Expr
    ): Equation =
        # Default implementation returns logic true => does not add any
        # constraint to the xref equation.
        %true

    |" Return the next part of this declaration, if applicable.
    |"
    |" .. note:: It is not named next_part, because BaseTypeDecl has a
    |"     more precise version of next_part that returns a BaseTypeDecl.
    |"     Probably, we want to rename the specific versions, and have the
    |"     root property be named next_part. (TODO R925-008)
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun next_part_for_decl(): Entity[BasicDecl] = {
        # Fetch the library level body unit that might contain the next part
        # for this declaration.
        val _ = match node.enclosing_compilation_unit().decl() {
            case _: Body => null[CompilationUnit]
            case b: BasicDecl =>
                b.as_bare_entity?.defining_name()?.referenced_unit(
                    AnalysisUnitKind.unit_body,
                    not_found_is_error=not (
                        (
                            # Body not mandatory if the library level
                            # declaration is a package (regular, generic, or
                            # instantiated). We don't try to be more precise
                            # than that.
                            b is BasePackageDecl
                            | GenericPackageDecl
                            | GenericInstantiation
                            | PackageRenamingDecl
                            | SubpRenamingDecl
                            | GenericRenamingDecl
                        )
                        or (
                            # A body is not expected if the library level
                            # declaration is an imported subprogram.
                            b is BasicSubpDecl | GenericSubpDecl
                            and (
                                # Now that get_aspect looks in all parts, we
                                # must not call has_aspect("Import") from here
                                # to avoid infinite recursion.
                                not b.as_entity.do(
                                    (e) =>
                                    e.get_aspect_assoc(s"Import")
                                    or? e.get_pragma(s"Import")
                                )
                                .is_null
                            )
                        )
                    )
                )
        };

        self.children_env.get_first(
            s"__nextpart",
            lookup=LookupKind.minimal,
            categories=RefCategories(inherited_primitives=false, _=true)
        )
        .as[BasicDecl]
    }

    |" Internal method for computing the next part of a basic decl according
    |" to one of its defining names. By default, this property behaves just
    |" like ``next_part_for_decl``. However it can be overridden for node
    |" types for which the next part depends on the defining name to consider.
    |" One example of that are constant declarations:
    |"
    |" .. code:: ada
    |"
    |"     package Pkg is
    |"         X, Y : constant Integer;
    |"     private
    |"         X : constant Integer := 1;
    |"         Y : constant Integer := 2;
    |"     end Pkg;
    |"
    |" So, ``next_part_for_name`` is overridden in ``ObjectDecl``.
    @with_dynvars(imprecise_fallback=false)
    fun next_part_for_name(
        @ignored
        sym: Symbol
    ): Entity[BasicDecl] = self.next_part_for_decl()

    |" Internal method for computing the previous part of a basic decl
    |" according to one of its defining names. By default, this property
    |" behaves just like ``next_part_for_decl``. However it can be overridden
    |" for node types for which the previous part depends on the defining name
    |" to consider. One example of that are subprogram parameters:
    |"
    |" .. code:: ada
    |"
    |"     package Pkg is
    |"         X : constant Integer;
    |"         Y : constant Integer;
    |"     private
    |"         X, Y : constant Integer := 1;
    |"     end Pkg;
    |"
    |" So, ``previous_part_for_name`` is overridden in ``ObjectDecl``.
    @with_dynvars(imprecise_fallback=false)
    fun previous_part_for_name(
        @ignored
        sym: Symbol
    ): Entity[BasicDecl] = self.previous_part_for_decl()

    |" Return whether this object is constant or not.
    @exported
    fun is_constant_object(): Bool =
        raise[Bool] PropertyError(
            "Property BasicDecl.is_constant_object not implemented"
        )
}

|" Contained (directly or indirectly) in an AbstractStateDeclExpr, and is used
|" to represent the BasicDecl associated with the abstract state introduced by
|" the Abstract_State aspect. This node is necessary because all of our name
|" resolution routines expect BasicDecls as environments' values.
|"
|" The only purpose of this node is to populate the env with the abstract
|" state declared through this node, so it can be referred in SPARK aspects
|" such as Global, Depends, Refined_State, etc.
class AbstractStateDecl: BasicDecl {
    @parse_field
    name: DefiningName
    @parse_field
    aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] = [self.name]

    fun type_expression(): Entity[TypeExpr] = null[Entity[TypeExpr]]

    env_spec {
        add_to_env_kv(node.name.name_symbol(), node)
    }
}

|" Represents a anonymous declaration that holds an expression.
|"
|" This is used to store the results of queries such as ``referenced_decl``
|" called on references to object formals from inside a instantiated generic
|" in order to return the relevant actual.
|"
|" Indeed, ``referenced_decl`` must return a ``BasicDecl``, but actuals of
|" generic instantiations are ``Expr``. This wrapper node is therefore a
|" way to both satisfy the ``BasicDecl`` interface, and provide to the user
|" the expression of the actual through the ``expr`` field.
@synthetic
class AnonymousExprDecl: BasicDecl {
    |" Return the expression wrapped by this declaration.
    @parse_field
    expr: Expr
    @parse_field
    @null_field
    aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] =
        null[Array[Entity[DefiningName]]]

    @with_dynvars(
        origin, include_ud_indexing=false, dottable_type=null[AdaNode]
    )
    fun defining_env(): LexicalEnv = self.type_expression().defining_env()

    |" Return the generic formal object declaration corresponding to this
    |" actual.
    @exported
    @memoized
    @with_dynvars(imprecise_fallback=false)
    fun get_formal(): Entity[DefiningName] = {
        val assoc = self.expr.parent.as[BasicAssoc];

        assoc.get_params()?[0]
    }

    |" Internal property that actually retrieves the type expression. Since
    |" this property requires non-trivial computation and is used during
    |" name resolution, it's important for the ``get_formal`` to be memoized.
    fun type_expression(): Entity[TypeExpr] =
        self.get_formal().basic_decl().type_expression()

    @with_dynvars(imprecise_fallback=false)
    fun is_static_decl(): Bool = self.expr.is_static_expr()
}

|" Base class for formal parameter declarations. This is used both for records
|" components and for subprogram parameters.
|"
|" This is a Libadalang abstraction, that has no ARM existence.
@abstract
class BaseFormalParamDecl: BasicDecl {
    |" Return the type for this formal.
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun formal_type(): Entity[BaseTypeDecl] =
        self.type_expression()?.designated_type()

    fun parent_decl(): Entity[BasicDecl] = self.semantic_parent().as[BasicDecl]

    fun get_param(
        part: Entity[BasicDecl],
        param: Symbol
    ): Entity[DefiningName] =
        part.do(
            (d) =>
            d.formal_param_holder_or_null()?.unpacked_formal_params().find(
                (sf) => sf.name_is(param)
            )
        )

    |" If self is a ParamSpec of a subprogram body or of an accept stmt, go
    |" fetch the equivalent spec in the subprogram decl.
    @with_dynvars(imprecise_fallback=false)
    fun decl_param(param: Entity[DefiningName]): Entity[DefiningName] =
        self.get_param(
            match self.semantic_parent() {
                case body: BaseSubpBody => body.decl_part()
                case accept: AcceptStmt => accept.corresponding_entry()
                case _ => null[Entity[BasicDecl]]
            },
            param.name_symbol()
        )
        or? param

    @with_dynvars(imprecise_fallback=false)
    fun next_part_for_name(sym: Symbol): Entity[BasicDecl] =
        self.get_param(self.parent_decl()?.next_part_for_decl(), sym)
        ?.basic_decl()

    @with_dynvars(imprecise_fallback=false)
    fun previous_part_for_name(sym: Symbol): Entity[BasicDecl] =
        self.get_param(self.parent_decl()?.previous_part_for_decl(), sym)
        ?.basic_decl()

    @with_dynvars(imprecise_fallback=false)
    fun next_part_for_decl(): Entity[BasicDecl] =
        self.next_part_for_name(self.name_symbol())

    @with_dynvars(imprecise_fallback=false)
    fun previous_part_for_decl(): Entity[BasicDecl] =
        self.previous_part_for_name(self.name_symbol())

    fun is_mandatory(): Bool = false

    |" Return the defining container type for this declaration. Note that this
    |" only makes sense for the ComponentDecl and DiscriminantSpec subclasses.
    fun container_type(): Entity[BaseTypeDecl] =
        node.parents().find((p) => p is BaseTypeDecl)
        .as[BaseTypeDecl]
        .as_entity

    @with_dynvars(origin)
    fun constrain_prefix(prefix: Expr): Equation =
        if node is ComponentDecl | DiscriminantSpec then (
            # If self is a component/discriminant of a SingleProtectedDecl or
            # ProtectedTypeDecl, do not constrain the equation further since
            # they do not have a type. Otherwise it is a record, so set the
            # expected type of the prefix to be the record type of this
            # component.
            if node.parents().any((p) => p is ProtectedDef)
            then %true
            else (
                prefix.expected_type_var() <- self.container_type()
                %and prefix.matches_expected_prefix_type()
            )
        ) else %false
}

|" Declaration for a component (:rmlink:`3.8`).
class ComponentDecl: BaseFormalParamDecl {
    @parse_field
    ids: ASTList[DefiningName]
    @parse_field
    component_def: ComponentDef
    @parse_field
    @nullable
    default_expr: Expr
    @parse_field
    aspects: AspectSpec

    |" See BasicDecl.defining_env
    @with_dynvars(
        origin, include_ud_indexing=false, dottable_type=null[AdaNode]
    )
    fun defining_env(): LexicalEnv =
        self.component_def.type_expr.defining_env()

    fun defining_names(): Array[Entity[DefiningName]] =
        node.ids.map((i) => i.as_entity)

    @with_dynvars(origin)
    fun array_ndims(): Int = self.component_def.type_expr.array_ndims()

    fun type_expression(): Entity[TypeExpr] =
        node.component_def.type_expr.as_entity

    fun is_constant_object(): Bool = false

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        val typ = self.expr_type();

        self.component_def.type_expr.sub_equation()
        %and self.default_expr.do(
            (de) =>
            (de.expected_type_var() <- typ %and de.sub_equation())
            %and de.matches_expected_assign_type(),
            default_val=%true
        )
    }

    fun xref_entry_point(): Bool = true

    env_spec {
        add_all_to_env(node.env_mappings(node.ids, node))
    }
}

|" Known list of discriminants in type declarations (:rmlink:`3.7`).
class DiscriminantSpec: BaseFormalParamDecl {
    @parse_field
    ids: ASTList[DefiningName]
    @parse_field
    type_expr: TypeExpr
    @parse_field
    @nullable
    default_expr: Expr
    @parse_field
    aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] =
        node.ids.map((id) => id.as_entity)

    @with_dynvars(
        origin, include_ud_indexing=false, dottable_type=null[AdaNode]
    )
    fun defining_env(): LexicalEnv = self.type_expr.defining_env()

    fun type_expression(): Entity[TypeExpr] = self.type_expr

    fun xref_entry_point(): Bool = true

    fun is_constant_object(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.type_expr.sub_equation()
        %and self.default_expr.do(
            (de) =>
            (de.expected_type_var() <- self.expr_type() %and de.sub_equation())
            %and de.matches_expected_assign_type(),
            default_val=%true
        )

    env_spec {
        add_all_to_env(node.env_mappings(node.ids, node))
    }
}

|" Enclosing declaration for a generic formal. The real declaration is
|" accessible via the ``decl`` field.
@abstract
class GenericFormal: BaseFormalParamDecl {
    @parse_field
    decl: BasicDecl
    @parse_field
    @null_field
    aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] =
        self.decl.defining_names()

    fun type_expression(): Entity[TypeExpr] = self.decl.type_expression()
}

|" Formal declaration for an object.
class GenericFormalObjDecl: GenericFormal {
}

|" Formal declaration for a package (:rmlink:`12.1`).
class GenericFormalPackage: GenericFormal {
}

|" Formal declaration for a subprogram (:rmlink:`12.1`).
class GenericFormalSubpDecl: GenericFormal {
}

|" Formal declaration for a type (:rmlink:`12.1`).
class GenericFormalTypeDecl: GenericFormal {
    fun default_type(): Entity[BaseTypeDecl] =
        match self.decl {
            case ft: FormalTypeDecl => ft.default_type
            case ift: IncompleteFormalTypeDecl => ift.default_type
            case _ => null[Entity[Name]]
        }
        ?.name_designated_type()
}

|" Specification for a parameter (:rmlink:`6.1`).
class ParamSpec: BaseFormalParamDecl {
    @parse_field
    ids: ASTList[DefiningName]
    @parse_field
    has_aliased: Aliased
    @parse_field
    @nullable
    mode: Mode
    @parse_field
    type_expr: TypeExpr
    @parse_field
    @nullable
    default_expr: Expr
    @parse_field
    aspects: AspectSpec

    fun is_mandatory(): Bool = node.default_expr.is_null

    fun defining_names(): Array[Entity[DefiningName]] =
        node.ids.map((id) => id.as_entity)

    fun type_expression(): Entity[TypeExpr] = self.type_expr

    fun is_constant_object(): Bool = node.mode is Mode.In | Mode.Default

    @with_dynvars(
        origin, include_ud_indexing=false, dottable_type=null[AdaNode]
    )
    fun defining_env(): LexicalEnv = self.type_expr.defining_env()

    @with_dynvars(origin)
    fun constrain_prefix(prefix: Expr): Equation =
        # If a dotted name refers to a parameter, it's necessarily because of
        # fully qualified name access, and thus the prefix of the dotted name
        # is the enclosing subprogram and must:
        #  - not have a type.
        #  - not have a called subp spec.
        prefix.type_var() <- null[Entity[BaseTypeDecl]]
        %and prefix.as[Name].do(
            (name) =>
            name.subp_spec_var() <- null[Entity[BaseFormalParamHolder]],
            default_val=%false
        )

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        val typ = self.expr_type();

        self.type_expr.sub_equation()
        %and self.default_expr.do(
            (de) =>
            (de.expected_type_var() <- typ %and de.sub_equation())
            %and de.matches_expected_assign_type(),
            default_val=%true
        )
    }

    fun xref_entry_point(): Bool = true

    env_spec {
        add_all_to_env(node.env_mappings(node.ids, node))
    }
}

|" Synthetic parameter declaration.
@synthetic
class SyntheticFormalParamDecl: BaseFormalParamDecl {
    param_name: Symbol
    @parse_field
    param_type: TypeExpr
    @parse_field
    @null_field
    aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] =
        [node.synthesize_defining_name(node.param_name).as_entity]

    fun is_mandatory(): Bool = true

    fun type_expression(): Entity[TypeExpr] = self.param_type

    fun corresponding_actual(): Entity[BasicDecl] = self
}

|" Base class for package declarations. This will be used
|" both for non-generic package declarations (via :typeref:`PackageDecl`) and
|" for generic ones (via :typeref:`GenericPackageInternal`).
@abstract
class BasePackageDecl: BasicDecl {
    @parse_field
    package_name: DefiningName
    @parse_field
    aspects: AspectSpec
    @parse_field
    public_part: PublicPart
    @parse_field
    @nullable
    private_part: PrivatePart
    @parse_field
    @nullable
    end_name: EndName

    fun defining_names(): Array[Entity[DefiningName]] = [self.package_name]

    @with_dynvars(
        origin, include_ud_indexing=false, dottable_type=null[AdaNode]
    )
    fun defining_env(): LexicalEnv = self.children_env

    |" Return the PackageBody corresponding to this node.
    @exported
    fun body_part(): Entity[PackageBody] = {
        bind imprecise_fallback = false;

        self.body_part_for_decl().as[PackageBody]
    }

    fun declarative_parts(): Array[Entity[DeclarativePart]] =
        [self.public_part.as[DeclarativePart]]
        & self.private_part.as[DeclarativePart].do((v1) => [v1])

    |" Return the env names that this package defines. Make sure to include
    |" the ``.__privatepart`` env name if this package doesn't have a private
    |" part, as some construct will always try to register themselves in the
    |" private part and therefore expect it to always be defined.
    fun env_names(): Array[Symbol] = {
        val fqn = node.top_level_env_name();

        fqn.do(
            (fqn) =>
            if not node.private_part.is_null then [fqn.to_symbol]
            else [fqn.to_symbol, (fqn & ".__privatepart").to_symbol]
        )
    }
}

# Implementation note: This exists so that we can insert an environment to
# distinguish between formal parameters and the package's contents.
|" This class denotes the internal package contained by a GenericPackageDecl.
class GenericPackageInternal: BasePackageDecl {
    |" Return whether this is a top-level element.
    fun is_library_item(): Bool = node.parent.parent is LibraryItem

    env_spec {
        add_env(names=node.env_names())
    }
}

|" Non-generic package declarations (:rmlink:`7.1`).
class PackageDecl: BasePackageDecl {
    env_spec {
        do(node.env_hook())
        set_initial_env(
            # TODO: This is wrong (should take into account whether the entity
            # is private or not), but we have no example of cases where this is
            # a problem yet.
            node.child_decl_initial_env(true)
        )
        add_all_to_env(self.child_decl_env_assocs())
        add_env(names=node.env_names())
        do(node.populate_dependent_units())
        reference(
            node.top_level_use_package_clauses(),
            Name.use_package_name_designated_env,
            cond=node.parent is LibraryItem | Subunit
        )
        reference(
            node.top_level_use_type_clauses(),
            Name.name_designated_type_env,
            cond=node.parent is LibraryItem | Subunit
        )
    }
}

|" Base class for type declarations. It unifies every kind of type that exists
|" in Ada, including types that have no source existence like classwide types.
@abstract
class BaseTypeDecl: BasicDecl {
    @parse_field
    @nullable
    name: DefiningName

    fun defining_names(): Array[Entity[DefiningName]] = [self.name]

    |" If this type decl is a subtype decl, return the base subtype. If not,
    |" return ``self``.
    @exported
    @memoized
    @with_dynvars(origin=null[AdaNode])
    fun base_subtype(): Entity[BaseTypeDecl] = match self {
        case db: DiscreteBaseSubtypeDecl => db
        case st: BaseSubtypeDecl => st.get_type().base_subtype()
        case _ => self
    }

    @memoized
    fun anonymous_access_type(): Entity[BaseTypeDecl] =
        SynthAnonymousTypeDecl(
            name=node.name,
            discriminants=null[DiscriminantPart],
            type_def=AnonymousTypeAccessDef(
                has_not_null=null[NotNull],
                type_decl=node
            )
        )
        .as[BaseTypeDecl]
        .as_entity

    fun anonymous_access_type_or_null(): Entity[BaseTypeDecl] =
        self?.anonymous_access_type()

    @lazy
    attributes_repo: TypeAttributesRepository =
        TypeAttributesRepository(base_type=node)

    |" Return the synthetic declaration of the built-in subprogram denoted by
    |" the given attribute name and defined on this type.
    fun synthesize_attribute_subprogram(
        attr_name: Symbol
    ): Entity[BasicSubpDecl] = {
        val repo = node.attributes_repo;
        val subp =
            if attr_name == s"succ" then repo.succ
            elif attr_name == s"pred" then repo.pred
            elif attr_name == s"min" then repo.min
            elif attr_name == s"max" then repo.max
            elif attr_name == s"round" then repo.round
            elif attr_name == s"rounding" then repo.rounding
            elif attr_name == s"unbiased_rounding" then repo.unbiased_rounding
            elif attr_name == s"ceiling" then repo.ceiling
            elif attr_name == s"floor" then repo.floor
            elif attr_name == s"truncation" then repo.truncation
            elif attr_name == s"machine" then repo.machine
            elif attr_name == s"machine_rounding" then repo.machine_rounding
            elif attr_name == s"fraction" then repo.fraction
            elif attr_name == s"exponent" then repo.exponent
            elif attr_name == s"copy_sign" then repo.copy_sign
            elif attr_name == s"remainder" then repo.remainder
            elif attr_name == s"adjacent" then repo.adjacent
            elif attr_name == s"scaling" then repo.scaling
            elif attr_name == s"compose" then repo.compose
            elif attr_name == s"leading_part" then repo.leading_part
            elif attr_name == s"mod" then repo.mod
            elif attr_name == s"image" then repo.image
            elif attr_name == s"wide_image" then repo.wide_image
            elif attr_name == s"wide_wide_image" then repo.wide_wide_image
            elif attr_name == s"put_image" then repo.put_image
            elif attr_name == s"value" then repo.value
            elif attr_name == s"wide_value" then repo.wide_value
            elif attr_name == s"wide_wide_value" then repo.wide_wide_value
            elif attr_name == s"fixed_value" then repo.fixed_value
            elif attr_name == s"integer_value" then repo.integer_value
            elif attr_name == s"pos" then repo.pos
            elif attr_name == s"val" then repo.val_attr
            elif attr_name == s"enum_rep" then repo.enum_rep
            elif attr_name == s"enum_val" then repo.enum_val
            elif attr_name == s"read" then repo.read
            elif attr_name == s"write" then repo.write
            elif attr_name == s"input" then repo.input
            elif attr_name == s"output" then repo.output
            elif attr_name == s"asm_input" then repo.asm_input
            elif attr_name == s"asm_output" then repo.asm_output
            elif attr_name == s"model" then repo.model
            else null[BasicSubpDecl];

        Entity[BasicSubpDecl](
            node=subp,
            info=EntityInfo(
                md=null[Metadata],
                rebindings=self.info.rebindings,
                from_rebound=self.info.from_rebound
            )
        )
    }

    |" Return the subprogram declaration denoted by this attribute name and
    |" defined on this type.
    @exported
    fun attribute_subprogram(attr_name: Symbol): Entity[BasicDecl] =
        if attr_name in s"read" | s"write" | s"input" | s"output"
        then
            self.get_representation_clause(attr_name).do(
                (x) => x.expr.as![Name].referenced_decl(),
                default_val=self.synthesize_attribute_subprogram(attr_name)
            )
        elif attr_name == s"put_image"
        then
            self?.get_aspect(s"put_image").value.as[Name].do(
                (n) => n.referenced_decl(),
                default_val=self.synthesize_attribute_subprogram(attr_name)
            )
        else self.synthesize_attribute_subprogram(attr_name)

    |" Return the private completion for this type, if there is one.
    @exported
    @memoized
    fun private_completion(): Entity[BaseTypeDecl] =
        self.declarative_scope()
        .as[PublicPart]
        ?.parent
        .as[BasePackageDecl]
        ?.private_part
        ?.decls
        .find(
            (d) =>
            d.as[BaseTypeDecl].do(
                (pp) => pp.name_symbol() == self.name_symbol()
            )
        )
        .do(
            (t) =>
            Entity[BaseTypeDecl](
                node=t.as[BaseTypeDecl],
                info=EntityInfo(
                    # Do not propagate the "metadata" and "from_rebound"
                    # information to the next part, as these only apply to
                    # the original part.
                    md=null[Metadata],
                    rebindings=self.info.rebindings,
                    from_rebound=false
                )
            )
        )

    @with_dynvars(origin)
    fun is_array_or_rec(): Bool =
        not node.is_null
        and (
            (self.is_array() or self.is_record_type())
            or (
                # Also consider container aggregates as array or rec
                origin is BracketAggregate and self.has_aspect(s"Aggregate")
            )
        )

    |" Assuming that P is a primitive of self, return whether the given
    |" primitive P is inherited from one of self's parents.
    @exported
    fun is_inherited_primitive(p: Entity[BasicDecl]): Bool =
        self.node != p.info.md.primitive

    |" Return the record representation clause associated to this type decl,
    |" if applicable (i.e. this type decl defines a record type).
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun get_record_representation_clause(): Entity[RecordRepClause] =
        self.declarative_scope()?.decls.as_entity.find(
            (d) =>
            d.as[RecordRepClause].do((p) => p.name.referenced_decl() == self)
        )
        .as[RecordRepClause]

    |" Return the enum representation clause associated to this type decl,
    |" if applicable (i.e. this type decl defines an enum type).
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun get_enum_representation_clause(): Entity[EnumRepClause] =
        self.declarative_scope()?.decls.as_entity.find(
            (d) =>
            d.as[EnumRepClause].do(
                (p) => p.type_name.referenced_decl() == self
            )
        )
        .as[EnumRepClause]

    |" Return the list of all subprograms that are direct primitives of this
    |" type. We look for them in the public part and private part of the
    |" package this type is declared in.
    @lazy
    direct_primitive_subps: Array[InnerEnvAssoc] = {
        val scope = node.declarative_scope();
        val is_derived_tagged =
            node.as_bare_entity.as[TypeDecl]?.is_derived_tagged_type();
        val decl_parts = scope?.parent.as_bare_entity.do((v1) =>
            match v1 {
                case pkg_decl: BasePackageDecl =>
                    # self is declared in a package scope, we should check all
                    # the declarative parts of it.
                    pkg_decl.public_part.decls.as_array()
                    & pkg_decl.private_part?.decls.as_array()
                case _ =>
                    # self is not declared in a package scope: the only way
                    # that there can be a primitive of self here is if self is
                    # a derived tagged type.
                    if is_derived_tagged
                    then
                        node.parent.parent.as[DeclarativePart].do(
                            (dp) => dp.as_bare_entity.decls.as_array()
                        )
                    else null[Array[Entity[AdaNode]]]
            }
        );
        val enum_lits = node.as[TypeDecl]?.type_def.as[EnumTypeDef].do(
            (etf) => etf.enum_literals.map(
                (lit) => InnerEnvAssoc(
                    key=lit.name.name_symbol(),
                    value=lit,
                    metadata=Metadata(primitive=node)
                )
            )
        );
        val prim_subps = decl_parts.filter((decl) =>
            decl.as[BasicDecl]?.subp_spec_or_null().do(
                (spec) => spec.candidate_primitive_subp_types().contains(
                    node.as_bare_entity
                ) and (
                    # For candidate primitives not declared in a package
                    # decl, we must further check if they are overriding a
                    # parent primitive.
                    #
                    # This check is not done in
                    # `candidate_type_for_primitive` because it may cause
                    # infinite recursions if the parent type is declared in
                    # the same scope as self.
                    if not scope.parent is BasePackageDecl
                    then {
                        bind origin = spec.origin_node();

                        node.as_bare_entity.parent_primitives_env().get(
                            spec.name().name_symbol()
                        ).any((x) =>
                            x.as[BasicDecl].subp_spec_or_null()
                            .match_signature(
                                spec,
                                match_name=false,
                                use_entity_info=true
                            )
                        )
                    }
                    else true
                )
            )
        ).mapcat((decl) => {
            val bd = decl.as[BasicDecl];
            val sym = bd.defining_name().name_symbol();

            [InnerEnvAssoc(
                key=sym,
                value=bd.node,
                metadata=Metadata(primitive=node)
            )] & (
                if sym == s"\"=\""
                then [InnerEnvAssoc(
                    key=s"\"/=\"",
                    value=bd.node,
                    metadata=Metadata(primitive=node)
                )]
                else null[Array[InnerEnvAssoc]]
            )
        });

        # Also add this types' predefined operators to the list of primitives
        val predefined_ops =
            node.as[TypeDecl]?.as_bare_entity.predefined_operators().map(
                (assoc) => InnerEnvAssoc(
                    key=assoc.key,
                    value=assoc.value,
                    metadata=Metadata(primitive=node)
                )
            );

        enum_lits & prim_subps & predefined_ops
    }

    |" Return the environment containing the primitives for self, rebound
    |" using the given rebindings.
    fun own_primitives_env(with_rebindings: EnvRebindings): LexicalEnv =
        self.direct_primitives_env.rebind_env(with_rebindings)

    |" Return the environments containing the primitives for self and its
    |" previous parts, if there are some. All returned environments are
    |" rebound using the given rebindings.
    fun own_primitives_envs(
        with_rebindings: EnvRebindings
    ): Array[LexicalEnv] =
        # If self has a previous part, it might have primitives too
        self.previous_part(false).as[TypeDecl].do(
            (pp) =>
            [
                self.own_primitives_env(with_rebindings),
                pp.own_primitives_env(with_rebindings)
            ],
            default_val=[self.own_primitives_env(with_rebindings)]
        )

    |" Return the environments containing the primitives for self (if
    |" ``include_self`` is True) and all its base types up to ``stop_at``:
    |" upon rewinding the base type chain, if we stumble on one of the types
    |" included in the ``stop_at`` set, we stop the recursion of that branch.
    |" All returned environments are rebound using the given rebindings.
    fun primitives_envs(
        with_rebindings: EnvRebindings,
        stop_at: Array[Entity[BaseTypeDecl]],
        include_self: Bool = false
    ): Array[LexicalEnv] =
    # TODO: Not clear if the below origin.bind is correct, investigate
    # later.
    {
        bind origin = node;

        self.base_types().mapcat(
            (t) =>
            match t {
                case td: TypeDecl => td
                case ttd: TaskTypeDecl => ttd
                case std: BaseSubtypeDecl =>
                    {
                        bind origin = std.node.origin_node();

                        std.get_type().as[TypeDecl]
                    }
                case _ => null[Entity[TypeDecl]]
            }
            .do(
                (bt) =>
                if stop_at.contains(bt) then null[Array[LexicalEnv]]
                else
                    bt.own_primitives_envs(with_rebindings)
                    & bt.primitives_envs(with_rebindings, stop_at, false)
            )
        )
        & (
            if include_self then self.own_primitives_envs(with_rebindings)
            else null[Array[LexicalEnv]]
        )
    }

    |" Return a environment containing all primitives accessible to self,
    |" with the adjusted ``primitive_real_type`` metadata field.
    @memoized
    fun compute_primitives_env(
        include_self: Bool = true,
        stop_at: Array[Entity[BaseTypeDecl]] =
            null[Array[Entity[BaseTypeDecl]]]
    ): LexicalEnv =
        self.primitives_envs(
            with_rebindings=self.info.rebindings,
            stop_at=stop_at,
            include_self=include_self
        )
        .env_group(with_md=Metadata(primitive_real_type=node))

    |" The environment that contains all subprograms that are direct
    |" primitives of this type, that is, primitives that are not inherited.
    @lazy
    direct_primitives_env: LexicalEnv =
        dynamic_lexical_env(
            BaseTypeDecl.direct_primitive_subps,
            transitive_parent=false
        )

    |" Return the list of all primitive operations that are available on this
    |" type. If ``only_inherited`` is True, it will only return the primitives
    |" that are implicitly inherited by this type, discarding those explicitly
    |" defined on this type. Predefined operators are included in the result
    |" iff ``include_predefined_operators`` is True. It defaults to False.
    @exported
    fun get_primitives(
        only_inherited: Bool = false,
        include_predefined_operators: Bool = false
    ): Array[Entity[BasicDecl]] = {
        val prim_env =
            if only_inherited then self.parent_primitives_env()
            else self.primitives_env();

        # First gather the set of names that primitives of this type can have
        val all_prim_names = prim_env.get(null[Symbol]).map(
            (t) => t.as[BasicDecl].defining_name().name_symbol()
        ).unique();

        # Next, for each of these names, we only want to keep the
        # "most overriding" ones.
        all_prim_names.mapcat((name) => {
            val all_prims = prim_env.get(name).map((t) => t.as[BasicDecl]);
            val bds =
                if include_predefined_operators
                then all_prims
                else all_prims.filter((p) => not p is SyntheticSubpDecl);

            bds.ifilter((a, i) => {
                val a_spec = a.subp_spec_or_null();
                val a_prim =
                    a.info.md.primitive.as_bare_entity.as[BaseTypeDecl];

                # Only keep primitive a if it is the "most overriding"
                # one.  So, the logic below checks that there isn't a
                # primitive b that overrides it.
                not bds.iany((b, j) => {
                    val b_prim = b.info.md.primitive.as[BaseTypeDecl];

                    (i != j)
                    and {
                        # If two primitives have the same
                        # signature...
                        bind origin = b.origin_node();

                        a_spec.match_signature(
                            b.subp_spec_or_null(),
                            match_name=false,
                            use_entity_info=true
                        )
                    }
                    and {
                        val b_prim_ent = b_prim.as_bare_entity;

                        # Test if the type of the first primitive
                        # (a) derives from the type of the second
                        # primitive (b)...
                        if a_prim.has_base_type(b_prim_ent.node) then (
                            # Case a derives from b...  If b also
                            # derives from a, it means the types
                            # are equal: both primitives are in
                            # fact the same subprogram, but the
                            # first one is the declaration and the
                            # second one is the body. In that case
                            # we decide to keep the body.  Else if
                            # b does not derive from a, it means
                            # the primitive on a overrides the
                            # primitive on b, so return False.
                            i < j
                            and b_prim_ent.has_base_type(
                                a_prim.node
                            )
                        )
                        else (
                            # Case a does *not* derive from b...
                            # If b also does not derive from a, the
                            # two base types are unrelated, it
                            # means that the primitives are merged
                            # in a single one (remember their
                            # signature match). We keep the one
                            # that is inherited first with respect
                            # to the list of parents.  But if b
                            # derives from a, we return True as we
                            # don't want to keep this primitive: we
                            # will keep the most inherited one
                            # (defined on b) later instead.
                            i > j
                            or b_prim_ent.has_base_type(
                                a_prim.node
                            )
                        )
                    }
                })
            })
        })
    }

    |" Return whether this type is an array type.
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun is_array_type(): Bool = self.is_array()

    # Assuming self is a tagged type, return the view conversion to the most
    # immediate specific parent type obtained by the `Super` attribute.
    @with_dynvars(origin)
    fun super_view_conversion(): Entity[BaseTypeDecl] = {
        val typ = self.accessed_type() or? self;

        match typ {
            case cw: ClasswideTypeDecl => cw.type_decl()
            case o => o
        }
        .base_type()
    }

    |" Find types derived from self in the given ``root`` and its children.
    @exported
    @with_dynvars(origin, imprecise_fallback=false)
    fun find_derived_types(root: Entity[AdaNode]): Array[Entity[TypeDecl]] =
        # TODO: Factor the traversal between this and `find_derived_types`
        root.children.do(
            (c) =>
            c.filter((n) => not (n.is_null or n.node == origin)).mapcat(
                (n) => self.find_derived_types(n)
            )
        )
        & root.as[TypeDecl].do(
            (type_decl) =>
            type_decl.is_derived_type(self).do((_) => [type_decl])
        )

    |" Create an env_assoc embedding the synthetic object declaration
    |" required for predicates name resolution.
    |"
    |" This property should only be called once by ``env_spec``
    |" (``SubtypeDecl``, ``TypeDecl``).
    @lazy
    synthetic_object_decl_env_assoc: EnvAssoc =
        EnvAssoc(
            key=node.name_symbol(),
            # This synthetic object declaration is used for resolving the
            # references to its own derived/subtype identifier that can be used
            # in predicates as object references. This virtual object only
            # lives in the scope of the derived/subtype declaration, and has
            # the same name and type than the declaration it derives from.
            value=SyntheticObjectDecl(
                name=node.name,
                # A `SubtypeDecl` has a type expression that we can reuse On
                # the contrary, we have to embed the TypeDecl into a synthetic
                # `TypeExpr` for `TypeDecl`s.
                type_expr=node.as_bare_entity.type_expression().node
                or? SyntheticTypeExpr(target_type=node)
            ),
            dest_env=DesignatedEnv(
                kind=DesignatedEnvKind.current_env,
                env_name=null[Symbol],
                direct_env=null[LexicalEnv]
            ),
            metadata=null[Metadata]
        )

    |" Whether type is a scalar type.
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun is_scalar_type(): Bool =
        (
            (
                (self.is_int_type() or self.is_real_type())
                or self.is_float_type()
            )
            or self.is_fixed_point()
        )
        or self.is_enum_type()

    |" Whether self is an implicitly dereferenceable type or not
    @with_dynvars(origin)
    fun is_implicit_deref(): Bool =
        self.access_def().do((d) => not d is AccessToSubpDef)
        or not self.get_imp_deref().is_null

    |" Return the specific type under a class-wide type. Consider for example:
    |"
    |" .. code-block:: ada
    |"
    |"    subtype S1 is T'Class
    |"    subtype S2 is S1'Class
    |"
    |" Calling this property on ``S2`` will return ``T``.
    @exported
    fun specific_type(): Entity[BaseTypeDecl] = match self {
        # Recurse on the class-wide type because it could be a subtype
        # renaming a class-wide type itself.
        case cw: ClasswideTypeDecl => cw.type_decl().specific_type()
        case bt: BaseSubtypeDecl =>
            {
                val bt = bt.base_subtype();

                # Check if the base subtype is self, to not do an infinite
                # recursion.
                if self == bt then self else bt.specific_type()
            }
        case _ => self
    }

    |" If this type defines an Implicit_Dereference aspect, return the
    |" accessed type, otherwise return self.
    @with_dynvars(origin=null[AdaNode])
    fun derefed_type(): Entity[BaseTypeDecl] =
        if self.is_null or self.get_imp_deref().is_null then self
        else self.accessed_type()

    |" Return the base subtype of this subtype. If this type defines an
    |" Implicit_Dereference aspect, return the base subtype of the accessed
    |" type instead.
    @with_dynvars(origin=null[AdaNode])
    fun derefed_base_subtype(): Entity[BaseTypeDecl] =
        if self.is_null then self
        else
            (
                if not self.get_imp_deref().is_null then self.accessed_type()
                else self
            )
            .base_subtype()

    |" Considering that self is the actual type of the left operand of an
    |" array concatenation and ``other`` the actual type of its right operand,
    |" return the type of the result of the array concatenation.
    @with_dynvars(origin=null[AdaNode])
    fun array_concat_result_type(
        other: Entity[BaseTypeDecl]
    ): Entity[BaseTypeDecl] =
        if self.is_null or other.is_null then null[Entity[BaseTypeDecl]]
        elif
            other.matching_formal_type(self)
            or other.matching_formal_type(self.comp_type())
        then self.derefed_base_subtype()
        elif
            self.matching_formal_type(other)
            or self.matching_formal_type(other.comp_type())
        then other.derefed_base_subtype()
        else null[Entity[BaseTypeDecl]]

    |" Considering that self is the result type of an array concatenation and
    |" ``operand_type`` is the actual type of one of the operands, return the
    |" expected type for that operand. In other words: if the actual type of
    |" the operand is a subtype of the component-type of the resulting array,
    |" return the component type of the array. Otherwise return the array type
    |" itself.
    @with_dynvars(origin=null[AdaNode])
    fun expected_array_concat_operand_type(
        operand_type: Entity[BaseTypeDecl]
    ): Entity[BaseTypeDecl] =
        if self.is_null or operand_type.is_null then null[Entity[BaseTypeDecl]]
        elif
            operand_type.matching_formal_type(self)
            or operand_type.matching_formal_type(self.comp_type())
        then operand_type.derefed_base_subtype()
        else null[Entity[BaseTypeDecl]]

    @with_dynvars(origin=null[AdaNode])
    fun is_non_null_char_type(): Bool =
        not node.is_null and self.is_char_type()

    fun scalar_base_type(): Entity[DiscreteBaseSubtypeDecl] =
        node.scalar_base_subtype_node().as_entity

    |" Return whether this type is one of the three universal types (universal
    |" integer, universal fixed, or universal real).
    |"
    |" .. note::
    |"     Returns False if self is null.
    fun is_universal_type(): Bool =
        not self.is_null
        and (
            self == node.universal_int_type()
            or self == node.universal_fixed_type()
            or self == node.universal_real_type()
        )

    |" Return whether this type is *not* one of the two universal types
    |" (universal integer or universal real).
    |"
    |" .. note::
    |"     Returns False if self is null.
    fun is_not_universal_type(): Bool =
        not self.is_null and not self.is_universal_type()

    |" Predicate to use by logic equation. Return True iff this is an access
    |" type, but checks first that this type is not null, in which case it
    |" returns False.
    @with_dynvars(origin)
    fun is_access_type_predicate(): Bool = self?.is_access_type()

    @with_dynvars(origin)
    fun array_ndims(): Int = 0

    |" Return the expression from the Static_Predicate or the Predicate aspect
    |" defined on this type.
    @with_dynvars(imprecise_fallback=false)
    fun static_predicate(): Entity[Expr] =
        self.get_aspect(s"Static_Predicate").value
        or? self.get_aspect(s"Predicate").value

    |" Return true if the given value satisfies all of this type's static
    |" predicates, including its parent predicates (in case this is a derived
    |" type) and its base type predicate (if this is a subtype declaration).
    |" Return true if no type predicates are defined for this type.
    @with_dynvars(imprecise_fallback=false, origin=null[AdaNode])
    fun satisfies_type_predicates(value: BigInt): Bool = {
        val true_val = 1b;
        val satisfies_own_predicate =
            self.static_predicate().do(
                (pred) =>
                true_val
                == pred.eval_as_int_in_env(
                    [
                        Substitution(
                            from_decl=self,
                            to_value=value,
                            value_type=self
                        )
                    ]
                ),
                default_val=true
            );
        val from_type = self.as[BaseSubtypeDecl]?.get_type();
        val base_type = self.base_type();

        satisfies_own_predicate
        and (
            if not from_type.is_null
            then from_type.satisfies_type_predicates(value)
            elif not base_type.is_null
            then base_type.satisfies_type_predicates(value)
            else true
        )
    }

    @memoized
    @with_dynvars(origin)
    fun is_iterator_type(): Bool = {
        val iifcs =
            self.get_unit_root_decl(
                [s"Ada", s"Iterator_Interfaces"],
                AnalysisUnitKind.unit_specification
            );
        val typ =
            self.as[ClasswideTypeDecl].do(
                (cw) => cw.type_decl(),
                default_val=self
            );

        typ.semantic_parent().semantic_parent().node == iifcs
        or self.canonical_part().has_aspect(s"Iterable")
    }

    |" Assuming this is an iterator type, return the associated cursor
    |" type.
    @with_dynvars(origin)
    fun cursor_type(): Entity[BaseTypeDecl] =
        # For containers and user defined iterator types, cursor type
        # is defined by the `Cursor` type declaration.
        self.children_env.get_first(s"Cursor")
        .as![BaseTypeDecl]
        # Check out cursor type for types with `Iterable` aspect
        or? self.iterable_cursor_type()

    fun is_not_root_int_type(): Bool =
        not node.is_null and self != node.root_int_type()

    |" Whether a universal integer can be used to initialize a value of this
    |" type. This is true for integer types in general, but also for arbitrary
    |" types that define the Integer_Literal aspect.
    @with_dynvars(origin=null[AdaNode])
    fun allows_universal_int(): Bool =
        self.is_int_type()
        or self.base_subtype().do(
            (bt) =>
            # We check on the base_subtype because the aspect can only be
            # specified on the type's first subtype.
            not bt.get_aspect(s"Integer_Literal", true).is_null,
            default_val=false
        )

    |" Whether a universal real can be used to initialize a value of this
    |" type. This is true for real types in general, but also for arbitrary
    |" types that define the Real_Literal aspect.
    @with_dynvars(origin=null[AdaNode])
    fun allows_universal_real(): Bool =
        self.is_real_type()
        or self.base_subtype().do(
            (bt) =>
            # We check on the base_subtype because the aspect can only be
            # specified on the type's first subtype.
            not bt.get_aspect(s"Real_Literal", true).is_null,
            default_val=false
        )

    |" Predicate that'll check that this type is not null. Meant to be used in
    |" equations, where we know that the expression's type cannot be
    |" determined if there is no expected type, as in::
    |"
    |"     Predicate(BaseTypeDecl.is_not_any_type,
    |"               self.expected_type_var,
    |"               error_location=self)
    @predicate_error("No inferable type for expression")
    fun is_not_any_type(): Bool = not node.is_null

    |" Whether a string literal can be used to initialize a value of this
    |" type. This is true for string types in general, but also for arbitrary
    |" types that define the String_Literal aspect.
    |"
    |" .. note:: We also check that the node is not null because this property
    |"    is used directly as a logic predicate and may be invoked with null
    |"    nodes (unlike the other ``allows_*`` properties).
    @with_dynvars(origin=null[AdaNode])
    @predicate_error("$Self does not allow string literals")
    fun allows_string_literal(): Bool =
        not node.is_null
        and (
            self.is_str_type()
            or self.base_subtype().do(
                (bt) =>
                # We check on the base_subtype because the aspect can only be
                # specified on the type's first subtype.
                not bt.get_aspect(s"String_Literal", true).is_null,
                default_val=false
            )
        )

    |" Whether this is a string type (a one dimensional array of characters).
    @with_dynvars(origin)
    fun is_str_type(): Bool =
        self.array_ndims() == 1 and self.comp_type()?.is_char_type()

    |" Like ``BaseTypeDecl.accessed_type``, but does not perform an implicit
    |" call if self represents an access-to-subprogram.
    @with_dynvars(origin)
    fun accessed_type_no_call(): Entity[BaseTypeDecl] =
        if self.is_null or self.access_def() is AccessToSubpDef
        then null[Entity[BaseTypeDecl]]
        else self.accessed_type()

    |" Call accessed_type recursively until we get the most nested accessed
    |" type. For example, for the following code::
    |"
    |"     type A is access Integer;
    |"     type AA is access A;
    |"     type AAA is access AA;
    |"
    |" ``AAA``'s final_accessed_type is Integer.
    @with_dynvars(origin)
    fun final_accessed_type(first_call: Bool = true): Entity[BaseTypeDecl] =
        self.accessed_type().do(
            (at) => at.final_accessed_type(false),
            default_val=if first_call then null[Entity[BaseTypeDecl]] else self
        )

    @with_dynvars(origin)
    fun is_access_to(typ: Entity[BaseTypeDecl]): Bool =
        self?.accessed_type()?.matching_formal_type(typ)

    |" Returns whether self is an access type whose accessed type matches
    |" other.
    @with_dynvars(origin)
    fun is_subp_access_of(other: Entity[BasicDecl]): Bool =
        self?.access_def().as[AccessToSubpDef].do(
            (sa) =>
            other.subp_spec_or_null().do(
                (se) => sa.subp_spec.match_signature(se, false)
            )
        )

    |" Return whether this type declaration is a generic formal.
    fun is_generic_formal(): Bool =
        node.parent is GenericFormalTypeDecl
        or node.parent.as[BaseTypeDecl]?.is_generic_formal()

    |" Return whether self is a tagged type after being implicitly
    |" dereferenced.
    @with_dynvars(origin=null[AdaNode])
    @predicate_error("expected tagged type, got $Self")
    fun is_tagged_type_with_deref(): Bool =
        (
            if not self.get_imp_deref().is_null then self.accessed_type()
            else self
        )
        .is_tagged_type()

    |" Return the list of all types that inherit (directly or indirectly) from
    |" self among the given units.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun find_all_derived_types(
        units: Array[AnalysisUnit]
    ): Array[Entity[TypeDecl]] = {
        bind origin = node;

        self.canonical_type().filter_is_imported_by(units, true).mapcat(
            (u) => u.root.do((r) => self.find_derived_types(r.as_bare_entity))
        )
    }

    |" Return the array definition corresponding to type ``self`` in the
    |" context of array-indexing, e.g. implicitly dereferencing if ``self`` is
    |" an access.
    @with_dynvars(origin)
    fun array_def_with_deref(): Entity[ArrayTypeDef] =
        if self.is_array() then self.array_def()
        elif self.is_implicit_deref()
        then self.accessed_type().do((c) => c.array_def())
        else null[Entity[ArrayTypeDef]]

    @with_dynvars(origin)
    fun is_array_def_with_deref(): Bool =
        not node.is_null and not self.array_def_with_deref().is_null

    @with_dynvars(origin)
    fun is_array_def_with_deref_or_null(): Bool =
        node.is_null or not self.array_def_with_deref().is_null

    |" Return the component type of ``self``, if applicable. The component
    |" type is the type you'll get if you call a value whose type is ``self``.
    |" So it can either be:
    |"
    |" 1. The component type for an array.
    |" 2. The return type for an access to function.
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun comp_type(is_subscript: Bool = false): Entity[BaseTypeDecl] =
        self.do(
            (e) => {
                val ad =
                    if is_subscript then self.array_def_with_deref()
                    else self.array_def();

                ad.do((ad) => ad.comp_type())
                or? e.access_def().do(
                    (v1) =>
                    match v1 {
                        case asd: AccessToSubpDef =>
                            asd.subp_spec.return_type()
                        case tad: BaseTypeAccessDef => tad.accessed_type()
                    }
                )
            }
        )

    |" Return the index type for dimension ``dim`` for this type, if
    |" applicable.
    |"
    |" .. WARNING:: ``dim`` is 0-based, so the first ``index_type`` is at
    |"     index 0.
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun index_type(dim: Int): Entity[BaseTypeDecl] =
        self.array_def_with_deref().do((ad) => ad.index_type(dim))

    @with_dynvars(origin)
    fun expr_type(): Entity[BaseTypeDecl] =
        # A BaseTypeDecl in an expression context corresponds to a type
        # conversion, so its type is itself.
        self

    |" Whether self is derived from other_type.
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun is_derived_type(other_type: Entity[BaseTypeDecl]): Bool = {
        val entity_can = self.canonical_type();
        val other_can = other_type.canonical_type();

        (
            # The canonical types are the same
            entity_can == other_can
        )
        or (
            # Other is classwide, and entity's classwide type is the same as
            # other.
            #
            # NOTE: This only works one way::
            #
            #     T'Class.is_derived_type (T) -> False
            #     T.is_derived_type (T'Class) -> True
            other_can.is_classwide()
            and entity_can.classwide_type() == other_can
        )
        or (
            # Recurse on base types
            self.base_types().any((bt) => bt.is_derived_type(other_type))
        )
        or (
            # If both types are classwide, then we also recurse on base types
            # for the specific type of ``self``. While this goes further than
            # the ARM definition of what is a derived type, it is a useful
            # complement.
            entity_can.is_classwide() and other_can.is_classwide()
            and entity_can.as[ClasswideTypeDecl].type_decl().base_types().any(
                (bt) => bt.is_derived_type(other_type)
            )
        )
    }

    |" Return True iff this type is limited, either because it is explicitly
    |" marked as such, or because it inherits from a limited type or has a
    |" component of a limited type. Also note that protected types and task
    |" types are limited by definition. Moreover, note that Ada requires
    |" all parts of a type to agree of its limitedness (e.g. the public view
    |" of a type must indicate that it is limited if its private completion
    |" ends up being limited), hence this property does not require looking at
    |" any other part of the type to determine its limitedness, excepted for
    |" incomplete type declarations. This implies that for illegal code where
    |" several parts don't agree, this property will return the result for the
    |" particular view of the type on which this property is called.
    @exported
    fun is_limited_type(): Bool =
    # This property does not require an "origin" parameter because as
    # explained above, all parts of a type must agree on the fact that the
    # type is limited or not.
    match self {
        case td: TypeDecl => td.type_def.is_limited_type()
        case sb: SubtypeDecl => sb.get_type().is_limited_type()
        case it: IncompleteTypeDecl => it.full_view().is_limited_type()
        case cw: ClasswideTypeDecl => cw.type_decl().is_limited_type()
        case _: ProtectedTypeDecl => true
        case _: TaskTypeDecl => true
        case _ => false
    }

    @with_dynvars(origin)
    fun iterable_comp_type_or_null(): Entity[BaseTypeDecl] =
        if node.is_null then null[Entity[BaseTypeDecl]]
        else
            (if self.is_implicit_deref() then self.accessed_type() else self)
            .iterable_comp_type()

    |" Given a dotted expression A.B, where container_type is the container
    |" type for B, and self is a potential type for A, returns whether self is
    |" a valid type for A in the dotted expression.
    @with_dynvars(origin)
    fun matching_prefix_type(container_type: Entity[BaseTypeDecl]): Bool = {
        val cont_type = container_type;

        (not node.is_null and not container_type.is_null)
        and (
            (
                # Derived type case
                self.matching_formal_prim_type(cont_type)
            )
            or (
                # Access to derived type case
                self.final_accessed_type()?.matching_formal_prim_type(
                    cont_type
                )
            )
            or (
                # Dot notation: The prefix can be a value type and the formal
                # an access type to this value type.
                cont_type.accessed_type().do(
                    (at) => self.matching_formal_prim_type(at)
                )
            )
        )
    }

    |" Whether self is a matching access type for expected_type.
    @with_dynvars(origin)
    fun matching_access_type(
        expected_type: Entity[BaseTypeDecl],
        for_assignment: Bool
    ): Bool = {
        val actual_type = self;

        match expected_type {
            case atd: Entity[AnonymousTypeDecl] =>
                atd.access_def_matches(actual_type, for_assignment)
            case _ =>
                match actual_type {
                    case atd2: Entity[AnonymousTypeDecl] =>
                        atd2.access_def_matches(expected_type, for_assignment)
                    case _ => false
                }
        }
    }

    @with_dynvars(origin)
    @predicate_error("expected $formal_type, got $Self")
    fun matching_formal_prim_type(formal_type: Entity[BaseTypeDecl]): Bool =
        not formal_type.is_null and not node.is_null
        and self.matching_formal_type_impl(formal_type, true)

    @with_dynvars(origin)
    @predicate_error("expected $formal_type, got $Self")
    fun matching_formal_type(formal_type: Entity[BaseTypeDecl]): Bool =
        not formal_type.is_null and not node.is_null
        and self.matching_formal_type_impl(formal_type)

    @with_dynvars(origin)
    fun matching_membership_type(formal_type: Entity[BaseTypeDecl]): Bool =
        not formal_type.is_null and not node.is_null
        and self.matching_formal_type_impl(formal_type, accept_root_types=true)

    @with_dynvars(origin)
    fun matching_formal_type_impl(
        formal_type: Entity[BaseTypeDecl],
        accept_derived: Bool = false,
        accept_root_types: Bool = false
    ): Bool = {
        val actual_type = self;

        (
            (formal_type.is_classwide() or accept_derived)
            and actual_type.specific_type().is_derived_type(formal_type)
        )
        or (
            actual_type.is_classwide()
            and actual_type.specific_type().matching_type(formal_type)
        )
        or (
            # Matching of access types parameters
            actual_type.accessed_type().do(
                (actual_accessed_type) =>
                formal_type.accessed_type().do(
                    (formal_accessed_type) =>
                    (
                        (formal_accessed_type.is_classwide() or accept_derived)
                        and actual_accessed_type.specific_type()
                        .is_derived_type(formal_accessed_type)
                    )
                    or (
                        actual_accessed_type.is_classwide()
                        and actual_accessed_type.specific_type().matching_type(
                            formal_accessed_type
                        )
                    )
                    or (
                        # In a MembershipExpr, if formal_type is a general
                        # access-to-object type, actual_type is convertible to
                        # formal_type (:rmlink:`4.5.2` 30.3/4).
                        accept_root_types
                        and formal_accessed_type.specific_type()
                        .is_derived_type(actual_accessed_type)
                    )
                )
            )
        )
        or (
            not actual_type.get_imp_deref().is_null
            and actual_type.accessed_type().matching_formal_type(formal_type)
        )
        or actual_type.matching_type(formal_type)
    }

    @with_dynvars(origin)
    @predicate_error("expected $expected_type, got $Self")
    fun matching_assign_type(expected_type: Entity[BaseTypeDecl]): Bool = {
        val actual_type = self;

        (not node.is_null and not expected_type.is_null)
        and (
            self.matching_type(expected_type)
            or (
                (
                    expected_type.is_classwide()
                    or expected_type.accessed_type()?.is_classwide()
                )
                and actual_type.matching_formal_prim_type(expected_type)
            )
            or self.matching_access_type(expected_type, true)
        )
    }

    |" Return whether ``self`` matches ``expected_type``.
    @exported
    @with_dynvars(origin=null[AdaNode])
    @predicate_error("expected $expected_type, got $Self")
    fun matching_type(expected_type: Entity[BaseTypeDecl]): Bool = {
        val actual_type = self;

        not expected_type.is_null and not actual_type.is_null
        and (
            {
                val uit = node.universal_int_type();

                (actual_type == uit and expected_type.allows_universal_int())
                or (expected_type == uit and actual_type.is_int_type())
            }
            or {
                val urt = node.universal_real_type();

                (actual_type == urt and expected_type.allows_universal_real())
                or (expected_type == urt and actual_type.is_real_type())
            }
            or {
                val uft = node.universal_fixed_type();

                (expected_type == uft and actual_type.is_fixed_point())
                or (actual_type == uft and expected_type.is_fixed_point())
            }
            or actual_type.canonical_type() == expected_type.canonical_type()
            or (
                not actual_type.get_imp_deref().is_null
                and actual_type.accessed_type().matching_type(expected_type)
            )
            or (
                not expected_type.get_imp_deref().is_null
                and expected_type.accessed_type().matching_type(actual_type)
            )
            or actual_type.matching_access_type(expected_type, false)
        )
    }

    @with_dynvars(origin)
    fun matching_allocator_type(allocated_type: Entity[BaseTypeDecl]): Bool =
        self.is_access_type()
        and allocated_type.matching_formal_type(self.accessed_type())

    |" Return whether this type (after implicit dereference) is or derives
    |" from the standard Boolean type. If this type is null, return False.
    @with_dynvars(origin)
    @predicate_error("expected boolean type, got $Self")
    fun derives_from_std_bool_type(): Bool =
        not node.is_null
        and self.derefed_base_subtype().is_derived_type(node.bool_type())

    @memoized
    fun classwide_type_node(): ClasswideTypeDecl =
        ClasswideTypeDecl(name=node.name)

    |" Helper for scalar_base_subtype. Return the interned node for the
    |" subtype entity.
    @memoized
    fun scalar_base_subtype_node(): DiscreteBaseSubtypeDecl =
        DiscreteBaseSubtypeDecl(name=node.name)

    |" Return the base subtype for this type. Note that this is only legal for
    |" scalar types.
    fun scalar_base_subtype(): Entity[DiscreteBaseSubtypeDecl] =
        node.scalar_base_subtype_node().as_entity

    |" Returns the previous part for this type decl.
    @exported
    @memoized
    fun previous_part(go_to_incomplete: Bool = true): Entity[BaseTypeDecl] =
        if node.is_generic_formal()
        then (
            # A generic formal type never has a previous part
            null[Entity[BaseTypeDecl]]
        )
        elif node is ClasswideTypeDecl
        then
            self.as[ClasswideTypeDecl].type_decl().previous_part(
                go_to_incomplete
            )
            .do((pp) => pp.classwide_type())
        # Otherwise look for the previous part in the immediate enclosing
        # declarative region.
        else
            node.name.do(
                (type_name) =>
                self.semantic_parent().immediate_declarative_region().get(
                    type_name.name_symbol(),
                    lookup=LookupKind.minimal,
                    from=node
                )
                .do(
                    (pp) =>
                    pp.find(
                        (pp) =>
                        (
                            self.is_in_private_part()
                            and pp.as[BaseTypeDecl]?.is_private()
                        )
                        or (go_to_incomplete and pp is IncompleteTypeDecl)
                    )
                )
                .as[BaseTypeDecl]
            )

    |" Returns the next part for this type decl.
    |"
    |" .. note:: Since this property returns a ``BaseTypeDecl``, it cannot be
    |"     used to retrieve the next part of ``TaskTypeDecl`` and
    |"     ``ProtectedTypeDecl`` nodes as their next part is actually a
    |"     ``Body``. Use ``BasicDecl.next_part_for_decl`` for those instead.
    @exported
    @memoized
    fun next_part(): Entity[BaseTypeDecl] = match self {
        case itd: IncompleteTypeDecl =>
            itd.declarative_scope().do(
                # The next part of a (non-private) incomplete type declaration
                # must either be in the same declarative scope...
                (s) => itd.find_next_part_in(s.as_entity)
            )
            or? self.is_in_private_part().do(
                (_) =>
                self.declarative_scope()
                .parent
                .as![BasePackageDecl]
                .as_entity
                .body_part()
                .do(
                    # Or in the particular case of taft-amendment types where
                    # the incomplete decl is in the private part of the package
                    # spec, the next part can be found in the package's body
                    # (RM 3.10.1).
                    (p) => itd.find_next_part_in(p.decls)
                )
            )
        case cwt: ClasswideTypeDecl =>
            {
                val td = cwt.type_decl();

                td.next_part().do(
                    # Sometimes `next_part` returns self itself, so check
                    # that to avoid an infinite loop.
                    (np) => if td == np then cwt else np.classwide_type()
                )
            }
        case _ =>
            if self.is_private() and not self.is_generic_formal()
            then self.private_completion()
            else null[Entity[BaseTypeDecl]]
    }

    |" Return the full completion of this type.
    @exported
    fun full_view(): Entity[BaseTypeDecl] =
        self.next_part().do((np) => np.full_view(), default_val=self)

    |" Returns whether this is a definite subtype.
    |"
    |" For convenience, this will return ``False`` for incomplete types, even
    |" though the correct answer is more akin to "non applicable".
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun is_definite_subtype(): Bool = match self {
        case _: IncompleteTypeDecl => false
        case td: TypeDecl =>
            td.discriminants.is_null
            and match td.type_def {
                case dtd: DerivedTypeDef =>
                    not dtd.subtype_indication.constraint.is_null
                    or dtd.base_type().is_definite_subtype()
                case atd: ArrayTypeDef =>
                    atd.indices is ConstrainedArrayIndices
                case _ => true
            }
        case st: SubtypeDecl =>
            not st.subtype.constraint.is_null
            or st.get_type().is_definite_subtype()
        case _: ClasswideTypeDecl => false
        case ttd: TaskTypeDecl => ttd.discriminants.is_null
        case ptd: ProtectedTypeDecl => ptd.discriminants.is_null
        case _ => true
    }

    |" Return the list of all discriminants of this type. If this type has no
    |" discriminant or only unknown discriminants, an empty list is returned.
    |"
    |" In order to obtain all the discriminants of an extended type, this
    |" property looks on parents, recursively.
    |"
    |" Extended aggregates can be build from any intermediate parent of an
    |" extended type. In that case, this property shouldn't recurse to the
    |" root type, but the one used as the aggregate's ancestor, designated by
    |" ``stop_recurse_at``.
    @exported
    @abstract
    @with_dynvars(origin=null[AdaNode])
    fun discriminants_list(
        stop_recurse_at: Entity[BaseTypeDecl] = null[Entity[BaseTypeDecl]]
    ): Array[Entity[BaseFormalParamDecl]]

    |" If self denotes the declaration of a character type (i.e. an enum type
    |" with character literals) and origin is bound to a character literal,
    |" return the EnumLiteralDecl that symbolically corresponds to the
    |" literal, or synthesize one if the enum type is one of the standard
    |" Character types (we need to synthesize them since we cannot declare
    |" them all in our standard package implementation because of their
    |" number).
    @memoized
    @with_dynvars(origin)
    fun corresponding_char_literal(): Entity[BasicDecl] = {
        val root = self.root_type();
        val enum_type = root.as[TypeDecl]?.type_def.as[EnumTypeDef];
        val sym = origin.as[CharLiteral].do((l) => l.symbol);
        val char_lit =
            enum_type?.enum_literals.find(
                (lit_decl) => lit_decl.name.name_is(sym)
            );

        # If we didn't find a char literal and the enum type is one of the
        # standard characters types, synthesize the corresponding character
        # enum literal.
        if char_lit.is_null and enum_type.is_std_char_type()
        then
            SyntheticCharEnumLit(
                name=null[DefiningName],
                char_symbol=sym,
                enum_type_decl=enum_type.parent.as[TypeDecl]
            )
            .as_entity
        else (
            # Ideally, name should take a SyntheticDefiningName, built from
            # the symbol `sym`, but that would mean that name's parent is
            # self here rather than the SyntheticCharEnumLit we are
            # creating. It matters for the DefiningName.basic_decl property
            # for example. To workaround that issue, we also pass the
            # symbol to the SyntheticCharEnumLit node in order to build the
            # SyntheticDefiningName there, afterwards.
            char_lit
        )
    }

    @with_dynvars(imprecise_fallback=false)
    fun next_part_for_decl(): Entity[BasicDecl] = match self {
        # SingleTaskTypeDecl next part is its parent SingleTaskDecl next
        # part.
        case sttd: SingleTaskTypeDecl =>
            sttd.parent_basic_decl().next_part_for_decl()
        case _: TaskTypeDecl => self.super()
        case _: ProtectedTypeDecl => self.super()
        case _ => self.next_part().as[BasicDecl]
    }

    |" Must be called on a record (sub-)type declaration. Return all the
    |" possible shapes that a value of this record type can take. For example,
    |" consider the following record definition:
    |"
    |" .. code::
    |"
    |"     type R (A : Integer; B : Integer) is record
    |"         X : Integer;
    |"         case A is
    |"             when 1 .. 10 =>
    |"                 Y_1 : Integer;
    |"                 case B is
    |"                     when 1 .. 10 =>
    |"                         Z_1 : Integer;
    |"                     when others => null;
    |"                 end case;
    |"             when 11 .. 20 =>
    |"                 Y_2 : Integer;
    |"                 case B is
    |"                     when 1 .. 10 =>
    |"                         Z_2 : Integer;
    |"                     when others => null;
    |"                 end case;
    |"             when others => null;
    |"         end case;
    |"     end record;
    |"
    |" For this instance, this property will return the following results:
    |"
    |" .. code::
    |"
    |"     [
    |"         [X, Y_1, Z_1],
    |"         [X, Y_1],
    |"         [X, Y_2, Z_2],
    |"         [X, Y_2],
    |"         [X]
    |"     ]
    |"
    |" .. ATTENTION::
    |"     This property is inaccurate when called on a record extension which
    |"     defines components under a certain condition C, and this same
    |"     condition is used to define some components in the parent record:
    |"     in that case, any feasible shape will in practice contain either
    |"     both the components defined under condition C in the child record
    |"     and the parent record, or none of them.
    |"
    |"     However, due to the simplified algorithm we use here to compute the
    |"     feasible shapes, we will also return shapes that include the
    |"     components of the child record but not the parent record, and
    |"     conversely.
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun shapes(include_discriminants: Bool = true): Array[Shape] = {
        val rdef = self.record_def();
        val comps = rdef.components;
        val parent_type = comps.type_def().as[DerivedTypeDef]?.base_type();
        val parent_record = parent_type?.record_def();
        val own_shapes = comps.shapes();
        # include parent shapes only if view on base type is indeed a record
        # (i.e. parent_record is not null).
        val all_shapes =
            parent_record.do(
                (_) =>
                parent_type.shapes(include_discriminants=false).mapcat(
                    (parent_shape) =>
                    own_shapes.map(
                        (own_shape) =>
                        Shape(
                            components=parent_shape.components
                            & own_shape.components,
                            discriminants_values=parent_shape
                            .discriminants_values
                            & own_shape.discriminants_values
                        )
                    )
                ),
                default_val=own_shapes
            );
        val discrs = comps.type_decl().discriminants_list();

        if include_discriminants
        then
            all_shapes.map(
                (s) =>
                Shape(
                    components=discrs & s.components,
                    discriminants_values=s.discriminants_values
                )
            )
        else all_shapes
    }

    |" The environment that contains all subprograms that can be called with
    |" the dot-notation on values of this type.
    @lazy
    dottable_subps_env: LexicalEnv =
        dynamic_lexical_env(
            BaseTypeDecl.dottable_subps,
            transitive_parent=false
        )

    |" Return the list of all subprograms that can be called with the dot-
    |" notation on values of this type.
    |"
    |" This property doesn't implement Ada standard but the GNAT experimental
    |" feature allowing dot-notation for untagged types.
    @memoized
    fun dottable_subps(): Array[InnerEnvAssoc] = {
        val scope = self.declarative_scope();
        val pkg =
            scope?.parent.as[PackageBody].do(
                (body) =>
                {
                    bind imprecise_fallback = false;

                    body.as_entity.previous_part()
                }
                .as[BasePackageDecl],
                default_val=scope?.parent.as[BasePackageDecl].as_entity
            );

        # Ada standard would requier to check that this type is tagged to
        # be called with the dot-notation. We do not comply to the standard
        # here in order to support a GNAT experimental feature which allows
        # to use the dot-notation on untagged types too. See
        # https://github.com/AdaCore/ada-spark-rfcs/blob/master/\
        #   prototyped/rfc-prefixed-untagged.rst.
        # If we are in a package, we look for subprograms that can be
        # called with the dot-notation in the public part, private part and
        # body part of the package this type is declared in.
        if not pkg.is_null
        then
            self.dottable_subps_in_declaratives_parts(
                [
                    pkg.public_part.as[DeclarativePart],
                    pkg.private_part.as[DeclarativePart],
                    pkg.body_part()?.decls
                ]
            )
        # Else, we look for subprograms in the declarative region this
        # type is declared in.
        else self.dottable_subps_in_declaratives_parts([scope.as_entity])
    }

    |" Return the list of all subprograms that can be called with the
    |" dot-notation on values of this type. We look for them in the
    |" declarative parts array ``parts``.
    fun dottable_subps_in_declaratives_parts(
        parts: Array[Entity[DeclarativePart]]
    ): Array[InnerEnvAssoc] =
        parts.mapcat((dp) => dp?.decls.as_array()).filtermap(
            (decl) => {
                val bd = decl.as[BasicDecl];

                InnerEnvAssoc(
                    key=bd.defining_name().name_symbol(),
                    value=bd.node,
                    metadata=Metadata(dottable_subp=true)
                )
            },
            (decl) =>
            decl.as[BasicDecl]?.subp_spec_or_null()?.dottable_subp_of()
            ?.base_subtype()
            == self
        )

    |" Helper function for ``find_base_type_rebindings``, which returns the
    |" first occurrence of the ``target`` type among the super types of the
    |" given array of types using a depth-first search.
    @with_dynvars(origin)
    fun find_base_type_rebindings_among(
        target: BaseTypeDecl,
        base_types: Array[Entity[BaseTypeDecl]],
        index: Int
    ): EnvRebindings =
        if index >= base_types.length() then null[EnvRebindings]
        else
            base_types?[index].find_base_type_rebindings(target)
            or? self.find_base_type_rebindings_among(
                target,
                base_types,
                index + 1
            )

    |" Given self & a target type node, browse the inheritance hierarchy of
    |" self until the target is found, and return its associated rebindings.
    |" For example, consider the following snippet.
    |"
    |" .. code::
    |"
    |"     package My_Vectors is new Ada.Containers.Vectors (...);
    |"
    |"     type My_Vector is new My_Vectors.Vector;
    |"
    |" Calling this property on ``My_Vector`` with the target type
    |" ``Ada.Containers.Vectors.Vector`` will return the rebindings
    |" corresponding to the instantiation in the first line of the snippet
    |" (package My_Vectors).
    @memoized
    @with_dynvars(origin)
    fun find_base_type_rebindings(target: BaseTypeDecl): EnvRebindings =
        if node == target then self.info.rebindings
        else
            self.find_base_type_rebindings_among(
                target=target,
                base_types=self.base_types(),
                index=0
            )

    |" Implementation of ``has_base_type``, which assumes that ``target`` has
    |" been canonicalized.
    fun has_base_type_impl(target: BaseTypeDecl): Bool =
        self.canonical_type().node == target
        or self.base_types().any((bt) => bt.has_base_type_impl(target))

    |" Return whether the given type is amongst the bases types (direct or
    |" indirect) of self.
    |"
    |" .. note:: Unlike ``is_derived_type``, we don't care here about the
    |"     rebindings of ``target``, meaning any instance of ``target`` will
    |"     be accepted.
    fun has_base_type(target: BaseTypeDecl): Bool =
        self.full_view().has_base_type_impl(
            target.as_bare_entity.canonical_type().node
        )

    fun parent_primitives_env(): LexicalEnv = node.empty_env()

    fun primitives_env(): LexicalEnv = null[LexicalEnv]

    |" Return whether this type is a record type.
    |"
    |" .. ATTENTION:: Private tagged types extending public tagged records are
    |"     not considered as record types.
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun is_record_type(): Bool = not self.record_def().is_null

    |" Whether type is a task type
    fun is_task_type(): Bool = false

    |" Whether type is a real type or not.
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun is_real_type(): Bool = false

    |" Whether type is a float type or not.
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun is_float_type(): Bool = false

    |" Whether type is a fixed point type or not.
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun is_fixed_point(): Bool = false

    |" Whether type is an enum type
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun is_enum_type(): Bool = false

    fun is_classwide(): Bool = false

    |" Whether self is an access type or not
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun is_access_type(): Bool = false

    |" Whether self has user defined indexing or not
    fun has_ud_indexing(): Bool = false

    |" For a type with user defined indexing, return the set of all
    |" Constant_Indexing functions.
    fun constant_indexing_fns(): Array[Entity[BasicDecl]] =
        null[Array[Entity[BasicDecl]]]

    |" For a type with user defined indexing, return the set of all
    |" Variable_Indexing functions.
    fun variable_indexing_fns(): Array[Entity[BasicDecl]] =
        null[Array[Entity[BasicDecl]]]

    |" If self has an Implicit_Dereference aspect, return its expression
    fun get_imp_deref(): Entity[Expr] = null[Entity[Expr]]

    @with_dynvars(origin)
    fun access_def(): Entity[AccessDef] = null[Entity[AccessDef]]

    |" Whether type is a character type or not
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun is_char_type(): Bool = false

    # TODO: Not clear if the below origin.bind is correct, investigate later
    |" Return the classwide type for this type, if applicable
    @exported
    fun classwide_type(): Entity[ClasswideTypeDecl] = {
        bind origin = node;

        if self.is_tagged_type() then node.classwide_type_node().as_entity
        else null[Entity[ClasswideTypeDecl]]
    }

    |" Return the discrete range for this type decl, if applicable.
    @exported
    fun discrete_range(): DiscreteRange = null[DiscreteRange]

    |" Whether type is a discrete type or not.
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun is_discrete_type(): Bool =
        (self.is_int_type() or self.is_enum_type()) or self.is_char_type()

    |" Whether type is an integer type or not.
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun is_int_type(): Bool = false

    |" If this type is an access type, or a type with an Implicit_Dereference
    |" aspect, return the type of a dereference of an instance of this type.
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun accessed_type(): Entity[BaseTypeDecl] = null[Entity[BaseTypeDecl]]

    |" Whether type is tagged or not
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun is_tagged_type(): Bool = false

    |" Return the base type entity for this derived type declaration
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun base_type(): Entity[BaseTypeDecl] = null[Entity[BaseTypeDecl]]

    |" Return the list of base types for self.
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun base_types(): Array[Entity[BaseTypeDecl]] =
        self.base_type().do((bt) => [bt]) & self.base_interfaces()

    @with_dynvars(origin)
    fun base_interfaces(): Array[Entity[BaseTypeDecl]] =
        null[Array[Entity[BaseTypeDecl]]]

    @with_dynvars(origin)
    fun record_def(): Entity[BaseRecordDef] = null[Entity[BaseRecordDef]]

    @with_dynvars(origin)
    fun array_def(): Entity[ArrayTypeDef] = null[Entity[ArrayTypeDef]]

    |" Whether self is a type that is iterable in a for .. of loop
    @with_dynvars(origin)
    fun is_iterable_type(): Bool = false

    |" Return True iff this type declaration is an interface definition.
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun is_interface_type(): Bool =
        self.full_view().do(
            (v1) =>
            match v1 {
                case td: TypeDecl => td.type_def is InterfaceTypeDef
                case sb: SubtypeDecl => sb.get_type().is_interface_type()
                case _ => false
            }
        )

    @with_dynvars(origin)
    fun iterable_comp_type(): Entity[BaseTypeDecl] = null[Entity[BaseTypeDecl]]

    @with_dynvars(origin)
    fun iterable_cursor_type(): Entity[BaseTypeDecl] =
        null[Entity[BaseTypeDecl]]

    |" Return the canonical type declaration for this type declaration. For
    |" subtypes, it will return the base type declaration.
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun canonical_type(): Entity[BaseTypeDecl] = {
        bind imprecise_fallback = false;

        self.canonical_part().as[BaseTypeDecl]
    }

    |" Whether node is a private view of corresponding type.
    @exported
    fun is_private(): Bool = false

    |" Return the type that is at the root of the derivation hierarchy
    |" (ignoring secondary interfaces derivations for tagged types)
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun root_type(): Entity[BaseTypeDecl] = self

    env_spec {
        add_to_env_kv(self.name_symbol(), node)
    }
}

|" Base class for subtype declarations (:rmlink:`3.2.2`).
@abstract
class BaseSubtypeDecl: BaseTypeDecl {
    fun from_type_bound(): Entity[BaseTypeDecl] =
    # TODO: This is a hack, to avoid making all of the predicates on types
    # take an origin. But ultimately, for semantic correctness, it will be
    # necessary to remove this, and migrate every property using it to
    # having a dynamic origin parameter.
    {
        bind origin = null[AdaNode];

        self.get_type()
    }

    |" Get the type for this subtype.
    @exported
    @abstract
    @with_dynvars(origin=null[AdaNode])
    fun get_type(): Entity[BaseTypeDecl]

    fun primitives_env(): LexicalEnv = self.from_type_bound().primitives_env()

    @with_dynvars(origin)
    fun array_ndims(): Int = self.get_type().array_ndims()

    @with_dynvars(
        origin, include_ud_indexing=false, dottable_type=null[AdaNode]
    )
    fun defining_env(): LexicalEnv = self.get_type().defining_env()

    @with_dynvars(origin=null[AdaNode])
    fun canonical_type(): Entity[BaseTypeDecl] =
        self.get_type().canonical_type()

    @with_dynvars(origin)
    fun record_def(): Entity[BaseRecordDef] = self.get_type().record_def()

    @with_dynvars(origin=null[AdaNode])
    fun accessed_type(): Entity[BaseTypeDecl] = self.get_type().accessed_type()

    fun is_task_type(): Bool = self.get_type().is_task_type()

    @with_dynvars(origin=null[AdaNode])
    fun is_int_type(): Bool = self.get_type().is_int_type()

    @with_dynvars(origin=null[AdaNode])
    fun is_discrete_type(): Bool = self.get_type().is_discrete_type()

    @with_dynvars(origin=null[AdaNode])
    fun is_real_type(): Bool = self.get_type().is_real_type()

    @with_dynvars(origin=null[AdaNode])
    fun is_float_type(): Bool = self.get_type().is_float_type()

    @with_dynvars(origin=null[AdaNode])
    fun is_fixed_point(): Bool = self.get_type().is_fixed_point()

    @with_dynvars(origin=null[AdaNode])
    fun is_enum_type(): Bool = self.get_type().is_enum_type()

    @with_dynvars(origin=null[AdaNode])
    fun is_access_type(): Bool = self.get_type().is_access_type()

    @with_dynvars(origin)
    fun access_def(): Entity[AccessDef] = self.get_type().access_def()

    @with_dynvars(origin=null[AdaNode])
    fun is_char_type(): Bool = self.get_type().is_char_type()

    @with_dynvars(origin=null[AdaNode])
    fun is_tagged_type(): Bool = self.get_type().is_tagged_type()

    @with_dynvars(origin=null[AdaNode])
    fun base_type(): Entity[BaseTypeDecl] = self.get_type().base_type()

    @with_dynvars(origin)
    fun base_interfaces(): Array[Entity[BaseTypeDecl]] =
        self.get_type().base_interfaces()

    @with_dynvars(origin=null[AdaNode])
    fun base_types(): Array[Entity[BaseTypeDecl]] =
        self.get_type().base_types()

    @with_dynvars(origin)
    fun array_def(): Entity[ArrayTypeDef] = self.get_type().array_def()

    fun is_classwide(): Bool = self.from_type_bound().is_classwide()

    @with_dynvars(origin)
    fun is_iterable_type(): Bool = self.get_type().is_iterable_type()

    @with_dynvars(origin)
    fun iterable_comp_type(): Entity[BaseTypeDecl] =
        self.get_type().iterable_comp_type()

    @with_dynvars(origin)
    fun iterable_cursor_type(): Entity[BaseTypeDecl] =
        self.get_type().iterable_cursor_type()

    @with_dynvars(origin=null[AdaNode])
    fun is_record_type(): Bool = self.get_type().is_record_type()

    fun is_private(): Bool = self.from_type_bound().is_private()

    @with_dynvars(origin=null[AdaNode])
    fun root_type(): Entity[BaseTypeDecl] = self.get_type().root_type()

    fun has_ud_indexing(): Bool = self.from_type_bound().has_ud_indexing()

    fun constant_indexing_fns(): Array[Entity[BasicDecl]] =
        self.from_type_bound().constant_indexing_fns()

    fun variable_indexing_fns(): Array[Entity[BasicDecl]] =
        self.from_type_bound().variable_indexing_fns()

    @with_dynvars(origin=null[AdaNode])
    fun discriminants_list(
        stop_recurse_at: Entity[BaseTypeDecl] = null[Entity[BaseTypeDecl]]
    ): Array[Entity[BaseFormalParamDecl]] =
        self.get_type().discriminants_list(stop_recurse_at)
}

|" Specific ``BaseSubtypeDecl`` synthetic subclass for the base type of scalar
|" types.
@synthetic
class DiscreteBaseSubtypeDecl: BaseSubtypeDecl {
    @parse_field
    @null_field
    aspects: AspectSpec

    @with_dynvars(imprecise_fallback=false)
    # TODO: If base subtype is from a formal type, then False
    fun is_static_decl(): Bool = true

    @with_dynvars(origin=null[AdaNode])
    fun get_type(): Entity[BaseTypeDecl] =
        node.parent.as![BaseTypeDecl].as_entity
}

|" Subtype declaration (:rmlink:`3.2.2`).
class SubtypeDecl: BaseSubtypeDecl {
    @parse_field
    subtype: SubtypeIndication
    @parse_field
    aspects: AspectSpec

    @with_dynvars(origin=null[AdaNode])
    fun get_type(): Entity[BaseTypeDecl] = match
        self.subtype.designated_type()
    {
        case st: SubtypeDecl => st.get_type()
        case t => t
    }

    @memoized
    fun get_imp_deref(): Entity[Expr] = self.get_type().get_imp_deref()

    fun discrete_range(): DiscreteRange = self.subtype.discrete_range()

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = self.subtype.sub_equation()

    @with_dynvars(imprecise_fallback=false)
    fun is_static_decl(): Bool = self.subtype.is_static_subtype()

    fun xref_entry_point(): Bool = true

    env_spec {
        add_to_env_kv(self.name_symbol(), node)
        # Subtype predicates expressions can refers to its own subtype
        # declaration identifier as an object such as in::
        #
        #     subtype Odd is Natural with
        #        Dynamic_Predicate => Odd mod 2 = 1;
        #
        # where ``Odd`` should refer to an anonymous object of the same name
        # and of its own subtype. This object only virtually exists in the
        # subtype environment, so we add a children environement here, just to
        # hold this object.
        add_env(transitive_parent=true)
        add_single_to_env(self.synthetic_object_decl_env_assoc)
    }
}

|" Synthetic node (not parsed, generated from a property call). Refers to the
|" classwide type for a given tagged type (:rmlink:`3.4.1`).
@synthetic
class ClasswideTypeDecl: BaseTypeDecl {
    @parse_field
    @null_field
    aspects: AspectSpec

    fun type_decl(): Entity[BaseTypeDecl] = self.parent.as[BaseTypeDecl]

    fun is_classwide(): Bool = true

    @with_dynvars(origin=null[AdaNode])
    fun is_tagged_type(): Bool = true

    @with_dynvars(origin=null[AdaNode])
    fun base_type(): Entity[BaseTypeDecl] = null[Entity[BaseTypeDecl]]

    @with_dynvars(origin)
    fun base_interfaces(): Array[Entity[BaseTypeDecl]] =
        null[Array[Entity[BaseTypeDecl]]]

    @with_dynvars(origin)
    fun record_def(): Entity[BaseRecordDef] = self.type_decl().record_def()

    fun classwide_type(): Entity[ClasswideTypeDecl] = self

    @with_dynvars(origin)
    fun is_iterable_type(): Bool = self.type_decl().is_iterable_type()

    fun has_ud_indexing(): Bool = self.type_decl().has_ud_indexing()

    fun constant_indexing_fns(): Array[Entity[BasicDecl]] =
        self.type_decl().constant_indexing_fns()

    fun variable_indexing_fns(): Array[Entity[BasicDecl]] =
        self.type_decl().variable_indexing_fns()

    fun is_task_type(): Bool = self.type_decl().is_task_type()

    @with_dynvars(origin)
    fun iterable_comp_type(): Entity[BaseTypeDecl] =
        self.type_decl().iterable_comp_type()

    @with_dynvars(
        origin, include_ud_indexing=false, dottable_type=null[AdaNode]
    )
    fun defining_env(): LexicalEnv = self.type_decl().defining_env()

    fun is_private(): Bool = self.type_decl().is_private()

    fun is_in_private_part(): Bool = self.type_decl().is_in_private_part()

    fun is_in_public_part(): Bool = self.type_decl().is_in_public_part()

    fun get_aspect_spec(): Entity[AspectSpec] =
        self.type_decl().get_aspect_spec()

    @with_dynvars(origin=null[AdaNode])
    fun is_interface_type(): Bool = self.type_decl().is_interface_type()

    @with_dynvars(origin=null[AdaNode])
    fun discriminants_list(
        stop_recurse_at: Entity[BaseTypeDecl] = null[Entity[BaseTypeDecl]]
    ): Array[Entity[BaseFormalParamDecl]] =
        self.type_decl().discriminants_list(stop_recurse_at)

    @with_dynvars(origin=null[AdaNode])
    fun canonical_type(): Entity[BaseTypeDecl] =
        self.type_decl().canonical_type().do(
            # The canonical type should be classwide whenever it makes sense
            # (e.g. if the canonical type is a tagged record type.) Otherwise
            # return a non-classwide type.
            (t) => t.classwide_type() or? t
        )

    # We don't want to add the classwide type to the environment
    env_spec {
    }
}

|" Incomplete declaration for a type (:rmlink:`12.5`).
class IncompleteTypeDecl: BaseTypeDecl {
    @parse_field
    @nullable
    discriminants: DiscriminantPart
    @parse_field
    @null_field
    aspects: AspectSpec

    |" Searches for the next part of self inside the given declarative part.
    |" Since self is an IncompleteTypeDecl, the next part will necessarily be
    |" the first type declaration of the same name that is not self.
    fun find_next_part_in(
        decl_part: Entity[DeclarativePart]
    ): Entity[BaseTypeDecl] =
        decl_part.children_env.get(
            node.name_symbol(),
            lookup=LookupKind.minimal,
            categories=RefCategories(inherited_primitives=false, _=true)
        )
        .find((t) => t.as[BaseTypeDecl].do((btd) => self != btd))
        .as[BaseTypeDecl]

    @with_dynvars(
        origin, include_ud_indexing=false, dottable_type=null[AdaNode]
    )
    fun defining_env(): LexicalEnv =
        [node.children_env, node.dottable_subps_env].env_group()

    @with_dynvars(origin=null[AdaNode])
    fun discriminants_list(
        @ignored
        stop_recurse_at: Entity[BaseTypeDecl] = null[Entity[BaseTypeDecl]]
    ): Array[Entity[BaseFormalParamDecl]] =
        self.discriminants.abstract_formal_params()

    env_spec {
        add_to_env_kv(self.name_symbol(), node)
        add_env()
    }
}

|" A formal incomplete type declaration.
class IncompleteFormalTypeDecl: IncompleteTypeDecl {
    @parse_field
    @nullable
    is_tagged: Tagged
    @parse_field
    @nullable
    default_type: Name

    @with_dynvars(origin=null[AdaNode])
    fun is_tagged_type(): Bool = not node.is_tagged.is_null

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = self.default_type.sub_equation()
}

|" Incomplete declaration for a tagged type.
class IncompleteTaggedTypeDecl: IncompleteTypeDecl {
    @parse_field
    has_abstract: Abstract

    @with_dynvars(origin=null[AdaNode])
    fun is_tagged_type(): Bool = true
}

|" Declaration for a protected type (:rmlink:`9.4`).
class ProtectedTypeDecl: BaseTypeDecl {
    @parse_field
    @nullable
    discriminants: DiscriminantPart
    @parse_field
    aspects: AspectSpec
    @parse_field
    interfaces: ParentList
    @parse_field
    definition: ProtectedDef

    @with_dynvars(origin=null[AdaNode])
    fun discriminants_list(
        @ignored
        stop_recurse_at: Entity[BaseTypeDecl] = null[Entity[BaseTypeDecl]]
    ): Array[Entity[BaseFormalParamDecl]] =
        self.discriminants.abstract_formal_params()

    @with_dynvars(
        origin, include_ud_indexing=false, dottable_type=null[AdaNode]
    )
    fun defining_env(): LexicalEnv =
        self.definition.private_part.do(
            (pp) =>
            # Include private_part's env unconditionally. This is safe since
            # ProtectedTypeDecl can't be overloaded, thus wrong name resolution
            # can only occur on invalid Ada code.
            [self.children_env, pp.children_env].env_group(),
            default_val=self.children_env
        )

    @with_dynvars(origin)
    fun base_interfaces(): Array[Entity[BaseTypeDecl]] =
        self.interfaces.map((i) => i.name_designated_type())

    fun xref_entry_point(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.interfaces.logic_all((ifc) => ifc.xref_equation())

    fun declarative_parts(): Array[Entity[DeclarativePart]] = {
        val pdef = self.definition;

        [pdef.public_part.as[DeclarativePart]]
        & pdef.private_part.as[DeclarativePart].do((v1) => [v1])
    }

    fun env_names(): Array[Symbol] =
        node.top_level_env_name().do((fqn) => [fqn.to_symbol])

    env_spec {
        add_to_env_kv(self.name_symbol(), node)
        add_env(names=node.env_names())
    }
}

|" Declaration for a task type (:rmlink:`9.1`).
class TaskTypeDecl: BaseTypeDecl {
    @parse_field
    @nullable
    discriminants: DiscriminantPart
    @parse_field
    aspects: AspectSpec
    @parse_field
    @nullable
    definition: TaskDef

    fun is_task_type(): Bool = true

    @with_dynvars(origin)
    fun base_interfaces(): Array[Entity[BaseTypeDecl]] =
        self.definition?.interfaces.map((i) => i.name_designated_type())

    fun env_names(): Array[Symbol] =
        node.top_level_env_name().do((fqn) => [fqn.to_symbol])

    @with_dynvars(
        origin, include_ud_indexing=false, dottable_type=null[AdaNode]
    )
    fun defining_env(): LexicalEnv = self.children_env

    @memoized
    fun primitives_env(): LexicalEnv =
        self.compute_primitives_env(include_self=true)

    @with_dynvars(origin=null[AdaNode])
    fun discriminants_list(
        @ignored
        stop_recurse_at: Entity[BaseTypeDecl] = null[Entity[BaseTypeDecl]]
    ): Array[Entity[BaseFormalParamDecl]] =
        self.discriminants.abstract_formal_params()

    fun xref_entry_point(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.definition.do((d) => d.xref_equation(), default_val=%true)

    fun declarative_parts(): Array[Entity[DeclarativePart]] =
        self.definition.do(
            (tdef) =>
            [tdef.public_part.as[DeclarativePart]]
            & tdef.private_part.as[DeclarativePart].do((v1) => [v1])
        )

    env_spec {
        add_to_env_kv(self.name_symbol(), node)
        add_env(names=node.env_names())
    }
}

|" Type declaration for a single task (:rmlink:`9.1`).
class SingleTaskTypeDecl: TaskTypeDecl {
    env_spec {
        # In this case, we don't want to add this type to the env, because it's
        # the single task that contains this type decl that will be added to
        # the env. So we don't call the inherited env spec.
        add_env()
    }
}

|" Type declarations that embed a type definition node. Corresponds to the
|" ARM's full type declarations (:rmlink:`3.2.1`).
@abstract
class TypeDecl: BaseTypeDecl {
    @parse_field
    @nullable
    discriminants: DiscriminantPart
    @parse_field
    type_def: TypeDef

    |" Whether self is a type that is iterable in a for .. of loop
    @with_dynvars(origin)
    fun is_iterable_type(): Bool =
        self.is_array()
        or not self.get_aspect(s"Iterator_Element", true)
        .value
        .is_null
        # TODO: The optional `Element` assoc must be defined, if not, a
        # type with the aspect `Iterable` only supports iteration over
        # cursors through the `for .. in` loop (W303-007).
        or not self.get_aspect(s"Iterable", true).value.is_null

    @with_dynvars(origin)
    fun iterable_comp_type(): Entity[BaseTypeDecl] = {
        val ie = self.get_aspect(s"Iterator_Element", true).value;
        val it = self.get_aspect(s"Iterable", true).value;

        {
            bind imprecise_fallback = false;

            if self.is_array() then self.comp_type()
            elif not ie.is_null
            then
                ie.as[Name].do(
                    (name) => {
                        bind env = name.node_env;

                        name.designated_type_impl()
                    }
                )
            elif not it.is_null
            then
                it.as[Aggregate].assocs.unpacked_params().find(
                    (sa) => sa.name.name_is(s"Element")
                )
                .assoc
                .expr()
                .as![Name]
                .referenced_decl()
                .expr_type()
            else null[Entity[BaseTypeDecl]]
        }
    }

    |" If self is a type that is iterable (i.e.: it has the Iterable aspect
    |" defined), return the type of the cursor in use by this iterable type.
    @with_dynvars(origin)
    fun iterable_cursor_type(): Entity[BaseTypeDecl] =
        self.get_aspect(s"Iterable", previous_parts_only=true).value.do(
            (it) =>
            it.as[Aggregate].assocs.unpacked_params().find(
                (sa) => sa.name.name_is(s"First")
            )
            .assoc
            .expr()
            .as![Name]
            .referenced_decl()
            .expr_type()
        )

    fun discrete_range(): DiscreteRange = self.type_def.discrete_range()

    @with_dynvars(origin=null[AdaNode])
    fun discriminants_list(
        stop_recurse_at: Entity[BaseTypeDecl] = null[Entity[BaseTypeDecl]]
    ): Array[Entity[BaseFormalParamDecl]] = {
        # TODO: investigate if below origin.bind is valid
        val base_type = self.base_type();
        val self_discs =
            self.discriminants.do((d) => d.abstract_formal_params());

        if self.is_access_type()
        then self.accessed_type().discriminants_list(stop_recurse_at)
        elif self_discs.length() > 0 then self_discs
        elif not base_type.is_null and base_type.matching_type(stop_recurse_at)
        then self_discs
        elif not base_type.is_null
        then self.base_type().discriminants_list(stop_recurse_at)
        else null[Array[Entity[BaseFormalParamDecl]]]
    }

    @with_dynvars(origin)
    fun array_ndims(): Int = self.type_def.array_ndims()

    @with_dynvars(origin=null[AdaNode])
    fun is_real_type(): Bool = self.type_def.is_real_type()

    @with_dynvars(origin=null[AdaNode])
    fun is_float_type(): Bool = self.type_def.is_float_type()

    @with_dynvars(origin=null[AdaNode])
    fun is_fixed_point(): Bool = self.type_def.is_fixed_point()

    @with_dynvars(origin=null[AdaNode])
    fun is_int_type(): Bool = self.type_def.is_int_type()

    @with_dynvars(origin=null[AdaNode])
    fun is_access_type(): Bool = node.as_bare_entity.type_def.is_access_type()

    @with_dynvars(imprecise_fallback=false)
    fun is_static_decl(): Bool = node.as_bare_entity.type_def.is_static()

    @with_dynvars(origin=null[AdaNode])
    fun accessed_type(): Entity[BaseTypeDecl] = {
        val imp_deref = self.get_imp_deref();

        if imp_deref.is_null then self.type_def.accessed_type()
        else (
            # Here, we need to call defining_env on TypeDef, in order to not
            # recurse for ever (accessed_type is called by defining_env).
            {
                bind include_ud_indexing = false;

                self.type_def.defining_env().get_first(
                    imp_deref.as[Name].name_symbol(),
                    categories=RefCategories(
                        inherited_primitives=false,
                        _=true
                    )
                )
            }

            # We cast to BaseFormalParamDecl. Following Ada's legality rule,
            # you need to implicit deref on a discriminant, but I see no reason
            # to enforce that here.
            .as![BaseFormalParamDecl]
            .formal_type()
            .accessed_type()
        )
    }

    @with_dynvars(origin)
    fun access_def(): Entity[AccessDef] = match self.type_def {
        case ad: AccessDef => ad
        case dtd: DerivedTypeDef => dtd.base_type().access_def()
        case _ => null[Entity[AccessDef]]
    }

    @with_dynvars(origin=null[AdaNode])
    fun is_tagged_type(): Bool = self.type_def.is_tagged_type()

    fun is_task_type(): Bool = self.type_def.is_task_type()

    @with_dynvars(origin=null[AdaNode])
    fun base_type(): Entity[BaseTypeDecl] = self.type_def.base_type()

    @with_dynvars(origin)
    fun base_interfaces(): Array[Entity[BaseTypeDecl]] =
        self.type_def.base_interfaces()

    @with_dynvars(origin=null[AdaNode])
    fun is_char_type(): Bool = self.type_def.is_char_type()

    @with_dynvars(origin=null[AdaNode])
    fun is_enum_type(): Bool = self.type_def.is_enum_type()

    fun is_private(): Bool =
        node.type_def is PrivateTypeDef
        or node.type_def.as[DerivedTypeDef].do(
            (dtd) => dtd.has_with_private.as_bool()
        )

    fun is_derived_tagged_type(): Bool =
        self.type_def.is_tagged_type()
        and self.type_def is DerivedTypeDef | InterfaceTypeDef

    @with_dynvars(origin)
    fun array_def(): Entity[ArrayTypeDef] = match self.type_def {
        case atd: ArrayTypeDef => atd
        case dtd: DerivedTypeDef => dtd.base_type().array_def()
        case _ => null[Entity[ArrayTypeDef]]
    }

    @with_dynvars(origin=null[AdaNode])
    fun root_type(): Entity[BaseTypeDecl] = match self.type_def {
        case dtd: DerivedTypeDef => dtd.base_type().root_type()
        case _ => self
    }

    @with_dynvars(
        origin, include_ud_indexing=false, dottable_type=null[AdaNode]
    )
    fun defining_env(): LexicalEnv = {
        val imp_deref = self.get_imp_deref();
        # Evaluating in type env, because the defining environment of a type
        # is always its own.
        val self_env = self.type_def.defining_env();

        if not imp_deref.is_null
        then [self_env, self.accessed_type().defining_env()].env_group()
        elif include_ud_indexing and self.has_ud_indexing()
        then {
            bind include_ud_indexing = false;

            (
                (self.constant_indexing_fns() & self.variable_indexing_fns())
                .map((fn) => fn.defining_env())
                & [self_env]
            )
            .env_group()
        }
        else self_env
    }

    @memoized
    fun primitives_env(): LexicalEnv =
        self.compute_primitives_env(include_self=true)

    |" Return all the predefined operators for this type, as an array of env
    |" associations ready to be added to a lexical environment.
    |"
    |" Note that the universal int and universal real types are not real
    |" type declarations and do not have their own operators
    |" (:rmlink:`3.4.1` - 7).
    @memoized
    fun predefined_operators(): Array[EnvAssoc] =
        if self in node.universal_int_type() | node.universal_real_type()
        then null[Array[EnvAssoc]]
        elif self == node.universal_fixed_type()
        then
            node
            .type_def
            .as[RealTypeDef]
            .universal_fixed_predefined_operators()
        else node.type_def.predefined_operators()

    @with_dynvars(origin)
    fun record_def(): Entity[BaseRecordDef] = match self.type_def {
        case r: RecordTypeDef => r.record_def

        # If the derived type is tagged, then return its own record def. If
        # it isn't tagged, return the base type's record def.
        case d: DerivedTypeDef =>
            if self.is_tagged_type() then d.record_extension
            else d.base_type()?.record_def()
        case _ => null[Entity[BaseRecordDef]]
    }

    fun xref_entry_point(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = # TODO: Handle discriminants
        self
        .type_def
        .sub_equation()

    @with_dynvars(origin=null[AdaNode])
    fun is_discrete_type(): Bool = self.type_def.is_discrete_type()

    fun parent_primitives_env(): LexicalEnv =
        if node.type_def is DerivedTypeDef | InterfaceTypeDef
        then self.compute_primitives_env(include_self=false)
        else node.empty_env()

    |" Return a lexical environment containing the primitives inherited by
    |" this type. This makes sure not to re-include primitives which have
    |" already been inherited by the previous part of this type, so as to:
    |"
    |"  - Not overload lexical envs with useless entries (when one has view
    |"    on this part, it necessarily has view on its previous part).
    |"
    |"  - But most importantly, to fix a visibility issue arising when
    |"    resolving a reference to a subprogram overridden in the public part
    |"    of a package if the type has a refined declaration in its private
    |"    part, in which case the inherited subprogram would take precedence
    |"    over the overridden one (see testcase precise_override_2, U817-024).
    |"
    |"    This change fixes this issue because, by construction, if the
    |"    overridden subprogram lies in the public part, it means the public
    |"    type declaration already has a view on the inherited subprogram,
    |"    which means we won't include it in the environment computed here
    |"    for the private view.
    fun refined_parent_primitives_env(): LexicalEnv =
        self.compute_primitives_env(
            include_self=false,
            stop_at=self.previous_part()?.base_types()
        )

    fun get_imp_deref(): Entity[Expr] =
        # Fast path: as the ``Implicit_Deference`` must refer to a
        # discriminant, we know the aspect cannot be defined if this type
        # doesn't have a discriminant part. Besides, if some part of a type
        # defines a discriminant part, then the next parts will necessarily
        # repeat it, therefore we don't need to recurse on this type's previous
        # part. This logic is however not valid for derived types, so don't
        # include them in the fast path.
        if node.discriminants.is_null and not node.type_def is DerivedTypeDef
        then null[Entity[Expr]]
        else self.get_aspect(s"Implicit_Dereference", true).value

    fun has_ud_indexing(): Bool =
        not self.get_aspect(s"Constant_Indexing", true).value.is_null
        or not self.get_aspect(s"Variable_Indexing", true).value.is_null

    |" Return the indexing functions locally defined for this type. If the
    |" type is the one for which the aspect has been defined, then return its
    |" corresponding user-defined functions. If this type is derived from a
    |" type having the aspect, this property only returns any overrides
    |" defined for it.
    fun indexing_fns(name: Entity[Name]): Array[Entity[BasicDecl]] =
        name.do(
            (name) => {
                bind env = self.node_env;
                bind origin = self.origin_node();

                # Get all elements for name in self's env
                name.all_env_els_impl(seq=false)
            }
        )
        .filtermap(
            (e) => e.as[BasicDecl],
            (e) =>
            e.as![BasicDecl].subp_spec_or_null().do(
                (ss) => {
                    bind origin = e.node;

                    # Unfortunately, we can't use `UserDefinedFunctionSubpSpec`
                    # (as in `user_defined_literal_fns`) here to filter
                    # candidates since user defined functions can have many
                    # parameters without any constraints on them. Only the
                    # first parameter should be a the type of self.
                    ss.unpacked_formal_params()?[0]?.formal_decl()
                    .formal_type()
                    .matching_formal_type(self)
                }
            )
        )
        .unique()

    |" Get all the indexing functions designated by ``name`` defined for
    |" this type by recursing parent types until ``root_type``.
    fun all_indexing_fns_impl(
        name: Entity[Name],
        root_type: Entity[TypeDecl]
    ): Array[Entity[BasicDecl]] =
        self.indexing_fns(name)
        & self.base_type().do(
            (bt) =>
            # The user indexing functions can be overriden, so recurse on all
            # base types to get them all.
            if self == root_type then null[Array[Entity[BasicDecl]]]
            else bt.as![TypeDecl].all_indexing_fns_impl(name, root_type)
        )

    |" Return all the indexing functions defined for this type, including
    |" ones defined by its parents.
    fun all_indexing_fns(sym: Symbol): Array[Entity[BasicDecl]] =
        self.get_aspect(sym, true).value.do(
            (value) => {
                # The indexing function's name is specified on the type for
                # which the aspect is defined (which is returned by
                # `get_aspect` here).
                val fn_name = value.as![Name];
                # The root type of the type derivation chain (to stop the
                # recursion in `all_indexing_fns`).
                val root_type = value.parent.parent.as[TypeDecl];

                self.all_indexing_fns_impl(fn_name, root_type)
            }
        )

    fun constant_indexing_fns(): Array[Entity[BasicDecl]] =
        self.all_indexing_fns(s"Constant_Indexing")

    fun variable_indexing_fns(): Array[Entity[BasicDecl]] =
        self.all_indexing_fns(s"Variable_Indexing")

    |" Return the functions detoned by the user defined literal aspect
    |" ``aspect`` for this type.
    fun user_defined_literal_fns(aspect: Symbol): Array[Entity[BasicDecl]] = {
        # User-defined literal aspects denote a function with a result type of
        # ``self`` and one parameter that is of type ``String`` (or
        # ``Wide_Wide_String`` for ``String_Literal``).
        val expected_spec =
            UserDefinedFunctionSubpSpec(
                subp_params_types=[
                    if aspect == s"String_Literal"
                    then node.std_wide_wide_string_type()
                    else node.std_string_type()
                ],
                subp_return_type=self
            );
        # ``Real_Literal`` detoned function can be overrode by a function with
        # a result type of ``self`` and two parameters that are of type
        # ``String``.
        val expected_specs =
            [
                if aspect == s"Real_Literal"
                then
                    UserDefinedFunctionSubpSpec(
                        subp_params_types=[
                            node.std_string_type(), node.std_string_type()
                        ],
                        subp_return_type=self
                    )
                else null[UserDefinedFunctionSubpSpec]
            ]
            & [expected_spec];

        self.get_aspect_spec_expr(aspect).do(
            (a) =>
            a.as![Name].all_env_elements_internal(seq=false).filtermap(
                (e) => e.as[BasicDecl],
                (e) =>
                e.as![BasicDecl].subp_spec_or_null().do(
                    (ss) =>
                    expected_specs.any(
                        (es) => ss.match_expected_user_defined_function(es)
                    )
                )
            )
        )
    }

    env_spec {
        add_to_env_kv(self.name_symbol(), node)
        add_all_to_env(node.as_entity.predefined_operators())
        add_env()
        handle_children()
        # Add a synthetic object declaration into its environement in order to
        # support name resolution of self-references that can appear in
        # predicates (see `SyntheticObjectDecl`) or in a records' body.
        # TODO: This could be added conditionally to avoid polluting envs with
        # unnecessary objects if we can statically detect whether it will be
        # useful or not, for example by checking if `Predicate` aspect is
        # specified on this type. However, it is not as easy because there can
        # `Predicate` pragmas defined *after* this.
        add_single_to_env(self.synthetic_object_decl_env_assoc)
        # Make sure the reference to the primitives env is created *AFTER* the
        # synthetic type predicate object has been added to self's env: since
        # this object has the same name as the type, it is indirectly used to
        # hide the type and avoid infinite recursions in invalid Ada code such
        # as ``type X is new X``. See nameres test `invalid_self_reference`.
        reference(
            [node.as[AdaNode]],
            TypeDecl.refined_parent_primitives_env,
            kind=transitive,
            dest_env=node.node_env,
            cond=node.type_def is DerivedTypeDef | InterfaceTypeDef,
            category="inherited_primitives"
        )
    }
}

|" Anonymous type declaration (for anonymous array or access types). This
|" class has no RM existence, and anonymous (sub)types are referred to
|" implicitly in the RM.
class AnonymousTypeDecl: TypeDecl {
    @parse_field
    @null_field
    aspects: AspectSpec

    |" Returns whether:
    |"
    |" 1. self and other are both access types.
    |" 2. Their access def matches structurally. If for_assignment is True,
    |"    matching_assign_type is used instead of matching_type to compare
    |"    the two access defs.
    @with_dynvars(origin)
    fun access_def_matches(
        other: Entity[BaseTypeDecl],
        for_assignment: Bool
    ): Bool = {
        val self_subp_access = self.type_def.as[AccessToSubpDef];
        val other_subp_access = other.access_def().as[AccessToSubpDef];

        # If the anonymous type is an access type definition, then verify if
        #  the accessed type corresponds to other's accessed type.
        if not self_subp_access.is_null and not other_subp_access.is_null
        then
            other_subp_access.subp_spec.match_signature(
                self_subp_access.subp_spec,
                false
            )
        elif self_subp_access.is_null and other_subp_access.is_null
        then
            self.type_def.as[AccessDef]?.accessed_type().do(
                (ast) =>
                other.accessed_type().do(
                    (oat) => {
                        # Forget the classwide view: GNAT always allows
                        # comparison/assignment between access-to-T and
                        # access-to-T'Class.
                        val exp = ast.specific_type();
                        val act = oat.specific_type();

                        if for_assignment
                        then (
                            # Pass the possibly-classwide view of the expected
                            # type here, because matching_assign_type will
                            # handle this case specifically.
                            act.matching_assign_type(ast)
                        )
                        else act.matching_type(exp)
                    }
                )
            )
        else false
    }

    fun xref_entry_point(): Bool = false

    # We don't want to add anonymous type declarations to the lexical
    # environments, so we reset the env spec.
    env_spec {
    }
}

|" Synthetic anonymous type decl. Used to generate anonymous access types.
@synthetic
class SynthAnonymousTypeDecl: AnonymousTypeDecl {
}

|" A concrete type declaration.
class ConcreteTypeDecl: TypeDecl {
    @parse_field
    aspects: AspectSpec
}

|" A formal type declaration.
class FormalTypeDecl: TypeDecl {
    @parse_field
    @nullable
    default_type: Name
    @parse_field
    aspects: AspectSpec

    |" Retrieves the actual for this formal type decl by finding the generic
    |" formal part in which self lies in self's rebindings, and then resolving
    |" the corresponding actual.
    fun corresponding_actual_impl(rb: EnvRebindings): Entity[BaseTypeDecl] =
        if rb.is_null then self
        elif rb.old_env == node.parent.node_env
        then
            rb.new_env.get_first(
                self.defining_name().name_symbol(),
                lookup=LookupKind.minimal,
                categories=RefCategories(inherited_primitives=false, _=true)
            )
            .as[BaseTypeDecl]
        else self.corresponding_actual_impl(rb.get_parent)

    |" For a ``FormalTypeDecl`` we must find the actual by looking in our own
    |" rebindings. See ``corresponding_actual_impl``.
    fun get_actual(): Entity[BaseTypeDecl] =
        self.corresponding_actual_impl(self.info.rebindings)

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.super()
        %and self.default_type.do((dt) => dt.sub_equation(), default_val=%true)
}

|" Base class for subprogram declarations.
@abstract
class BasicSubpDecl: BasicDecl {
    fun defining_names(): Array[Entity[DefiningName]] =
        [self.subp_decl_spec().name()]

    @with_dynvars(
        origin, include_ud_indexing=false, dottable_type=null[AdaNode]
    )
    fun defining_env(): LexicalEnv = self.subp_decl_spec().defining_env()

    |" The expr type of a subprogram declaration is the return type of the
    |" subprogram if the subprogram is a function.
    fun type_expression(): Entity[TypeExpr] = self.subp_decl_spec().returns()

    @with_dynvars(imprecise_fallback=false)
    fun get_body_in_env(env: LexicalEnv): Entity[Body] = {
        val elements =
            env.get(
                self.name_symbol(),
                lookup=LookupKind.flat,
                categories=RefCategories(inherited_primitives=false, _=true)
            );
        val self_spec = self.subp_decl_spec().node.as_bare_entity;
        val precise = {
            bind origin = self_spec.origin_node();

            elements.find(
                (ent) =>
                # Discard the rebindings of self before trying to match
                # against the tentative body, as those do not carry that info.
                ent.node.as_bare_entity.as[Body]?.formal_param_holder_or_null()
                .match_other(self_spec, true)
            )
            .as[Body]
        };
        val result =
            if precise.is_null and imprecise_fallback
            then elements.find((e) => e is Body).as[Body]
            else precise;

        # If found, reuse the rebindings of the decl on the body
        result.node.as_entity?.without_md().as[Body]
    }

    @with_dynvars(imprecise_fallback=false)
    fun next_part_for_decl(): Entity[BasicDecl] = {
        val decl_scope = self.declarative_scope();
        val parent_decl =
            decl_scope.as_entity.do(
                (ds) => ds.semantic_parent().as[BasicDecl]
            );
        val default_next_part = self.super();

        # If __nextpart is registered in the decl's env, simply return
        # that.
        if not default_next_part.is_null then default_next_part
        elif decl_scope is PrivatePart | PublicPart
        then {
            val other_part =
                if decl_scope is PrivatePart
                then parent_decl.next_part_for_decl()
                else parent_decl.decl_private_part();

            # Search in other part
            other_part.do((op) => self.get_body_in_env(op.children_env))
            or? parent_decl.body_part_for_decl().do(
                # If not found, search in body
                (np) => self.get_body_in_env(np.children_env)
            )
        }
        # No declarative scope: Bail out!

        elif decl_scope.is_null then null[Entity[Body]]
        # self is declared in any other declarative scope. Search for decl
        # in it directly.
        else self.get_body_in_env(decl_scope.children_env)
    }

    @with_dynvars(origin)
    fun constrain_prefix(prefix: Expr): Equation =
        self.subp_constrain_prefix(prefix)

    @with_dynvars(origin)
    fun expr_type(): Entity[BaseTypeDecl] =
        self.subp_spec_or_null()?.return_type()

    fun env_names(): Array[Symbol] =
        node.top_level_env_name().do((fqn) => [fqn.to_symbol])

    |" Return the specification for this subprogram
    @exported
    @abstract
    fun subp_decl_spec(): Entity[BaseSubpSpec]

    env_spec {
        # Call the env hook to parse eventual parent unit
        do(node.env_hook())
        set_initial_env(
            # TODO: This is wrong (should take into account whether the entity
            # is private or not), but we have no example of cases where this is
            # a problem yet.
            node.child_decl_initial_env(true)
        )
        add_all_to_env(self.child_decl_env_assocs())
        add_env(names=node.env_names())
        do(node.populate_dependent_units())
        reference(
            node.top_level_use_package_clauses(),
            Name.use_package_name_designated_env,
            cond=node.parent is LibraryItem | Subunit
        )
        reference(
            node.top_level_use_type_clauses(),
            Name.name_designated_type_env,
            cond=node.parent is LibraryItem | Subunit
        )
        handle_children()
        do(node.populate_body_unit())
    }
}

|" This is an intermediate abstract class for subprogram declarations with a
|" common structure: overriding indicator, ``SubpSpec``, aspects,
|" <other fields>.
@abstract
class ClassicSubpDecl: BasicSubpDecl {
    @parse_field
    overriding: Overriding
    @parse_field
    subp_spec: SubpSpec

    fun subp_decl_spec(): Entity[BaseSubpSpec] = self.subp_spec

    |" Return the BaseSubpBody corresponding to this node.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun body_part(): Entity[BaseSubpBody] =
        self.body_part_for_decl().as![BaseSubpBody]
}

|" Declaration for an abstract subprogram (:rmlink:`3.9.3`).
class AbstractSubpDecl: ClassicSubpDecl {
    @parse_field
    aspects: AspectSpec
}

|" Formal subprogram declarations, in generic declarations formal parts
|" (:rmlink:`12.6`).
@abstract
class FormalSubpDecl: ClassicSubpDecl {
    @parse_field
    @nullable
    default_expr: Expr
    @parse_field
    aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] = [self.subp_spec.name()]

    fun xref_entry_point(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.default_expr.do(
            (e) =>
            match e {
                case _: NullLiteral => %true
                case _: BoxExpr => %true
                case n: Name =>
                    (
                        if n is AttributeRef then n.sub_equation()
                        else n.xref_no_overloading(all_els=true)
                    )
                    %and BasicDecl.subp_decl_match_signature%(n.ref_var(),
                    self.as[BasicDecl])
                case _ => raise[Equation] PropertyError("Should not happen")
            },
            default_val=%true
        )

    |" Given the name used in the instantiation for this formal subp decl,
    |" resolve it at the instantiation site to the corresponding declaration.
    |" This property basically replaces ``AdaNode.resolve_generic_actual`` but
    |" is more precise because we have access to the formal spec, which means
    |" we can disambiguate between overloaded actuals.
    |" Note that we cannot simply call ``referenced_decl`` here as this would
    |" cause name resolution recursions which we want to avoid at all cost.
    @memoized
    fun resolve_actual_name(name: Entity[Expr]): Entity[BasicDecl] = {
        bind origin = name.node;

        if name is AttributeRef
        then name.as[AttributeRef].attribute_subprogram()
        elif name is BoxExpr
        then
        # We are inside an instantiation of formal package without
        # constraint on this function (so, a BoxExpr).
            null[Entity[BasicDecl]]
        elif name is Name
        then
            name.as[Name].all_env_elements().find(
                (el) => el.as[BasicDecl]?.subp_decl_match_signature(self)
            )
            .as[BasicDecl]
        else
            raise[Entity[BasicDecl]] PropertyError(
                "invalid actual for subprogram formal"
            )
    }

    |" Retrieves the actual for this formal subprogram by finding the generic
    |" formal part in which self lies in self's rebindings, and then resolving
    |" the corresponding actual.
    fun corresponding_actual_impl(rb: EnvRebindings): Entity[BasicDecl] =
        if rb.is_null then self
        elif rb.old_env == node.parent.node_env
        then
            rb.new_env.env_node.as[GenericInstantiation].do(
                (inst) =>
                Entity[GenericInstantiation](
                    node=inst,
                    info=EntityInfo(
                        md=null[Metadata],
                        rebindings=rb.get_parent,
                        from_rebound=false
                    )
                )
            )
            .actual_for_formal(self.defining_name().node)
            .do((name) => self.resolve_actual_name(name))
            .do(
                (actual) =>
                Entity[BasicDecl](
                    node=actual.node,
                    info=EntityInfo(
                        md=actual.info.md,
                        rebindings=actual.info.rebindings,
                        # We (manually) found an actual for our formal through
                        # the given rebindings, so set the `from_rebound` flag.
                        from_rebound=true
                    )
                )
                .corresponding_actual()
            )
            or? self
        else self.corresponding_actual_impl(rb.get_parent)

    |" For a ``FormalSubpDecl`` we must find the actual by looking in our own
    |" rebindings. See ``corresponding_actual_impl``.
    fun corresponding_actual(): Entity[BasicDecl] =
        self.corresponding_actual_impl(self.info.rebindings)

    |" Return the first visible subprogram that can match this formal subp in
    |" the context of an instantiation. This is used to find the matching
    |" subprogram in an instantiation for a formal subp with a box expr.
    |" This property assumes that ``self`` is already in the context of the
    |" given instantiation.
    fun designated_subprogram_from(
        inst: Entity[GenericInstantiation]
    ): Entity[BasicDecl] = {
        val subps =
            node.env_get(
                env=inst.node_env,
                symbol=self.defining_name().name_symbol(),
                from_node=inst.node
            );
        # Search for the first subprogram that matches the instantiated profile
        val found = {
            bind origin = inst.origin_node();

            subps.find(
                (subp) =>
                subp.as[BasicDecl].subp_spec_or_null().do(
                    (spec) =>
                    self.subp_spec.match_signature(
                        other=spec,
                        # Names must already match due to the env_get call
                        match_name=false
                    )
                )
            )
            .as[BasicDecl]
        };

        # ``found`` can be null, for example when it is supposed to designate
        # a builtin operator.
        found?.wrap_public_reference()
    }
}

|" Formal declaration for an abstract subprogram (:rmlink:`12.6`).
class AbstractFormalSubpDecl: FormalSubpDecl {
}

|" Formal declaration for a concrete subprogram (:rmlink:`12.6`).
class ConcreteFormalSubpDecl: FormalSubpDecl {
}

|" Regular subprogram declaration (:rmlink:`6.1`).
class SubpDecl: ClassicSubpDecl {
    @parse_field
    aspects: AspectSpec

    fun is_constant_object(): Bool = true
}

|" Entry declaration (:rmlink:`9.4`).
class EntryDecl: BasicSubpDecl {
    @parse_field
    overriding: Overriding
    @parse_field
    spec: EntrySpec
    @parse_field
    aspects: AspectSpec

    fun subp_decl_spec(): Entity[BaseSubpSpec] = self.spec

    fun defining_names(): Array[Entity[DefiningName]] = [self.spec.name()]

    |" Return the entry body associated to this entry declaration.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun body_part(): Entity[Body] = self.body_part_for_decl()

    |" Return whether this actually declares a family of entries.
    fun has_family(): Bool = not node.spec.family_type.is_null

    |" Return the type designated by the family type, if relevant. Note that
    |" the family type may be an anonymous range, in which case this property
    |" returns None.
    @with_dynvars(origin)
    fun family_type(): Entity[BaseTypeDecl] =
        self.spec.family_type.as[TypeExpr]?.designated_type()

    |" Return an array of accept statements corresponding to this entry.
    @exported
    fun accept_stmts(): Array[Entity[AcceptStmt]] =
        self.find_accept_stmts(
            # Find the body part of the task declaration for the current entry
            match self.parent_basic_decl() {
                case st: Entity[SingleTaskTypeDecl] => st.parent_basic_decl()
                case tt: TaskTypeDecl => tt
                case _ =>
                    raise[Entity[BasicDecl]] PreconditionFailure(
                        "Can only be called on EntryDecl in Tasks"
                    )
            }
            .body_part_for_decl()
        )

    |" Find all accept statements in all children of ``root`` that correspond
    |" to this entry declaration.
    fun find_accept_stmts(root: Entity[AdaNode]): Array[Entity[AcceptStmt]] =
        root.children.do(
            (child) =>
            child.filter((n) => not n.is_null).mapcat(
                (n) => self.find_accept_stmts(n)
            )
        )
        & root.as[AcceptStmt].do(
            (stmt) =>
            if stmt.corresponding_entry() == self then [stmt]
            else null[Array[Entity[AcceptStmt]]]
        )

    |" ``next_part_for_decl implementation``, specific to entry declarations:
    |" Will try both the regular case with an ``EntryBody`` (for protected
    |" objects), and the fallback case with an ``AceptStmtBody``.
    @with_dynvars(imprecise_fallback=false)
    fun next_part_for_decl(): Entity[BasicDecl] =
        # For tasks, get the corresponding accept statement's body
        if self.parent_basic_decl() is SingleTaskTypeDecl | TaskTypeDecl
        then self.accept_stmts()?[0]?.body_decl

        # For protected entries, call the superclass ``next_part_for_decl``
        else self.super()

    env_spec {
        add_to_env_kv(self.name_symbol(), node)
        add_env()
    }
}

|" Declaration for an enumeration literal (:rmlink:`3.5.1`).
class EnumLiteralDecl: BasicSubpDecl {
    @parse_field
    @nullable
    name: DefiningName
    @parse_field
    @null_field
    aspects: AspectSpec

    @with_dynvars(imprecise_fallback=false)
    fun is_static_decl(): Bool = true

    fun is_constant_object(): Bool = true

    |" Return the integer used to encode this enum literal.
    |"
    |" .. note::
    |"     This property is equivalent to GNAT's ``Enum_Rep`` attribute.
    @exported
    fun enum_rep(): BigInt = {
        val enum_type = self.enum_type();
        val rep_clause = enum_type.get_enum_representation_clause();
        # Equivalent of 'Pos: the 0-based position of this enum literal in the
        # type declaration.
        val pos = node.child_index;

        if rep_clause.is_null
        then (
            # If there is no representation clause for this enum, so 'Enum_Rep
            # is equivalent to 'Pos.
            pos.as_big_int()
        )
        else (
            # Ada mandates that elements in the aggregate for the
            # representation clause are in the same order as the enum literals
            # in the type declaration, so we can just use 'Pos to find the
            # correct value.
            rep_clause.aggregate.assocs?[pos].expr().eval_as_int()
        )
    }

    fun defining_names(): Array[Entity[DefiningName]] = [self.name]

    @memoized
    fun synth_type_expr(): Entity[EnumLitSynthTypeExpr] =
        EnumLitSynthTypeExpr().as_entity

    @memoized
    fun subp_decl_spec(): Entity[BaseSubpSpec] = EnumSubpSpec().as_entity

    |" Return the enum type corresponding to this enum literal.
    @exported
    fun enum_type(): Entity[TypeDecl] =
        node.parents().find((p) => p is TypeDecl).as_entity.as[TypeDecl]

    fun enum_decl_name(): Entity[DefiningName] = self.name

    env_spec {
        add_to_env_kv(
            node.name_symbol(),
            node,
            dest_env=DesignatedEnv(
                kind=DesignatedEnvKind.direct_env,
                env_name=null[Symbol],
                direct_env=self.enum_type().node_env
            )
        )
        # We add an env here so that parent_basic_decl/semantic_parent on the
        # enum subp spec work correctly and returns the EnumLiteralDecl rt. the
        # type decl.
        add_env()
    }
}

|" Synthetic character enum literal declaration.
@synthetic
class SyntheticCharEnumLit: EnumLiteralDecl {
    char_symbol: Symbol
    enum_type_decl: Entity[TypeDecl]

    fun enum_type(): Entity[TypeDecl] = self.enum_type_decl

    |" Return the CharLiteral expression corresponding to this enum literal.
    @exported
    fun expr(): Entity[DefiningName] = self.defining_names()?[0]

    fun enum_decl_name(): Entity[DefiningName] = self.expr()

    fun defining_names(): Array[Entity[DefiningName]] =
        [node.synthesize_defining_name(node.char_symbol).as_entity]
}

|" Internal node for generic subprograms.
class GenericSubpInternal: BasicSubpDecl {
    @parse_field
    subp_spec: SubpSpec
    @parse_field
    aspects: AspectSpec

    fun subp_decl_spec(): Entity[BaseSubpSpec] = self.subp_spec

    env_spec {
        add_env(names=node.env_names())
    }
}

|" Synthetic subprogram declaration.
|"
|" Is used to represent predefined operators. This should also be usable
|" for synthesizing function attributes.
@synthetic
class SyntheticSubpDecl: BasicSubpDecl {
    @parse_field
    @null_field
    aspects: AspectSpec
    @parse_field
    spec: BaseSubpSpec

    fun subp_decl_spec(): Entity[BaseSubpSpec] = self.spec

    @with_dynvars(imprecise_fallback=false)
    fun next_part_for_decl(): Entity[BasicDecl] = null[Entity[BasicDecl]]

    @with_dynvars(imprecise_fallback=false)
    fun is_static_decl(): Bool = true
}

|" Base class for an Ada body (:rmlink:`3.11`). A body is the completion
|" of a declaration.
@abstract
class Body: BasicDecl {
    |" Helper for the AdaNode.env_hook. Handle library-level unit body nodes.
    fun env_hook_body(): Bool =
        # If this a library-level subprogram/package body, load the spec
        # corresponding to this body.
        if node is PackageBody | SubpBody
        then {
            val _ =
                node.get_unit(
                    node.as_bare_entity.defining_name().as_symbol_array(),
                    AnalysisUnitKind.unit_specification,
                    load_if_needed=true,
                    not_found_is_error=not node is SubpBody
                );

            # A library level subprogram body does not have to have a spec.
            # So we have to compute the parents directly from here.
            node.as[SubpBody].do(
                (subp_body) => subp_body.env_hook_basic_decl()
            )
        }
        else false

    fun subunit_decl_env(): LexicalEnv = {
        bind env = node.default_initial_env();

        match
            self.body_scope(true).get(
                self.name_symbol(),
                categories=RefCategories(inherited_primitives=false, _=true)
            )?[
                0
            ]
        {
            case gpd: GenericPackageDecl =>
            # For generic package decls, we regroup the formal part & the
            # package decl itself, since the reference will be
            # non-transitive.
                [gpd.children_env, gpd.package_decl.children_env]
                .env_group()
            case pd: BasicDecl => pd.children_env
            case _ => raise[LexicalEnv] PropertyError()
        }
        .do(
            (public_part) =>
            public_part.get(
                s"__privatepart",
                lookup=LookupKind.flat,
                categories=RefCategories(inherited_primitives=false, _=true)
            )?[
                0
            ]
            .do(
                # If there is a private part, group it with the rest
                (pp) => [pp.children_env, public_part].env_group(),
                default_val=public_part
            )
        )
    }

    |" Return True if ``origin`` is directly in the scope of this body.
    @with_dynvars(origin)
    fun in_scope(): Bool =
        not origin.is_null
        and (
            (
                # Either origin and self are in the same unit
                origin.unit == node.unit
                and not origin.parents().find((p) => node == p).is_null
            )
            or (
                # Either origin is nested in a subprogam subunit of self
                origin.enclosing_compilation_unit().body.as[Subunit].do(
                    (su) =>
                    su.bodies_root().any(
                        (br) => br is BaseSubpBody and br.unit == node.unit
                    )
                )
            )
        )

    |" Return the scope of this body's decl.
    fun body_decl_scope(): LexicalEnv = {
        bind env = node.default_initial_env();

        self.body_scope(true, true)
    }

    |" A package or subprogram body has a named parent env only if it is a
    |" compilation unit root, in which case it will be the name of its
    |" corresponding declaration.
    fun body_initial_env_name(): Symbol =
        if node.is_library_item()
        then (node.top_level_env_name() & ".__privatepart").to_symbol
        elif node.is_subunit()
        then (node.top_level_env_name() & "__stub").to_symbol
        else null[Symbol]

    |" Return the initial env for a body. It's always the current environment
    |" except for compilation unit roots for which we use the environment of
    |" their corresponding declaration.
    fun body_initial_env(): DesignatedEnv =
        node.body_initial_env_name().do(
            (non_null_name) =>
            DesignatedEnv(
                kind=DesignatedEnvKind.named_env,
                env_name=non_null_name,
                direct_env=null[LexicalEnv]
            ),
            default_val=DesignatedEnv(
                kind=DesignatedEnvKind.current_env,
                env_name=null[Symbol],
                direct_env=null[LexicalEnv]
            )
        )

    |" Return the decl corresponding to this body. Specialized implementation
    |" for subprogram bodies.
    |"
    |" .. ATTENTION:: It is important to not perform any signature match in
    |"     cases where we don't need to (top-level subprograms), as the
    |"     robustness of some important properties is at stake (e.g.
    |"     imported_units, and therefore find_all_references).
    @with_dynvars(imprecise_fallback=false)
    fun subp_previous_part(): Entity[BasicDecl] = {
        val parent =
            if self.is_library_item() then self.parent.parent
            else self.semantic_parent();
        val elements =
            if parent.is_null then null[Array[Entity[AdaNode]]]
            # If this is a library-level subprogram, the previous part can be
            # found by fetching the compilation unit spec.

            elif parent is CompilationUnit
            then
                parent.as[CompilationUnit].other_part().do(
                    # Make sure the previous part is at least a subprogram,
                    # and not an arbitrary declaration.
                    (cu) =>
                    if cu.decl() is BasicSubpDecl | GenericSubpDecl
                    then [cu.decl().as[AdaNode].as_entity]
                    else null[Array[Entity[AdaNode]]]
                )
            # If this subprogram's parent is a BodyStub, this subprogram is
            # necessarily a Subunit and the stub is thus its previous part.

            elif parent is BodyStub then [parent]
            # Otherwise, look in its immediate declarative region
            else
                parent.immediate_declarative_region().get(
                    self.name_symbol(),
                    lookup=LookupKind.minimal
                );
        # Since no overloading is possible for library-level subprograms and
        # separate subprograms, the element we found is already precise, and so
        # we don't need to perform the signature matching below.
        val already_precise = parent is CompilationUnit | BodyStub;
        val precise =
            (
                if already_precise then elements?[0]
                else
                    elements.find(
                        (sp) =>
                        not sp.is_null and sp.node != node
                        and match sp {
                            # If this body completes a generic subprogram, then
                            # we just return it (no need to match the
                            # signature).
                            case _: GenericSubpDecl => true

                            # A formal subprogram cannot be the previous part
                            # of any subprogram.
                            case _: FormalSubpDecl => false
                            case subp_decl: BasicSubpDecl =>
                                {
                                    bind origin = node.origin_node();

                                    subp_decl.subp_decl_spec().match_signature(
                                        self.subp_spec_or_null().as[SubpSpec],
                                        true,
                                        # We set use_entity_info to False so as
                                        # to not match base subprograms.
                                        use_entity_info=false
                                    )
                                }
                            case subp_stub: SubpBodyStub =>
                                {
                                    bind origin = node.origin_node();

                                    subp_stub.subp_spec.match_signature(
                                        self.subp_spec_or_null().as[SubpSpec],
                                        true,
                                        # We set use_entity_info to False so as
                                        # to not match base subprograms.
                                        use_entity_info=false
                                    )
                                }
                            case _ => false
                        }
                    )
            )
            .as![BasicDecl];

        if precise.is_null and imprecise_fallback
        then
            elements.find(
                (sp) =>
                not sp.is_null and sp.node != node
                and sp is BasicSubpDecl | SubpBodyStub
            )
            .as![BasicDecl]
        else precise
    }

    |" Return the EntryDecl corresponding to this node.
    @with_dynvars(env)
    fun entry_previous_part(): Entity[EntryDecl] = {
        val spec = self.as![EntryBody].params;

        env.get(
            self.name_symbol(),
            categories=RefCategories(inherited_primitives=false, _=true)
        )
        .find(
            (sp) =>
            not sp.is_null and sp.node != node
            and match sp {
                case entry_decl: EntryDecl =>
                    {
                        bind origin = node.origin_node();

                        entry_decl.spec.match_formal_params(spec)
                    }
                case _ => false
            }
        )
        .as![EntryDecl]
    }

    |" Return the BasePackageDecl corresponding to this node.
    |"
    |" If the case of generic package declarations, this returns the
    |" ``package_decl`` field instead of the ``GenericPackageDecl`` itself.
    @with_dynvars(env)
    fun package_previous_part(): Entity[BasicDecl] =
        (
            if node.is_library_item()
            then
                node.enclosing_compilation_unit().other_part().do(
                    (part) =>
                    part.decl().as_entity.as[AdaNode].do((v1) => [v1])
                )
            else {
                bind origin = node.origin_node();

                self.defining_name().all_env_els_impl(
                    categories=RefCategories(
                        inherited_primitives=false,
                        _=true
                    )
                )
            }
        )
        .map(
            (e) =>
            match e {
                case pkg_decl: PackageDecl => pkg_decl
                case gen_pkg_decl: GenericPackageDecl =>
                    gen_pkg_decl.package_decl
                case _ => null[Entity[BasicDecl]]
            }
        )
        .find((e) => not e.is_null)

    |" Return the task decl corresponding to this node.
    @with_dynvars(env)
    fun task_previous_part(): Entity[BasicDecl] =
        {
            bind origin = node.origin_node();

            self.defining_name().all_env_els_impl()
        }?[
            0
        ]
        .as[BasicDecl]

    |" Return the ProtectedDecl corresponding to this node.
    @with_dynvars(env)
    fun protected_previous_part(): Entity[BasicDecl] =
        self.defining_name().env_elements()?[0].do(
            (v1) =>
            match v1 {
                case prot_type: ProtectedTypeDecl => prot_type
                case prot_decl: SingleProtectedDecl => prot_decl
                case _ => null[Entity[BasicDecl]]
            }
        )

    |" Return the previous part for this body. Might be a declaration or a
    |" body stub.
    @with_dynvars(env, imprecise_fallback=false)
    fun unbound_previous_part(): Entity[BasicDecl] = {
        val pp = match self {
            case _: BaseSubpBody => self.subp_previous_part()
            case _: SubpBodyStub => self.subp_previous_part()
            case _: EntryBody => self.entry_previous_part()
            case _: PackageBody => self.package_previous_part()
            case _: PackageBodyStub => self.package_previous_part()
            case _: ProtectedBody => self.protected_previous_part()
            case _: ProtectedBodyStub => self.protected_previous_part()
            case _: TaskBody => self.task_previous_part()
            case _: TaskBodyStub => self.task_previous_part()
            case a: AcceptStmtBody => a.accept_stmt_previous_part()
        };

        # TODO: It would be cleaner if the previous_part implems returned
        # the stubs, but for the moment they're not even added to the lexical
        # environments.
        if self is BodyStub then pp
        else {
            val pp_next_part = pp?.next_part_for_decl();

            if pp_next_part is BodyStub then pp_next_part else pp
        }
    }

    |" Return the previous part for this body. Might be a declaration or a
    |" body stub.
    |"
    |" .. note::
    |"     This internal property was introduced by T812-020 in order to break
    |"     an infinite recursion.
    @with_dynvars(imprecise_fallback=false)
    fun previous_part_internal(): Entity[BasicDecl] =
    # Use self.as_bare_entity and not self as a prefix for the following
    # call to unbound_previous_part. The reasoning is that the previous
    # part of a given Body is a static concept that does not depend on a
    # particular context, and thus should not be impacted by an entity's
    # metadata. In particular, this addresses T610-028.
    {
        bind env = node.node_env;

        node.as_bare_entity.unbound_previous_part().node.as_entity
    }

    |" Return the previous part for this body. Might be a declaration or a
    |" body stub.
    @exported
    @memoized
    @with_dynvars(imprecise_fallback=false)
    fun previous_part(): Entity[BasicDecl] = self.previous_part_internal()

    |" Return the decl corresponding to this node if applicable.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun decl_part(): Entity[BasicDecl] =
        self.previous_part_internal().do(
            (prev_part) =>
            match prev_part {
                # Stubs have one more previous part. Go back one more level
                # to get the decl.
                case stub: BodyStub => stub.previous_part_internal()
                case other => other
            }
        )

    |" Return the generic declaration corresponding to this body, if relevant.
    |" This property is designed to be usable from within env specs.
    fun safe_generic_decl_part(): Entity[GenericDecl] = {
        bind imprecise_fallback = false;

        if node is PackageBody
        then self.decl_part().do((d) => d.parent.as[GenericPackageDecl])
        elif node is BaseSubpBody | SubpBodyStub
        then (
            # We're only searching for generics. We look at index 1 and
            # 2, because if self is a subunit, the first entity we find
            # will be the separate declaration. NOTE: We don't use
            # decl_part/previous_part on purpose: They can cause env
            # lookups, hence doing an infinite recursion.
            self.children_env.env_parent.get(
                self.name_symbol(),
                categories=RefCategories(inherited_primitives=false, _=true)
            )
            ?.find((r) => r is GenericSubpDecl)
            .as[GenericSubpDecl]
        )
        else null[Entity[GenericDecl]]
    }

    |" By default, bodies don't have a next part. This is not true for body
    |" stubs, hence this property is overridden there.
    @with_dynvars(imprecise_fallback=false)
    fun next_part_for_decl(): Entity[BasicDecl] = null[Entity[BasicDecl]]

    fun is_subunit(): Bool = node.parent is Subunit

    |" If self is a subunit, return the body in which it is rooted.
    @exported
    fun subunit_root(): Entity[BasicDecl] =
        node.parent.as[Subunit].do((su) => su.body_root())

    |" Return the scope for this body.
    |" If follow_private, then returns the private part if possible.
    |"
    |" If force_decl, then returns the corresponding declaration's scope,
    |" rather than the parent body's scope.
    @with_dynvars(env)
    fun body_scope(
        follow_private: Bool,
        force_decl: Bool = false
    ): LexicalEnv = {
        val scope =
        # Subunits always appear at the top-level in package bodies. So if
        # this is a subunit, the scope is the same as the scope of the
        # corresponding "is separate" decl, hence: the defining env of this
        # top-level package body.
            if not node.subunit_root().is_null
            then node.subunit_root().children_env
            # In case this is a library level subprogram that has no spec
            # (which is legal), we'll register this body in the parent
            # scope.

            elif node.is_subprogram() and node.is_compilation_unit_root()
            then {
                val dns = self.defining_name().scope();

                # If the scope is self's scope, return parent scope, or
                # else we'll have an infinite recursion.
                if dns.is_null or dns.env_node == node
                then self.defining_name().parent_scope()
                else dns
            }
            # If this is a library level unit, or force_decl is True, return
            # the enclosing decl.

            elif node.is_compilation_unit_root() or force_decl
            then self.defining_name().scope()
            # The rest of cases are nested declarations: In that case we want
            # to take the parent's env.
            else node.parent.children_env;
        # If this the corresponding decl is a generic, go grab the internal
        # package decl.
        val public_scope =
            scope.env_node.as[GenericPackageDecl].do(
                (gen_pkg_decl) => gen_pkg_decl.package_decl.children_env,
                default_val=scope
            );

        # If the package has a private part, then get the private part,
        # else return the public part.
        if
            follow_private
            and public_scope.env_node.do(
                (v1) =>
                v1 is BasePackageDecl | SingleProtectedDecl | ProtectedTypeDecl
            )
        then
            public_scope.get(
                s"__privatepart",
                lookup=LookupKind.flat,
                categories=RefCategories(inherited_primitives=false, _=true)
            )?[
                0
            ]
            .do((pp) => pp.children_env, default_val=public_scope)
        else public_scope
    }

    |" Get all ``GNATprove`` annotations specified for that body.
    @memoized
    fun gnatprove_annotations(): Array[Entity[Expr]] = {
        val subp_decl_part = self.decl_part();
        # GNATprove annotations are specified in the specification, or else on
        # the body if it doesn't have a specification.
        val aspects =
            subp_decl_part.do((part) => part.aspects, default_val=self.aspects)
            ?.aspect_assocs
            .filtermap(
                (a) => a.expr.as[Aggregate].assocs?[1].expr(),
                (a) =>
                (a.id.name_is(s"Annotate") and a.expr is Aggregate)
                and a.expr.as[Aggregate].assocs?[0].expr().as[Name]?.name_is(
                    s"GNATprove"
                )
            );
        # GNATprove pragmas immediately follow the specification, or the body
        # iff it's an `ExprFunction`.
        val pragma_scope = subp_decl_part or? self.as[ExprFunction];
        # List all the pragmas that appear in the same declarative scope,
        # or in the case of a library item, the pragmas at the end of the
        # compilation unit.
        val scope_decls = (
            pragma_scope?.declarative_scope()?.decls.filtermap(
                (p) => p.as[Pragma],
                (p) => p is Pragma
            )
            or? pragma_scope?.library_item_pragmas().map((p) => p.node)
        );
        # Find those that are a "GNATProve" annotation
        val pragmas =
            scope_decls.filtermap(
                (d) => d.args?[1].as_entity.assoc_expr(),
                (d) =>
                (
                    (d > pragma_scope.node and d?.id.name_is(s"Annotate"))
                    and d.args?[0]?.as_entity.assoc_expr().as[Name]?.name_is(
                        s"GNATprove"
                    )
                )
                and d.args?[2]?.as_entity.assoc_expr().as[Name]?.name_is(
                    self.defining_names()?[0].name_symbol()
                )
            );
        # Also look for annotations declared on the enclosing bodies
        val enclosing_subp_annotations =
            self.parents(with_self=false).find((n) => n is BaseSubpBody)
            .as[BaseSubpBody]
            ?.gnatprove_annotations();

        aspects & pragmas & enclosing_subp_annotations
    }

    |" Return the name of the lexical env of the previous part of this body.
    |" For a subunit, the previous part is its stub, otherwise it's the body's
    |" declaration. If that declaration has a named env, it will be registered
    |" with the same top_level_env_name as this body.
    fun previous_part_env_name(): Symbol =
        if node.is_subunit()
        then (node.top_level_env_name() & "__stub").to_symbol
        else node.top_level_env_name().to_symbol

    |" Return the env association that describes where to add a ``__nextpart``
    |" entry for this body, if it corresponds to a non-overloadable entity
    |" (i.e. not a subprogram).
    |"
    |" Note that entry navigation is handled a bit differently and in
    |" particular we don't need a ``__nextpart`` link for them. Hence this
    |" property is never called from EntryBody env specs.
    fun previous_part_link_env_assoc(): EnvAssoc =
        EnvAssoc(
            key=s"__nextpart",
            value=node,
            dest_env=node.previous_part_env_name().do(
                (name) =>
                DesignatedEnv(
                    kind=DesignatedEnvKind.named_env,
                    env_name=name,
                    direct_env=null[LexicalEnv]
                ),
                default_val={
                    bind env = node.default_initial_env();

                    self.body_scope(follow_private=false, force_decl=true)
                }
                .do(
                    (non_null_env) =>
                    DesignatedEnv(
                        kind=DesignatedEnvKind.direct_env,
                        env_name=null[Symbol],
                        direct_env=non_null_env
                    ),
                    default_val=DesignatedEnv(
                        kind=DesignatedEnvKind.current_env,
                        env_name=null[Symbol],
                        direct_env=null[LexicalEnv]
                    )
                )
            ),
            metadata=null[Metadata]
        )
}

|" BasicDecl that is always the declaration of an AcceptStmt. This is nested
|" *inside* of the accept statement.
class AcceptStmtBody: Body {
    @parse_field
    name: DefiningName
    @parse_field
    @null_field
    aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] = [self.name]

    @with_dynvars(
        origin, include_ud_indexing=false, dottable_type=null[AdaNode]
    )
    fun defining_env(): LexicalEnv = node.parent.as[AcceptStmt].children_env

    fun accept_stmt_previous_part(): Entity[EntryDecl] =
        self.parent.as![AcceptStmt].corresponding_entry()
}

|" Base class for subprogram bodies (:rmlink:`6.3`).
@abstract
class BaseSubpBody: Body {
    @parse_field
    overriding: Overriding
    @parse_field
    subp_spec: SubpSpec

    fun defining_names(): Array[Entity[DefiningName]] = [self.subp_spec.name()]

    @with_dynvars(origin)
    fun constrain_prefix(prefix: Expr): Equation =
        self.subp_constrain_prefix(prefix)

    @with_dynvars(
        origin, include_ud_indexing=false, dottable_type=null[AdaNode]
    )
    fun defining_env(): LexicalEnv =
        if self.in_scope()
        then
            [
                if
                    self.subp_spec_or_null()?.paramless(
                        self.info.md.dottable_subp,
                        can_be=true
                    )
                then
                    [self.children_env, self.subp_spec.defining_env()]
                    .env_group()
                else self.children_env,
                self.decl_part().do(
                    (decl) =>
                    decl.as[GenericSubpDecl]?.formal_part?.children_env
                )
            ]
            .env_group()
        # For bodies corresponding to generic declaration, add the
        # declaration's formal_part env to the body one, as for
        # example in:
        #
        # .. code:: ada
        #   procedure Gen_Proc is
        #      C : constant T := Gen_Proc.F;
        #   begin
        #      null;
        #   end Gen_Proc;
        #
        # with `F` being a `Gen_Proc` formal's function:
        #
        # .. code ada
        #   generic
        #     type T is private;
        #     with function F return T is <>;
        #   procedure Gen_Proc;
        else self.subp_spec.defining_env()

    fun type_expression(): Entity[TypeExpr] = self.subp_spec.returns()

    @with_dynvars(origin)
    fun expr_type(): Entity[BaseTypeDecl] =
        self.subp_spec_or_null()?.return_type()

    fun initial_env_name(follow_private: Bool = false): Symbol =
        if node.is_library_item()
        then node.child_decl_initial_env_name(follow_private)
        else node.body_initial_env_name()

    |" Return the name of the lexical env of the previous part of this
    |" subprogram body. Due to overloading, do not return anything in case
    |" we are not a library item or subunit.
    fun previous_part_env_name(): Symbol =
        if node.is_subunit()
        then (node.top_level_env_name() & "__stub").to_symbol
        elif node.is_library_item() then node.top_level_env_name().to_symbol
        else null[Symbol]

    env_spec {
        do(node.env_hook())
        set_initial_env(
            node.initial_env_name(true).do(
                (non_null_name) =>
                DesignatedEnv(
                    kind=DesignatedEnvKind.named_env,
                    env_name=non_null_name,
                    direct_env=null[LexicalEnv]
                ),
                default_val=DesignatedEnv(
                    kind=DesignatedEnvKind.current_env,
                    env_name=null[Symbol],
                    direct_env=null[LexicalEnv]
                )
            )
        )
        add_all_to_env(
            self.basic_decl_env_assocs(
                node.initial_env_name(false).do(
                    (non_null_name) =>
                    DesignatedEnv(
                        kind=DesignatedEnvKind.named_env,
                        env_name=non_null_name,
                        direct_env=null[LexicalEnv]
                    ),
                    default_val=DesignatedEnv(
                        kind=DesignatedEnvKind.current_env,
                        env_name=null[Symbol],
                        direct_env=null[LexicalEnv]
                    )
                )
            )
        )
        add_env(transitive_parent=true)
        add_to_env_kv(
            s"__nextpart",
            node,
            dest_env=node.previous_part_env_name().do(
                (name) =>
                DesignatedEnv(
                    kind=DesignatedEnvKind.named_env,
                    env_name=name,
                    direct_env=null[LexicalEnv]
                ),
                # Due to overloading, it's not possible to find the previous
                # part of a non-library item subprogram at this stage if it
                # has a top level env name (e.g. a subprogram declared in a
                # package), since its body could be defined in another unit.
                default_val=if node.has_top_level_env_name()
                then
                    DesignatedEnv(
                        kind=DesignatedEnvKind.none,
                        env_name=null[Symbol],
                        direct_env=null[LexicalEnv]
                    )
                else {
                    bind env = node.default_initial_env();

                    self.body_scope(follow_private=false, force_decl=true).do(
                        (non_null_env) =>
                        DesignatedEnv(
                            kind=DesignatedEnvKind.direct_env,
                            env_name=null[Symbol],
                            direct_env=non_null_env
                        ),
                        default_val=DesignatedEnv(
                            kind=DesignatedEnvKind.current_env,
                            env_name=null[Symbol],
                            direct_env=null[LexicalEnv]
                        )
                    )
                }
            )
        )
        do(node.populate_dependent_units())
        reference(
            node.top_level_use_package_clauses(),
            Name.use_package_name_designated_env,
            cond=node.parent is LibraryItem | Subunit
        )
        reference(
            node.top_level_use_type_clauses(),
            Name.name_designated_type_env,
            cond=node.parent is LibraryItem | Subunit
        )
        # If self, which is assumed to be a SubpBody, is a library-level
        # subprogram, it must "inherit" the use clauses of its declaration, if
        # there is one.
        reference(
            node.as[AdaNode].do((v1) => [v1]),
            AdaNode.use_clauses_in_spec_of_subp_body,
            cond=node.parent is LibraryItem
        )
        reference(
            node.as[AdaNode].do((v2) => [v2]),
            AdaNode.nested_generic_formal_part,
            kind=prioritary,
            cond=node.should_ref_generic_formals(),
            shed_corresponding_rebindings=true
        )
        # We must also "inherit" the use clauses from the generic formal part
        # of this body's generic declaration, if relevant.
        reference(
            node.as[AdaNode].do((v3) => [v3]),
            AdaNode.use_clauses_in_generic_formal_part,
            cond=node.should_ref_generic_formals()
        )
    }
}

|" Expression function (:rmlink:`6.8`).
class ExprFunction: BaseSubpBody {
    @parse_field
    expr: Expr
    @parse_field
    aspects: AspectSpec

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        (
            self.expr.expected_type_var() <- self.subp_spec.return_type()
            %and self.expr.sub_equation()
        )
        %and node.expr.matches_expected_assign_type()

    fun xref_entry_point(): Bool = true
}

|" Declaration for a null subprogram (:rmlink:`6.1`).
class NullSubpDecl: BaseSubpBody {
    @parse_field
    aspects: AspectSpec
}

|" Subprogram body(:rmlink:`6.3`) .
class SubpBody: BaseSubpBody {
    @parse_field
    aspects: AspectSpec
    @parse_field
    decls: DeclarativePart
    @parse_field
    stmts: HandledStmts
    @parse_field
    @nullable
    end_name: EndName

    fun declarative_parts(): Array[Entity[DeclarativePart]] = [self.decls]
}

|" Declaration for a subprogram renaming (:rmlink:`8.5.4`).
class SubpRenamingDecl: BaseSubpBody {
    @parse_field
    renames: RenamingClause
    @parse_field
    aspects: AspectSpec

    fun xref_entry_point(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        val renamed_object = self.renames.renamed_object;

        (
            if renamed_object is CharLiteral
            then (
                # If the renamed object is a char literal, simply resolves its
                # equation.
                renamed_object.expected_type_var()
                <- self.subp_spec.return_type()
                %and renamed_object.sub_equation()
            )
            elif renamed_object is AttributeRef
            then (
                # If the renamed object is an attribute ref, do normal
                # resolution to synthesize its corresponding function.
                renamed_object.sub_equation()
            )
            else
                match renamed_object {
                    # If renamed_object is a CallExpr, this is likely the
                    # renaming of an entry decl with a family member specified,
                    # so use sub_equation.
                    case ce: CallExpr => ce.sub_equation()
                    case ed: ExplicitDeref =>
                        ed.general_xref_equation(renamed_object.node)

                    # On the other cases, prefix is a simple identifier
                    case o => o.xref_no_overloading(all_els=true)
                }
                %and (
                    if renamed_object is DottedName
                    then
                        BasicDecl
                        .subp_renaming_decl_match_signature%(renamed_object
                        .ref_var(),
                        renamed_object.as[DottedName].prefix.ref_var(),
                        self.as[BasicDecl])
                    elif renamed_object is ExplicitDeref
                    then
                        BasicDecl
                        .access_to_subp_decl_match_signature%(renamed_object
                        .ref_var(),
                        self.as[BasicDecl])
                    else
                        BasicDecl.subp_decl_match_signature%(renamed_object
                        .ref_var(),
                        self.as[BasicDecl])
                )
        )
        %or (
            # Operators might be built-in, so if we cannot find a reference,
            # we'll just abandon resolution...
            if renamed_object.is_operator_name() then %true else %false
        )
    }
}

|" Base class for a body stub (:rmlink:`10.1.3`). A body stub is meant to
|" be completed by .
@abstract
class BodyStub: Body {
    @with_dynvars(imprecise_fallback=false)
    fun next_part_for_decl(): Entity[BasicDecl] =
        node.get_unit_root_decl(
            self.syntactic_fully_qualified_name(),
            AnalysisUnitKind.unit_body,
            process_parents=false
        )
        .as_entity

    |" Return the syntactic fully qualified name to refer to this body.
    |"
    |" Note that this can raise a Property_Error when the stub is in an
    |" illegal place (too nested, in a declare block, etc.).
    @exported
    fun syntactic_fully_qualified_name(): Array[Symbol] = {
        # Compute the "relative" name of the body for this stub
        val rel_name = node.as_bare_entity.defining_name().as_symbol_array();
        # Fetch the compilation unit in which this stub is rooted.
        #
        # Body stubs can appear only in the top-level declarative part of a
        # library-level body or of a subunit. This means that:
        #
        # * ``self.parent`` must be an ``AdaNode.list``,
        # * ``self.parent.parent`` must be a ``DeclarativePart``,
        # * ``self.parent.parent.parent`` must be a library item or subunit
        #   ``Body``.
        val top_body = match node.parent.parent.parent {
            case b: SubpBody => b
            case b: ProtectedBody => b
            case b: PackageBody => b
            case b: TaskBody => b
            case _ => raise[Body] PropertyError("invalid body stub")
        };

        val cu =
            if top_body.parent is LibraryItem | Subunit
            then top_body.parent.parent.as[CompilationUnit]
            else raise[CompilationUnit] PropertyError("invalid body stub");

        cu.syntactic_fully_qualified_name() & rel_name
    }

    |" All body stubs allow for a named environment, which is registered with
    |" a ``__stub`` appended to the body's top_level_env_name.
    fun env_names(): Array[Symbol] =
        [(node.top_level_env_name() & "__stub").to_symbol]

    fun previous_part_link_env_assoc(): EnvAssoc =
        EnvAssoc(
            key=s"__nextpart",
            value=node,
            dest_env=DesignatedEnv(
                kind=DesignatedEnvKind.named_env,
                env_name=node.top_level_env_name().to_symbol,
                direct_env=null[LexicalEnv]
            ),
            metadata=null[Metadata]
        )
}

|" Stub for a package body (``is separate``) (:rmlink:`10.1.3`).
class PackageBodyStub: BodyStub {
    @parse_field
    name: DefiningName
    @parse_field
    aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] = [self.name]

    env_spec {
        add_single_to_env(self.previous_part_link_env_assoc())
        add_env(names=node.env_names())
    }
}

|" Stub for a protected object body (``is separate``) (:rmlink:`10.1.3`).
class ProtectedBodyStub: BodyStub {
    @parse_field
    name: DefiningName
    @parse_field
    aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] = [self.name]

    env_spec {
        add_single_to_env(self.previous_part_link_env_assoc())
        add_env(names=node.env_names())
    }
}

|" Stub for a subprogram body (``is separate``) (:rmlink:`10.1.3`).
class SubpBodyStub: BodyStub {
    @parse_field
    overriding: Overriding
    @parse_field
    subp_spec: SubpSpec
    @parse_field
    aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] = [self.subp_spec.name()]
    # Note that we don't have to override the defining_env property here since
    # what we put in lexical environment is their SubpSpec child.

    fun type_expression(): Entity[TypeExpr] = self.subp_spec.returns()

    env_spec {
        add_to_env_kv(node.name_symbol(), node)
        add_env(names=node.env_names())
        reference(
            node.as[AdaNode].do((v1) => [v1]),
            AdaNode.nested_generic_formal_part,
            kind=prioritary,
            cond=node.should_ref_generic_formals(),
            shed_corresponding_rebindings=true
        )
        # We must also "inherit" the use clauses from the generic formal part
        # of this body's generic declaration, if relevant.
        reference(
            node.as[AdaNode].do((v2) => [v2]),
            AdaNode.use_clauses_in_generic_formal_part,
            cond=node.should_ref_generic_formals()
        )
    }
}

|" Stub for a task body (``is separate``) (:rmlink:`10.1.3`).
class TaskBodyStub: BodyStub {
    @parse_field
    name: DefiningName
    @parse_field
    aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] = [self.name]

    env_spec {
        add_single_to_env(self.previous_part_link_env_assoc())
        add_env(names=node.env_names())
    }
}

|" Entry body (:rmlink:`9.5.2`).
class EntryBody: Body {
    @parse_field
    entry_name: DefiningName
    @parse_field
    @nullable
    index_spec: EntryIndexSpec
    @parse_field
    params: EntryCompletionFormalParams
    @parse_field
    aspects: AspectSpec
    @parse_field
    barrier: Expr
    @parse_field
    decls: DeclarativePart
    @parse_field
    stmts: HandledStmts
    @parse_field
    @nullable
    end_name: EndName

    fun defining_names(): Array[Entity[DefiningName]] = [self.entry_name]

    fun declarative_parts(): Array[Entity[DeclarativePart]] = [self.decls]

    fun xref_entry_point(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        node.barrier.expected_type_var() <- node.bool_type()
        %and self.barrier.sub_equation()
        %and self.barrier.matches_expected_formal_type()

    env_spec {
        do(node.env_hook())
        set_initial_env(
            DesignatedEnv(
                kind=DesignatedEnvKind.direct_env,
                env_name=null[Symbol],
                direct_env={
                    bind env = node.default_initial_env();

                    self.body_scope(false)
                }
            )
        )
        # Add the body to its own parent env
        add_all_to_env(
            [
                EnvAssoc(
                    key=self.name_symbol(),
                    value=node,
                    dest_env=DesignatedEnv(
                        kind=DesignatedEnvKind.current_env,
                        env_name=null[Symbol],
                        direct_env=null[LexicalEnv]
                    ),
                    metadata=null[Metadata]
                )
            ]
        )
        add_env()
    }
}

|" Package body (:rmlink:`7.2`).
class PackageBody: Body {
    @parse_field
    package_name: DefiningName
    @parse_field
    aspects: AspectSpec
    @parse_field
    decls: DeclarativePart
    @parse_field
    @nullable
    stmts: HandledStmts
    @parse_field
    @nullable
    end_name: EndName

    fun defining_names(): Array[Entity[DefiningName]] = [self.package_name]

    @with_dynvars(
        origin, include_ud_indexing=false, dottable_type=null[AdaNode]
    )
    fun defining_env(): LexicalEnv = self.children_env

    fun declarative_parts(): Array[Entity[DeclarativePart]] = [self.decls]

    |" Return the environments for the use clauses of the package decl of this
    |" body. Used because they need to be explicitly referenced.
    fun package_decl_use_clauses_envs(): LexicalEnv =
        {
            bind imprecise_fallback = false;

            self.decl_part().as![BasePackageDecl]
        }
        .do(
            (pd) =>
            [
                pd.public_part.use_clauses_envs(),
                pd.private_part?.use_clauses_envs()
            ]
            .env_group()
        )

    env_spec {
        do(node.env_hook())
        # Parent link is the package's decl, or private part if there is one
        set_initial_env(node.body_initial_env())
        add_single_to_env(self.previous_part_link_env_assoc())
        # We make a transitive parent link only when the package is a library
        # level package.
        add_env(transitive_parent=node.is_library_item())
        do(node.populate_dependent_units())
        reference(
            node.top_level_use_package_clauses(),
            Name.use_package_name_designated_env,
            cond=node.parent is LibraryItem | Subunit
        )
        reference(
            node.top_level_use_type_clauses(),
            Name.name_designated_type_env,
            cond=node.parent is LibraryItem | Subunit
        )
        reference(
            node.as[AdaNode].do((v1) => [v1]),
            AdaNode.nested_generic_formal_part,
            kind=prioritary,
            cond=node.should_ref_generic_formals(),
            shed_corresponding_rebindings=true
        )
        # We must also "inherit" the use clauses from the generic formal part
        # of this body's generic declaration, if relevant.
        reference(
            node.as[AdaNode].do((v2) => [v2]),
            AdaNode.use_clauses_in_generic_formal_part,
            cond=node.should_ref_generic_formals()
        )
        # Separate packages and nested packages basically need to be treated
        # the same way: we cannot use a transitive ref because of hiding
        # issues, so we'll do a prioritary ref, that groups together the
        # necessary envs.
        #
        # TODO: We need to ref use clauses, as in the regular package decl
        # case.
        reference(
            [node.as[AdaNode]],
            Body.subunit_decl_env,
            kind=prioritary,
            cond=node.is_subunit()
        )
        # If self is not a library level package body (and hence is a nested
        # package), we need to explicitly reference its package decl, because
        # it is not in the chain of parents.
        #
        # The reference is non transitive because if it was it would cause some
        # visibility order issues.
        #
        # TODO: We can regroup this ref with the following ref, making
        # body_decl_scope return a grouped env with the use clauses in it.
        reference(
            [node.as[AdaNode]],
            Body.body_decl_scope,
            kind=prioritary,
            cond=not node.is_compilation_unit_root()
        )
        # Since the reference to the package decl is non transitive, we still
        # want to reference the envs that are "used" there.
        reference(
            [node.as[AdaNode]],
            PackageBody.package_decl_use_clauses_envs,
            cond=not node.is_compilation_unit_root() or node.is_subunit()
        )
    }
}

|" Protected object body (:rmlink:`9.4`).
class ProtectedBody: Body {
    @parse_field
    name: DefiningName
    @parse_field
    aspects: AspectSpec
    @parse_field
    decls: DeclarativePart
    @parse_field
    @nullable
    end_name: EndName

    fun defining_names(): Array[Entity[DefiningName]] = [self.name]

    fun declarative_parts(): Array[Entity[DeclarativePart]] = [self.decls]

    fun protected_type(): Entity[ProtectedTypeDecl] = match self.decl_part() {
        case t: ProtectedTypeDecl => t
        case _: SingleProtectedDecl => null[Entity[ProtectedTypeDecl]]
        case _ =>
            raise[Entity[ProtectedTypeDecl]] PropertyError("Should not happen")
    }

    env_spec {
        do(node.env_hook())
        set_initial_env(node.body_initial_env())
        add_single_to_env(self.previous_part_link_env_assoc())
        add_env()
        do(node.populate_dependent_units())
        reference(
            node.top_level_use_package_clauses(),
            Name.use_package_name_designated_env,
            cond=node.parent is LibraryItem | Subunit
        )
        reference(
            node.top_level_use_type_clauses(),
            Name.name_designated_type_env,
            cond=node.parent is LibraryItem | Subunit
        )
        reference(
            node.as[AdaNode].do((v1) => [v1]),
            AdaNode.nested_generic_formal_part,
            kind=prioritary,
            cond=node.should_ref_generic_formals(),
            shed_corresponding_rebindings=true
        )
        # We must also "inherit" the use clauses from the generic formal part
        # of this body's generic declaration, if relevant.
        reference(
            node.as[AdaNode].do((v2) => [v2]),
            AdaNode.use_clauses_in_generic_formal_part,
            cond=node.should_ref_generic_formals()
        )
        reference([node.as[AdaNode]], Body.body_decl_scope, kind=prioritary)
        # Reference stub's env if the body is a separate
        reference(
            [node.as[AdaNode]],
            Body.subunit_decl_env,
            kind=prioritary,
            cond=node.is_subunit()
        )
    }
}

|" Task body (:rmlink:`9.1`).
class TaskBody: Body {
    @parse_field
    name: DefiningName
    @parse_field
    aspects: AspectSpec
    @parse_field
    decls: DeclarativePart
    @parse_field
    stmts: HandledStmts
    @parse_field
    @nullable
    end_name: EndName

    fun defining_names(): Array[Entity[DefiningName]] = [self.name]

    @with_dynvars(
        origin, include_ud_indexing=false, dottable_type=null[AdaNode]
    )
    fun defining_env(): LexicalEnv = self.children_env

    fun declarative_parts(): Array[Entity[DeclarativePart]] = [self.decls]

    fun task_type_decl_scope(): LexicalEnv = {
        val pp = self.task_type()?.definition?.private_part;

        if pp.is_null then self.task_type().children_env else pp.children_env
    }

    fun task_type(): Entity[TaskTypeDecl] = {
        bind imprecise_fallback = false;

        match self.decl_part() {
            case t: TaskTypeDecl => t
            case t: SingleTaskDecl => t.task_type
            case _ =>
                raise[Entity[TaskTypeDecl]] PropertyError("Should not happen")
        }
    }

    env_spec {
        do(node.env_hook())
        set_initial_env(node.body_initial_env())
        add_single_to_env(self.previous_part_link_env_assoc())
        add_env()
        do(node.populate_dependent_units())
        reference(
            node.top_level_use_package_clauses(),
            Name.use_package_name_designated_env,
            cond=node.parent is LibraryItem | Subunit
        )
        reference(
            node.top_level_use_type_clauses(),
            Name.name_designated_type_env,
            cond=node.parent is LibraryItem | Subunit
        )
        reference(
            node.as[AdaNode].do((v1) => [v1]),
            AdaNode.nested_generic_formal_part,
            kind=prioritary,
            cond=node.should_ref_generic_formals(),
            shed_corresponding_rebindings=true
        )
        # We must also "inherit" the use clauses from the generic formal part
        # of this body's generic declaration, if relevant.
        reference(
            node.as[AdaNode].do((v2) => [v2]),
            AdaNode.use_clauses_in_generic_formal_part,
            cond=node.should_ref_generic_formals()
        )
        reference(
            [node.as[AdaNode]],
            TaskBody.task_type_decl_scope,
            kind=prioritary
        )
        # Reference stub's env if the body is a separate
        reference(
            [node.as[AdaNode]],
            Body.subunit_decl_env,
            kind=prioritary,
            cond=node.is_subunit()
        )
    }
}

|" Index specification for an entry body (:rmlink:`9.5.2`).
class EntryIndexSpec: BasicDecl {
    @parse_field
    id: DefiningName
    @parse_field
    subtype: AdaNode
    @parse_field
    aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] = [self.id]

    @with_dynvars(
        origin, include_ud_indexing=false, dottable_type=null[AdaNode]
    )
    fun defining_env(): LexicalEnv = self.expr_type().defining_env()

    @with_dynvars(origin)
    fun expr_type(): Entity[BaseTypeDecl] = match self.subtype {
        case subt: SubtypeIndication => subt.designated_type()
        case e => e.as![Expr].expression_type()
    }

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = self.subtype.sub_equation()

    fun xref_entry_point(): Bool = true

    env_spec {
        add_to_env_kv(self.name_symbol(), node)
    }
}

|" Placeholder node for syntax errors in lists of declarations.
class ErrorDecl: BasicDecl implements ErrorNode {
    @parse_field
    @null_field
    aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] =
        null[Array[Entity[DefiningName]]]

    |" Override for error decls, which cannot be child decls.
    fun child_decl_initial_env_name(
        @ignored
        private_part: Bool = false
    ): Symbol =
        # TODO: investigate if we can/should do better here
        null[Symbol]
}

|" Exception declarations (:rmlink:`11.1`).
class ExceptionDecl: BasicDecl {
    @parse_field
    ids: ASTList[DefiningName]
    @parse_field
    @nullable
    renames: RenamingClause
    @parse_field
    aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] =
        self.ids.map((id) => id)

    |" An exception declaration never has a next part.
    @with_dynvars(imprecise_fallback=false)
    fun next_part_for_decl(): Entity[BasicDecl] = null[Entity[BasicDecl]]

    fun xref_entry_point(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.renames.do(
            (c) => c.renamed_object.xref_no_overloading(),
            default_val=%true
        )

    env_spec {
        add_all_to_env(node.env_mappings(node.ids, node))
    }
}

|" Exception handler (:rmlink:`11.2`).
class ExceptionHandler: BasicDecl {
    @parse_field
    @nullable
    exception_name: DefiningName
    @parse_field
    handled_exceptions: AlternativesList
    @parse_field
    stmts: StmtList
    @parse_field
    @null_field
    aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] =
        self.exception_name.do((n) => [n])

    @with_dynvars(origin)
    fun expr_type(): Entity[BaseTypeDecl] =
        self.get_unit_root_decl(
            [s"Ada", s"Exceptions"],
            AnalysisUnitKind.unit_specification
        )
        ?.children_env
        .get_first(s"Exception_Occurrence", lookup=LookupKind.flat)
        .as[BaseTypeDecl]

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        node.handled_exceptions.logic_all((he) => he.as_entity.sub_equation())

    fun xref_entry_point(): Bool = true

    fun is_constant_object(): Bool = true

    env_spec {
        add_env()
        add_all_to_env(
            self.exception_name.do(
                (n) =>
                [n].map(
                    (n) =>
                    EnvAssoc(
                        key=n.name_symbol(),
                        value=node,
                        dest_env=DesignatedEnv(
                            kind=DesignatedEnvKind.current_env,
                            env_name=null[Symbol],
                            direct_env=null[LexicalEnv]
                        ),
                        metadata=null[Metadata]
                    )
                )
            )
        )
    }
}

|" Declaration for the controlling variable in a ``for`` loop
|" (:rmlink:`5.5`).
class ForLoopVarDecl: BasicDecl {
    @parse_field
    id: DefiningName
    @parse_field
    @nullable
    id_type: TypeExpr
    @parse_field
    @null_field
    aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] = [self.id]

    @with_dynvars(
        origin, include_ud_indexing=false, dottable_type=null[AdaNode]
    )
    fun defining_env(): LexicalEnv = self.expr_type().defining_env()

    @memoized
    @call_memoizable
    @with_dynvars(origin)
    fun expr_type(): Entity[BaseTypeDecl] =
        if node.id_type.is_null
        then (
            # The type of a for loop variable does not need to be annotated, it
            # can eventually be inferred, which necessitates name resolution on
            # the loop specification. Run resolution if necessary.
            # NOTE: if we are in the context of an Ada 202x iterated component
            # association things are a bit different: `id`'s type_var should
            # already be set by the enclosing IteratedAssoc's resolution, and
            # must be retrieved directly. Calling `expression_type` now would
            # trigger an infinite loop because the enclosing ForLoopSpec is
            # not an entry point in this context.
            if node.parent.as[ForLoopSpec].is_iterated_assoc_spec()
            then node.id.type_val().as![BaseTypeDecl]
            else self.id.expression_type()
        )
        # If there is a type annotation, just return it
        else self.id_type.designated_type()

    fun is_constant_object(): Bool = {
        # TODO: add support for Constant/Variable_Indexing
        val loop_spec = self.parent.as[ForLoopSpec];

        # IterType.alt_of loops are constant if the iterable object is
        # constant.
        if loop_spec.loop_type is IterType.Of
        then loop_spec.iter_expr.as![Name].is_constant()

        # IterType.alt_in loops are always constant
        else true
    }

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.id.sub_equation()
        %and if self.id_type.is_null then %true
        else self.id_type.sub_equation()

    env_spec {
        add_to_env_kv(node.name_symbol(), node)
    }
}

|" Base class for generic declarations (:rmlink:`12.1`).
@abstract
@rebindable
class GenericDecl: BasicDecl {
    @parse_field
    formal_part: GenericFormalPart

    @abstract
    fun decl(): Entity[BasicDecl]

    fun get_aspect_spec(): Entity[AspectSpec] =
        # The aspect is actually on the Generic*Internal node, so forward
        # the call to it.
        self.decl().get_aspect_spec()

    @with_dynvars(imprecise_fallback=false)
    fun next_part_for_decl(): Entity[BasicDecl] =
        self.decl().next_part_for_decl()
}

|" Generic package declaration (:rmlink:`12.1`).
class GenericPackageDecl: GenericDecl {
    @parse_field
    package_decl: GenericPackageInternal
    @parse_field
    @null_field
    aspects: AspectSpec

    @with_dynvars(
        origin, include_ud_indexing=false, dottable_type=null[AdaNode]
    )
    fun defining_env(): LexicalEnv = self.package_decl.defining_env()

    fun defining_names(): Array[Entity[DefiningName]] =
        [node.package_decl.package_name.as_entity]

    fun declarative_parts(): Array[Entity[DeclarativePart]] =
        self.package_decl.declarative_parts()

    |" Return the PackageBody corresponding to this node, or null if there is
    |" none.
    @exported
    fun body_part(): Entity[PackageBody] = self.package_decl.body_part()

    fun decl(): Entity[BasicDecl] = self.package_decl

    env_spec {
        do(node.env_hook())
        set_initial_env(
            # TODO: This is wrong (should take into account whether the entity
            # is private or not), but we have no example of cases where this is
            # a problem yet.
            node.child_decl_initial_env(true)
        )
        add_all_to_env(self.child_decl_env_assocs())
        add_env()
        do(node.populate_dependent_units())
        reference(
            node.top_level_use_package_clauses(),
            Name.use_package_name_designated_env,
            cond=node.parent is LibraryItem | Subunit
        )
        reference(
            node.top_level_use_type_clauses(),
            Name.name_designated_type_env,
            cond=node.parent is LibraryItem | Subunit
        )
    }
}

|" Generic subprogram declaration (:rmlink:`12.1`).
class GenericSubpDecl: GenericDecl {
    @parse_field
    subp_decl: GenericSubpInternal
    @parse_field
    @null_field
    aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] =
        [self.subp_decl.subp_spec.name()]

    |" Return the BaseSubpBody corresponding to this node.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun body_part(): Entity[BaseSubpBody] =
        self.body_part_for_decl().as[BaseSubpBody]

    fun decl(): Entity[BasicDecl] = self.subp_decl

    # Overriding properties forwarding to internal subp decl
    fun is_imported(): Bool = self.subp_decl.is_imported()

    @with_dynvars(imprecise_fallback=false)
    fun next_part_for_decl(): Entity[BasicDecl] =
        self.subp_decl.next_part_for_decl()

    env_spec {
        # Call the env hook to parse eventual parent unit
        do(node.env_hook())
        set_initial_env(
            # TODO: This is wrong (should take into account whether the entity
            # is private or not), but we have no example of cases where this is
            # a problem yet.
            node.child_decl_initial_env(true)
        )
        add_all_to_env(self.child_decl_env_assocs())
        add_env()
        do(node.populate_dependent_units())
        reference(
            node.top_level_use_package_clauses(),
            Name.use_package_name_designated_env,
            cond=node.parent is LibraryItem | Subunit
        )
        reference(
            node.top_level_use_type_clauses(),
            Name.name_designated_type_env,
            cond=node.parent is LibraryItem | Subunit
        )
        handle_children()
        do(node.populate_body_unit())
    }
}

|" Instantiations of generics (:rmlink:`12.3`).
@abstract
class GenericInstantiation: BasicDecl {
    @lazy
    instantiation_env: LexicalEnv =
        dynamic_lexical_env(
            GenericInstantiation.instantiation_bindings,
            assoc_resolver=AdaNode.resolve_generic_actual,
            transitive_parent=false
        )

    fun instantiation_bindings(): Array[InnerEnvAssoc] = {
        # We force the computation of the corresponding generic declaration
        # in this non-memoized property to avoid a false "infinite recursion"
        # property error that can happen when the computation is only done in
        # instantiation_bindings_internal.
        val _ = node.nonbound_generic_decl_from_self();

        self.instantiation_bindings_internal()
    }

    @memoized
    fun instantiation_bindings_internal(): Array[InnerEnvAssoc] =
        if self.is_any_formal() then null[Array[InnerEnvAssoc]]
        else
            node.nonbound_generic_decl_from_self()
            .as![GenericDecl]
            .formal_part
            .match_param_list(self.generic_inst_params(), false)
            .imap(
                (pm, i) =>
                InnerEnvAssoc(
                    key=pm.formal.name.name_symbol(),
                    # Do not put formal subprograms in the rebindings to
                    # avoid them being eagerly resolved to an actual, as
                    # the formal part is needed to implement correct name
                    # resolution.
                    # We will use ``BasicDecl.corresponding_actual``
                    # instead to manually resolve it.
                    value=if
                        pm.actual.assoc.expr() is BoxExpr
                        or pm.formal.formal_decl() is GenericFormalSubpDecl
                    then null[Expr]
                    elif pm.formal.formal_decl() is GenericFormalObjDecl
                    then self.actual_expr_decls?[i]
                    else pm.actual.assoc.expr().node,
                    metadata=Metadata()
                )
            )
            .filter((env_assoc) => not env_assoc.value.is_null)

    |" Return the name of the generic entity designated by this generic
    |" instantiation.
    @abstract
    fun generic_entity_name(): Entity[Name]

    |" Return the parameters of this generic instantiation
    @abstract
    fun generic_inst_params(): Entity[AssocList]

    fun is_any_formal(): Bool =
        self.generic_inst_params()?[0].do((v1) => v1.expr() is BoxExpr)

    |" Return the generic package designated by the right hand part of this
    |" generic package instantiation as seen from the current generic context.
    |"
    |" See nonbound_generic_decl_from_self property below for follow_renaming
    |" parameter documentation.
    fun nonbound_generic_decl_from_entity(
        follow_renaming: Bool = true
    ): Entity[BasicDecl] =
        self.generic_entity_name().all_env_elements_internal(
            seq=true,
            seq_from=node,
            categories=RefCategories(inherited_primitives=false, _=true)
        )
        .find((e) => node.has_visibility(e))
        .do(
            (v1) =>
            match v1 {
                case b: Body =>
                    {
                        bind imprecise_fallback = false;

                        b.decl_part()
                    }
                case rd: GenericRenamingDecl =>
                    if follow_renaming then rd.resolve() else rd
                case d: BasicDecl => d
                case _ => null[Entity[BasicDecl]]
            }
        )

    |" Return the generic package designated by the right hand part of this
    |" generic package instantiation from a bare generic context.
    |"
    |" By default, this property follows renaming declarations to return the
    |" designated generic declaration. Set follow_renaming to false in order to
    |" return the renaming declaration instead if any.
    fun nonbound_generic_decl_from_self(
        follow_renaming: Bool = true
    ): Entity[BasicDecl] =
        node.as_bare_entity.nonbound_generic_decl_from_entity(follow_renaming)

    |" Return the generic decl entity designated by this instantiation,
    |" including instantiation information. This is equivalent to the expanded
    |" generic unit in GNAT.
    @exported
    @abstract
    fun designated_generic_decl(): Entity[GenericDecl]

    |" Return the generic decl designated by this instantiation, but without
    |" the associated generic context.
    fun designated_bare_generic_decl(): Entity[BasicDecl] = {
        val decl = self.designated_generic_decl();

        Entity[AdaNode](
            node=decl.node,
            info=EntityInfo(
                md=decl.info.md,
                rebindings=decl.info.rebindings.get_parent,
                from_rebound=decl.info.from_rebound
            )
        )
        .as[BasicDecl]
    }

    @lazy
    actual_expr_decls: Array[AnonymousExprDecl] =
        match node {
            case subp: GenericSubpInstantiation => subp.params
            case pkg: GenericPackageInstantiation => pkg.params
        }
        .map(
            (assoc) => AnonymousExprDecl(expr=assoc.as_bare_entity.expr().node)
        )

    |" Return the defining environment of the parent of this generic package
    |" instantiation , if it has one. This is used by child package
    |" instantiation to create a reference env to their parent. To see why
    |" this is needed, consider the following snippet:
    |"
    |" .. code::
    |"
    |"     -- pkg_g.ads
    |"     generic package Pkg_G is end Pkg_G;
    |"
    |"     -- pkg_g-child_g.ads
    |"     generic package Pkg_G.Child_G is end Pkg_G.Child_G;
    |"
    |"     -- my_pkg.ads
    |"     package My_Pkg is new Pkg_G;
    |"
    |"     -- my_pkg-my_child.ads
    |"     package My_Pkg.My_Child is new Child_G;
    |"
    |" In the env spec of the last instantiation, we have to set the parent
    |" env of ``My_Child`` to be the ``My_Pkg`` instantiation node. However,
    |" this does not give us visibility on the instantiat*ed* package
    |" ``Pkg_G [My_Pkg]``, which we need in order to resolve the following
    |" non-prefixed reference to ``Child_G``. Therefore, we must explicitly
    |" create a reference from ``My_Pkg.My_Child`` to ``Pkg_G [My_Pkg]`` in
    |" order to gain visibility on ``Child_G [My_Pkg]``.
    fun parent_instantiation_env(): LexicalEnv =
        self.defining_name().name.as[DottedName]?.prefix.do(
            (parent_name) => {
                bind origin = node;
                bind env = self.children_env;

                parent_name.designated_env_no_overloading()
            },
            default_val=node.empty_env()
        )

    fun xref_entry_point(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        (
            self.generic_entity_name().ref_var()
            <- self.nonbound_generic_decl_from_self(false)
            %and match self.generic_entity_name() {
                case dn: DottedName => dn.prefix.xref_no_overloading()
                case _ => %true
            }
        )
        %and if self.is_any_formal() then %true
        else
            self.designated_generic_decl()?.formal_part.match_param_list(
                self.generic_inst_params(),
                false
            )
            .filter((pm) => not pm.actual.assoc.expr() is BoxExpr)
            .logic_all(
                (pm) => {
                    val actual_name = pm.actual.assoc.expr().as[Name];

                    match pm.formal.formal_decl().as[GenericFormal].decl {
                        case _: BaseTypeDecl =>
                            actual_name.xref_type_equation()
                        case _: GenericPackageInstantiation =>
                            actual_name.xref_no_overloading()
                        case subp_decl: Entity[FormalSubpDecl] =>
                            if actual_name is AttributeRef
                            then actual_name.sub_equation()
                            else
                                actual_name.xref_no_overloading(all_els=true)
                                %and BasicDecl
                                .subp_decl_match_signature%(actual_name
                                .ref_var(),
                                subp_decl.as[BasicDecl])
                                %or %true
                        case obj_decl: ObjectDecl =>
                            pm.actual.assoc.expr().expected_type_var()
                            <- obj_decl.expr_type()
                            %and pm.actual.assoc.expr().sub_equation()
                            %and pm.actual.assoc.expr()
                            .matches_expected_assign_type()
                        case _ => %true
                    }
                    %and pm.actual.name.do(
                        (n) =>
                        n.ref_var()
                        <- pm.formal.node.as_bare_entity.basic_decl(),
                        default_val=%true
                    )
                }
            )

    fun initial_env_name(): Symbol =
        if node.is_library_item() then node.child_decl_initial_env_name()
        else null[Symbol]

    fun env_names(): Array[Symbol] =
        node.top_level_env_name().do((fqn) => [fqn.to_symbol])

    |" Returns an array of pairs, associating formal parameters to actual or
    |" default expressions.
    @exported
    fun inst_params(): Array[ParamActual] = {
        val ap = self.generic_inst_params();

        self.designated_generic_decl()?.formal_part.decls.mapcat(
            # Unpack generic formals with their default expressions
            (d) =>
            match d {
                case t: GenericFormalPackage =>
                    [
                        ParamActual(
                            param=t.decl.as[GenericPackageInstantiation].name,
                            actual=null[Entity[Expr]]
                        )
                    ]
                case t: GenericFormalTypeDecl =>
                    [
                        ParamActual(
                            param=t.decl.as[BaseTypeDecl].name,
                            actual=null[Entity[Expr]]
                        )
                    ]
                case o: GenericFormalObjDecl =>
                    o.decl.as[ObjectDecl].ids.map(
                        (i) =>
                        ParamActual(
                            param=i,
                            actual=o.decl.as[ObjectDecl].default_expr
                        )
                    )
                case sp: GenericFormalSubpDecl =>
                    [
                        {
                            val subp = sp.decl.as[FormalSubpDecl];

                            ParamActual(
                                param=sp.defining_name(),
                                actual=if subp.default_expr is BoxExpr
                                then
                                    subp.designated_subprogram_from(inst=self)
                                    ?.defining_name()
                                else subp.default_expr
                            )
                        }
                    ]
                case _: Pragma => null[Array[ParamActual]]
                case _: UseClause => null[Array[ParamActual]]
                case _ =>
                    raise[Array[ParamActual]] PropertyError(
                        "unexpected declaration in generic formal part"
                    )
            }
        )
        .imap(
            (dp, i) =>
            ParamActual(
                param=dp.param,
                # Update actuals from instantiation params
                actual=ap.actual_for_param_at(dp.param, i, dp.actual)
            )
        )
    }

    |" Return the expression of the actual used for the given formal in this
    |" generic instantiation. Returns null if none is provided, even if there
    |" is a default value.
    fun actual_for_formal(formal_name: DefiningName): Entity[Expr] = {
        val gen_decl = node.nonbound_generic_decl_from_self().as[GenericDecl];

        gen_decl?.formal_part.match_param_list(
            self.generic_inst_params(),
            false
        )
        .find((pm) => pm.formal.node == formal_name)
        .do((pm) => pm.actual.assoc.expr())
    }

    env_spec {
        do(node.env_hook())
        set_initial_env(
            node.initial_env_name().do(
                (non_null_name) =>
                DesignatedEnv(
                    kind=DesignatedEnvKind.named_env,
                    env_name=non_null_name,
                    direct_env=null[LexicalEnv]
                ),
                default_val=DesignatedEnv(
                    kind=DesignatedEnvKind.current_env,
                    env_name=null[Symbol],
                    direct_env=null[LexicalEnv]
                )
            )
        )
        add_to_env_kv(self.name_symbol(), node)
        add_env(names=node.env_names())
        do(node.populate_dependent_units())
        reference(
            node.top_level_use_package_clauses(),
            Name.use_package_name_designated_env,
            cond=node.parent is LibraryItem | Subunit
        )
        reference(
            node.top_level_use_type_clauses(),
            Name.name_designated_type_env,
            cond=node.parent is LibraryItem | Subunit
        )
        reference(
            [node.as[AdaNode]],
            GenericInstantiation.parent_instantiation_env,
            cond=node.parent is LibraryItem | Subunit
        )
    }
}

|" Instantiations of a generic package.
class GenericPackageInstantiation: GenericInstantiation {
    @parse_field
    name: DefiningName
    @parse_field
    generic_pkg_name: Name
    @parse_field
    params: AssocList
    @parse_field
    aspects: AspectSpec

    fun generic_entity_name(): Entity[Name] = self.generic_pkg_name

    fun generic_inst_params(): Entity[AssocList] = self.params

    fun designated_package(): Entity[BasePackageDecl] =
        self.nonbound_generic_decl_from_entity().do(
            (p) =>
            Entity[BasePackageDecl](
                node=p.node.as[GenericPackageDecl].package_decl,
                info=EntityInfo(
                    md=p.info.md,
                    rebindings=node.add_rebinding(
                        # A subset of ``self``'s rebindings were used to
                        # resolve ``p``, now use ``insert_rebindings`` to add
                        # the rest of them.
                        node.insert_rebindings(
                            p.info.rebindings,
                            self.info.rebindings
                        ),
                        # Append the rebindings for the current instantiation.
                        # NOTE: We use the formal env to create rebindings.
                        # There, we purposefully want the children env of the P
                        # node, with no rebindings associated, since the
                        # rebinding indication concerns the *naked* generic.
                        # Hence we use `p.node.children_env`.
                        p.node.children_env,
                        node.instantiation_env
                    ),
                    from_rebound=p.info.from_rebound
                )
            )
        )

    fun designated_generic_decl(): Entity[GenericDecl] =
        self.designated_package().parent.as![GenericDecl]

    |" Specialized function for getting the defining env for this generic
    |" instantiation.
    |"
    |" If ``inst_from_formal`` is True, we know that this generic package
    |" instantiation is coming from a rebound formal package, and that we need
    |" visibility on the formals.
    @with_dynvars(origin)
    fun defining_env_impl(inst_from_formal: Bool = false): LexicalEnv = {
        val dp = self.designated_package();

        # In some specific scenarios on valid Ada code, dp can be null
        # here (see U630-018). For example, consider the following snippet.
        #
        # .. code::
        #   use U; -- U contains the declaration of G
        #   package A is new G;
        #   use A;
        #
        # Now consider an env lookup attempting to traverse the "use U"
        # clause. When calling the use clause's resolver, we lookup "U" and
        # we end up traversing "use A" (this is the critical part: although
        # the use clause is located after, we still traverse it in order
        # to cache further lookups to "U", no matter their origin). When
        # resolving "use A", we need to lookup G. However, since U is
        # already being visited, our lexical env mechanism preventing
        # infinite recursion returns an empty vector, which in turn makes
        # ``self.designated_package`` be null here.
        # Fortunately, returning EmptyEnv in this case is fine, because
        # there would be no way for U to be found through A anyways.
        if dp.is_null then null[LexicalEnv]
        else
            [
                if node.is_formal() or inst_from_formal
                then [dp.children_env, dp.parent.children_env].env_group()
                else dp.children_env,
                # The environment of the instantiation needs to be available,
                # because library unit generic package instantiations can be
                # nested, and so need to be available, such as in::
                #
                #     --  a.ads
                #     package A is new Gen_A;
                #
                #     --  a-b.ads
                #     package A.B is new A.Gen_B;
                #
                self.children_env
            ]
            .env_group()
    }

    @with_dynvars(
        origin, include_ud_indexing=false, dottable_type=null[AdaNode]
    )
    fun defining_env(): LexicalEnv = self.defining_env_impl()

    fun defining_names(): Array[Entity[DefiningName]] = [self.name]
}

|" Instantiations of a generic subprogram .
class GenericSubpInstantiation: GenericInstantiation {
    @parse_field
    overriding: Overriding
    @parse_field
    kind: SubpKind
    @parse_field
    subp_name: DefiningName
    @parse_field
    generic_subp_name: Name
    @parse_field
    params: AssocList
    @parse_field
    aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] = [self.subp_name]

    fun generic_entity_name(): Entity[Name] = self.generic_subp_name

    fun generic_inst_params(): Entity[AssocList] = self.params

    @with_dynvars(origin)
    fun expr_type(): Entity[BaseTypeDecl] =
        self.subp_spec_or_null()?.return_type()

    @with_dynvars(
        origin, include_ud_indexing=false, dottable_type=null[AdaNode]
    )
    fun defining_env(): LexicalEnv = self.subp_spec_or_null()?.defining_env()

    |" Return the subprogram decl designated by this instantiation.
    @exported
    fun designated_subp(): Entity[BasicSubpDecl] =
        self.nonbound_generic_decl_from_entity().do(
            (p) =>
            Entity[BasicSubpDecl](
                node=p.node.as[GenericSubpDecl].subp_decl,
                info=EntityInfo(
                    md=self.info.md,
                    rebindings=node.add_rebinding(
                        node.insert_rebindings(
                            p.info.rebindings,
                            self.info.rebindings
                        ),
                        p.node.children_env,
                        node.instantiation_env
                    ),
                    from_rebound=p.info.from_rebound
                )
            )
        )

    fun designated_generic_decl(): Entity[GenericDecl] =
        self.designated_subp().parent.as![GenericDecl]
}

|" Base node for all generic renaming declarations (:rmlink:`8.5.5`).
@abstract
class GenericRenamingDecl: BasicDecl {
    @abstract
    fun renaming_name(): Entity[Name]

    |" Resolve the GenericDecl this renaming decl is pointing at
    fun resolve(): Entity[GenericDecl] =
        # We must use `all_env_elements_internal` here and not `env_elements`,
        # as the latter assumes the Name is used in an expression context,
        # which is not the case here.
        self.renaming_name().all_env_elements_internal(
            seq=true,
            seq_from=node,
            categories=RefCategories(inherited_primitives=false, _=true)
        )
        .filter((e) => not e is Body)?[
            0
        ]
        .do(
            (v1) =>
            match v1 {
                case gd: GenericDecl => gd
                case grd: GenericRenamingDecl => grd.resolve()
                case _ => null[Entity[GenericDecl]]
            }
        )

    fun xref_entry_point(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = self.renaming_name().xref_no_overloading()
}

|" Declaration for a generic package renaming (:rmlink:`8.5.5`).
class GenericPackageRenamingDecl: GenericRenamingDecl {
    @parse_field
    name: DefiningName
    @parse_field
    renames: RenamingClause
    @parse_field
    aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] = [self.name]

    @with_dynvars(
        origin, include_ud_indexing=false, dottable_type=null[AdaNode]
    )
    fun defining_env(): LexicalEnv = self.resolve().defining_env()

    fun renaming_name(): Entity[Name] = self.renames.renamed_object

    env_spec {
        do(node.env_hook())
        set_initial_env(node.child_decl_initial_env())
        add_to_env_kv(self.name_symbol(), node)
        add_env()
        do(node.populate_dependent_units())
        reference(
            node.top_level_use_package_clauses(),
            Name.use_package_name_designated_env,
            cond=node.parent is LibraryItem | Subunit
        )
        reference(
            node.top_level_use_type_clauses(),
            Name.name_designated_type_env,
            cond=node.parent is LibraryItem | Subunit
        )
    }
}

|" Declaration for a generic subprogram renaming.
class GenericSubpRenamingDecl: GenericRenamingDecl {
    @parse_field
    kind: SubpKind
    @parse_field
    name: DefiningName
    @parse_field
    renames: RenamingClause
    @parse_field
    aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] = [self.name]

    fun renaming_name(): Entity[Name] = self.renames.renamed_object

    env_spec {
        do(node.env_hook())
        set_initial_env(node.child_decl_initial_env())
        add_to_env_kv(self.name_symbol(), node)
        add_env()
        do(node.populate_dependent_units())
        reference(
            node.top_level_use_package_clauses(),
            Name.use_package_name_designated_env,
            cond=node.parent is LibraryItem | Subunit
        )
        reference(
            node.top_level_use_type_clauses(),
            Name.name_designated_type_env,
            cond=node.parent is LibraryItem | Subunit
        )
    }
}

|" Declaration for a code label (:rmlink:`5.1`).
class LabelDecl: BasicDecl {
    @parse_field
    name: DefiningName
    @parse_field
    @null_field
    aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] = [self.name]

    env_spec {
        add_to_env_kv(node.name_symbol(), node)
    }
}

|" BasicDecl that is always the declaration inside a named statement.
class NamedStmtDecl: BasicDecl {
    @parse_field
    name: DefiningName
    @parse_field
    @null_field
    aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] = [self.name]

    @with_dynvars(
        origin, include_ud_indexing=false, dottable_type=null[AdaNode]
    )
    fun defining_env(): LexicalEnv =
        node.parent.as[NamedStmt].stmt.children_env
}

|" Declaration for a static constant number (:rmlink:`3.3.2`).
class NumberDecl: BasicDecl {
    @parse_field
    ids: ASTList[DefiningName]
    @parse_field
    expr: Expr
    @parse_field
    @null_field
    aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] =
        self.ids.map((id) => id)

    @call_memoizable
    @with_dynvars(origin)
    fun expr_type(): Entity[BaseTypeDecl] =
        if self.expr.expression_type().is_int_type()
        then node.universal_int_type()
        else node.universal_real_type()

    fun xref_entry_point(): Bool = true

    @with_dynvars(imprecise_fallback=false)
    fun is_static_decl(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        (
            (
                node.expr.expected_type_var() <- node.universal_int_type()
                %or node.expr.expected_type_var() <- node.universal_real_type()
            )
            %and self.expr.sub_equation()
        )
        %and self.expr.matches_expected_type()

    fun is_constant_object(): Bool = true

    env_spec {
        add_all_to_env(node.env_mappings(node.ids, node))
    }
}

|" Base class for Ada object declarations (:rmlink:`3.3.1`). Ada object
|" declarations are variables/constants declarations that can be declared in
|" any declarative scope.
class ObjectDecl: BasicDecl {
    @parse_field
    ids: ASTList[DefiningName]
    @parse_field
    @nullable
    has_aliased: Aliased
    @parse_field
    @nullable
    has_constant: Constant
    @parse_field
    @nullable
    mode: Mode
    @parse_field
    @nullable
    type_expr: TypeExpr
    @parse_field
    @nullable
    default_expr: Expr
    @parse_field
    @nullable
    renaming_clause: RenamingClause
    @parse_field
    aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] =
        self.ids.map((id) => id)

    @with_dynvars(
        origin, include_ud_indexing=false, dottable_type=null[AdaNode]
    )
    fun defining_env(): LexicalEnv = self.type_expr.defining_env()

    fun type_expression(): Entity[TypeExpr] = self.type_expr

    fun is_constant_object(): Bool =
        self.has_constant.do((c) => c.as_bool())

        # A GenericFormalObjDecl is constant if the Mode is `in`
        or self.mode.do(
            (m) =>
            node.parent is GenericFormalObjDecl and m is Mode.In | Mode.Default
        )

        # Renaming clause is constant if the renamed object is constant
        or self.renaming_clause?.renamed_object.is_constant()

        # Constant if the object is protected
        or self.type_expr.designated_type_decl() is ProtectedTypeDecl

    @with_dynvars(imprecise_fallback=false)
    fun is_static_decl(): Bool =
        (
            node.has_constant.as_bool()
            and self.default_expr.do((expr) => expr.is_static_expr())
        )
        or self.renaming_clause?.renamed_object.is_static_expr()

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        val typ = self.expr_type();

        (
            self.type_expr.sub_equation()
            %and self.default_expr.do(
                (de) =>
                (de.expected_type_var() <- typ %and de.sub_equation())
                %and de.matches_expected_assign_type(),
                default_val=%true
            )
        )
        %and self.renaming_clause.do(
            (rc) =>
            (
                rc.renamed_object.expected_type_var() <- typ
                %and rc.renamed_object.sub_equation()
            )
            %and rc.renamed_object.matches_expected_assign_type(),
            default_val=%true
        )
    }

    @with_dynvars(imprecise_fallback=false)
    fun next_part_for_name(sym: Symbol): Entity[BasicDecl] =
        if self.is_in_public_part() and node.has_constant.as_bool()
        then
            node.declarative_scope()
            .parent
            .as_entity
            .as[BasePackageDecl]
            .private_part
            ?.children_env
            .get_first(
                sym,
                lookup=LookupKind.minimal,
                categories=RefCategories(inherited_primitives=false, _=true)
            )
            .as[BasicDecl]
        else null[Entity[BasicDecl]]

    @with_dynvars(imprecise_fallback=false)
    fun previous_part_for_name(sym: Symbol): Entity[BasicDecl] =
        if self.is_in_private_part() and node.has_constant.as_bool()
        then
            node.declarative_scope()
            .parent
            .as_entity
            .as[BasePackageDecl]
            .public_part
            .children_env
            .get_first(
                sym,
                lookup=LookupKind.minimal,
                categories=RefCategories(inherited_primitives=false, _=true)
            )
            .as[BasicDecl]
        else null[Entity[BasicDecl]]

    |" If this object decl is the constant completion of an object decl in the
    |" public part, return the object decl from the public part.
    @exported
    fun private_part_decl(): Entity[BasicDecl] =
        self.next_part_for_name(self.defining_name_or_raise().name_symbol())

    |" If this object decl is the incomplete declaration of a constant in a
    |" public part, return its completion in the private part.
    @exported
    fun public_part_decl(): Entity[BasicDecl] =
        self.previous_part_for_name(
            self.defining_name_or_raise().name_symbol()
        )

    @with_dynvars(imprecise_fallback=false)
    fun next_part_for_decl(): Entity[BasicDecl] = self.private_part_decl()

    @with_dynvars(imprecise_fallback=false)
    fun previous_part_for_decl(): Entity[BasicDecl] = self.public_part_decl()

    fun xref_entry_point(): Bool = true

    env_spec {
        add_all_to_env(node.env_mappings(node.ids, node))
    }
}

|" Object declaration that is part of an extended return statement
|" (:rmlink:`6.5`).
class ExtendedReturnStmtObjectDecl: ObjectDecl {
}

|" Object declaration without subtype indication. This node has been
|" introduced to cover a special case for ``ObjectDecl``, where
|" ``type_expr`` is made optional (AI12-0275), and therefore cannot
|" fit in an ``ObjectDecl``.
class NoTypeObjectRenamingDecl: ObjectDecl {
    @with_dynvars(origin)
    fun expr_type(): Entity[BaseTypeDecl] =
        self.renaming_clause.renamed_object.expression_type()

    @with_dynvars(
        origin, include_ud_indexing=false, dottable_type=null[AdaNode]
    )
    fun defining_env(): LexicalEnv = self.expr_type().defining_env()

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.renaming_clause.renamed_object.sub_equation()
}

|" Declaration for a package renaming (:rmlink:`8.5.3`).
class PackageRenamingDecl: BasicDecl {
    @parse_field
    name: DefiningName
    @parse_field
    renames: RenamingClause
    @parse_field
    aspects: AspectSpec

    |" Return the declaration of the package that is renamed by self.
    @exported
    fun renamed_package(): Entity[BasicDecl] = {
        # Workaround for V714-016. We perform an initial "dummy" env get query
        # to prepare the referenced envs that will be traversed by the next
        # query by allowing `Name.use_package_name_designated_env` to get
        # memoized. It is important to use the `no_prims` category to avoid
        # traversing primitive environments, as those can trigger name
        # resolution queries (when checking signatures of subprograms in order
        # to determine the primitives of a type), which in turn can cause
        # infinite recursions if those queries need to resolve this package
        # renaming as well.
        val node_env = self.node_env;
        val _ =
            node_env.get(
                s"__dummy",
                categories=RefCategories(inherited_primitives=false, _=true)
            );

        # We can then safely perform the actual query which will not trigger
        # the infinite recursion.
        {
            bind env = node_env;

            self.renames.renamed_object.env_elements()?[0].as[BasicDecl]
        }
    }

    |" Return the declaration of the package that is ultimately renamed by
    |" self, skipping through all intermediate package renamings.
    @exported
    fun final_renamed_package(): Entity[BasicDecl] = {
        val pkg = self.renamed_package();

        pkg.as[PackageRenamingDecl].do(
            (r) => r.final_renamed_package(),
            default_val=pkg
        )
    }

    fun defining_names(): Array[Entity[DefiningName]] = [self.name]

    @with_dynvars(
        origin, include_ud_indexing=false, dottable_type=null[AdaNode]
    )
    fun defining_env(): LexicalEnv = self.renamed_package().defining_env()

    fun xref_entry_point(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.renames.renamed_object.xref_no_overloading()

    env_spec {
        do(node.env_hook())
        set_initial_env(node.child_decl_initial_env())
        add_to_env_kv(self.name_symbol(), node)
        add_env()
        do(node.populate_dependent_units())
        reference(
            node.top_level_use_package_clauses(),
            Name.use_package_name_designated_env,
            cond=node.parent is LibraryItem | Subunit
        )
        reference(
            node.top_level_use_type_clauses(),
            Name.name_designated_type_env,
            cond=node.parent is LibraryItem | Subunit
        )
    }
}

|" Declaration for a single protected object (:rmlink:`9.4`).
class SingleProtectedDecl: BasicDecl {
    @parse_field
    name: DefiningName
    @parse_field
    aspects: AspectSpec
    @parse_field
    interfaces: ParentList
    @parse_field
    definition: ProtectedDef

    fun defining_names(): Array[Entity[DefiningName]] = [self.name]

    @with_dynvars(
        origin, include_ud_indexing=false, dottable_type=null[AdaNode]
    )
    fun defining_env(): LexicalEnv =
        self.definition.private_part.do(
            (pp) =>
            # Include private_part's env unconditionally. This is safe since
            # SingleProtectedDecl can't be overloaded, thus wrong name
            # resolution can only occur on invalid Ada code.
            [self.children_env, pp.children_env].env_group(),
            default_val=self.children_env
        )

    fun xref_entry_point(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.interfaces.logic_all((ifc) => ifc.xref_equation())

    fun env_names(): Array[Symbol] =
        node.top_level_env_name().do((fqn) => [fqn.to_symbol])

    fun declarative_parts(): Array[Entity[DeclarativePart]] = {
        val pdef = self.definition;

        [pdef.public_part.as[DeclarativePart]]
        & pdef.private_part.as[DeclarativePart].do((v1) => [v1])
    }

    env_spec {
        add_to_env_kv(self.name_symbol(), node)
        add_env(names=node.env_names())
    }
}

|" Declaration for a single task (:rmlink:`9.1`).
class SingleTaskDecl: BasicDecl {
    @parse_field
    task_type: SingleTaskTypeDecl
    @parse_field
    @null_field
    aspects: AspectSpec

    fun defining_names(): Array[Entity[DefiningName]] =
        self.task_type.defining_names()

    @with_dynvars(origin)
    fun expr_type(): Entity[BaseTypeDecl] = self.task_type

    @with_dynvars(
        origin, include_ud_indexing=false, dottable_type=null[AdaNode]
    )
    fun defining_env(): LexicalEnv = self.task_type.defining_env()

    fun env_names(): Array[Symbol] =
        node.top_level_env_name().do((fqn) => [fqn.to_symbol])

    env_spec {
        add_to_env_kv(node.name_symbol(), node)
        add_env(names=node.env_names())
    }
}

|" SyntheticObjectDecl is a declaration that holds a virtual object. This is
|" for example used in type predicates to refer to an object of the enclosing
|" type, as in::
|"
|"      subtype Odd is Natural with
|"         Dynamic_Predicate => Odd mod 2 = 1;
|"
|" where we have to create an object named ``Odd``, and of type ``Odd`` so
|" that the name in the aspect expression refers to it and can be properly
|" resolved to the type identifier.
|"
|" This node has no existance in the Ada RM, it's only used for internal name
|" resolution purposes.
@synthetic
class SyntheticObjectDecl: BasicDecl {
    name: DefiningName
    type_expr: TypeExpr
    @parse_field
    @null_field
    aspects: AspectSpec

    fun type_expression(): Entity[TypeExpr] = node.type_expr.as_entity

    fun defining_names(): Array[Entity[DefiningName]] = [node.name.as_entity]

    |" Return whether a synthetic type predicate object can be seen from the
    |" given ``origin`` node. If we are outside the type definition, this will
    |" always be the type itself. Otherwise this will always be the synthetic
    |" object, unless we are in an access type definition. In particular, this
    |" allows correctly resolving:
    |"
    |" .. code:: ada
    |"
    |"     type T is record
    |"        X : access T := T'Unrestricted_Access;
    |"        --        (1)  (2)
    |"     end record;
    |"
    |" Here, the reference (1) points to the type, whereas (2) refers to the
    |" synthetic object.
    fun is_referred_by(origin: AdaNode): Bool =
        origin.parents().find((p) => p is AccessDef).is_null
        and node.is_children_env(
            node.type_expr.as[SyntheticTypeExpr].target_type.children_env,
            origin.children_env
        )
}

|" Alternative in a ``case`` statement (``when ... => ...``).
class CaseStmtAlternative: AdaNode {
    @parse_field
    choices: AlternativesList
    @parse_field
    stmts: StmtList

    fun xref_entry_point(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        val case_stmt = self.parent.parent.as![CaseStmt];
        # Trigger name resolution on the case statement
        val selected_type = case_stmt.expr.expression_type();

        self.choices.logic_all(
            (c) =>
            match c {
                # Expression case
                case e: Expr =>
                    if
                        e is Name
                        and not e.as[Name].name_designated_type().is_null
                    then e.as[Name].xref_type_equation()
                    else
                        (
                            e.expected_type_var() <- selected_type
                            %and e.sub_equation()
                        )
                        %and e.matches_expected_type()

                # SubtypeIndication case (``when Color range Red .. Blue``)
                case t: SubtypeIndication => t.xref_equation()
                case _: OthersDesignator => %true
                case _ => raise[Equation] PropertyError("Should not happen")
            }
        )
    }
}

|" Root node for all Ada analysis units (:rmlink:`10.1.1`).
@ple_unit_root
class CompilationUnit: AdaNode {
    |" ``with``, ``use`` or ``pragma`` statements.
    @parse_field
    prelude: ASTList[AdaNode]
    @parse_field
    body: AdaNode
    @parse_field
    pragmas: ASTList[Pragma]
    no_env: LexicalEnv

    |" Returns an empty env to use in env specs. This is meant as an
    |" optimization: Langkit referenced envs that return empty env can never
    |" be cached, so we used a CompilationUnit specific empty env, that will
    |" live for the same duration as its analysis unit, and then be
    |" invalidated.
    @external(uses_envs=true)
    fun get_empty_env(): LexicalEnv

    |" Return the syntactic fully qualified name of this compilation unit.
    @exported
    fun syntactic_fully_qualified_name(): Array[Symbol] = match
        node.as_bare_entity.body
    {
        case li: LibraryItem => li.item.defining_name()?.as_symbol_array()
        case su: Subunit =>
            su.name.as_symbol_array()
            & su.body.defining_name().as_symbol_array()
        case _ =>
            raise[Array[Symbol]] PropertyError(
                "Unexpected CompilationUnit.f_body attribute"
            )
    }

    |" Return the kind corresponding to this analysis unit.
    @exported
    fun unit_kind(): AnalysisUnitKind = match node.body {
        case li: LibraryItem =>
            match li.item {
                case _: Body => AnalysisUnitKind.unit_body
                case _ => AnalysisUnitKind.unit_specification
            }
        case _: Subunit => AnalysisUnitKind.unit_body
        case _ =>
            raise[AnalysisUnitKind] PropertyError(
                "Unexpected CompilationUnit.f_body attribute"
            )
    }

    |" Return all units referenced in this name. For example in the name
    |" ``A.B.C``, this returns units ``A``,  ``A.B`` and ``A.B.C``.
    fun referenced_units_in(
        name: Entity[Name]
    ): Array[Entity[CompilationUnit]] = {
        val self_refd = name.referenced_decl()?.enclosing_compilation_unit();

        name.as[DottedName].do(
            (dn) => node.referenced_units_in(dn.prefix),
            default_val=null[Array[Entity[CompilationUnit]]]
        )
        & self_refd.as_bare_entity.do((v1) => [v1])
    }

    |" Look for all "with" clauses at the top of this compilation unit and
    |" return all the compilation units designated by them. For the complete
    |" dependencies list of compilation units, see the ``unit_dependencies``
    |" property. Units imported with a "private with" are included in this
    |" list only if ``include_privates`` is True.
    @exported
    @memoized
    fun withed_units(
        include_privates: Bool = true
    ): Array[Entity[CompilationUnit]] =
        node.top_level_with_package_clauses(include_privates).mapcat(
            # Try to fetch the compilation unit in a spec file first. If this
            # fails, the "with" must designate a body without spec (e.g. a
            # library-level procedure).
            (p) => node.referenced_units_in(p.as_bare_entity)
        )
        .unique()

    |" Return all the compilation units that are directly imported by this
    |" one. This includes "with"ed units as well as the direct parent unit.
    |" Units imported with a "private with" are included in this list only if
    |" ``include_privates`` is True.
    @exported
    @memoized
    fun imported_units(
        include_privates: Bool = true
    ): Array[Entity[CompilationUnit]] =
        node.withed_units(include_privates)
        & (
            # Library-level subprogram bodies are handled specially here,
            # as their parent environment is *not* their corresponding spec in
            # our implementation (unlike for the rest of the library-level
            # declarations).
            node.decl().as[BaseSubpBody].do(
                # We call subp_previous_part directly to avoid unnecessary
                # detours in which code that raises property errors could
                # be accidentally added.
                (subp) =>
                subp.as_bare_entity.subp_previous_part().do(
                    (pp) => [pp.enclosing_compilation_unit().as_bare_entity]
                )
            )
            or? node.decl()?.node_env?.env_node.do(
                (n) => [n.enclosing_compilation_unit().as_bare_entity]
            )
        )

    |" Return the list of units that are only visible in private parts of this
    |" compilation units. Note that this is not equivalent to the list of
    |" units that are private-withed, as Ada allows the same unit to be both
    |" "with"ed and "private with"ed, in which case it will also be visible in
    |" public parts. So, in order to compute that list, we must subtract the
    |" list of units that are (non-private-)"with"ed from the list of all
    |" "with"ed and "private with"ed units.
    @memoized
    fun privately_imported_units(): Array[AnalysisUnit] =
        # Shortcut: if there are no "private with" clauses, the subtraction
        # will be empty.
        if
            node.prelude.any(
                (clause) => clause.as[WithClause]?.has_private.as_bool()
            )
        then {
            val all_imports = node.imported_units(include_privates=true);
            val public_imports = node.imported_units(include_privates=false);

            all_imports.filtermap(
                (cu) => cu.unit,
                (cu) => not public_imports.contains(cu)
            )
        }
        else null[Array[AnalysisUnit]]

    |" Helper function for "unit_dependencies" that computes transitively
    |" the unit dependencies of the given ``to_visit`` units. The ``visited``
    |" set of units is used to terminate the search once a fix-point has
    |" been reached, which is when all direct dependencies of ``to_visit`` are
    |" already included in the ``visited`` set.
    fun unit_dependencies_helper(
        visited: Array[Entity[CompilationUnit]],
        to_visit: Array[Entity[CompilationUnit]]
    ): Array[Entity[CompilationUnit]] = {
        val now_visited = visited & to_visit;
        val new_imports = to_visit.mapcat((c) => c.imported_units()).unique();
        val to_visit_next =
            new_imports.filter((c) => not now_visited.contains(c));

        if to_visit_next.length() > 0
        then node.unit_dependencies_helper(now_visited, to_visit_next)
        else now_visited
    }

    |" Return the list of all the compilation units that are (direct and
    |" indirect) dependencies of this one. See the
    |" ``withed_units``/``imported_units`` properties to only get the direct
    |" dependencies of this unit.
    @exported
    @memoized
    fun unit_dependencies(): Array[Entity[CompilationUnit]] =
        node.unit_dependencies_helper(
            null[Array[Entity[CompilationUnit]]],
            [self]
        )
        .unique()
        .filter(
            # Remove self from the list of dependencies
            (u) => u.node != node
        )

    |" Get the root basic decl defined in this compilation unit.
    @exported
    fun decl(): BasicDecl = match node.body {
        case li: LibraryItem => li.item
        case su: Subunit => su.body
        case _ => null[BasicDecl]
    }

    |" Implementation helper for ``is_preelaborable``.
    |"
    |" Return whether ``self`` or its spec (if any) make it preelaborable.
    |" ``from_body`` has the same semantics as in
    |" ``does_aspects_make_preelaborate``.
    @with_dynvars(imprecise_fallback=false)
    fun is_preelaborable_impl(from_body: Bool): Bool = match self.body {
        # Subunits are preelaborable iff the body they relate to is
        # preelaborable.
        case su: Subunit =>
            su.body_root()
            .parent
            .parent
            .as![CompilationUnit]
            .is_preelaborable_impl(from_body=true)
        case li: LibraryItem =>
            match li.item {
                case subp_decl: SubpDecl =>
                    subp_decl.does_aspects_make_preelaborable(from_body)
                case gen_subp_decl: GenericSubpDecl =>
                    gen_subp_decl.decl().does_aspects_make_preelaborable(
                        from_body
                    )
                case subp_body: SubpBody =>
                # Subprogram bodies can have elaboration pragmas, so
                # look for them, first.
                    subp_body
                    .does_aspects_make_preelaborable(from_body=false)
                    # Otherwise recurse on the corresponding procedure spec (if
                    # any).
                    or subp_body.decl_part().do(
                        (dp) =>
                        dp
                        .parent
                        .parent
                        .as![CompilationUnit]
                        .is_preelaborable_impl(from_body=true)
                    )
                case pkg_decl: PackageDecl =>
                    pkg_decl.does_aspects_make_preelaborable(from_body)
                case gen_pkg_decl: GenericPackageDecl =>
                    gen_pkg_decl.package_decl.does_aspects_make_preelaborable(
                        from_body
                    )
                case pkg_body: PackageBody =>
                # Elaboration control pragmas cannot appear in package
                # bodies, so recurse on the corresponding package spec.
                    pkg_body
                    .decl_part()
                    .unit
                    .root
                    .as_bare_entity
                    .as![CompilationUnit]
                    .is_preelaborable_impl(from_body=true)
                case _ => false
            }
        case _ => false
    }

    |" Whether this compilation unit is preelaborable or not.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun is_preelaborable(): Bool = self.is_preelaborable_impl(from_body=false)

    |" Return the list of restrictions pragmas that appear in the prelude of
    |" this particular unit. We only check the prelude as it's the only place
    |" they are allowed to appear in.
    fun self_restrictions(): Array[Symbol] =
        node.as_bare_entity.prelude.filtermap(
            (n) =>
            n.as[Pragma].args?[0]?.assoc_expr().as[BaseId].name_symbol(),
            (n) =>
            n.as[Pragma].do((p) => p.id.name_symbol() == s"Restrictions")
        )

    |" If this compilation unit is of kind UnitSpecification, return its
    |" corresponding body unit, and conversely.
    @exported
    fun other_part(): Entity[CompilationUnit] = {
        val other_kind =
            if node.unit_kind() == AnalysisUnitKind.unit_specification
            then AnalysisUnitKind.unit_body
            else AnalysisUnitKind.unit_specification;

        node.designated_compilation_unit(
            node.syntactic_fully_qualified_name(),
            kind=other_kind,
            not_found_is_error=false
        )
        ?.as_bare_entity
    }

    |" Whether this compilation unit is affected by the restriction with the
    |" given name.
    |"
    |" .. WARNING::
    |"     This property only supports the ``No_Elaboration_Code`` restriction
    |"     for now.
    @exported
    fun has_restriction(name: Symbol): Bool =
        if name == s"No_Elaboration_Code"
        then
            match node.body {
                # For library items, restriction No_Elaboration_Code can appear
                # in the body or in the spec.
                case li: LibraryItem =>
                    node.self_restrictions().contains(name)
                    or node.other_part()?.self_restrictions().contains(name)
                    # Pragma No_Elaboration_Code_All establishes the
                    # restriction No_Elaboration_Code for the current unit and
                    # any extended main source units (body and subunits).
                    or {
                        val spec =
                            li.item.as_bare_entity.do(
                                (i) =>
                                if i is Body then i.as[Body].decl_part() else i
                            );

                        not spec.is_null
                        and spec.defining_name().has_aspect(
                            s"No_Elaboration_Code_All"
                        )
                    }
                # For subunits, restriction must appear in the root unit, so
                # we only check that.
                case su: Subunit => su.root_unit()?.has_restriction(name)
                case _ =>
                    raise[Bool] PropertyError(
                        "Unexpected CompilationUnit.f_body attribute"
                    )
            }
        else raise[Bool] PropertyError("Unsupported restriction")

    |" Returns whether this compilation unit defines a child package of
    |" Ada.Text_IO.
    fun is_text_io_child(): Bool = {
        val name_parts = node.syntactic_fully_qualified_name();

        name_parts.length() == 3 and name_parts?[0] == s"ada"
        and name_parts?[1] in s"text_io"
            | s"wide_text_io"
            | s"wide_wide_text_io"
    }

    |" Return the list of pragmas from configuration pragmas files that apply
    |" to ``self``'s unit.
    @external()
    fun external_config_pragmas(): Array[Pragma]

    |" Return the list of configuration pragmas defined in the prelude of the
    |" current unit.
    fun local_config_pragmas(): Array[Pragma] =
        node.prelude.filtermap((n) => n.as[Pragma], (n) => n is Pragma)

    |" Return the list of configuration pragmas defined in Ada sources and
    |" which apply to the current unit.
    fun sources_config_pragmas(
        include_other_part: Bool = true
    ): Array[Pragma] = {
        # First get pragmas in the prelude
        val current_unit = node.local_config_pragmas();
        # Then get pragmas in related units
        val related_units =
        # If self is a spec, we need to look at its body, and conversely
            if include_other_part and node.body is LibraryItem
            then node.other_part()?.local_config_pragmas()

            # If self is a sub-unit, we need to look at all subunits up in the
            # chain, the root body, and the corresponding spec.
            elif node.body is Subunit
            then
                node.body.as[Subunit].root_unit()?.sources_config_pragmas(
                    include_other_part
                )
            else null[Array[Pragma]];

        current_unit & related_units
    }

    |" Return the list of configuration pragmas that apply to the current
    |" unit.
    @exported
    fun all_config_pragmas(): Array[Entity[Pragma]] =
        (node.sources_config_pragmas() & node.external_config_pragmas()).map(
            (n) => n.as_bare_entity
        )

    |" Return the ``SPARK_Mode`` configuration pragma that applies to the
    |" current unit.
    fun spark_config_pragma(): Entity[Pragma] =
        (
            node.external_config_pragmas()
            & node.sources_config_pragmas(include_other_part=false)
        )
        .filtermap(
            (n) => n.as_bare_entity,
            (n) => n.id.name_is(s"SPARK_Mode")
        )?[
            -1
        ]

    |" Return the list of configuration pragmas with the given name that apply
    |" to the current unit.
    @exported
    fun config_pragmas(name: Symbol): Array[Entity[Pragma]] =
        node.all_config_pragmas().filter((n) => n.id.name_symbol() == name)

    |" Look for the stub in ``self`` corresponding to ``su`` or one of its
    |" parents. Return a null node if unsuccessful.
    |"
    |" For instance, with the following units::
    |"
    |"    procedure A is
    |"       procedure B is separate;
    |"    begin
    |"       null;
    |"    end A;
    |"
    |"    separate (A)
    |"    procedure B is
    |"       procedure C is separate;
    |"    begin
    |"       null;
    |"    end B;
    |"
    |"    separate (A.B)
    |"    procedure C is
    |"    begin
    |"       null;
    |"    end C;
    |"
    |" We have the following::
    |"
    |"    A.stub_for(B) -> "procedure B is separate"
    |"    A.stub_for(C) -> "procedure B is separate"
    |"    B.stub_for(C) -> "procedure C is separate"
    |"
    |" This is an internal helper for ``AdaNode.can_reach``: since it is used
    |" in all lexical env lookups, its implementation cannot do lookups itself
    |" as it would trigger infinite recursions. Libadalang users can use
    |" ``BasicDecl.previous_part_for_decl`` instead.
    |"
    |" Note that this wrapper only takes care of memoization. The actual
    |" implementation is in ``CompilationUnit.stub_for_impl``. Memoizing this
    |" property is very important for performance.
    @memoized
    # At the time of its introduction, this property was used only by
    # AdaNode.can_reach, which was an external property.
    @ignored
    fun stub_for(su: Subunit): BodyStub = node.stub_for_impl(su)

    |" Ada implementation of ``CompilationUnit.stub_for``.
    @external()
    fun stub_for_impl(su: Subunit): BodyStub

    |" Return whether the given ``origin`` node has view on "private withs" of
    |" its unit or parent units.
    fun has_private_view(origin: AdaNode): Bool = {
        val decl = node.decl();

        (
            # A private package necessarily has private-with visibility
            node.body.as[LibraryItem]?.has_private.as_bool()
        )
        or (
            # If this compilation doesn't declare a package, then we
            # necessarily have private-with visibility because it means we are
            # inside a body.
            not decl is BasePackageDecl | GenericPackageDecl
        )
        or (
            # Otherwise (this compilation unit declares a package), check
            # whether `origin` lies in a private part.
            origin.has_private_part_parent(decl.children_env.env_node)
        )
    }
}

|" Representation clause for a single component (:rmlink:`13.5.1`).
class ComponentClause: AdaNode {
    @parse_field
    id: Identifier
    @parse_field
    position: Expr
    @parse_field
    range: RangeSpec

    fun xref_entry_point(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        # Find the record representation clause in which the component clause
        # appears.
        val rep_clause = self.parent.parent.as![RecordRepClause];
        # rep_clause.name must refer to a subtype, so it's safe to use
        # designated_env_no_overloading.
        val record_env = rep_clause.name.designated_env_no_overloading();

        (
            # Resolve `id` in the environment of the original record
            {
                bind env = record_env;

                self.id.xref_equation()
            }
        )
        %and self.position.sub_equation()
        %and self.range.sub_equation()
    }
}

|" Definition for a component (:rmlink:`3.6`).
class ComponentDef: AdaNode {
    @parse_field
    has_aliased: Aliased
    @parse_field
    has_constant: Constant
    @parse_field
    type_expr: TypeExpr

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = self.type_expr.sub_equation()
}

|" Qualifier for the ``constant`` keyword.
@qualifier
enum class Constant: AdaNode {
}

|" Base class for type constraints (:rmlink:`3.2.2`).
@abstract
class Constraint: AdaNode {
    fun subtype(): Entity[BaseTypeDecl] = {
        bind origin = node.origin_node();

        node.parent.as![SubtypeIndication].as_entity.designated_type()
    }

    @with_dynvars(imprecise_fallback=false)
    fun is_static(): Bool = match self {
        case rc: RangeConstraint => rc.range.range.is_static_expr()
        case cc: CompositeConstraint =>
            if cc.is_index_constraint()
            then
                cc.constraints.all(
                    (c) =>
                    match c.as[CompositeConstraintAssoc].constraint_expr {
                        case st: SubtypeIndication => st.is_static_subtype()
                        case e: Expr => e.is_static_expr()
                        case _ => false
                    }
                )
            else cc.constraints.all((c) => c.expr().is_static_expr())
        case dc: DigitsConstraint =>
            dc.range.do(
                (range) => range.range.is_static_expr(),
                default_val=true
            )
        case dc: DeltaConstraint =>
            dc.range.do(
                (range) => range.range.is_static_expr(),
                default_val=true
            )
    }
}

|" Constraint for a composite type (:rmlink:`3.6.1`). Due to ambiguities in
|" the Ada grammar, this could be either a list of index constraints, if the
|" owning type is an array type, or a list of discriminant constraints, if the
|" owning type is a discriminated record type.
class CompositeConstraint: Constraint {
    @parse_field
    constraints: AssocList

    |" Whether this composite constraint is an index constraint.
    @exported
    fun is_index_constraint(): Bool =
        self.subtype().is_array_type()
        or (
            self.subtype().is_access_type()
            and self.subtype().accessed_type().is_array_type()
        )

    @with_dynvars(origin)
    fun complete_item_weight(item: Entity[BasicDecl]): Int =
        # If the constraint's type is an enum, promote EnumLiteralDecl nodes
        # that match that type.
        if
            self.subtype().discriminants_list().any(
                (td) =>
                td.formal_type() == item.as[EnumLiteralDecl]?.enum_type()
            )
        then 100
        else self.super(item)

    |" Whether this composite constraint is a discriminant constraint.
    @exported
    fun is_discriminant_constraint(): Bool = not self.is_index_constraint()

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        val typ = self.subtype();

        if self.is_index_constraint()
        then
            self.constraints.ilogic_all(
                (c, i) => {
                    val ex = c.as[CompositeConstraintAssoc].constraint_expr;

                    # If the index constraint is an expression (which means it
                    # is either a BinOp (first .. last) or an AttributeRef
                    # (X'Range)), we assign to the type of that expression the
                    # type of the index which we are constraining, or else it
                    # would be resolved without any context and we could get
                    # erroneous types in some cases.  Consider for example
                    # ``subtype T is List ('A' .. 'B')``: here, 'A' and 'B'
                    # could type to e.g. ``Character`` although the index type
                    # of ``List`` is for example ``My_Character``. But if we
                    # bind the type of ``'A' .. 'B'`` to ``My_Character`` as we
                    # now do, the type will be propagated to both 'A' and 'B'
                    # and therefore they will get the correct types.
                    # Note that it's currently necessary to first assign the
                    # expected type to the range before recursively
                    # constructing its xref equations, as we have cases (e.g.
                    # BinOp) where resolution takes different paths depending
                    # on its operands' types (e.g. whether it's a universal
                    # type or not).
                    ex.as[Expr].do(
                        (e) =>
                        e.expected_type_var()
                        <- typ.index_type(i).base_subtype(),
                        default_val=%true
                    )
                    %and ex.sub_equation()
                }
            )
        else (
            # Regular discriminant constraint case
            node.match_formals(
                typ.discriminants_list(),
                self.constraints,
                false
            )
            .logic_all(
                (pm) =>
                (
                    (
                        pm.actual.assoc.expr().expected_type_var()
                        <- pm.formal.formal_decl().formal_type()
                        %and pm.actual.assoc.expr().sub_equation()
                    )
                    %and pm.actual.assoc.expr().matches_expected_formal_type()
                )
                %and pm.actual.name.do(
                    (name) => name.ref_var() <- pm.formal.formal_decl(),
                    default_val=%true
                )
            )
        )
    }

    |" Returns an array of pairs, associating each discriminant to its
    |" actual or default expression.
    @exported
    fun discriminant_params(): Array[ParamActual] = {
        # Build a discriminants list with their default expressions
        val discrs =
            self.subtype().discriminants_list().mapcat(
                (d) => {
                    val ds = d.as[DiscriminantSpec];

                    ds.ids.map(
                        (i) => ParamActual(param=i, actual=ds.default_expr)
                    )
                }
            );

        # Update the constraints expressions if some are provided
        self.constraints.do(
            (c) =>
            discrs.imap(
                (dp, i) =>
                ParamActual(
                    param=dp.param,
                    actual=c.actual_for_param_at(dp.param, i, dp.actual)
                )
            ),
            default_val=discrs
        )
    }
}

|" Delta and range type constraint (:rmlink:`J.3`).
class DeltaConstraint: Constraint {
    @parse_field
    delta: Expr
    @parse_field
    @nullable
    range: RangeSpec

    |" Build an equation for a delta constraint definition.
    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        (
            # As per :rmlink:`J.3`, the delta expression is expected to be of
            # any real type.
            self.universal_real_bind(self.delta.expected_type_var())
        )
        %and self.delta.sub_equation()
        %and self.delta.matches_expected_type()
        %and (if node.range.is_null then %true else self.range.sub_equation())
}

|" Digits and range type constraint (:rmlink:`3.5.9`).
class DigitsConstraint: Constraint {
    @parse_field
    digits: Expr
    @parse_field
    @nullable
    range: RangeSpec

    |" Build an equation for a digits constraint definition.
    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        (
            # As per :rmlink:`3.5.9`, the digits expression is expected to be
            # of any integer type.
            self.universal_int_bind(self.digits.expected_type_var())
        )
        %and self.digits.sub_equation()
        %and self.digits.matches_expected_type()
        %and (if node.range.is_null then %true else self.range.sub_equation())
}

|" Range-based type constraint (:rmlink:`3.5`).
class RangeConstraint: Constraint {
    @parse_field
    range: RangeSpec

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        node.range.range.expected_type_var() <- self.subtype().base_subtype()
        %and self.range.sub_equation()
        %and self.range.range.matches_expected_type()
}

|" List of declarations (:rmlink:`3.11`).
@snaps
class DeclarativePart: AdaNode {
    @parse_field
    decls: ASTList[AdaNode]

    |" Returns the envs for all the use clauses declared in this declarative
    |" part.
    fun use_clauses_envs(): LexicalEnv =
        self.decls.children.filtermap(
            (u) => u.as[UseClause].used_envs(),
            (u) => u is UseClause
        )
        .env_group()

    |" Return the ``SPARK_Mode`` pragma node declared in this declarative
    |" part if any.
    fun spark_mode_pragma(): Entity[Pragma] =
        # `SPARK_Mode` pragma can only be at the begining of the declarative
        # region.
        self.decls.take_while((decl) => decl is Pragma).find(
            (decl) => decl.as[Pragma].id.name_is(s"SPARK_Mode")
        )
        .as[Pragma]

    |" Return whether this declarative part has SPARK mode set to On.
    fun spark_mode_aspect(): Aspect =
        # Look if a `SPARK_Mode` pragma has been specified for that part
        self.spark_mode_pragma().do(
            # Then, is it `On` or `Off`?
            (pragma) => pragma.as_aspect(),

            # Else, `SPARK_Mode` can also be specified by an aspect
            default_val=self.parent.as[BasicDecl].do(
                (bd) =>
                bd.get_aspect(s"SPARK_Mode")
                # If not pragma or aspect sets `SPARK_Mode`, have a look at
                # the parent declarative scope.
                or? self.super(),
                default_val=self.super()
            )
        )
}

|" List of declarations in a private part.
class PrivatePart: DeclarativePart {
    |" A private part allows for a named env iff its parent package is a
    |" library item, in which case it will be ``.__privatepart`` appended to
    |" that package's top_level_env_name.
    fun env_names(): Array[Symbol] =
        node.parent.as[BasePackageDecl].do(
            (pkg) =>
            pkg.top_level_env_name().do(
                (name) => [(name & ".__privatepart").to_symbol]
            )
        )

    fun immediate_declarative_region(): LexicalEnv =
        self.semantic_parent().immediate_declarative_region()

    |" Return whether this private part has SPARK mode set to On.
    fun spark_mode_aspect(): Aspect =
        # Look if a `SPARK_Mode` pragma has been specified for that part
        self.spark_mode_pragma().do(
            (pragma) => pragma.as_aspect(),
            # If not pragma sets `SPARK_Mode`, have a look at the corresponding
            # public part if any.
            default_val=self
            .parent
            .as[PackageDecl]
            ?.public_part
            .spark_mode_aspect()
        )

    env_spec {
        add_to_env_kv(s"__privatepart", node)
        add_env(transitive_parent=true, names=node.env_names())
    }
}

|" List of declarations in a public part.
class PublicPart: DeclarativePart {
}

|" ``elsif`` block, part of an ``if`` expression.
class ElsifExprPart: AdaNode {
    @parse_field
    cond_expr: Expr
    @parse_field
    then_expr: Expr
}

|" ``elsif`` part in an ``if`` statement block.
class ElsifStmtPart: AdaNode {
    @parse_field
    cond_expr: Expr
    @parse_field
    stmts: StmtList

    fun xref_entry_point(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.cond_expr.sub_equation()
        %and node.cond_expr.expect_bool_derived_type()
}

|" Base class for expressions (:rmlink:`4.4`).
@abstract
@with_abstract_list
class Expr: AdaNode {
    logic_vars: Address

    @external()
    fun type_var(): LogicVar

    @external()
    fun expected_type_var(): LogicVar

    fun type_val(): Entity[AdaNode] = node.type_var().get_value()

    |" Return the declaration corresponding to the type of this expression
    |" after name resolution.
    @exported
    fun expression_type(): Entity[BaseTypeDecl] =
        node.logic_val(self, node.type_var()).value.as![BaseTypeDecl]

    |" Return the declaration corresponding to the expected type of this
    |" expression after name resolution.
    @exported
    fun expected_expression_type(): Entity[BaseTypeDecl] =
        node.logic_val(self, node.expected_type_var()).value.as![BaseTypeDecl]

    @with_dynvars(origin)
    fun matches_expected_type(): Equation = {
        bind error_location = node;
        BaseTypeDecl.matching_type%(node.type_var(), node.expected_type_var())
    }

    @with_dynvars(origin)
    fun matches_expected_assign_type(): Equation = {
        bind error_location = node;
        BaseTypeDecl.matching_assign_type%(node.type_var(),
        node.expected_type_var())
    }

    @with_dynvars(origin)
    fun matches_expected_formal_type(): Equation = {
        bind error_location = node;
        BaseTypeDecl.matching_formal_type%(node.type_var(),
        node.expected_type_var())
    }

    @with_dynvars(origin)
    fun matches_expected_membership_type(): Equation =
        BaseTypeDecl.matching_membership_type%(node.type_var(),
        node.expected_type_var())

    @with_dynvars(origin)
    fun matches_expected_prefix_type(): Equation =
        BaseTypeDecl.matching_prefix_type%(node.type_var(),
        node.expected_type_var())

    |" Construct an equation which asserts that the expected type of this
    |" expression is the standard boolean type or any type that derives from
    |" it.
    @with_dynvars(origin)
    fun expect_bool_derived_type(): Equation =
        (
            node.expected_type_var() <- node.bool_type()
            %or node.expected_type_var()
            <- BaseTypeDecl.derefed_base_subtype%(node.type_var())
        )
        %and {
            bind error_location = node;
            BaseTypeDecl.derives_from_std_bool_type%(node.type_var())
        }

    |" Build the xref_equation for this expression in the context of an
    |" ``Annotate`` aspect argument, which requires it to either be of any of
    |" the standard String types, or to be a general non-ambiguous expression.
    |" Hence, we try here to resolve it using corresponding expected types.
    |" Note that we don't even check that the expected and actual types match
    |" in order to allow the same kind of flexibility that GNAT has.
    |" GNAT also allows direct references to subprograms (even though they are
    |" not valid expressions per-se), so we also fallback to resolving the
    |" first visible declaration of the given name.
    @with_dynvars(env, origin, entry_point)
    fun annotate_argument_equation(): Equation =
        (
            self.sub_equation()
            %and %domain(
                node.expected_type_var(),
                [
                    null[Entity[BaseTypeDecl]],
                    node.std_string_type(),
                    node.std_wide_string_type(),
                    node.std_wide_wide_string_type()
                ]
            )
        )
        %or self.as[Name].do(
            (name) => name.xref_no_overloading(),
            default_val=%false
        )

    |" Equation for the case where this is an expression on the RHS of a
    |" Loop_Variant or Subprogram_Variant association.
    |" See SPARK RM 6.1.8 for more details.
    @with_dynvars(env, origin, entry_point)
    fun spark_variant_equation(designator: Entity[BaseId]): Equation =
        if designator.name_symbol() in s"Increases" | s"Decreases"
        then
            (
                # For a numeric subprogram variant, the expression must be of
                # any discrete type, or one of the allowed `Big_Integer` types.
                (
                    AdaNode.is_not_null%(self.type_var())
                    %and BaseTypeDecl.is_discrete_type%(self.type_var())
                ) %or (
                    %domain(
                        self.expected_type_var(),
                        [
                            self.big_integer_type(),
                            self.big_integer_ghost_type(),
                            self.spark_big_integer_type()
                        ]
                    )
                    %and self.matches_expected_type()
                )
            )
            %and self.sub_equation()
        elif designator.name_symbol() in s"Structural"
        then
            # For a structural variant, the expression must denote a formal
            # parameter of the subprogram or a local object, so a simple call
            # to sub_equation will do.
            self.sub_equation()
        else %false

    |" Returns whether this expression is dynamically tagged (See
    |" :rmlink:`3.9.2`).
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun is_dynamically_tagged(): Bool = # See ARM 3.9.2 for the rules
    {
        bind origin = node.origin_node();

        self.expression_type().is_classwide()
        or self.expression_type().accessed_type()?.is_classwide()
        or match self {
            case qual_expr: QualExpr =>
                qual_expr.suffix.is_dynamically_tagged()

            # If expr is a call with a controlling result which has at
            # least one dynamically tagged controlling operand, then it's
            # dynamically tagged.
            case n: Name =>
                n.is_direct_call()
                and n.called_subp_spec().as[BaseSubpSpec].do(
                    (spec) =>
                    spec.has_controlling_result()
                    and n.has_dynamic_controlling_operand(spec)
                )
            case cond_expr: CondExpr =>
                cond_expr.dependent_exprs().all(
                    (e) => e.is_dynamically_tagged()
                )
            case decl_expr: DeclExpr => decl_expr.expr.is_dynamically_tagged()
            case paren_expr: ParenExpr =>
                paren_expr.expr.is_dynamically_tagged()
            case _ => false
        }
    }

    |" Return whether this call has at least one controlling operand which is
    |" dynamically tagged.
    @with_dynvars(imprecise_fallback=false)
    fun has_dynamic_controlling_operand(spec: Entity[BaseSubpSpec]): Bool =
        # Retrieve the candidate expressions on which the tag check could
        # be made, together with the expected type for them.
        # Then, check that there is a pair (``formal``, ``actual``)
        # where ``formal`` is a controlling formal parameter of the
        # primitive subprogram ``decl``, and ``actual`` is a dynamically
        # tagged expression used for this parameter.
        self.potential_actuals_for_dispatch(spec).any(
            (c) =>
            spec.get_candidate_type_for_primitive(c.expected_type).do(
                (typ) =>
                (
                    # We don't need accurate tagged-visibility information on
                    # `typ` at the callsite, we just want to abort early here
                    # to avoid having to handle nonsensical types in the
                    # `is_dynamically_tagged` property.
                    typ.full_view().is_tagged_type()
                )
                and c.expr.is_dynamically_tagged()
            )
        )

    |" Return the closest parent expression that can be a dispatching call and
    |" which can control the tag value of this expression according to Ada
    |" semantics (see :rmlink:`3.9.2` 17/2).
    fun parent_candidate_dispatching_call(): Entity[Expr] = match self.parent {
        case ce: CallExpr =>
            if self == ce.name then ce.parent_candidate_dispatching_call()
            else ce
        case dn: DottedName =>
            if self == dn.suffix then dn.parent_candidate_dispatching_call()
            else dn
        case uo: UnOp =>
            if self == uo.op then uo.parent_candidate_dispatching_call()
            else uo
        case bo: BinOp =>
            if self == bo.op then bo.parent_candidate_dispatching_call()
            else bo
        case ce: CondExpr =>
            if ce.dependent_exprs().contains(self)
            then ce.parent_candidate_dispatching_call()
            else null[Entity[Expr]]
        case pe: ParenExpr => pe.parent_candidate_dispatching_call()
        case qe: QualExpr => qe.parent_candidate_dispatching_call()
        case de: DeclExpr => de.parent_candidate_dispatching_call()
        case pa: ParamAssoc => pa.parent.parent.as[CallExpr]
        case _ => null[Entity[Expr]]
    }

    |" Return whether the tag value for this tag-indeterminate expression can
    |" be determined from the enclosing context, that is, whether this is the
    |" RHS of an assign statement which destination has a classwide type, or a
    |" controlling operand of an enclosing call which is itself dispatching.
    @with_dynvars(imprecise_fallback=false)
    fun has_dynamic_context(): Bool =
        self.parent.as[AssignStmt].do(
            (a) =>
            (
                # If we're the RHS of an assignment, RM 3.9.2 (18.1/2) applies:
                # The controlling operand is the LHS of the assignment.  This
                # only applies to the RHS of the assign statement.
                a.expr == self
            )
            and self.expected_expression_type().is_classwide(),

            # If we're an argument of an enclosing dispatching call, then
            # RM 3.9.2 (18/2) applies: The controlling tag value of this
            # call is the controlling tag value of the enclosing call.
            default_val=self.parent_candidate_dispatching_call()
            ?.is_dispatching_call()
        )

    |" Common logic for the implementation of is_dispatching_call on the
    |" various node types. ``decl`` should be the declaration of the
    |" subprogram being called.
    @with_dynvars(imprecise_fallback=false)
    fun is_dispatching_call_impl(decl: Entity[BasicDecl]): Bool = {
        val spec =
            decl.canonical_part().subp_spec_or_null(follow_generic=true);

        (
            # A call to an abstract formal subprogram is necessarily
            # dispatching (see RM 12.6 8.5/2).
            decl is AbstractFormalSubpDecl
        )
        or (
            # Alternatively, check if there is a controlling operand that is
            # dynamically tagged.
            self.has_dynamic_controlling_operand(spec)
        )
        or (
            # Otherwise, it means that all controlling operands are statically
            # tagged or tag-indeterminate. In the latter case, we need to check
            # that the called primitive has a controlling result and that the
            # tag can be determined from context.
            spec.has_controlling_result() and self.has_dynamic_context()
        )
    }

    |" Return whether this expression is static according to the ARM
    |" definition of static. See :rmlink:`4.9`.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun is_static_expr(): Bool = {
        bind origin = node.origin_node();

        match self {
            case _: NumLiteral => true
            case _: StringLiteral => true
            case ar: AttributeRef =>
                (
                    ar.prefix.is_static_expr()
                    and (
                        (
                            not ar.prefix.name_designated_type()?.root_type()
                            ?.is_formal()
                            and ar.attribute.name_symbol() == s"Base"
                        )
                        or (
                            ar.prefix.name_designated_type()?.is_static_decl()
                            and ar.attribute.name_symbol() in s"First"
                                | s"Last"
                                | s"Range"
                                | s"Val"
                                | s"Pos"
                        )
                        or (
                            ar.prefix.referenced_decl()?.is_array()
                            and ar.attribute.name_symbol() in s"First"
                                | s"Last"
                                | s"Length"
                                | s"Range"
                        )
                    )
                )
                and ar.args.do(
                    (args) => args.all((arg) => arg.expr().is_static_expr()),
                    default_val=true
                )

            # No matter the attribute, if it has arguments they must all be
            # static for the whole thing to be considered static.
            case ce: CallExpr =>
                ce.name.is_static_expr()
                and ce.params().all((pa) => pa.expr().is_static_expr())
            case qe: QualExpr =>
                qe.prefix.name_designated_type()?.is_static_decl()
                and qe.suffix.is_static_expr()
            case n: Name => n.referenced_decl()?.is_static_decl()
            case me: MembershipExpr =>
                me.expr.is_static_expr()
                and me.membership_exprs.all((e) => e.is_static_expr())
            case bo: BinOp =>
                (bo.left.is_static_expr() and bo.right.is_static_expr())
                and bo.op.referenced_decl().do(
                    (decl) => decl.is_static_decl(),
                    default_val=true
                )
            case co: ConcatOperand =>
                co.operand.is_static_expr()
                and co.operator.referenced_decl().do(
                    (decl) => decl.is_static_decl(),
                    default_val=true
                )
            case co: ConcatOp =>
                co.first_operand.is_static_expr()
                and co.other_operands.all((o) => o.is_static_expr())
            case uo: UnOp =>
                uo.expr.is_static_expr()
                and uo.op.referenced_decl().do(
                    (decl) => decl.is_static_decl(),
                    default_val=true
                )
            case i: IfExpr =>
                (
                    (
                        i.cond_expr.is_static_expr()
                        and i.then_expr.is_static_expr()
                    )
                    and i.alternatives.all(
                        (a) =>
                        a.cond_expr.is_static_expr()
                        and a.then_expr.is_static_expr()
                    )
                )
                and i.else_expr.is_static_expr()
            case pe: ParenExpr => pe.expr.is_static_expr()
            case _ => false
        }
    }

    |" Statically evaluates self, and returns the value of the evaluation as
    |" an integer.
    |"
    |" .. note::
    |"     In order for a call to this not to raise, the expression needs to
    |"     be a static expression, as specified in :rmlink:`4.9`. You
    |"     can verify whether an expression is static with the
    |"     ``is_static_expr`` property.
    |"
    |" .. ATTENTION::
    |"     This is an experimental feature, so even if it is exposed to allow
    |"     experiments, it is totally unsupported and the API and behavior are
    |"     very likely to change in the future.
    @exported
    fun eval_as_int(): BigInt =
        self.eval_as_int_in_env(null[Array[Substitution]])

    |" Statically evaluates self, and returns the value of the evaluation as
    |" an integer. The given environment is used to substitute references
    |" to declarations by actual values.
    |"
    |" .. note::
    |"     In order for a call to this not to raise, the expression needs to
    |"     be a static expression, as specified in :rmlink:`4.9`. You
    |"     can verify whether an expression is static with the
    |"     ``is_static_expr`` property.
    |"
    |" .. ATTENTION::
    |"     This is an experimental feature, so even if it is exposed to allow
    |"     experiments, it is totally unsupported and the API and behavior are
    |"     very likely to change in the future.
    @exported
    @external(uses_entity_info=true)
    fun eval_as_int_in_env(env: Array[Substitution]): BigInt

    |" Statically evaluates self, and returns the value of the evaluation as
    |" a string.
    |"
    |" .. note::
    |"     In order for a call to this not to raise, the expression needs to
    |"     be a static expression, as specified in :rmlink:`4.9`. You
    |"     can verify whether an expression is static with the
    |"     ``is_static_expr`` property.
    |"
    |" .. ATTENTION::
    |"     This is an experimental feature, so even if it is exposed to allow
    |"     experiments, it is totally unsupported and the API and behavior are
    |"     very likely to change in the future.
    @exported
    fun eval_as_string(): String =
        self.eval_as_string_in_env(null[Array[Substitution]])

    |" Statically evaluates self, and returns the value of the evaluation as
    |" a string. The given environment is used to substitute references
    |" to declarations by actual values.
    |"
    |" .. note::
    |"     In order for a call to this not to raise, the expression needs to
    |"     be a static expression, as specified in :rmlink:`4.9`. You
    |"     can verify whether an expression is static with the
    |"     ``is_static_expr`` property.
    |"
    |" .. ATTENTION::
    |"     This is an experimental feature, so even if it is exposed to allow
    |"     experiments, it is totally unsupported and the API and behavior are
    |"     very likely to change in the future.
    @exported
    @external(uses_entity_info=true)
    fun eval_as_string_in_env(env: Array[Substitution]): String

    |" Return the discrete range for this expression, if applicable.
    fun discrete_range(): DiscreteRange = match self {
        # TODO: This won't handle array objects
        case ar: AttributeRef => ar.prefix.discrete_range()
        case n: Name =>
            n.name_designated_type().do((dt) => dt.discrete_range())
        case bo: BinOp => DiscreteRange(low_bound=bo.left, high_bound=bo.right)
        case _ => null[DiscreteRange]
    }

    @with_dynvars(env, no_visibility=false)
    fun env_elements(): Array[Entity[AdaNode]] =
        self.env_elements_impl().filter((e) => node.has_visibility(e))

    |" Return the list of AST nodes that can be a match for this expression
    |" before overloading analysis.
    @exported
    fun matching_nodes(): Array[Entity[AdaNode]] = {
        bind env = node.node_env;

        self.env_elements()
    }

    |" This is an internal helper for name resolution: return True if the
    |" type of this expression can be determined without context, i.e. that
    |" when constructing its xref equation, we never need to use its expected
    |" type to find its type. For example, an integer literal can always be
    |" typed to universal integer, so ``has_context_free_type`` returns True
    |" for it. However, the type of a binary operation in general cannot be
    |" determined solely by looking at its operands' types. This is used
    |" to optimize the xref equations we construct for some nodes. See
    |" ``BinOp.no_overload_equation`` for an example.
    fun has_context_free_type(): Bool = true

    |" Assuming self is a call to a subprogram, return an array of pairs
    |" (expected_type, expression) for each expression in the call that could
    |" be used for performing a dynamic dispatch for this call.
    |"
    |" .. note:: Implementations should not check that the call is done in the
    |"    RHS of an assign statement in order to take into account return type
    |"    dispatching, as this logic does not depend on the node kind and
    |"    is therefore factorized in ``is_dispatching_call_impl``.
    @with_dynvars(imprecise_fallback=false)
    fun potential_actuals_for_dispatch(
        @ignored
        spec: Entity[BaseSubpSpec]
    ): Array[ExpectedTypeForExpr] =
        raise[Array[ExpectedTypeForExpr]] PropertyError(
            "Property Expr.potential_actuals_for_dispatch not implemented"
        )

    |" Returns True if this ``Name`` corresponds to a dispatching call,
    |" including:
    |"
    |" - Calls done through subprogram access types.
    |" - Calls to dispatching subprograms, in the object-oriented sense.
    |"
    |" .. note:: This is an experimental feature. There might be some
    |"     discrepancy with the GNAT concept of "dispatching call".
    |"
    |" .. note:: This should only be called on a ``Name`` and ``UnOp``
    |"     or a ``BinOp``.
    |"
    |" .. attention:: There is a known bug, where the ConcatOp node is not
    |"    supported, so calling is_dispatching_call on operators nested inside
    |"    of a concat operator will always return false. (Internal TN:
    |"    VC08-029)
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun is_dispatching_call(): Bool =
        raise[Bool] PreconditionFailure(
            "Invalid node type: expected Name, UnOp or BinOp"
        )

    |" Return the first decl that is lexically named like self in self's
    |" scope.
    @exported
    fun first_corresponding_decl(): Entity[BasicDecl] = null[Entity[BasicDecl]]

    |" Returns the lexical environment designated by this name, assuming
    |" that this name cannot be overloaded.
    |"
    |" If ``no_visibility``, discard visibility checks.
    @with_dynvars(env, origin, no_visibility=false)
    fun designated_env_no_overloading(): LexicalEnv = self.designated_env()

    |" Returns the lexical environment designated by this name.
    |"
    |" If this name involves overloading, this will return a combination of
    |" the various candidate lexical environments.
    |"
    |" If ``no_visibility``, discard visibility checks.
    @with_dynvars(env, origin, no_visibility=false)
    fun designated_env(): LexicalEnv =
        raise[LexicalEnv] PropertyError(
            "Property Expr.designated_env not implemented"
        )

    |" Returns the list of annotated elements in the lexical environment
    |" that can statically be a match for expr before overloading analysis.
    @with_dynvars(env)
    fun env_elements_impl(): Array[Entity[AdaNode]] =
        raise[Array[Entity[AdaNode]]] PropertyError(
            "Property Expr.env_elements_impl not implemented"
        )
}

|" Directly corresponds to the right-hand side of the Abstract_State aspect.
|" Only exists because the RHS of an AspectAssoc must be an expression: the
|" actual logic is in AbstractStateDecl.
class AbstractStateDeclExpr: Expr {
    @parse_field
    state_decl: AdaNode

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = %true
}

|" Allocator expression (``new ...``) (:rmlink:`4.8`).
class Allocator: Expr {
    @parse_field
    @nullable
    subpool: Name
    @parse_field
    type_or_expr: AdaNode

    fun has_context_free_type(): Bool = false

    |" Return the allocated type for this allocator.
    @exported
    fun get_allocated_type(): Entity[BaseTypeDecl] = {
        bind origin = node.origin_node();

        match self.type_or_expr {
            case t: Entity[SubtypeIndication] => t.designated_type()
            case q: Entity[QualExpr] => q.prefix.name_designated_type()
            case _ => null[Entity[BaseTypeDecl]]
        }
    }

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        (
            self.type_or_expr.sub_equation()
            %and node.expected_type_var() <-> node.type_var()
        )
        %and BaseTypeDecl.matching_allocator_type%(node.type_var(),
        self.get_allocated_type())
}

|" Base class for aggregates (:rmlink:`4.3`).
@abstract
class BaseAggregate: Expr {
    @parse_field
    @nullable
    ancestor_expr: Expr
    @parse_field
    assocs: AssocList

    fun has_context_free_type(): Bool = false

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        # An aggregate (or more precisely, its associations) are resolved
        # separately from the rest of an expression. However,resolution of the
        # containing expression can leverage the knowledge that self is an
        # aggregate, by accepting only type that can be represented by an
        # aggregate (e.g. records and arrays).
        val type_constraint =
            if
            # In the following cases, the aggregate is not a real
            # expression: it's merely re-used as a pure syntactic
            # construct to aggregate information.
                node
                .in_aspect(s"Global")
                or node.in_aspect(s"Refined_Global")
                or node.in_aspect(s"Depends")
                or node.in_aspect(s"Refined_Depends")
                or node.in_aspect(s"Test_Case")
                or node.in_aspect(s"Refined_State")
                or node.in_aspect(s"Aggregate")
                or node.in_aspect(s"Subprogram_Variant")

                # Careful: normal aggregates can appear inside a contract_cases
                # aspect's expression, so we must only special case the direct
                # aggregate of that aspect.
                or node.is_contract_cases_base_aggregate()
            then %true
            else {
                bind origin = node.origin_node();

                BaseTypeDecl.is_array_or_rec%(node.expected_type_var())
                %and node.expected_type_var() <-> node.type_var()
            };

        # Note that we explicitly avoid calling `sub_equation` on each assoc
        # of the `assocs` field. This is okay because we know at this stage
        # that they all cut resolution (by overriding `stop_resolution` to
        # `True`). The reason we do it is that for really big aggregates, the
        # concatenation of all the `%true` atoms returned by each assoc's
        # call to sub_equation could end up blowing up the stack when the
        # solver allocates its internal data structures.
        val assocs_eq = if self.assocs.all((a) => a.xref_stop_resolution())
            then %true
            else raise[Equation] PropertyError("Unexpected aggregate assoc");

        type_constraint %and assocs_eq %and self.ancestor_expr.do(
            (ae) =>
            # We have an ancestor part, which can be either a subtype mark
            # designating a type as in `(Controlled with X => 2)`, or an
            # arbitrary expression as in `(Foo(1) with X => 2)`.
            if
                ae is Name
                and not ae.as[Name].name_designated_type().is_null
            then ae.as[Name].xref_type_equation()
            elif node is DeltaAggregate then ae.sub_equation()
            # If self is not a delta aggregate but has an ancestor part,
            # it means it is an extension aggregate. In that case, ARM
            # 4.3.2 - 4/2 specifies "If the ancestor_part is an expression,
            # it is expected to be of any tagged type", hence we also add
            # the following predicate.
            else
                ae.sub_equation()
                %and {
                    bind error_location = ae.node;
                    BaseTypeDecl.is_tagged_type_with_deref%(ae.type_var())
                },
            default_val=%true
        )
    }

    |" Return whether this is the aggregate directly used as the RHS of the
    |" ``Contract_Cases`` aspect.
    fun is_contract_cases_base_aggregate(): Bool =
        node.parent.as[AspectAssoc].do(
            (aspect) => aspect.id.name_is(s"Contract_Cases")
        )

    |" Return the root parent aggregate if self is part of a multidimensional
    |" array aggregate (either the root or a sub-aggregate).
    @memoized
    @call_memoizable
    @with_dynvars(origin)
    fun multidim_root_aggregate(r: Int = 0): MultidimAggregateInfo =
        # Nested aggregates of a multidimensional array have no types, so we're
        # searching for the first aggregate with a type inside type_val.
        self.type_val().as[BaseTypeDecl].do(
            (tv) =>
            # If we have a multidimensional array type here, return all the
            # needed info (rank, root aggregate and type of the array).
            if tv.array_ndims() > 1
            then MultidimAggregateInfo(agg=self, typ=tv, rank=r)
            else (
                # If we're here, we found a type, and it's not a multidim
                # array: Stop there.
                null[MultidimAggregateInfo]
            ),
            # If we're here, there is a parent aggregate and no type_val:
            # recurse up.
            default_val=self
            .parent
            .parent
            .parent
            .as[Aggregate]
            ?.multidim_root_aggregate(r + 1)
        )

    |" Return the list of all discriminants that must be associated by this
    |" aggregate.
    |"
    |" .. attention::
    |"     This property is part of the name resolution algorithm for
    |"     AggregateAssocs and therefore is probably not what you're looking
    |"     for, as it makes several assumptions on the content of logic vars.
    |"     Find more details in ``AggregateAssoc.record_assoc_equation``.
    |"
    |" .. note::
    |"     This property must be memoized because all AggregateAssocs that are
    |"     children of this aggregate will call it during their name
    |"     resolution routine.
    @memoized
    @call_memoizable
    @with_dynvars(origin)
    fun all_discriminants(): Array[Entity[BaseFormalParamDecl]] = {
        val td = node.type_val().as[BaseTypeDecl];
        val stop_recurse_at = self.ancestor_expr_type(resolve_type=false);
        val record_decl = td.record_def().comps().type_decl();

        record_decl.discriminants_list(stop_recurse_at)
    }

    |" Return the list of all components that must be associated by this
    |" aggregate.
    |"
    |" .. attention::
    |"     This property is part of the name resolution algorithm for
    |"     AggregateAssocs. More details under ``all_discriminants``.
    @memoized
    @call_memoizable
    @with_dynvars(origin, env)
    fun all_components(): Array[Entity[BaseFormalParamDecl]] = {
        val td = node.type_val().as[BaseTypeDecl];
        val stop_recurse_at = self.ancestor_expr_type(resolve_type=false);
        val comp_list = td.record_def().comps();

        if self is DeltaAggregate
        then (
            # For delta aggregates, get all the components regardless of the
            # discriminant values.
            comp_list.abstract_formal_params_for_delta_assocs()
        )
        else
            comp_list.abstract_formal_params_for_assocs(
                self.assocs,
                stop_recurse_at
            )
    }

    |" Return the list of all discriminants specified by this aggregate,
    |" together with the actual used for it.
    |"
    |" When match_others is true, unspecified discriminants are matched with
    |" OthersDesignator value if any.
    |"
    |" .. attention::
    |"     This property is part of the name resolution algorithm for
    |"     AggregateAssocs. More details under ``all_discriminants``.
    @memoized
    @with_dynvars(origin)
    fun matched_discriminants(match_others: Bool = true): Array[ParamMatch] =
        node.match_formals(
            self.all_discriminants(),
            self.assocs,
            false,
            match_others
        )

    |" Return the list of all components specified by this aggregate,
    |" together with the actual used for it.
    |"
    |" .. attention::
    |"     This property is part of the name resolution algorithm for
    |"     AggregateAssocs. More details under ``all_discriminants``.
    @memoized
    @with_dynvars(origin, env)
    fun matched_components(): Array[ParamMatch] =
        node.match_formals(self.all_components(), self.assocs, false)

    |" Return the first discriminant or component that is not matched
    |" explicitly.
    |"
    |" .. attention::
    |"     This property is part of the name resolution algorithm for
    |"     AggregateAssocs. More details under ``all_discriminants``.
    @with_dynvars(origin, env)
    fun first_unmatched_formal(): Entity[DefiningName] = {
        val matched_discr = self.matched_discriminants(match_others=false);
        # Try to find an unmatched discriminant first
        val unmatched_discr =
            node.unpack_formals(self.all_discriminants()).find(
                (f) => not matched_discr.any((m) => m.formal == f)
            );

        if not unmatched_discr.is_null then unmatched_discr
        else (
            # If there is no unmatched discriminant, this means all of them
            # are specified, so the shape of the record is known: we can now
            # try to find the unmatched formal.
            # WARNING: for the same reason stated in
            # AggregateAssoc.record_assoc_equation, this must be done in this
            # order.
            node.unpack_formals(self.all_components()).find(
                (f) => not self.matched_components().any((m) => m.formal == f)
            )
        )
    }

    |" Returns an array of pairs, associating formal parameters to actual
    |" expressions. See ``zip_with_params``.
    @exported
    fun aggregate_params(): Array[ParamActual] = self.assocs.zip_with_params()

    |" Return whether this aggregate is actually a subaggregate of a
    |" multidimensional array aggregate, as described in :rmlink:`4.3.3`.
    @exported
    fun is_subaggregate(): Bool = {
        # The `multidim_root_aggregate` property assumes that the top-level
        # aggregate's type_var has been set, so run nameres beforehand.
        val _ = self.resolve_names_from_closest_entry_point();

        {
            bind origin = node;

            self.multidim_root_aggregate().rank > 0
        }
    }

    |" If this aggregate instance is a subaggregate of a multidimensional
    |" array aggregate, return the overall array type.
    @exported
    fun subaggregate_array_type(): Entity[BaseTypeDecl] =
        if self.is_subaggregate() then {
            bind origin = node;
            self.multidim_root_aggregate().typ
        }
        else raise[Entity[BaseTypeDecl]] PreconditionFailure(
            "Expected subaggregate"
        )

    |" If this aggregate instance is a subaggregate of a multidimensional
    |" array aggregate, return the index of its matching dimension.
    |"
    |" .. note:: the returned index is 0-based, where index 0 designates the
    |"    the first dimension of the array type. However, since this property
    |"    works on subaggregates, the returned index will necessarily always
    |"    be greater or equal to 1.
    @exported
    fun subaggregate_dimension(): Int =
        if self.is_subaggregate() then {
            bind origin = node;
            self.multidim_root_aggregate().rank
        } else raise[Int] PreconditionFailure(
            "Expected subaggregate"
        )

    |" The ancestor part of an aggregate can either be a subtype mark or an
    |" arbitrary expression. In the first case, this property returns the
    |" type designated by the subtype mark. In the other case, it returns the
    |" type of the expression, after running name resolution if
    |" ``resolve_type`` is True, and otherwise by looking into the ancestor
    |" part's already populated type variable.
    @call_memoizable
    fun ancestor_expr_type(resolve_type: Bool = true): Entity[BaseTypeDecl] =
        self.ancestor_expr.do(
            (ae) =>
            ae.as[Name].do((n) => n.name_designated_type())
            or? (
                if resolve_type then ae.expression_type()
                else ae.type_val().as[BaseTypeDecl]
            )
        )
}

|" Aggregate that is not a ``null record`` aggregate (:rmlink:`4.3`).
class Aggregate: BaseAggregate {
    |" Return the ``Add_Named`` subprogram parameter specified by ``index``.
    |" This aggregate must be a container aggregate aspect specification.
    fun add_named_param_at(index: Int): Entity[BaseTypeDecl] = {
        # `Add_Named`denotes exactly one procedure that has three parameters,
        # the first an in out parameter of the container type, the second an in
        # parameter of a nonlimited type (the key type of the container type),
        # and the third, an in parameter of a nonlimited type that is called
        # the element type of the container type (so index should be an Int
        # between 0 and 2).
        val add_named =
            self.assocs.find(
                (assoc) =>
                assoc.as[AggregateAssoc].names()?[0].as[Name].name_is(
                    s"Add_Named"
                )
            );
        val add_named_params =
            add_named.do(
                (an) =>
                an.expr().as[Name].referenced_decl().subp_spec_or_null()
                .params()
            );

        add_named.do(
            (_) =>
            add_named_params?[index].type_expression().designated_type_decl()
        )
    }

    |" Return the element type of that Aggregate. This aggregate must be a
    |" container aggregate aspect specification.
    fun element_type(): Entity[BaseTypeDecl] = {
        # Position container case: `Add_Unnamed` should be specified. It
        # denotes exactly one procedure that has two parameters, the first an
        # in out parameter of the container type, and the second an in
        # parameter of some nonlimited type, called the element type of the
        # container type.
        val add_unnamed =
            self.assocs.find(
                (assoc) =>
                assoc.as[AggregateAssoc].names()?[0].as[Name].name_is(
                    s"Add_Unnamed"
                )
            );
        val unnamed_element_type =
            add_unnamed.do(
                (au) =>
                au.expr().as[Name].referenced_decl().subp_spec_or_null()
                .params()?[
                    1
                ]
                .type_expression()
                .designated_type_decl()
            );
        # Named container case: `Add_Named` should be specified
        val named_element_type = self.add_named_param_at(2);

        if add_unnamed.is_null then named_element_type
        else unnamed_element_type
    }

    |" Return the key type of that Aggregate. This aggregate must be a
    |" container aggregate aspect specification.
    fun key_type(): Entity[BaseTypeDecl] = {
        # Named container case: `Add_Named` should be specified
        val key_type = self.add_named_param_at(1);

        key_type
        # If add_named is not specified, key_type is the universal integer
        # type used for indexed aggregates.
        or? self.universal_int_type()
    }
}

|" Bracket array or container aggregate (Ada 2020, :rmlink:`4.3`).
class BracketAggregate: Aggregate {
}

|" Aggregate for delta aggregate (Ada 2022, :rmlink:`4.3`).
class DeltaAggregate: BaseAggregate {
}

|" Bracket delta aggregate (Ada 2020, :rmlink:`4.3`).
class BracketDeltaAggregate: DeltaAggregate {
}

|" Aggregate for ``null record`` (:rmlink:`4.3`).
class NullRecordAggregate: BaseAggregate {
}

|" Binary expression.
|"
|" This encompasses several ARM expressions, because it is used for every
|" binary expression in Ada, all documented in ::rmlink:`4.4`.
class BinOp: Expr {
    @parse_field
    left: Expr
    @parse_field
    op: Op
    @parse_field
    right: Expr

    fun has_context_free_type(): Bool = node.op is Op.AndThen | Op.OrElse

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        bind logic_context =
            LogicContext(ref_node=self.op, decl_node=null[Entity[AdaNode]]);

        %all(
            self.left.sub_equation(),
            self.right.sub_equation(),
            if node.op is Op.DoubleDot then self.double_dot_equation()
            elif node.op is Op.AndThen | Op.OrElse then node.test_eq()
            else %any(
                self.overload_equation(),
                self.no_overload_equation(),
                self.universal_fixed_predefined_operators_equation()
            )
        )
    }

    @with_dynvars(origin, env, logic_context)
    fun double_dot_equation(): Equation = {
        bind logic_context = null[LogicContext];
        %any(
            %true,
            node.expected_type_var() <- node.root_int_type(),
            node.expected_type_var() <- node.int_type()
        ) %and %all(
            AdaNode.is_not_null%(node.expected_type_var()),
            node.expected_type_var() <-> node.type_var(),
            node.type_var() <-> node.left.expected_type_var(),
            node.type_var() <-> node.right.expected_type_var(),
            node.left.matches_expected_formal_type(),
            node.right.matches_expected_formal_type()
        )
    } %and node.use_expected_type_or(
        # In some cases the expected type is given explicitly, so we can
        # simply check that the type inferred for the operands matches.
        # This is generally the case for ranges in component representation
        # clauses or in subtype indications' constraints.
        # However if the expected is not given explicitly, we must infer
        # it here from one of the operands. This is generally the case
        # for ranges in for-loop specs.
        self.infer_from_either_operands(node.type_var())
    )

    @with_dynvars(origin)
    fun test_eq(): Equation = %all(
        node.left.expected_type_var() <- node.bool_type(),
        node.right.expected_type_var() <- node.bool_type(),
        node.left.expect_bool_derived_type(),
        node.right.expect_bool_derived_type(),
        node.type_var() <-> node.left.type_var()
    )

    @with_dynvars(origin, env, logic_context)
    fun arguments_eq(spec: Entity[BaseSubpSpec]): Equation = {
        val ps = spec.unpacked_formal_params();

        if ps.length() == 2
        then %all(
            # The subprogram's first argument must match self's left
            # operand.
            spec.call_argument_equation(ps?[0].formal_decl(), self.left),
            # The subprogram's second argument must match self's right
            # operand.
            spec.call_argument_equation(
                ps?[1].formal_decl(),
                self.right
            ),
            # The subprogram's return type is the type of self
            node.type_var() <- spec.return_type()
        )
        else %false
    }

    @with_dynvars(origin, env, logic_context)
    fun entity_eq(subp: Entity[BasicDecl]): Equation = {
        val spec = subp.subp_spec_or_null();

        self.arguments_eq(spec) %and {
            # The operator references the subprogram
            bind logic_context = null[LogicContext];
            node.op.ref_var() <- subp
            %and node.op.subp_spec_var() <- spec
        }
    }

    @with_dynvars(origin, env)
    fun overload_equation(): Equation =
        self.op.subprograms().logic_any(
            (subp) => {
                bind logic_context =
                    LogicContext(ref_node=self.op, decl_node=subp);

                self.entity_eq(subp)
            }
        )

    |" When no subprogram is found for this node's operator, try to resolve
    |" it as a universal_fixed predefined operator (:rmlink:`4.5.5` - 18).
    @with_dynvars(origin)
    fun universal_fixed_predefined_operators_equation(): Equation =
        if node.op is Op.Mult | Op.Div
        then %all(
            node.type_var() <- node.universal_fixed_type(),
            node.left.expected_type_var() <- node.universal_fixed_type(),
            node.right.expected_type_var() <- node.universal_fixed_type(),
            node.left.matches_expected_formal_type(),
            node.right.matches_expected_formal_type()
        )
        else %false

    |" Construct the xref equation that first attempts to resolve this binary
    |" operation using the expected type given by the context only, and then
    |" by using the additional equation given as argument (typically this
    |" equation will try to infer the type from one of the operands).
    fun use_expected_type_or(eq: Equation): Equation =
        AdaNode.is_not_null%(node.expected_type_var()) %or eq

    |" Construct the xref equation that must bind the given variable to the
    |" type of this binary operation's operands, assuming we are dealing with
    |" numeric types and arithmetic operators with the following profile:
    |" ``function "op" (X : T, Y : U) return T`` (we want to infer ``T``).
    @with_dynvars(origin, logic_context)
    fun infer_from_left_operand(dest_var: LogicVar): Equation =
        BaseTypeDecl.is_not_universal_type%(node.left.type_var())
        %and dest_var <- BaseTypeDecl.derefed_base_subtype%(
            node.left.type_var()
        )

    |" Construct the xref equation that must bind the given variable to the
    |" type of this binary operation's operands, assuming we are dealing with
    |" numeric types and arithmetic operators with the following profile:
    |" ``function "op" (X : U, Y : T) return T`` (we want to infer ``T``).
    @with_dynvars(origin, logic_context)
    fun infer_from_right_operand(dest_var: LogicVar): Equation =
        BaseTypeDecl.is_not_universal_type%(node.right.type_var())
        %and dest_var <- BaseTypeDecl.derefed_base_subtype%(
            node.right.type_var()
        )

    |" Construct the xref equation that must bind the given variable to the
    |" type of this binary operation's operands, assuming we are dealing with
    |" numeric types and arithmetic operators with the following profile:
    |" ``function "op" (X, Y : T) return T`` (we want to infer ``T``).
    @with_dynvars(origin, logic_context)
    fun infer_from_either_operands(dest_var: LogicVar): Equation = {
        val infer_left = self.infer_from_left_operand(dest_var);
        val infer_right = self.infer_from_right_operand(dest_var);

        infer_left %or infer_right
    }

    @with_dynvars(imprecise_fallback=false)
    fun potential_actuals_for_dispatch(
        spec: Entity[BaseSubpSpec]
    ): Array[ExpectedTypeForExpr] = {
        val params = spec.unpacked_formal_params();

        [
            ExpectedTypeForExpr(
                expected_type=params?[0].formal_decl().type_expression(),
                expr=self.left
            ),
            ExpectedTypeForExpr(
                expected_type=params?[1].formal_decl().type_expression(),
                expr=self.right
            )
        ]
    }

    @with_dynvars(imprecise_fallback=false)
    fun is_dispatching_call(): Bool = self.op.is_dispatching_call()

    |" When no subprogram is found for this node's operator, use this property
    |" to construct the xref equation for this node.
    @with_dynvars(origin, logic_context)
    fun no_overload_equation(): Equation = %all(
        # For multiplication operators, we must handle three shapes
        if node.op is Op.Mult | Op.Div then
            (
                # `function "op" (X, Y : T) return T`
                {
                    bind logic_context = null[LogicContext];
                    node.type_var() <-> node.left.expected_type_var()
                    %and node.type_var()
                        <-> node.right.expected_type_var()
                }
                %and node.use_expected_type_or(
                    self.infer_from_either_operands(node.type_var())
                )
            )
            %or (
                # `function "op" (X : Integer, Y : T) return T`
                {
                    bind logic_context = null[LogicContext];
                    node.left.expected_type_var() <- node.int_type()
                    %and node.right.expected_type_var()
                        <-> node.type_var()
                }
                %and node.use_expected_type_or(
                    self.infer_from_right_operand(node.type_var())
                )
            )
            %or (
                # `function "op" (X : T, Y : Integer) return T`
                {
                    bind logic_context = null[LogicContext];
                    node.right.expected_type_var() <- node.int_type()
                    %and node.left.expected_type_var()
                        <-> node.type_var()
                }
                %and node.use_expected_type_or(
                    self.infer_from_left_operand(node.type_var())
                )
            )

        # For power operators, we must only handle the shape
        # `function "op" (X : T, Y : Integer) return T`.
        elif node.op is Op.Pow then
            {
                bind logic_context = null[LogicContext];
                node.right.expected_type_var()
                    <- node.int_type()
                %and node.left.expected_type_var()
                    <-> node.type_var()
            }
            %and node.use_expected_type_or(
                self.infer_from_left_operand(node.type_var())
            )

        # For other operators, we only need to handle the shape
        # `function "op" (X, Y : T) return T`.
        else
            {
                bind logic_context = null[LogicContext];
                node.type_var() <-> node.left.expected_type_var()
                %and node.type_var()
                    <-> node.right.expected_type_var()
            }
            %and node.use_expected_type_or(
                self.infer_from_either_operands(node.type_var())
            ),

        (
            # We have an expected type: we can directly infer the actual type
            # of the result, and of the operands using the equations above.
            # Note that there is a difference between not having an expected
            # type at all (as in a type conversion), and having an expected
            # type but not inferrable from the context (as in an operand of a
            # comparison operator `(A + B) = 2`. The latter simply means
            # that the expected type itself will be inferred from the operands
            # using one of `self.infer_from_*` properties.
            AdaNode.is_not_null%(node.expected_type_var())
            %and node.type_var() <- BaseTypeDecl.derefed_base_subtype%(
                node.expected_type_var()
            )
        ) %or {
            # There is no expected type (e.g. we are in a type conversion).
            # In this case, the type of the result will be inferred from the
            # type of operands: we know that at least one of them has a
            # context-free type (otherwise this wouldn't be valid Ada code).
            bind logic_context = null[LogicContext];
            node.expected_type_var() <- null[Entity[BaseTypeDecl]]
        },
        node.left.matches_expected_formal_type(),
        node.right.matches_expected_formal_type()
    )
}

|" Binary operation that compares two value, producing a boolean
|" (:rmlink:`4.4`).
class RelationOp: BinOp {
    fun has_context_free_type(): Bool = true

    @with_dynvars(origin, logic_context)
    fun no_overload_equation(): Equation = %all(
        {
            bind logic_context = null[LogicContext];
            node.type_var() <- node.bool_type()
            %and node.left.expected_type_var()
                <-> node.right.expected_type_var()
        },
        self.infer_from_either_operands(
            node.left.expected_type_var()
        ),
        node.left.matches_expected_formal_type(),
        node.right.matches_expected_formal_type()
    )
}

|" Box expression (``<>``).
|"
|" This is not an expression per-se in Ada, but treating it as one helps us
|" keep coherent types in some cases, like aggregates expressions.
class BoxExpr: Expr {
    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        node.type_var() <-> node.expected_type_var()
}

|" Alternative in a ``case`` expression (``when ... => ...``).
class CaseExprAlternative: Expr {
    @parse_field
    choices: AlternativesList
    @parse_field
    expr: Expr
}

|" Concatenation expression.
|"
|" Since concatenation expression can be huge in practice, this node handles
|" them as a list of operands rather than a deep tree of binary operators, in
|" order to avoid crashes while parsing of running name resolution on such
|" huge expression.
|"
|" The purpose of this node is to replace the arbitrarily too deep tree of
|" binary operators (which can lead to a stack overflow), as for example with
|" ``"A & B & C & D & E"``:
|"
|" .. code::
|"
|"     BinOp(
|"       Binop(
|"         BinOp(
|"           BinOp(A, &, B), & , C), &, D), &, E)
|"
|" by a single operator, handling a list of operands that can be processed
|" without having to perform deep recursions:
|"
|" .. code::
|"
|"     ConcatOp(A,
|"       ConcatOperand(&, B),
|"       ConcatOperand(&, C),
|"       ConcatOperand(&, D),
|"       ConcatOperand(&, E))
class ConcatOp: Expr {
    @parse_field
    first_operand: Expr
    @parse_field
    other_operands: ASTList[ConcatOperand]

    |" Return the operands of this concatenation expression
    @exported
    fun operands(): Array[Entity[Expr]] =
        [self.first_operand] & self.other_operands.map((oo) => oo.operand)

    fun has_context_free_type(): Bool = false

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        val operand_count = node.other_operands.length();
        val last_operand = node.other_operands?[operand_count - 1];
        val concat_subprograms =
            self.other_operands?[0].operator.subprograms();

        # Perform expression resolution from left to right
        (
            (
                (
                    self.first_operand.sub_equation()
                    %and self.other_operands.logic_all(
                        (concat_operand) =>
                        concat_operand.operand.sub_equation()
                    )
                )
                %and (
                    # Build the equations for the concatenations themselves.
                    # WARNING: for now, the equations should appear in the
                    # order below, that is: the equation constraining the
                    # leftmost operand should be first, and equations for
                    # successive operands should follow in the corresponding
                    # order, with the rightmost operand having its equation
                    # last. This allows optimal resolution (performance-wise)
                    # until eng/libadalang/langkit#725 is addressed.
                    self.other_operands.ilogic_all(
                        (_, index) => {
                            val pos = operand_count - index - 1;

                            {
                                val left =
                                    if pos > 0
                                    then self.other_operands?[pos - 1]
                                    else self.first_operand;
                                val concat_operand = self.other_operands?[pos];
                                val right = self.other_operands?[pos].operand;

                                (
                                    # TODO: this is implementation is actually
                                    # not correct w.r.t. visibility
                                    # (eng/libadalang/libadalang#1138).  First,
                                    # try to resolve this operator using
                                    # built-in operators only.
                                    self.operator_no_subprogram_equation(
                                        left,
                                        concat_operand,
                                        right
                                    )
                                )
                                %or (
                                    # If that didn't work, try to resolve it by
                                    # considering visible user-defined
                                    # overloads of "&". NOTE: for performance
                                    # reasons it is better to first try the
                                    # built-in operators first.
                                    concat_subprograms.logic_any(
                                        (subp) => {
                                            val spec =
                                                subp.subp_spec_or_null();

                                            {
                                                bind logic_context =
                                                    LogicContext(
                                                        ref_node=concat_operand
                                                        .operator,
                                                        decl_node=subp
                                                    );

                                                self.arguments_eq(
                                                    spec,
                                                    left,
                                                    concat_operand,
                                                    right
                                                )
                                                %and {
                                                    bind logic_context =
                                                        null[LogicContext];
                                                    concat_operand
                                                    .operator
                                                    .ref_var()
                                                    <- subp
                                                }
                                                %and {
                                                    bind logic_context =
                                                        null[LogicContext];
                                                    concat_operand
                                                    .operator
                                                    .subp_spec_var()
                                                    <- spec
                                                }
                                            }
                                        }
                                    )
                                )
                            }
                        }
                    )
                )
            )
            %and (
                # Just propagate last operand's type/expected_type to self
                node.type_var() <-> last_operand.type_var()
            )
        )
        %and node.expected_type_var() <-> last_operand.expected_type_var()
    }

    @with_dynvars(origin, env, logic_context)
    fun arguments_eq(
        spec: Entity[BaseSubpSpec],
        left: Entity[Expr],
        op: Entity[ConcatOperand],
        right: Entity[Expr]
    ): Equation = {
        val ps = spec.unpacked_formal_params();

        if ps.length() == 2
        then (
            # The subprogram's first argument must match left operand
            (
                spec.call_argument_equation(ps?[0].formal_decl(), left)
                %and (
                    # The subprogram's second argument must match right operand
                    spec.call_argument_equation(ps?[1].formal_decl(), right)
                )
            )
            %and (
                # The subprogram's return type is the type of op
                {
                    bind logic_context = null[LogicContext];
                    op.type_var() <- spec.return_type()
                }
            )
        )
        else %false
    }

    |" When no subprogram is found for this operator, use this property to
    |" construct the xref equation for this node.
    @with_dynvars(origin)
    fun operator_no_subprogram_equation(
        left: Entity[Expr],
        op: Entity[ConcatOperand],
        right: Entity[Expr]
    ): Equation = {
        bind logic_context =
            LogicContext(
                ref_node=op.operator,
                decl_node=null[Entity[AdaNode]]
            );

        (
            BaseTypeDecl.is_array_def_with_deref_or_null%(op
            .expected_type_var())
            %and BaseTypeDecl.is_array_def_with_deref%(op.type_var())
        )
        %and (
            (
                # If the expected is not null, use it to infer self's type
                # and the type of the operands.
                AdaNode.is_not_null%(op.expected_type_var())
                %and self.array_concat_expected_type_equation(left, op, right)
            )
            %or (
                # If the expected type is null (e.g. we are in a type
                # conversion), we must infer self's type from the operands.
                # Since we assume Ada code, either the LHS or the RHS will have
                # a context-free type which we can use to infer the rest.
                # Make sure to propagate the base type of the inferred type so
                # that concatenation between compatible array subtypes works
                # as expected.
                {
                    bind logic_context = null[LogicContext];
                    op.expected_type_var() <- null[Entity[BaseTypeDecl]]
                }
                %and (
                    (
                        # Type is determined by the LHS
                        (
                            op.type_var()
                            <- BaseTypeDecl.derefed_base_subtype%(
                                left.type_var()
                            )
                            %and {
                                bind logic_context = null[LogicContext];
                                op.type_var() <-> left.expected_type_var()
                            }
                        )
                        %and (
                            {
                                bind logic_context = null[LogicContext];
                                op.type_var() <-> right.expected_type_var()
                            }
                            %or node.comp_bind(
                                op.type_var(),
                                right.expected_type_var()
                            )
                        )
                    )
                    %or (
                        # Type is determined by the RHS
                        (
                            op.type_var()
                            <- BaseTypeDecl.derefed_base_subtype%(
                                right.type_var()
                            )
                            %and {
                                bind logic_context = null[LogicContext];
                                op.type_var() <-> right.expected_type_var()
                            }
                        )
                        %and (
                            {
                                bind logic_context = null[LogicContext];
                                op.type_var() <-> left.expected_type_var()
                            }
                            %or node.comp_bind(
                                op.type_var(),
                                left.expected_type_var()
                            )
                        )
                    )
                )
            )
        )
    }

    |" Assume this operator represents a predefined array concatenation
    |" operator, construct the xref equation that must bind the operator's
    |" type to the type of the result of the concatenation, using the type of
    |" the operands or the type from the context.
    @with_dynvars(origin, logic_context)
    fun array_concat_expected_type_equation(
        left: Entity[Expr],
        op: Entity[ConcatOperand],
        right: Entity[Expr]
    ): Equation = {
        val left_ctx_free = left.has_context_free_type();
        val right_ctx_free = right.has_context_free_type();

        # Generate different xref equations depending on which operands have a
        # context-free type. This helps reduce the final number of disjunction
        # compared to handling all the cases in a single equation.
        if left_ctx_free and right_ctx_free
        then
            (
                # Both operands have a context-free type, so use their types to
                # find the type of the result. This equation handles the
                # following operators:
                #  - "&" (Array_Of_T, T) -> Array_Of_T
                #  - "&" (T, Array_Of_T) -> Array_Of_T
                #  - "&" (Array_Of_T, Array_Of_T) -> Array_Of_T.
                (
                    op.type_var()
                    <- BaseTypeDecl.array_concat_result_type%(
                        left.type_var(),
                        right.type_var()
                    )
                    %and left.expected_type_var()
                    <- BaseTypeDecl.expected_array_concat_operand_type%(
                        op.type_var(),
                        left.type_var()
                    )
                )
                %and right.expected_type_var()
                <- BaseTypeDecl.expected_array_concat_operand_type%(
                    op.type_var(),
                    right.type_var()
                )
            )
            %or (
                # But we need another disjunction to handle the case:
                #  - "&" (T, T) -> Array_Of_T
                # For this case, we necessarily need to use the type of the
                # context even though both operands have a context-free type.
                (
                    (
                        (
                            op.type_var()
                            <- BaseTypeDecl.derefed_base_subtype%(
                                op.expected_type_var()
                            )
                            %and node.comp_bind(
                                op.type_var(),
                                left.expected_type_var()
                            )
                        )
                        %and node.comp_bind(
                            op.type_var(),
                            right.expected_type_var()
                        )
                    )
                    %and left.matches_expected_formal_type()
                )
                %and right.matches_expected_formal_type()
            )
        elif left_ctx_free
        then
            (
                (
                    (
                        # Left operand has a context free, use to infer the
                        # type of the result. This can handle the cases: - "&"
                        # (Array_Of_T, *) -> Array_Of_T.
                        op.type_var()
                        <- BaseTypeDecl.derefed_base_subtype%(left.type_var())
                        %and {
                            bind logic_context = null[LogicContext];
                            op.type_var() <-> left.expected_type_var()
                        }
                    )
                    %or (
                        # We need another disjunction to handle the remaining
                        # cases: - "&" (T, *) -> Array_Of_T For both these
                        # cases, we need to use the type of the context even
                        # though LHS has a context-free type.
                        (
                            op.type_var()
                            <- BaseTypeDecl.derefed_base_subtype%(
                                op.expected_type_var()
                            )
                            %and node.comp_bind(
                                op.type_var(),
                                left.expected_type_var()
                            )
                        )
                        %and left.matches_expected_formal_type()
                    )
                )
                %and (
                    # The type of op has been inferred from the LHS, use it to
                    # determine the type of the RHS.
                    {
                        bind logic_context = null[LogicContext];
                        op.type_var() <-> right.expected_type_var()
                    }
                    %or node.comp_bind(
                        op.type_var(),
                        right.expected_type_var()
                    )
                )
            )
            %and right.matches_expected_formal_type()
        elif right_ctx_free
        then
            (
                (
                    (
                        # Right operand has a context free, use to infer the
                        # type of the result. This can handle the cases: - "&"
                        # (*, Array_Of_T) -> Array_Of_T.
                        op.type_var()
                        <- BaseTypeDecl.derefed_base_subtype%(right.type_var())
                        %and {
                            bind logic_context = null[LogicContext];
                            op.type_var() <-> right.expected_type_var()
                        }
                    )
                    %or (
                        # We need another disjunction to handle the remaining
                        # cases: - "&" (*, T) -> Array_Of_T For both these
                        # cases, we need to use the type of the context even
                        # though RHS has a context-free type.
                        (
                            op.type_var()
                            <- BaseTypeDecl.derefed_base_subtype%(
                                op.expected_type_var()
                            )
                            %and node.comp_bind(
                                op.type_var(),
                                right.expected_type_var()
                            )
                        )
                        %and right.matches_expected_formal_type()
                    )
                )
                %and (
                    # The type of op has been inferred from the RHS, use it to
                    # determine the type of the LHS.
                    {
                        bind logic_context = null[LogicContext];
                        op.type_var() <-> left.expected_type_var()
                    }
                    %or node.comp_bind(op.type_var(), left.expected_type_var())
                )
            )
            %and left.matches_expected_formal_type()
        # None of the operands have a context-free type, so we necessarily
        # have an expected type (otherwise it wouldn't be valid Ada code).
        # Use it to determine the type of the operands.
        else
            (
                (
                    (
                        op.type_var()
                        <- BaseTypeDecl.derefed_base_subtype%(
                            op.expected_type_var()
                        )
                        %and (
                            {
                                bind logic_context = null[LogicContext];
                                op.type_var() <-> left.expected_type_var()
                            }
                            %or node.comp_bind(
                                op.type_var(),
                                left.expected_type_var()
                            )
                        )
                    )
                    %and (
                        {
                            bind logic_context = null[LogicContext];
                            op.type_var() <-> right.expected_type_var()
                        }
                        %or node.comp_bind(
                            op.type_var(),
                            right.expected_type_var()
                        )
                    )
                )
                %and left.matches_expected_formal_type()
            )
            %and right.matches_expected_formal_type()
    }
}

|" A concatenation operator and its RHS operand.
|"
|" This node is used to represent the tuple ("&", operand) used by the
|" ``ConcatOp`` node to store its ``other_operands`` list.
class ConcatOperand: Expr {
    @parse_field
    operator: Op.Concat
    @parse_field
    operand: Expr

    fun has_context_free_type(): Bool = false
}

|" Base class for a conditional expressions (:rmlink:`4.5.7`).
@abstract
class CondExpr: Expr {
    |" Return the dependent expressions for this conditional expression.
    @exported
    @abstract
    fun dependent_exprs(): Array[Entity[Expr]]
}

|" ``case`` expression (:rmlink:`4.5.7`).
class CaseExpr: CondExpr {
    @parse_field
    expr: Expr
    @parse_field
    cases: ASTList[CaseExprAlternative]

    fun has_context_free_type(): Bool = false

    fun dependent_exprs(): Array[Entity[Expr]] = self.cases.map((c) => c.expr)

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        # We solve self.expr separately because it is not dependent on the rest
        # of the semres.
        val _ =
            self.expr.resolve_names_internal_with_eq(
                BaseTypeDecl.is_discrete_type%(node.expr.type_var())
            );

        self.cases.logic_all(
            (alt) =>
            (
                (
                    (
                        (
                            alt.choices.logic_all(
                                (c) =>
                                match c {
                                    # Expression case
                                    case e: Expr =>
                                        if
                                            e is Name
                                            and not e
                                            .as[Name]
                                            .name_designated_type()
                                            .is_null
                                        then e.as[Name].xref_type_equation()
                                        else
                                            (
                                                e.expected_type_var()
                                                <- node.expr.type_val()
                                                %and e.sub_equation()
                                            )
                                            %and e.matches_expected_type()

                                    # SubtypeIndication case (``when Color
                                    # range Red .. Blue``).
                                    case t: SubtypeIndication =>
                                        t.xref_equation()
                                    case _: OthersDesignator => %true
                                    case _ =>
                                        raise[Equation] PropertyError(
                                            "Should not happen"
                                        )
                                }
                            )
                            %and (
                                # Equations for the dependent expressions
                                node.type_var()
                                <-> alt.expr.expected_type_var()
                            )
                        )
                        %and alt.expr.expected_type_var()
                        <- BaseTypeDecl.derefed_base_subtype%(
                            node.expected_type_var()
                        )
                    )
                    %and alt.expr.sub_equation()
                )
                %and alt.expr.matches_expected_type()
            )
            %and (
                if alt.expr.has_context_free_type()
                then
                    (
                        (
                            BaseTypeDecl.is_not_universal_type%(alt
                            .expr
                            .type_var())
                            %and alt.expr.expected_type_var()
                            <- BaseTypeDecl.base_subtype%(alt.expr.type_var())
                        )
                        %and alt.expr.expected_type_var()
                        <-> node.expected_type_var()
                    )
                    %or %true
                else %true
            )
        )
    }
}

|" ``if`` expression (:rmlink`4.5.7`).
class IfExpr: CondExpr {
    @parse_field
    cond_expr: Expr
    @parse_field
    then_expr: Expr
    @parse_field
    alternatives: ASTList[ElsifExprPart]
    @parse_field
    @nullable
    else_expr: Expr

    fun has_context_free_type(): Bool = false

    fun dependent_exprs(): Array[Entity[Expr]] =
        [self.then_expr] & self.alternatives.map((a) => a.then_expr)
        & self.else_expr.do((v1) => [v1])

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        (
            # Construct sub equations for common sub exprs
            (
                (
                    (
                        self.cond_expr.sub_equation()
                        %and self.cond_expr.expect_bool_derived_type()
                    )
                    %and (
                        # Construct the equation for the then branch
                        self.then_expr.sub_equation()
                    )
                )
                %and self.alternatives.logic_all(
                    (elsif) =>
                    (
                        # Build the sub equations for cond and then exprs
                        elsif.cond_expr.sub_equation()
                        %and elsif.cond_expr.expect_bool_derived_type()
                    )
                    %and elsif.then_expr.sub_equation()
                )
            )
            %and (
                if not node.else_expr.is_null
                then (
                    # If there is an else, then construct sub equation
                    self.else_expr.sub_equation()
                )
                else (
                    # If no else, then the then_expression has type bool
                    self.then_expr.expect_bool_derived_type()
                )
            )
        )
        %and (
            (
                AdaNode.is_not_null%(node.expected_type_var())
                %and self.expected_type_equation()
            )
            %or (
                node.expected_type_var() <- null[Entity[BaseTypeDecl]]
                %and self.no_expected_type_equation()
            )
        )

    |" Return the equation to use in the case where the expected type for this
    |" if-expression is known. In that case, we can use it to infer the
    |" branches' types.
    @with_dynvars(env, origin, entry_point)
    fun expected_type_equation(): Equation =
        (
            (
                node.type_var() <-> node.then_expr.expected_type_var()
                %and (
                    if not node.else_expr.is_null
                    then
                        (
                            (
                                (
                                    node.type_var()
                                    <-> node.else_expr.expected_type_var()
                                    %and node.else_expr.expected_type_var()
                                    <- BaseTypeDecl.derefed_base_subtype%(
                                        node.expected_type_var()
                                    )
                                )
                                %and node.then_expr.expected_type_var()
                                <- BaseTypeDecl.derefed_base_subtype%(
                                    node.expected_type_var()
                                )
                            )
                            %and self.else_expr.matches_expected_formal_type()
                        )
                        %and self.then_expr.matches_expected_formal_type()
                    else %true
                )
            )
            %and self.alternatives.logic_all(
                (elsif) =>
                (
                    node.type_var() <-> elsif.then_expr.expected_type_var()
                    %and elsif.then_expr.expected_type_var()
                    <- BaseTypeDecl.derefed_base_subtype%(
                        node.expected_type_var()
                    )
                )
                %and elsif.then_expr.matches_expected_formal_type()
            )
        )
        %and self.dependent_exprs().filter((e) => e.has_context_free_type())
        .logic_all(
            (e) =>
            (
                BaseTypeDecl.is_not_universal_type%(e.type_var())
                %and e.expected_type_var()
                <- BaseTypeDecl.base_subtype%(e.type_var())
            )
            %or %true
        )

    |" Return the equation to use when the expected type is not known, for
    |" example if we are inside a type conversion. In that case, we'll infer
    |" the type of the if expression by taking the common base subtype of the
    |" context-free types of all the sub-branches.
    @with_dynvars(env, origin, entry_point)
    fun no_expected_type_equation(): Equation =
        self.dependent_exprs().filter((e) => e.has_context_free_type())
        .logic_all(
            (e) =>
            BaseTypeDecl.is_universal_type%(e.type_var())
            %or (
                AdaNode.is_not_null%(e.type_var())
                %and node.type_var()
                <- BaseTypeDecl.base_subtype%(e.type_var())
            )
        )
}

|" List of associations for the ``Contract_Case`` aspect.
|"
|" Contract cases is a non standard Ada extension that's mainly useful in
|" SPARK. See `the SPARK RM <https://docs.adacore.com/spark2014-docs/>`_ for
|" more details.
class ContractCases: Expr {
    @parse_field
    contract_cases: ASTList[ContractCaseAssoc]
}

|" Declare expression (Ada 2022, :rmlink:`4.5.9`).
class DeclExpr: Expr {
    @parse_field
    decls: ASTList[AdaNode]
    @parse_field
    expr: Expr

    fun has_context_free_type(): Bool = node.expr.has_context_free_type()

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        {
            bind env = self.children_env;

            self.expr.sub_equation()
        }
        %and node.expr.expected_type_var() <-> node.expected_type_var()
        %and node.expr.type_var() <-> node.type_var()

    env_spec {
        add_env()
    }
}

|" Interpolated string expression.
|"
|" See :gnat_rm:`string-interpolation` for more details.
class FormatStringLiteral: Expr {
    @parse_field
    opening_chunk: FormatStringTokStart
    @parse_field
    mid_exprs: ASTList[FormatStringChunk]

    # This field is null when no expressions to expand are given in the
    # interpolated string, for example with `f"a dummy interpolated string"`.
    @parse_field
    @nullable
    trailing_expr: FormatStringChunk

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        (
            {
                bind error_location = node;
                BaseTypeDecl.allows_string_literal%(node.expected_type_var())
            }
            %and node.expected_type_var() <-> node.type_var()
            %and self.trailing_expr.do(
                (te) => te.sub_equation(),
                default_val=%true
            )
        )
        %and self.mid_exprs.logic_all((m) => m.expr.sub_equation())
}

|" Represent a membership test (in/not in operators) (:rmlink:`4.4`).
|"
|" Note that we don't consider them as binary operators since multiple
|" expressions on the right hand side are allowed.
class MembershipExpr: Expr {
    @parse_field
    expr: Expr
    @parse_field
    op: Op
    @parse_field
    membership_exprs: ExprAlternativesList

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        (node.type_var() <- node.bool_type() %and self.expr.sub_equation())
        %and self.membership_exprs.logic_all(
            (m) => {
                val typ = m.as[Name]?.name_designated_type();

                if not typ.is_null
                then (
                    # Tagged type check or subtype membership check
                    m.as[Name].xref_type_equation()
                    %and (
                        # If testing a specific tagged type membership, the
                        # expected type of the tested expression is the type at
                        # the root of the tagged type hierarchy.
                        #
                        # TODO: This is currently not possible to express
                        # because of an unrelated bug (see V408-038), but we
                        # can at least constrain the resulting type to be
                        # tagged after implicit dereference.
                        if typ.is_tagged_type()
                        then
                            node.expr.expected_type_var()
                            <- null[Entity[BaseTypeDecl]]
                            %and {
                                bind error_location = node;
                                BaseTypeDecl.is_tagged_type_with_deref%(node
                                .expr
                                .type_var())
                            }
                        else (
                            # This is a simple subtype membership test, so the
                            # expected type of the tested expression is the
                            # subtype's base type.
                            node.expr.expected_type_var() <- typ.base_subtype()
                            %and node.expr.matches_expected_membership_type()
                        )
                    )
                )
                else (
                    # Regular membership check
                    m.expected_type_var() <-> node.expr.type_var()
                    %and m.sub_equation()
                    %and m.matches_expected_type()
                )
            }
        )
}

|" Base class for names (:rmlink:`4.1`).
@abstract
class Name: Expr {
    |" If this name is part of a defining name, return the enclosing defining
    |" name node.
    @exported
    fun enclosing_defining_name(): Entity[DefiningName] =
        self.parents().find((p) => p is DefiningName).as[DefiningName]

    |" Return True if this name is part of a defining name.
    @exported
    fun is_defining(): Bool =
        (
            # Obvious case
            node is DefiningName
        )
        or (
            # The whole Identifier/DottedName contained in the defining name
            # is always considered defining.
            node.parent is DefiningName
        )
        or (
            # And in case of a dotted name, the suffix of the outermost dotted
            # name is also considered defining.
            node.parent.parent is DefiningName
            and node.parent.as[DottedName]?.suffix == node
        )

    |" Helper. Check that this name matches ``sym``.
    @exported
    fun name_is(sym: Symbol): Bool = node.name_symbol().do((ns) => ns == sym)

    |" Return True iff this name represents a call to a subprogram which is
    |" referred by its defining name. (i.e. not through a subprogram access).
    @exported
    fun is_direct_call(): Bool =
        self.is_call()
        and not self.called_subp_spec().parent is AccessToSubpDef

    |" Return True iff this name represents a call to subprogram through
    |" an access type.
    @exported
    fun is_access_call(): Bool =
        self.is_call() and self.called_subp_spec().parent is AccessToSubpDef

    |" Returns True if this Name corresponds to a call.
    @exported
    fun is_call(): Bool =
        not self.is_defining() and not self.called_formal_subp_spec().is_null

    |" Returns True if this Name corresponds to a dot notation call.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun is_dot_call(): Bool =
        not self.is_defining() and self.referenced_decl().info.md.dottable_subp

    |" Failsafe version of ``referenced_defining_name``. Returns a
    |" ``RefdDef``, which can be precise, imprecise, or error.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun failsafe_referenced_def_name(): RefdDef = {
        val ref_decl = self.failsafe_referenced_decl();
        val def_name =
            ref_decl.decl.do(
                (ref_decl) =>
                self.name_symbol().do(
                    (rel_name) =>
                    ref_decl.defining_names().find(
                        (dn) => dn.name_is(rel_name)
                    )
                )
                or? ref_decl.defining_name(),
                default_val=null[Entity[DefiningName]]
            );

        RefdDef(def_name=def_name, kind=ref_decl.kind)
    }

    |" Like ``referenced_decl``, but will return the defining identifier for
    |" the decl, rather than the basic declaration node itself.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun referenced_defining_name(): Entity[DefiningName] = {
        val ref_decl = self.referenced_decl();

        ref_decl.do(
            (ref_decl) =>
            self.name_symbol().do(
                (rel_name) =>
                ref_decl.defining_names().find((dn) => dn.name_is(rel_name))
            )
            or? ref_decl.defining_name(),
            default_val=null[Entity[DefiningName]]
        )
    }

    |" Implementation helper for DefiningName.gnat_xref. TODO: Get rid of that
    |" by inlining in DefiningName.gnat_xref.
    @with_dynvars(imprecise_fallback=false)
    fun gnat_xref_decl(): Entity[DefiningName] = {
        val dn = self.is_defining().do((_) => self.enclosing_defining_name());
        val bd = dn.do((dn) => dn.basic_decl());

        if bd.do((bd) => bd is ParamSpec) then bd.as[ParamSpec].decl_param(dn)
        elif bd.do((bd) => bd is Body)
        then bd.as[Body].decl_part()?.defining_name()
        elif
            bd.do(
                (bd) =>
                bd is BaseTypeDecl and bd.as[BaseTypeDecl].is_in_private_part()
            ) then bd.as[BaseTypeDecl].previous_part(true)?.defining_name()
        elif bd.do((bd) => bd is ObjectDecl)
        then (
            # TODO: Implement jumping to full object decl view for constant
            # object decls with no value.
            null[Entity[DefiningName]]
        )
        elif bd.do((bd) => bd is NumberDecl)
        then (
            # Number decls cannot have a next part, always return None
            null[Entity[DefiningName]]
        )
        elif bd.do((bd) => bd is BasicDecl) then dn
        else self.referenced_defining_name()
    }

    |" Internal property like all_env_elements, but accepting an additional
    |" ``categories`` parameter for internal uses.
    fun all_env_elements_internal(
        seq: Bool = true,
        seq_from: AdaNode = null[AdaNode],
        categories: RefCategories = RefCategories(_=true)
    ): Array[Entity[AdaNode]] = {
        bind origin = node.origin_node();
        bind env = self.node_env;

        self.all_env_els_impl(
            seq=seq,
            seq_from=seq_from,
            categories=categories
        )
    }

    |" Return all elements in self's scope that are lexically named like self.
    @exported
    fun all_env_elements(
        seq: Bool = true,
        seq_from: AdaNode = null[AdaNode]
    ): Array[Entity[AdaNode]] = self.all_env_elements_internal(seq, seq_from)

    fun first_corresponding_decl(): Entity[BasicDecl] =
        if node.parent is DottedName and node.is_suffix()
        then self.parent.as[DottedName].first_corresponding_decl()
        else self.all_env_elements_internal()?[0].as[BasicDecl]

    |" Constructs the xref equations for all the argument lists of CallExprs
    |" appearing between ``self`` and ``root``. This is done in a single
    |" distinct pass instead of directly inside the ``parent_name_equation``
    |" & co. properties as we were accidentally duplicating the construction
    |" of xref equations for some arguments lists and fixing this inside these
    |" properties proved to be difficult.
    @with_dynvars(env, origin, entry_point)
    fun all_args_xref_equation(root: Name): Equation =
        self.as[CallExpr].do(
            (ce) => ce.params()?.logic_all((pa) => pa.expr().sub_equation()),
            default_val=%true
        )
        %and self.parent_name(root).do(
            (name) => name.all_args_xref_equation(root),
            default_val=%true
        )

    |" Return an equation that always emits a diagnostic indicating that the
    |" entity designated by this name is missing.
    fun undefined_reference_equation(): Equation =
        node.ref_var() <- null[Entity[AdaNode]]
        %and {
            bind error_location = node;
            AdaNode.missing_entity_error%(node.ref_var())
        }

    @with_dynvars(env, origin, entry_point)
    fun bottom_up_name_equation(): Equation = match
        node.innermost_name().as_entity
    {
        case ce: CallExpr => ce.general_xref_equation(node)
        case ed: ExplicitDeref => ed.general_xref_equation(node)
        case qe: QualExpr => qe.general_xref_equation(node)
        case _ => %false
    }

    |" Helper property. Return the innermost name following the name chain.
    |" For example, given::
    |"
    |"     A (B) (C) (D)
    |"     ^-----------^ self
    |"     ^-------^     self.name
    |"     ^---^         self.name.name
    |"
    |" ``self.innermost_name`` will return the node corresponding to
    |" ``self.name.name``.
    fun innermost_name(): Name = {
        val name = match node {
            case ce: CallExpr => ce.name
            case ed: ExplicitDeref => ed.prefix
            case _ => null[Name]
        };

        if name is CallExpr | ExplicitDeref then name.innermost_name()
        elif name is QualExpr then name
        else node
    }

    |" Returns the leftmost name following the name chain.
    |" For example, given::
    |"
    |"     A (B) (C) (D)  -- Case 1: CallExpr
    |"     (A) (B)        -- Case 2: ArraySubcomponentChoiceName
    |"     A.B.C (D).E    -- Case 3: DottedName
    |"     A              -- Case 4: Identifier
    |"     A'First        -- Case 5: AttributeRef
    |"
    |" ``self.leftmost_name`` will return:
    |"
    |"   - A for Case 1,
    |"   - null for Case 2,
    |"   - A for Case 3,
    |"   - A for Case 4,
    |"   - A for Case 5.
    |"
    |" This property has been introduced to resolve deep delta aggregates so it
    |" may not be useful in other context as is. Do not make it exported.
    fun leftmost_name(): Name = match node {
        case ce: CallExpr => ce.name.leftmost_name()
        case ascn: ArraySubcomponentChoiceName => ascn.name?.leftmost_name()
        case dn: DottedName => dn.prefix.leftmost_name()
        case ar: AttributeRef => ar.prefix.leftmost_name()
        case _ => node
    }

    |" Construct the xref equation for the chain of parent nested names.
    @with_dynvars(env, origin, entry_point)
    fun parent_name_equation(
        typ: Entity[BaseTypeDecl],
        root: Name
    ): Equation = {
        val as_subp_access = typ?.access_def().as[AccessToSubpDef];
        val is_paramless =
            as_subp_access?.subp_spec.paramless(
                dottable_subp=false,
                can_be=false
            );
        val can_be_paramless =
            as_subp_access?.subp_spec.paramless(
                dottable_subp=false,
                can_be=true
            );
        val comp_type =
        # TODO: Try to perform this test directly in comp_type. We can't do
        # it at the moment since iterable_comp_type can call comp_type,
        # leading to an infinite recursion.
            if typ?.is_iterable_type() then typ?.iterable_comp_type()
            else typ?.comp_type(is_subscript=not node is ExplicitDeref);

        if typ.is_null then %false
        else
            match node {
                case ce: CallExpr =>
                    ce.as_entity.subscriptable_type_equation(typ)
                case ed: ExplicitDeref =>
                    ed.as_entity.eq_for_type(typ)
                    %and (
                        # If ``typ`` is an access to subprogram, it means self
                        # (an ExplicitDeref) is actually a call to that
                        # subprogram. So, bind its subp_spec_var to the
                        # subprogram spec of the access.
                        node.subp_spec_var() <- as_subp_access?.subp_spec
                    )
                case _ => node.type_var() <- null[Entity[AdaNode]]
            }
            %and self.parent_name(root).do(
                (pn) =>
                if node is ExplicitDeref and not as_subp_access.is_null
                then (
                    # If self is an explicit deref of a subprogram access type,
                    # we need to handle several cases:
                    # The subprogram doesn't take parameters, in which case
                    # the explicit dereference necessarily means accessing
                    # the component type of the access type (it represents
                    # the call).
                    if is_paramless
                    then pn.parent_name_equation(comp_type, root)
                    # The subprogram can be called without parameters, in
                    # which case we don't know for sure whether the
                    # explicit dereference accesses the component type or
                    # if it is the parent CallExpr that will.

                    elif can_be_paramless
                    then
                        pn.parent_name_equation(comp_type, root)
                        %or pn.parent_name_equation(typ, root)
                    # The subprogram must be called with parameters, in
                    # which case the parent CallExpr will expect the non-
                    # dereferenced type.
                    else pn.parent_name_equation(typ, root)
                )
                # If self is an array slice, we recurse with the same type

                elif self.as[CallExpr]?.check_array_slice(typ)
                then pn.parent_name_equation(typ, root)
                # Otherwise the name necessarily accesses the
                # component type of typ.
                else pn.parent_name_equation(comp_type, root),
                default_val=%true
            )
    }

    @with_dynvars(env, origin, entry_point)
    fun subtype_indication_equation(): Equation = self.xref_type_equation()

    |" Return True if this name can refer to a primitive subprogram.
    |" This is used in env lookups to avoid visiting referenced primitive envs
    |" when it is not relevant.
    |"
    |" .. note:: This is not an optimisation, it actually prevents potential
    |"     infinite recursions during lookups.
    fun can_designate_primitive(): Bool = match node.parent {
        case n: Name => n.can_designate_primitive()
        case r: RenamingClause => not r.parent is PackageRenamingDecl
        case _ => true
    }

    |" Will return the parent name until the stop point.
    fun parent_name(stop_at: Name): Entity[Name] =
        if stop_at.is_null or node == stop_at then null[Entity[Name]]
        else self.parent.as[Name]

    |" If this name qualifies the prefix in a call expression, this returns
    |" the corresponding CallExpr node. Return null otherwise. For example::
    |"
    |"     C (12, 15);
    |"     ^ parent_callexpr = <CallExpr>
    |"
    |"     A.B.C (12, 15);
    |"         ^ parent_callexpr = <CallExpr>
    |"
    |"     A.B.C (12, 15);
    |"       ^ parent_callexpr = null
    |"
    |"     C (12, 15);
    |"        ^ parent_callexpr = null
    fun parent_callexpr(): Entity[CallExpr] =
        self.parents().take_while(
            (p) =>
            p is CallExpr
            or (
                p is DottedName | BaseId
                and match p.parent {
                    case pfx: DottedName => pfx.suffix == p
                    case ce: CallExpr => ce.name == p
                    case _ => false
                }
            )
        )
        .find((p) => p is CallExpr)
        .as[CallExpr]

    |" Predicate that returns True if self is a range attribute ref.
    fun is_range_attribute(): Bool =
        node.as[AttributeRef].do(
            (attr_ref) => attr_ref.as_bare_entity.attribute.name_is(s"Range")
        )

    |" Return the subprogram specification of the subprogram or subprogram
    |" access that is being called by this exact Name, if relevant. Note that
    |" when inside an instantiated generic, this will return the spec of the
    |" actual subprogram.
    @exported
    fun called_subp_spec(): Entity[BaseFormalParamHolder] =
        self.called_formal_subp_spec()?.corresponding_actual()

    |" Return the declaration this node references after name resolution.
    |" If imprecise_fallback is True, errors raised during resolution of the
    |" xref equation are caught and a fallback mechanism is triggered, which
    |" tries to find the referenced declaration in an ad-hoc way.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun referenced_decl(): Entity[BasicDecl] =
        self.referenced_decl_internal().decl

    |" Failsafe version of ``referenced_decl``. Returns a ``RefdDecl``, which
    |" can be precise, imprecise, or error.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun failsafe_referenced_decl(): RefdDecl =
        try self.referenced_decl_internal() else RefdDecl(
            kind=RefResultKind.error
        )

    |" Wrapper to get the referenced declaration inside ``self.ref_var``.
    |"
    |" This wrapper will put back the generic context on generic bodies. When
    |" you are inside an instantiation and you lookup the generic by name,
    |" such as in this example:
    |"
    |" .. code-block:: ada
    |"
    |"     generic procedure P2_G;
    |"
    |"     procedure P2_G is
    |"     begin
    |"         P2_G; <- Reference to the generic body
    |"     end;
    |"
    |"     procedure P2 is new P2_G; <- Through this instantiation
    |"
    |" It needs to return the instantiated generic, but by default this will
    |" not work.
    |"
    |" TODO: This is kind of a special case, and we need to investigate
    |" whether a rework of the rebindings mechanism can simplify this or not.
    fun get_referenced_decl(): LogicValResult = {
        val val_result = node.logic_val(self, node.ref_var());
        val entity = val_result.value.as![BasicDecl];
        val generic_context_node = self.info.rebindings?.old_env.env_node;
        # Put back the generic context on entity if applicable as per the
        # example in the docstring.
        val entity_with_generic_context =
            if
                not generic_context_node.is_null
                and (
                    # The referenced node is the generic declaration inside
                    # of which we are.
                    generic_context_node
                    == entity
                    .node
                    # The referenced node is the generic body inside of which
                    # we are.
                    or generic_context_node
                    == entity.as[Body]?.decl_part()?.node
                )
            then (
                # Add back the rebindings if the conditions are satisfied
                entity.unshed_rebindings_helper(self.info.rebindings)
            )
            else entity;

        val_result.success.do(
            (s) => LogicValResult(success=s, value=entity_with_generic_context)
        )
    }

    |" Return the declaration this node references. Try not to run name res if
    |" already resolved.
    @with_dynvars(imprecise_fallback=false)
    fun referenced_decl_internal(): RefdDecl =
        # First, check whether the name is defining, in which case it
        # cannot be a reference.
        if self.is_defining() then null[RefdDecl]
        else
            (
                if imprecise_fallback
                then # The imprecise_fallback path cannot raise
                {
                    val v =
                        try self.get_referenced_decl()
                        else null[LogicValResult];

                    if v.success
                    then (
                        # If we resolved correctly using full nameres, return a
                        # precise result.
                        RefdDecl(
                            decl=v.value.as[BasicDecl],
                            kind=RefResultKind.precise
                        )
                    )
                    else (
                        # Else, just take the first corresponding declaration,
                        # return as an imprecise result.
                        self?.first_corresponding_decl().do(
                            (fcd) =>
                            RefdDecl(decl=fcd, kind=RefResultKind.imprecise),
                            default_val=RefdDecl(kind=RefResultKind.error)
                        )
                    )
                }
                else # No fallback path
                {
                    val v = self.get_referenced_decl();

                    if v.success
                    then
                        RefdDecl(
                            decl=v.value.as![BasicDecl],
                            kind=RefResultKind.precise
                        )
                    else
                        RefdDecl(
                            decl=null[Entity[BasicDecl]],
                            kind=RefResultKind.error
                        )
                }
            )
            .do(
                (res) =>
                RefdDecl(decl=res.decl?.wrap_public_reference(), kind=res.kind)
                .do(
                    # Never return a null node with a Precise result: this
                    # indicates that it should be a no_ref (e.g. builtin
                    # operator).
                    (res) =>
                    if res.decl.is_null and res.kind == RefResultKind.precise
                    then null[RefdDecl]
                    else res
                )
            )

    |" Like SubtypeIndication.designated_type, but on names, since because of
    |" Ada's ambiguous grammar, some subtype indications will be parsed as
    |" names.
    @exported
    fun name_designated_type(): Entity[BaseTypeDecl] = {
        bind env = self.node_env;
        bind origin = node.origin_node();

        self.designated_type_impl()
    }

    |" Returns whether self denotes a static subtype or not.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun is_static_subtype(): Bool =
        self.name_designated_type().is_static_decl()

    # ATTENTION: As for Name.use_package_name_designated_env this property must
    # not be memoized because of an unsoundness issue between infinite
    # recursion guards in lexical envs and memoized properties. See
    # libadalang#1307.
    fun name_designated_type_env(): LexicalEnv =
        self.name_designated_type()?.primitives_env()

    |" Return the compilation unit referenced by this name and for the given
    |" unit kind, if there is one.
    fun referenced_unit(
        kind: AnalysisUnitKind,
        not_found_is_error: Bool = true
    ): CompilationUnit =
        node.designated_compilation_unit(
            node.as_symbol_array(),
            kind,
            true,
            not_found_is_error
        )

    |" Return whether two names match each other.
    |"
    |" This only handles Identifiers, SyntheticIdentifiers, StringLiteral,
    |" DefiningName and DottedName nodes: it always returns False for any
    |" other node kind.
    fun matches(n: Name): Bool =
        if
            (
                node is Identifier | SyntheticIdentifier
                and n is Identifier | SyntheticIdentifier
            )
            or (node is StringLiteral and n is StringLiteral)
        then node.name_symbol() == n.name_symbol()
        elif node is DefiningName then node.as[DefiningName].name.matches(n)
        elif n is DefiningName then node.matches(n.as[DefiningName].name)
        elif node is DottedName and n is DottedName
        then
            node.as[DottedName].prefix.matches(n.as[DottedName].prefix)
            and node.as[DottedName].suffix.matches(n.as[DottedName].suffix)
        else false

    |" Return whether two names match each other.
    |"
    |" This compares the symbol for Identifier and StringLiteral nodes. We
    |" consider that there is no match for all other node kinds.
    @exported
    fun name_matches(n: Entity[Name]): Bool = node.matches(n.node)

    # ATTENTION: this property must not be memoized because of an unsoundness
    # issue between infinite recursion guards in lexical envs and memoized
    # properties. See VC13-023.
    |" Assuming self is a name that is the direct child of a
    |" UsePackageClause's package name list, return the memoized designated
    |" environment for it.
    fun use_package_name_designated_env(): LexicalEnv =
        self.parent.parent.as![UsePackageClause].designated_env(
            node.child_index
        )

    |" Simple xref equation for names designating types. Doesn't try to
    |" resolve overloads. Originally derived from xref_no_overloading to match
    |" the behavior of designated_type properties.
    @with_dynvars(env, origin, entry_point)
    fun xref_type_equation(): Equation = match self {
        case dn: DottedName =>
            dn.prefix.xref_no_overloading(sequential=true, all_els=false)
            %and {
                bind env = dn.prefix.designated_env_no_overloading();

                dn.suffix.xref_type_equation()
            }
        case i: BaseId =>
            i.designated_type_impl().do(
                (type) => i.ref_var() <- type,
                default_val=self.undefined_reference_equation()
            )
        case ar: AttributeRef =>
            ar.prefix.xref_type_equation()
            %and (
                if ar.attribute.sym() == s"Class"
                then
                    ar.ref_var()
                    <- BaseTypeDecl.classwide_type%(ar.prefix.ref_var())
                elif ar.attribute.sym() == s"Base"
                then
                    ar.ref_var()
                    <- BaseTypeDecl.scalar_base_type%(ar.prefix.ref_var())
                else %true
            )
        case _ => %false
    }

    |" Simple xref equation for names. Doesn't try to resolve overloads. If
    |" ``all_els`` is True, then the name will be bound to the domain of all
    |" elements that corresponds. Else, it will be bound to the first one.
    |"
    |" ``sequential`` determines whether the lookup will be sequential or not.
    @with_dynvars(env, origin, entry_point)
    fun xref_no_overloading(
        sequential: Bool = true,
        all_els: Bool = false
    ): Equation = match self {
        case dn: DottedName =>
            dn.prefix.xref_no_overloading(sequential, all_els)
            %and {
                bind env = dn.prefix.designated_env();

                dn.suffix.xref_no_overloading(sequential, all_els)
            }
        case i: BaseId =>
            if all_els and node.is_suffix()
            then
                %domain(
                    i.ref_var(),
                    node.env_get(
                        env,
                        i.name_symbol(),
                        from_node=if sequential then self.node else null[Name],
                        lookup=if node.is_prefix() then LookupKind.recursive
                        else LookupKind.flat
                    )
                    .filter((e) => node.has_visibility(e))
                )
            else
                i.ref_var()
                <- i.env_get_first_visible(
                    env,
                    from_node=if sequential then self.node else null[Name],
                    lookup_type=if node.is_prefix() then LookupKind.recursive
                    else LookupKind.flat
                )
        case _ => %false
    }

    |" Returns whether self is the prefix in name. Is used to determine
    |" whether lookups on this name should be recursive or not, without having
    |" to pass down the information as a function parameter.
    @memoized
    fun is_prefix(): Bool =
        (
            (
                node.parent is DottedName
                and node.parent.as[DottedName].prefix == node
            )
            and node.parent.as[Name].is_prefix()
        )
        or not node.parent is DottedName

    |" Returns whether self is the suffix in name.
    @memoized
    fun is_suffix(): Bool =
        (
            (
                node.parent is DottedName
                and node.parent.as[DottedName].suffix == node
            )
            and node.parent.as[Name].is_suffix()
        )
        or not node.parent is DottedName

    |" Return whether the name that self designates is an operator.
    @exported
    fun is_operator_name(): Bool =
        self.name_symbol() in s"\"=\""
            | s"\"/=\""
            | s"\"<\""
            | s"\"<=\""
            | s"\">\""
            | s"\">=\""
            | s"\"and\""
            | s"\"or\""
            | s"\"xor\""
            | s"\"abs\""
            | s"\"*\""
            | s"\"/\""
            | s"\"mod\""
            | s"\"rem\""
            | s"\"+\""
            | s"\"-\""
            | s"\"&\"\"+\""
            | s"\"-\""
            | s"\"not\""
            | s"\"abs\""

    |" Whether this name is a write reference.
    |"
    |" For example, ``X`` is a write reference in the following cases:
    |"
    |" 1. ``X := 2;``
    |" 2. ``X (2) := 2;``
    |" 3. ``P(F => X)`` where F is declared ``out`` or ``in out``.
    |" 4. ``P(F => T (X))`` where F is declared ``out`` or ``in out``
    |" 5. ``X'Access``.
    |" 6. ``X.C := 2``, ``R.X := 2``
    |" 7. ``X.P`` where the formal for X is declared ``out`` or ``in out``.
    |"
    |" .. note:: This is an experimental feature. There might be some
    |"     discrepancy with the GNAT concept of "write reference".
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun is_write_reference(): Bool = match self.parent {
        # Handle assignment case::
        #     X := 2;
        case a: AssignStmt => a.dest == self

        # Handle assignment to component case::
        #     X (2) := 2;
        case c: CallExpr =>
            c.name == self
            and (
                # self is the name of component access
                c.is_write_reference()
            )

        # Handle assignment to component case::
        #    X.C := 2
        #    R.X := 2
        #
        # As well as calls using the dot notation with out/inout operand.
        case d: DottedName =>
            (
                # Component writes
                d.is_write_reference()
            )
            or (
                # Dot calls with "out" first parameter
                d.prefix == self
                and d.suffix.called_subp_spec().do(
                    (spec) =>
                    spec.info.md.dottable_subp
                    and spec.abstract_formal_params()?[0]
                    .as[ParamSpec]
                    ?.mode
                    ?.is_writable()
                )
            )

        # Handle out/inout param case
        case p: ParamAssoc =>
            if {
                bind env = node.node_env;
                bind origin = node.origin_node();

                p.parent.parent.as[CallExpr]?.is_type_conversion()
            }
            then p.parent.parent.as[CallExpr].is_write_reference()
            else
                p.get_params().any(
                    (m) => m.basic_decl().as[ParamSpec]?.mode?.is_writable()
                )

        # handle 'Access case
        case a: AttributeRef => a.prefix == self and a.is_access_attr()
        case l: AlternativesList => l.parent is AggregateAssoc
        case _ => false
    }

    |" Implementation for calls done via a CallExpr, a DottedName
    |" or an Identifier. The result includes the prefix of the call in case
    |" the dot-notation is used.
    @with_dynvars(imprecise_fallback=false)
    fun potential_actuals_for_dispatch(
        spec: Entity[BaseSubpSpec]
    ): Array[ExpectedTypeForExpr] = {
        # Handle calls done using the dot notation. Retrieve the prefix and
        # match it with the type of the first parameter of the called
        # subprogram.
        val prefix =
            self.is_dot_call().do(
                (_) =>
                match self {
                    case c: CallExpr => c.name.as![DottedName]
                    case d: DottedName => d
                    case i: Identifier => i.parent.as![DottedName]
                    case _ => null[Entity[DottedName]]
                }
                .do(
                    (d) =>
                    [
                        ExpectedTypeForExpr(
                            expected_type=spec.unpacked_formal_params()?[0]
                            .formal_decl()
                            .type_expression(),
                            expr=d.prefix
                        )
                    ]
                )
            );
        # Handle the rest of the arguments if this is a CallExpr, matching
        # them with the types of the parameters of the called subprogram.
        val args =
            self.as[CallExpr]?.params()?.zip_with_params().map(
                (pm) =>
                ExpectedTypeForExpr(
                    expected_type=pm.param.basic_decl().type_expression(),
                    expr=pm.actual
                )
            );

        prefix & args
    }

    @with_dynvars(imprecise_fallback=false)
    fun is_dispatching_call(): Bool =
        self.is_access_call()
        or (
            self.is_direct_call()
            and (self.parent_callexpr().as[Name] or? self)
            .is_dispatching_call_impl(self.referenced_decl())
        )

    |" Returns True if this Name corresponds to a static non-dispatching call.
    |" In other words, this will return True if and only if the target of the
    |" call is known statically.
    |"
    |" .. note:: This is an experimental feature. There might be some
    |"     discrepancy with the GNAT concept of "static call".
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun is_static_call(): Bool =
        self.is_call() and not self.is_dispatching_call()

    |" Return the array of SingleTokNode nodes that compose this name.
    |"
    |" Only simple name kinds are allowed: Identifier, DottedName and
    |" DefiningName. Any other kind will trigger a PreconditionFailure.
    fun as_single_tok_node_array(): Array[SingleTokNode] = match node {
        case dname: DefiningName => dname.name.as_single_tok_node_array()
        case tok: SingleTokNode => [tok]
        case dot: DottedName =>
            dot.prefix.as_single_tok_node_array()
            & dot.suffix.as_single_tok_node_array()
        case _ => raise[Array[SingleTokNode]] PreconditionFailure()
    }

    |" Returns an array of pairs, associating formal parameters to actual or
    |" default expressions.
    @exported
    fun call_params(): Array[ParamActual] = {
        val formal_spec = self.called_formal_subp_spec();
        val is_call = not formal_spec.is_null;
        val is_prefix_call =
            if is_call then self.is_dot_call() or self is AttributeRef
            else false;
        val offset = if is_prefix_call then 1 else 0;
        val call_prefix = match
            self.as[CallExpr].do((ce) => ce.name) or? self
        {
            case dn: DottedName => dn.prefix
            case ar: AttributeRef => ar.prefix
            case _ => null[Entity[Expr]]
        };
        # Get the actuals of this call expression if any
        val aparams = self.parent_callexpr().do((ce) =>
            if ce.called_formal_subp_spec() == formal_spec
            then ce
            else null[Entity[CallExpr]]
        )?.params();

        # Get the formals of the called subprogams
        val fparams = formal_spec?.abstract_formal_params();
        # Get a flatten list of the parameters of the actual subprogram, so
        # that we can easily find them by index when mapping from the
        # parameter of the formal subprogram.
        val actual_formals =
            formal_spec?.corresponding_actual().unpacked_formal_params();

        if is_call
        then {
            # Create an array of pairs from the subprogram formals and default
            # expressions.
            val dparams =
                fparams.imapcat(
                    (p, i) =>
                    p.defining_names().map(
                        (n) =>
                        ParamActual(
                            param=n,
                            # Handling dot notation (first actual is
                            # denoted by the prefix of the dot call).
                            actual=if is_prefix_call and i == 0
                            then call_prefix
                            else p.as[ParamSpec]?.default_expr
                        )
                    )
                );

            # Create a new array by updating the actuals if the call
            # expression provides some.
            aparams.do(
                (ap) =>
                dparams.imap(
                    (dp, i) =>
                    ParamActual(
                        param=actual_formals?[i],
                        # Search if a named param expression exists for
                        # this formal param in the call assoc list.
                        # Handling dot notation (do not update first
                        # actual).
                        actual=if is_prefix_call and i == 0 then dp.actual
                        else
                            ap.actual_for_param_at(
                                dp.param,
                                i - offset,
                                dp.actual
                            )
                    )
                ),
                default_val=dparams
            )
        }
        else
            raise[Array[ParamActual]] PreconditionFailure(
                "this name doesn't reference a call expression"
            )
    }

    |" Returns the lexical environment that is the scope in which the
    |" entity designated by this name is defined/used.
    @with_dynvars(env)
    fun parent_scope(): LexicalEnv =
        raise[LexicalEnv] PropertyError(
            "Property Name.parent_scope not implemented"
        )

    @with_dynvars(env, origin)
    fun all_env_els_impl(
        @ignored
        seq: Bool = true,
        @ignored
        seq_from: AdaNode = null[AdaNode],
        @ignored
        categories: RefCategories = RefCategories(_=true)
    ): Array[Entity[AdaNode]] =
        raise[Array[Entity[AdaNode]]] PropertyError(
            "Property Name.all_env_els_impl not implemented"
        )

    |" Lexical environment this identifier represents. This is similar to
    |" designated_env although it handles only cases for child units and it is
    |" used only during the environment population pass so it does not return
    |" orphan environments.
    @with_dynvars(env)
    fun scope(): LexicalEnv = null[LexicalEnv]

    |" This property proxies the logic variable that points to the entity that
    |" this name refers to. For example, for a simple dotted name::
    |"
    |"     A.B
    |"
    |" The dotted name's ref var is the one of the SingleTokNode B.
    fun ref_var(): LogicVar =
        raise[LogicVar] PropertyError("Property Name.ref_var not implemented")

    |" This logic variable holds the specification of the subprogram or
    |" subprogram access that is being called by this exact Name.
    fun subp_spec_var(): LogicVar =
        raise[LogicVar] PropertyError(
            "Property Name.subp_spec_var not implemented"
        )

    fun defines_subp_spec_var(): Bool =
        # A null logic variable could have been used instead of this additional
        # property to indicate that an AST node does not define subp_spec_var.
        # Unfortunately, No(LogicVar) is not a valid dsl expression. Therefore,
        # we provide a default implementation for this property, which is then
        # overridden in relevant child classes to indicate that one can call
        # p_subp_spec_var.
        false

    |" Return the subprogram specification of the subprogram or subprogram
    |" access that is being called by this exact Name, if relevant. Note that
    |" when inside an instantiated generic, this will return the spec of the
    |" formal subprogram.
    fun called_formal_subp_spec(): Entity[BaseFormalParamHolder] =
        if node.defines_subp_spec_var()
        then
            node.logic_val(from_node=self, lvar=node.subp_spec_var())
            .value
            .as[BaseFormalParamHolder]
        else null[Entity[BaseFormalParamHolder]]

    |" Assuming this name designates a type, return this type.
    |"
    |" Since in Ada this can be resolved locally without any non-local
    |" analysis, this doesn't use logic equations.
    @with_dynvars(env, origin)
    fun designated_type_impl(): Entity[BaseTypeDecl] =
        null[Entity[BaseTypeDecl]]

    |" Returns the relative name of this instance. For example,
    |" for a prefix ``A.B.C``, this will return ``C``.
    @exported
    fun relative_name(): Entity[Name] =
        raise[Entity[Name]] PropertyError(
            "Property Name.relative_name not implemented"
        )

    fun name_symbol(): Symbol =
        node.as_bare_entity.relative_name().name_symbol()

    |" Turn this name into an array of symbols.
    |"
    |" For instance, a node with name ``A.B.C`` is turned into
    |" ``['A', 'B', 'C']``.
    |"
    |" Only simple name kinds are allowed: Identifier, DottedName and
    |" DefiningName. Any other kind will trigger a PreconditionFailure.
    @exported
    fun as_symbol_array(): Array[Symbol] =
        node.as_single_tok_node_array().map((t) => t.symbol)

    |" Return a canonicalized version of this name's text.
    |"
    |" Only simple name kinds are allowed: Identifier, DottedName and
    |" DefiningName. Any other kind will trigger a PreconditionFailure.
    @exported
    fun canonical_text(): Symbol =
        node.sym_join(node.as_symbol_array(), ".").to_symbol

    |" Return whether this name denotes a constant value.
    @exported
    fun is_constant(): Bool =
        raise[Bool] PropertyError("Property Name.is_constant not implemented")
}

|" Expression to reference an attribute (:rmlink:`4.1.4`).
class AttributeRef: Name {
    @parse_field
    prefix: Name
    @parse_field
    attribute: Identifier
    @parse_field
    args: AssocList
    r_ref_var: LogicVar

    fun ref_var(): LogicVar = node.r_ref_var

    fun relative_name(): Entity[Name] = self.prefix.relative_name()

    fun is_constant(): Bool = true

    @with_dynvars(env, origin)
    fun designated_type_impl(): Entity[BaseTypeDecl] =
        if node.attribute.sym() == s"Class"
        then self.prefix.designated_type_impl()?.classwide_type()
        elif node.attribute.sym() == s"Base"
        then self.prefix.designated_type_impl().scalar_base_subtype()
        else null[Entity[BaseTypeDecl]]

    fun has_context_free_type(): Bool = not node.is_access_attr()

    fun is_access_attr(): Bool =
        node.attribute.name_symbol() in s"Access"
            | s"Unchecked_Access"
            | s"Unrestricted_Access"

    @with_dynvars(env, origin, no_visibility=false)
    fun designated_env(): LexicalEnv =
        if
            self.is_access_attr()
            or self.attribute.name_symbol() in s"Old" | s"Super"
        then self.prefix.designated_env()
        elif self.attribute.name_is(s"Result")
        then
            node.parents().find((p) => p is BasicSubpDecl | BaseSubpBody)
            .as_entity
            .as[BasicDecl]
            .subp_spec_or_null()
            .return_type()
            .defining_env()
        else null[LexicalEnv]

    |" Return the subprogram declaration referred by this attribute name,
    |" assuming its prefix denotes a type.
    fun attribute_subprogram(): Entity[BasicDecl] =
        self.prefix.name_designated_type()?.attribute_subprogram(
            self.attribute.name_symbol()
        )

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        val rel_name = self.attribute.name_symbol();

        # Attributes that have arguments
        if rel_name in s"First" | s"Last" | s"Range" | s"Length"
        then self.array_attr_equation()
        # Attributes that simply return subprograms

        elif
            rel_name in s"Succ"
                | s"Pred"
                | s"Min"
                | s"Max"
                | s"Ceiling"
                | s"Floor"
                | s"Rounding"
                | s"Unbiased_Rounding"
                | s"Leading_Part"
                | s"Truncation"
                | s"Exponent"
                | s"Fraction"
                | s"Copy_Sign"
                | s"Remainder"
                | s"Adjacent"
                | s"Machine"
                | s"Machine_Rounding"
                | s"Scaling"
                | s"Compose"
                | s"Mod"
                | s"Value"
                | s"Wide_Value"
                | s"Wide_Wide_Value"
                | s"Fixed_Value"
                | s"Integer_Value"
                | s"Pos"
                | s"Val"
                | s"Enum_Val"
                | s"Write"
                | s"Read"
                | s"Output"
                | s"Input"
                | s"Put_Image"
                | s"Asm_Input"
                | s"Asm_Output"
                | s"Model"
                | s"Round" then self.attribute_subprogram_equation()
        elif rel_name in s"Size" | s"VADS_Size" then self.size_equation()
        elif
            rel_name in s"Max_Size_In_Storage_Elements"
                | s"Max_Alignment_For_Allocation"
                | s"Aft"
                | s"Object_Size"
                | s"Value_Size"
                | s"Storage_Size"
                | s"Scale" then self.subtype_attr_equation()
        elif
            rel_name in s"Access"
                | s"Unchecked_Access"
                | s"Unrestricted_Access" then self.access_equation()
        elif rel_name == s"Image"
        then self.image_equation(node.std_string_type())
        elif rel_name == s"Wide_Image"
        then self.image_equation(node.std_wide_string_type())
        elif rel_name == s"Wide_Wide_Image"
        then self.image_equation(node.std_wide_wide_string_type())
        elif rel_name == s"Enum_Rep" then self.enum_rep_equation()
        elif rel_name in s"Invalid_Value" | s"First_Valid" | s"Last_Valid"
        then self.self_type_equation()
        elif rel_name == s"Identity" then self.identity_equation()
        elif rel_name in s"Address" | s"Code_Address"
        then self.address_equation()
        elif
            rel_name in s"Small"
                | s"Model_Small"
                | s"Safe_Small"
                | s"Epsilon"
                | s"Model_Epsilon"
                | s"Large"
                | s"Safe_Large"
                | s"Delta"
                | s"Safe_First"
                | s"Safe_Last" then self.universal_real_equation()
        elif rel_name == s"Img" then self.img_equation(node.std_string_type())
        elif rel_name == s"Tag" then self.tag_attr_equation()
        elif rel_name == s"Result" then self.result_attr_equation()
        elif rel_name in s"Old" | s"Loop_Entry" then self.bind_to_prefix_eq()
        elif rel_name in s"Class" | s"Base" then self.prefix.sub_equation()
        elif
            rel_name in s"Valid"
                | s"Machine_Overflows"
                | s"Machine_Rounds"
                | s"Has_Access_Values"
                | s"Has_Discriminants"
                | s"Has_Tagged_Values"
                | s"Definite"
                | s"Constrained"
                | s"Initialized"
                | s"Valid_Scalars"
                | s"Unconstrained_Array"
                | s"Library_Level"
                | s"Preelaborable_Initialization"
                | s"Denorm"
                | s"Signed_Zeros"
                | s"Fast_Math"
                | s"Passed_By_Reference"
        then
            self.prefix.sub_equation() %and node.type_var() <- node.bool_type()
        # In the case of the ``Enabled`` attribute, the prefix is supposed
        # to be a check name, so it's not even an entity that has source
        # existence. In that case, we just bind the type of the expr to
        # bool.

        elif rel_name == s"Enabled" then node.type_var() <- node.bool_type()
        elif
            rel_name in s"Width"
                | s"Component_Size"
                | s"Position"
                | s"Mantissa"
                | s"Model_Mantissa"
                | s"Machine_Mantissa"
                | s"Fore"
                | s"Aft"
                | s"Digits"
                | s"Modulus"
                | s"Word_Size"
                | s"Wchar_T_Size"
                | s"Max_Integer_Size"
                | s"Address_Size"
                | s"Maximum_Alignment"
                | s"System_Allocator_Alignment"
                | s"Finalization_Size"
                | s"Descriptor_Size"
                | s"Alignment"
                | s"First_Bit"
                | s"Last_Bit"
                | s"Default_Bit_Order"
                | s"Range_Length"
                | s"Storage_Unit"
                | s"Stream_Size"
                | s"Small_Numerator"
                | s"Small_Denominator"
                | s"Machine_Emin"
                | s"Machine_Emax"
                | s"Model_Emin"
        then
            self.prefix.sub_equation()
            %and node.universal_int_bind(node.type_var())
        elif rel_name in s"External_Tag" | s"Type_Key"
        then
            self.prefix.sub_equation()
            %and node.type_var() <- node.std_string_type()
        elif rel_name == s"Target_Name"
        then node.type_var() <- node.std_string_type()
        elif rel_name == s"Storage_Pool" then self.storage_pool_equation()
        elif
            rel_name in s"Bit_Order"
                | s"Scalar_Storage_Order"
                | s"Default_Scalar_Storage_Order" then self.order_equation()
        elif rel_name == s"Type_Class" then self.type_class_equation()
        # Task attributes (RM 9.9)

        elif rel_name in s"Callable" | s"Terminated"
        then
            self.prefix.sub_equation() %and node.type_var() <- node.bool_type()
        # Entry attributes (RM 9.9)

        elif rel_name == s"Count"
        then
            match self.prefix {
                # If prefix is a CallExpr, use sub_equation to resolve the
                # entry reference as it specifies a family member.
                case ce: CallExpr => ce.sub_equation()

                # On the other cases, prefix is a simple identifier
                case o => o.xref_no_overloading()
            }
            %and node.universal_int_bind(node.type_var())
        elif rel_name == s"Caller"
        then
            self.prefix.xref_no_overloading()
            %and node.type_var() <- node.task_id_type()
        elif rel_name == s"Machine_Radix" then self.universal_int_equation()
        elif rel_name == s"To_Address" then self.to_address_equation()
        elif rel_name == s"Index" then self.index_equation()
        elif rel_name == s"Abort_Signal"
        then
            node.ref_var() <- node.std_entity(s"abort_signal_")
            %and node.type_var() <- null[Entity[BaseTypeDecl]]
        elif rel_name in s"Has_Same_Storage" | s"Overlaps_Storage"
        then self.storage_equation()
        elif rel_name == s"Deref" then self.deref_equation()
        elif rel_name == s"Mechanism_Code" then self.mechanism_code_equation()
        elif rel_name == s"Super" then self.super_equation()
        else raise[Equation] PropertyError("Unhandled attribute")
    }

    |" Equation for type attributes that denote functions.
    @with_dynvars(env, origin, entry_point)
    fun attribute_subprogram_equation(): Equation =
        self.prefix.xref_type_equation()
        %and node.ref_var() <- self.attribute_subprogram()

    |" Implementation of the Type_Class attribute, provided for compatibility
    |" with DEC 83.
    @with_dynvars(env, origin, entry_point)
    fun type_class_equation(): Equation = {
        val typ =
            self.get_unit_root_decl(
                [s"System", s"Aux_DEC"],
                AnalysisUnitKind.unit_specification
            )
            ?.children_env
            .get_first(s"Type_Class", lookup=LookupKind.flat)
            .as[BaseTypeDecl];

        self.prefix.xref_equation() %and node.type_var() <- typ
    }

    |" Equation for the Storage_Pool attribute.
    @with_dynvars(env, origin, entry_point)
    fun storage_pool_equation(): Equation = {
        val typ =
            self.get_unit_root_decl(
                [s"System", s"Storage_Pools"],
                AnalysisUnitKind.unit_specification
            )
            ?.children_env
            .get_first(s"Root_Storage_Pool", lookup=LookupKind.flat)
            .as[BaseTypeDecl]
            .classwide_type();

        self.prefix.xref_equation() %and node.type_var() <- typ
    }

    |" Equation for the Bit_Order/[Default_]Scalar_Storage_Order attributes.
    @with_dynvars(env, origin, entry_point)
    fun order_equation(): Equation = {
        val typ =
            self.get_unit_root_decl(
                [s"System"],
                AnalysisUnitKind.unit_specification
            )
            ?.children_env
            .get_first(s"Bit_Order", lookup=LookupKind.flat)
            .as[BaseTypeDecl];

        self.prefix.xref_equation() %and node.type_var() <- typ
    }

    @with_dynvars(env, origin, entry_point)
    fun bind_to_prefix_eq(): Equation =
        node.prefix.expected_type_var() <-> node.expected_type_var()
        %and self.prefix.sub_equation()
        %and node.type_var() <-> node.prefix.type_var()

    @with_dynvars(env, origin, entry_point)
    fun result_attr_equation(): Equation = {
        # We find the containing declaration (a function declaration or an
        # access-to-function type) starting the bound env's node instead of
        # self, as this attribute can appear in a pragma Post appearing
        # *after* the declaration.
        val containing_decl =
            env.env_node.parents().find(
                (p) =>
                p is BasicSubpDecl | BaseSubpBody
                or p.as[ConcreteTypeDecl].do(
                    (v1) => v1.type_def is AccessToSubpDef
                )
            )
            .as_entity
            .as[BasicDecl];
        val returns =
            match containing_decl {
                case sd: ConcreteTypeDecl =>
                    sd.type_def.as[AccessToSubpDef].subp_spec
                case bd: BasicDecl => bd.subp_spec_or_null()
            }
            .do((ss) => ss.return_type());

        node.type_var() <- returns
        %and self.prefix.ref_var() <- containing_decl
    }

    @with_dynvars(env, origin, entry_point)
    fun tag_attr_equation(): Equation = {
        val tag_type =
            self.get_unit_root_decl(
                [s"Ada", s"Tags"],
                AnalysisUnitKind.unit_specification
            )
            ?.children_env
            .get_first(s"Tag", lookup=LookupKind.flat)
            .as[BaseTypeDecl];

        # Prefix is an expression, bind prefix's ref var to it
        self.prefix.xref_equation()

        # Type of self is String
        %and node.type_var() <- tag_type
    }

    @with_dynvars(env, origin, entry_point)
    fun address_equation(): Equation =
        # Just like in access_equation, handle subprograms first, otherwise
        # paramless subprograms could match the normal path and therefore be
        # considered called.
        (
            (
                self.prefix.xref_no_overloading()
                %and BasicDecl.is_subprogram%(node.prefix.ref_var())
            )
            %or self.prefix.sub_equation()
        )
        %and node.type_var() <- self.system_address_type()

    @with_dynvars(env, origin, entry_point)
    fun identity_equation(): Equation =
        # NOTE: We don't verify that the prefix designates an exception
        # declaration, because that's legality, not name resolution.
        self.prefix.sub_equation()
        %and node.type_var() <- BasicDecl.identity_type%(node.prefix.ref_var())

    @with_dynvars(env, origin, entry_point)
    fun universal_real_equation(): Equation =
        node.universal_real_bind(node.type_var())
        %and self.prefix.sub_equation()

    @with_dynvars(env, origin, entry_point)
    fun universal_int_equation(): Equation = {
        val typ = self.prefix.name_designated_type();

        (
            self.prefix.sub_equation()
            %and node.universal_int_bind(node.type_var())
        )
        %and self.args.logic_all(
            (arg) =>
            (
                arg.expr().expected_type_var() <- typ
                %and arg.expr().sub_equation()
            )
            %and arg.expr().matches_expected_type()
        )
    }

    @with_dynvars(env, origin, entry_point)
    fun image_equation(str_type: Entity[AdaNode]): Equation = {
        val typ = self.prefix.name_designated_type();

        if typ.is_null
        then (
            # If prefix is not a type, then it is an expression
            self.prefix.sub_equation() %and node.type_var() <- str_type
        )
        else
            self.prefix.xref_type_equation()
            %and node.ref_var() <- self.attribute_subprogram()
    }

    @with_dynvars(env, origin, entry_point)
    fun img_equation(str_type: Entity[AdaNode]): Equation =
        (
            # Prefix is an expression, bind prefix's ref var to it
            self.prefix.xref_equation()
        )
        %and
        # Type of self is String
        node
        .type_var()
        <- str_type

    @with_dynvars(env, origin, entry_point)
    fun enum_rep_equation(): Equation = {
        val typ = self.prefix.name_designated_type();

        if typ.is_null
        then (
            # If prefix is not a type, then it is an expression
            self.prefix.sub_equation()
            %and node.type_var() <- node.universal_int_type()
        )
        else
            self.prefix.xref_type_equation()
            %and node.ref_var() <- self.attribute_subprogram()
    }

    |" Assuming the prefix of this attribute designates a type T, return
    |" an equation that binds the value of this attribute to that type T.
    @with_dynvars(env, origin, entry_point)
    fun self_type_equation(): Equation = {
        val typ = self.prefix.name_designated_type();

        self.prefix.xref_type_equation() %and node.type_var() <- typ
    }

    @with_dynvars(env, origin, entry_point)
    fun access_equation(): Equation =
        (
            # Access to statically known subprogram
            self.prefix.xref_no_overloading(all_els=true)
            %and BaseTypeDecl.is_subp_access_of%(node.type_var(),
            node.prefix.ref_var())
            %and node.type_var() <-> node.expected_type_var()
        )
        %or (
            # Access to object
            self.prefix.sub_equation()
            %and (
                # If the expected type is known, use it to infer the prefix's
                # expected type, and also use it as the actual type of the
                # access attribute which avoids synthesizing an anonymous
                # access type.
                # Note: We use the `accessed_type_no_call` conversion property
                # here in case `self.type_var` holds an access-to-
                # subprogram type so that we don't propagate its
                # return type to the prefix of the 'Access attribute.
                node.expected_type_var() <-> node.type_var()
                %and node.prefix.expected_type_var()
                <- BaseTypeDecl.accessed_type_no_call%(
                    node.expected_type_var()
                )
                %and (
                    # Either the expected type of the prefix is None, meaning
                    # the conversion property above was applied on a subprogram
                    # access (for which we cannot retrieve the dereferenced
                    # type). In that case type should be None as well.
                    node.prefix.expected_type_var() <-> node.prefix.type_var()
                    %and node.prefix.type_var()
                    <- null[Entity[BaseTypeDecl]]

                    # Or it's an object access and so the actual type must
                    # match the expected type we inferred above.
                    %or self.prefix.matches_expected_formal_type()
                )
                %or
                # If this `X'Access` is the prefix of a DottedName, we may be
                # resolving an implicit dereference. In that case, our expected
                # type is also the expected type of the prefix `X`, and we
                # should synthesize an anonymous access type for the actual
                # type of `X'Access`.
                if node.parent is DottedName and node.is_prefix()
                then
                    node.prefix.expected_type_var()
                    <-> node.expected_type_var()
                    %and self.prefix.matches_expected_prefix_type()
                    %and node.type_var()
                    <- BaseTypeDecl.anonymous_access_type_or_null%(
                        node.prefix.type_var()
                    )
                elif node.parent is ExplicitDeref
                then
                    node.type_var()
                    <- BaseTypeDecl.anonymous_access_type_or_null%(
                        node.prefix.type_var()
                    )
                else %false
            )
        )

    @with_dynvars(env, origin, entry_point)
    fun size_equation(): Equation = {
        val typ = self.prefix.name_designated_type();

        if not typ.is_null
        then
            node.prefix.ref_var() <- typ
            %and node.universal_int_bind(node.type_var())
        else
            self.prefix.sub_equation()
            %and node.universal_int_bind(node.type_var())
    }

    @with_dynvars(env, origin, entry_point)
    fun array_attr_equation(): Equation = {
        val is_length = self.attribute.name_is(s"Length");
        val typ = self.prefix.name_designated_type();
        # If the range attribute has an argument, then it's a static expression
        # representing an int that we will use as a dimension.
        val dim =
            self.args?[0].do(
                (arg) =>
                arg.expr().do(
                    (expr) => {
                        val _ = expr.resolve_names_internal(false);

                        expr.eval_as_int().as_int()
                    },
                    default_val=1
                ),
                default_val=1
            )
            - 1;

        if not typ.is_null
        then (
            # Prefix is a type
            self.prefix.xref_type_equation()
            %and (
                if typ.is_array_def_with_deref() and is_length
                then node.universal_int_bind(node.type_var())
                # If it's an array, take the appropriate index type

                elif typ.is_array_def_with_deref()
                then node.type_var() <- typ.index_type(dim)
                # If it's a discrete type, then bind to the discrete type

                elif
                    typ.is_discrete_type()
                    or (typ.is_real_type() and not is_length)
                then node.type_var() <- typ
                else %false
            )
        )
        # Prefix is not a type: In that case we have permission to resolve
        # prefix separately.
        else {
            val res =
                self.prefix.resolve_names_internal_with_eq(
                    BaseTypeDecl.is_array_def_with_deref%(self
                    .prefix
                    .type_var())
                );
            val pfx_typ = self.prefix.type_val().as[BaseTypeDecl];

            if res
            then
                if is_length then node.universal_int_bind(node.type_var())
                else node.type_var() <- pfx_typ.index_type(dim)
            else %false
        }
    }

    |" Generates the xref equation for a an attribute that is defined on any
    |" subtype and that evaluates to an universal integer.
    @with_dynvars(env, origin, entry_point)
    fun subtype_attr_equation(): Equation =
        node.prefix.ref_var() <- self.prefix.name_designated_type()
        %and node.universal_int_bind(node.type_var())

    |" Return the xref equation for the ``To_Address`` attribute.
    @with_dynvars(env, origin, entry_point)
    fun to_address_equation(): Equation = {
        # TODO: this property can be completely removed once we support
        # attributes that return functions.
        val to_address_subp =
            self.get_unit_root_decl(
                [s"System", s"Storage_Elements"],
                AnalysisUnitKind.unit_specification
            )
            ?.children_env
            .get_first(s"To_Address", lookup=LookupKind.minimal)
            .as[BasicSubpDecl];

        self.prefix.sub_equation() %and node.ref_var() <- to_address_subp
    }

    |" Return the xref equation for the ``Index`` attribute.
    @with_dynvars(env, origin, entry_point)
    fun index_equation(): Equation = {
        val typ =
            env.get_first(self.prefix.name_symbol())
            .as![EntryDecl]
            .family_type();

        self.prefix.sub_equation() %and node.type_var() <- typ
    }

    |" Return the xref equation for the ``Deref`` attribute.
    @with_dynvars(env, origin, entry_point)
    fun deref_equation(): Equation =
        self.prefix.xref_type_equation()
        %and node.type_var() <-> node.prefix.ref_var()
        %and self.args?[0].do(
            (arg) =>
            arg.expr().sub_equation()
            %and arg.expr().expected_type_var() <- node.system_address_type()
            %and arg.expr().matches_expected_type(),
            default_val=%false
        )

    |" Return the xref equation for the ``Mechanism_Code`` attribute.
    @with_dynvars(env, origin, entry_point)
    fun mechanism_code_equation(): Equation =
        self.prefix.xref_no_overloading()
        %and self.universal_int_bind(node.type_var())
        %and self.args?[0].do(
            (arg) =>
            arg.expr().sub_equation()
            %and self.universal_int_bind(arg.expr().expected_type_var())
            %and arg.expr().matches_expected_type(),
            default_val=%true
        )

    |" Return the xref equation for the ``Super`` attribute.
    @with_dynvars(env, origin, entry_point)
    fun super_equation(): Equation =
        self.prefix.sub_equation()
        %and node.type_var()<-BaseTypeDecl.super_view_conversion%(node
        .prefix
        .type_var())

    |" Return the xref equation for the ``Has_Same_Storage`` and
    |" ``Overlaps_Storage`` attributes.
    @with_dynvars(env, origin, entry_point)
    fun storage_equation(): Equation =
        # Prefix denotes an object
        self.prefix.sub_equation()

        # The attribute return a boolean value
        %and node.type_var()
        <- node.bool_type()

        # The only one argument of the attribute can be of any type
        %and self.args?[0].sub_equation()

    fun called_formal_subp_spec(): Entity[BaseFormalParamHolder] = {
        val rel_name = self.attribute.name_symbol();

        if rel_name in s"Image" | s"Wide_Image" | s"Wide_Wide_Image"
        then
            self.prefix.expression_type().do(
                (typ) => typ.attribute_subprogram(rel_name).subp_spec_or_null()
            )
        else null[Entity[BaseFormalParamHolder]]
    }
}

|" Represent a syntactic call expression.
|"
|" At the semantic level, this can be either a subprogram call, an array
|" subcomponent access expression, an array slice or a type conversion, all
|" described in :rmlink:`4.1`, except for subprogram call statements,
|" described in :rmlink:`6.4`.
class CallExpr: Name {
    @parse_field
    name: Name
    @parse_field
    suffix: AdaNode
    r_called_spec: LogicVar

    fun ref_var(): LogicVar = node.name.ref_var()

    fun subp_spec_var(): LogicVar = node.r_called_spec

    fun defines_subp_spec_var(): Bool = true

    fun relative_name(): Entity[Name] = self.name.relative_name()

    |" Return whether this expression is a subprogram call, an array
    |" subcomponent access expression, an array slice or a type conversion.
    @exported
    fun kind(): CallExprKind =
        if self.is_call() then CallExprKind.call
        elif self.is_array_slice() then CallExprKind.array_slice
        elif {
            bind origin = node.origin_node();

            not self.name.expression_type().do(
                (typ) => typ.array_def_with_deref()
            )
            .is_null
        } then CallExprKind.array_index
        # Case for type conversion: CallExpr has one
        # argument and its name denotes a type declaration.

        elif
            self.params().length() == 1
            and self.name.referenced_decl() is BaseTypeDecl
        then CallExprKind.type_conversion
        # This is important to make this test *after* the check for
        # ``is_call`` so that real entry calls are correctly flagged as
        # such. We only want to catch family indexes here.

        elif self.name.referenced_decl() is EntryDecl
        then CallExprKind.family_index
        # Should not happen
        else raise[CallExprKind] PropertyError("undetermined CallExpr kind")

    fun is_constant(): Bool =
        if self.kind() == CallExprKind.type_conversion
        then
            match self.params()?[0].expr() {
                # View conversion: constant if the object is constant (value
                # conversion is always constant).
                case n: Name => n.is_constant()
                case _ => true
            }
        # A call is always constant

        elif self.kind() == CallExprKind.call then true
        # General case that handles, array subcomponent access expression
        # and array slice.
        else self.referenced_decl().is_constant_object()

    @with_dynvars(env, origin, no_visibility=false)
    fun designated_env(): LexicalEnv = {
        val typ = self.name.name_designated_type();

        if not typ.is_null then typ.defining_env()
        else (
            # Since we are in a CallExpr, we need to include user-defined
            # indexing in defining_env of the prefix, as it might actually be
            # used here.
            {
                bind include_ud_indexing = true;

                self.env_elements().map(
                    (e) =>
                    match e {
                        case bd: Entity[BasicDecl] => bd.defining_env()
                        case _ => null[LexicalEnv]
                    }
                )
                .env_group()
            }
        )
    }

    |" A call expression can never provide any dot-accessible entities in
    |" a "no overloading" context. In other words, it's never valid to have
    |" a ``CallExpr`` in the middle of a name that designates a type, so we
    |" can return an empty environment.
    @with_dynvars(env, origin, no_visibility=false)
    fun designated_env_no_overloading(): LexicalEnv = null[LexicalEnv]

    @with_dynvars(env)
    fun env_elements_impl(): Array[Entity[AdaNode]] =
        self.name.env_elements_impl()

    # CallExpr can appear in type expressions: they are used to create implicit
    # subtypes for discriminated records or arrays.
    @with_dynvars(env, origin)
    fun designated_type_impl(): Entity[BaseTypeDecl] = {
        # Retrieve the type designated by the prefix
        val prefix_tpe = self.name.designated_type_impl();
        # Check that this CallExpr is a valid type, which in this context
        # is the case if and only if the arguments of this CallExpr match
        # the discriminant list of the type designated by the prefix.
        val matches_formals =
            self.params().do(
                (ps) =>
                node.match_formals(prefix_tpe?.discriminants_list(), ps, false)
                .all(
                    (pm) =>
                    pm.has_matched
                    and pm.formal.formal_decl().formal_type().matching_type(
                        pm.actual.assoc.expr().as[Name]?.name_designated_type()
                    )
                ),
                default_val=true
            );

        # Make sure to not return the type designated by the prefix if this
        # CallExpr does not designate a type!
        if matches_formals then prefix_tpe else null[Entity[BaseTypeDecl]]
    }

    fun params(): Entity[AssocList] = self.suffix.as[AssocList]

    |" Return whether this CallExpr can correspond to taking a slice of the
    |" given array type.
    @with_dynvars(origin)
    fun check_array_slice(typ: Entity[BaseTypeDecl]): Bool = {
        val atd = typ.do((t) => t.array_def_with_deref());

        not atd.is_null
        and self.suffix.do(
            (sfx) =>
            (
                # array slice using the ``(A .. B)`` notation
                sfx is BinOp
            )
            or (
                # array slice using the ``(X'Range)`` notation
                sfx is AttributeRef
            )
            or (
                # array slice using the ``(Subtype range ..)`` notation
                sfx is SubtypeIndication
            )
            or (
                # array slice using the ``(Subtype)`` notation
                sfx.as[AssocList].do(
                    (al) =>
                    al.length() == 1
                    and al?[0].expr().as[Name].do(
                        (n) => not n.name_designated_type().is_null
                    )
                )
            )
        )
    }

    |" Return whether this CallExpr is actually an access to a slice of
    |" the array denoted by the prefix of this CallExpr.
    @exported
    fun is_array_slice(): Bool = {
        bind origin = node.origin_node();

        self.check_array_slice(self.name.expression_type())
    }

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = self.bottom_up_name_equation()

    |" Helper for xref_equation and stop_resolution_equation, handles the
    |" construction of the equation in type conversion cases, without the
    |" recursion on the argument.
    @with_dynvars(env, origin, entry_point)
    fun type_conv_self_xref_equation(): Equation =
        self.name.subtype_indication_equation()
        %and node.type_var() <-> node.name.ref_var()

    |" Build the xref equation in case this node represents a call to the
    |" given entry declaration.
    @with_dynvars(env, origin, entry_point, logic_context)
    fun entry_equation(e: Entity[EntryDecl], root: Name): Equation =
        if e.has_family()
        then (
            # Handle calls to entry families
            e.family_type().do(
                (ft) =>
                {
                    bind logic_context = null[LogicContext];
                    self.params()?[0].expr().expected_type_var() <- ft
                }
                %and self.params()?[0].expr().matches_expected_type(),
                default_val=%true
            )
            %and (
                # If the family type is None, it means it is an anonymous range
                # in which case we don't need to constrain it further.
                self.parent_name(root).as[CallExpr].do(
                    (c) =>
                    c.params().logic_all((pa) => pa.expr().sub_equation())
                    %and c.entity_equation(e, root),
                    default_val=%true
                )
            )
        )
        # The parent name can be null if the entry declaration has no
        # parameter section besides the family type section.
        # If this entry decl declares no family we can treat it the same
        # way as a subprogram call.
        else self.entity_equation(e, root)

    @with_dynvars(env, origin, entry_point, logic_context)
    fun entity_equation(
        s: Entity[BasicDecl],
        root: Name
    ): Equation = # The called entity is the matched entity
        # If s does not have any parameters, then we construct the
        # chain of name equations starting from self, with the parent
        # component.
        if s.is_paramless() then self.parent_name_equation(s.expr_type(), root)
        # If S can be called in a paramless fashion, but can also be
        # called with parameters, we are forced to make a disjunction.

        elif s.can_be_paramless()
        then
            self.parent_name_equation(s.expr_type(), root)
            %or (
                self.subprogram_equation(
                    s.subp_spec_or_null(),
                    s.info.md.dottable_subp
                )
                %and self.parent_name(root).do(
                    (pn) => pn.parent_name_equation(s.expr_type(), root),
                    default_val=%true
                )
            )
        elif not self.params().is_null
        then
            self.subprogram_equation(
                s.subp_spec_or_null(),
                s.info.md.dottable_subp
            )
            %and self.parent_name(root).do(
                (pn) => pn.parent_name_equation(s.expr_type(), root),
                default_val=%true
            )
        else %false

    |" Return whether this CallExpr actually represents a type conversion.
    @with_dynvars(env, origin)
    fun is_type_conversion(): Bool =
        not self.name is QualExpr
        # Directly call designated_type_impl instead of
        # name_designated_type to propagate self's origin.
        and not self.name.designated_type_impl().is_null

    @with_dynvars(env, origin)
    fun xref_stop_resolution(): Bool =
        self.super() or self.is_type_conversion()

    @with_dynvars(env, origin, entry_point)
    fun stop_resolution_equation(): Equation =
        if self.is_type_conversion() then self.type_conv_self_xref_equation()
        else self.super()

    |" Helper for xref_equation, handles construction of the equation in
    |" subprogram call cases.
    @with_dynvars(env, origin, entry_point)
    fun general_xref_equation(root: Name): Equation =
        if self.is_type_conversion()
        then (
            # Type conversion case
            (
                (
                    self.type_conv_self_xref_equation()
                    %and self.params()?[0].expr().expected_type_var()
                    <- null[Entity[BaseTypeDecl]]
                )
                %and self.all_args_xref_equation(root)
            )
            %and self.parent_name(root).do(
                (pn) =>
                pn.parent_name_equation(
                    self.name.name_designated_type(),
                    root
                ),
                default_val=%true
            )
        )
        # Attribute ref case: we can always resolve the AttributeRef first
        # without ambiguity. This allows us to use its type in order to
        # solve the rest of the expression.

        elif self.name is AttributeRef
        then
            self.name.resolve_names_internal(false).do(
                (_) =>
                self.all_args_xref_equation(root)
                %and self.name.type_val().as[BaseTypeDecl].do(
                    (typ) => self.parent_name_equation(typ, root),
                    default_val={
                        bind logic_context =
                            LogicContext(
                                ref_node=self.name,
                                decl_node=self.name.ref_var().get_value()
                            );

                        # If the attribute has no type, it must necessarily
                        # reference a subprogram. Therefore, handle the rest as
                        # if it was an entity call.
                        self.entity_equation(
                            self.name.ref_var().get_value().as![BasicDecl],
                            root
                        )
                    }
                ),
                default_val=%false
            )
        else
            {
                # If we are resolving this CallExpr from a DeltaAggregate, env
                # is the one of the aggregate type, so we need to bind env to
                # self's env to resolve the CallExpr params (array indicies).
                bind env =
                    if
                        entry_point
                        .as[AggregateAssoc]
                        ?.as_entity
                        .base_aggregate() is DeltaAggregate
                    then self.children_env
                    else env;

                self.all_args_xref_equation(root)
            }
            %and (
                # For each potential entity match, we want to express the
                # following constraints:
                {
                    val subps = self.env_elements();

                    if subps.is_null then %true
                    else
                        subps.logic_any(
                            (s) => {
                                bind logic_context =
                                    LogicContext(
                                        ref_node=self.name,
                                        decl_node=s
                                    );

                                {
                                    bind logic_context = null[LogicContext];
                                    node.name.ref_var()
                                    <- s.as[BasicDecl].corresponding_actual()
                                }
                                %and s.as[EntryDecl].do(
                                    (e) => self.entry_equation(e, root),
                                    default_val=self.entity_equation(
                                        s.as[BasicDecl],
                                        root
                                    )
                                )
                            }
                        )
                }
                %and self.name.sub_equation()
                # TODO: Bug here: if operator equation, then parent equation is
                # not called!
            )

    |" Construct an equation verifying if self is conformant to the type
    |" designator passed in parameter.
    @with_dynvars(env, origin, entry_point)
    fun subscriptable_type_equation(typ: Entity[BaseTypeDecl]): Equation = {
        val atd = typ.do((t) => t.array_def_with_deref());
        val real_typ =
            typ.do(
                (t) => if t.is_implicit_deref() then t.accessed_type() else t
            );

        # First handle the case where this is an access to subprogram
        if typ.access_def() is AccessToSubpDef
        then
            typ.access_def().as[AccessToSubpDef].do(
                (asd) => {
                    bind logic_context =
                        LogicContext(ref_node=self.name, decl_node=typ);

                    self.subprogram_equation(asd.subp_spec, false)
                },
                default_val=%false
            )
        elif not atd.is_null and not atd.indices.is_null
        then
            match self.suffix {
                case _: AssocList =>
                    (
                        # Either an array slice through subtype indication
                        self.params()?[0].do(
                            (param) =>
                            param.expr().as[Name].do(
                                (name) =>
                                if name.name_designated_type().is_null
                                then %false
                                else
                                    name.xref_type_equation()
                                    %and node.type_var() <- real_typ,
                                default_val=%false
                            ),
                            default_val=%false
                        )
                    )
                    %or (
                        # Or a regular array access
                        self.params()?.ilogic_all(
                            (pa, i) =>
                            atd.indices.constrain_index_expr(pa.expr(), i)
                        )
                        %and node.type_var() <- atd.comp_type()
                    )

                # Explicit slice access
                case bo: BinOp =>
                    (
                        (
                            (
                                (
                                    atd.indices.constrain_index_expr(
                                        bo.left,
                                        0
                                    )
                                    %and atd.indices.constrain_index_expr(
                                        bo.right,
                                        0
                                    )
                                )
                                %and bo.expected_type_var()
                                <-> bo.right.expected_type_var()
                            )
                            %and node.type_var() <- real_typ
                        )
                        %and bo.left.sub_equation()
                    )
                    %and bo.right.sub_equation()

                # Range attribute
                case ar: AttributeRef =>
                    (
                        ar.sub_equation()
                        %and atd.indices.constrain_index_expr(ar, 0)
                    )
                    %and node.type_var() <- real_typ

                # Subtype indication
                case st: SubtypeIndication =>
                    st.sub_equation() %and node.type_var() <- real_typ
                case _ => %false
            }
        # Type has user defined indexing

        elif not typ.is_null and typ.has_ud_indexing()
        then
            (typ.constant_indexing_fns() & typ.variable_indexing_fns())
            .logic_any(
                (fn) => {
                    val formals =
                        fn.subp_spec_or_null().unpacked_formal_params();
                    val ret_type = fn.subp_spec_or_null().return_type();
                    val params = self.params();

                    # The user indexing function that matches has one more
                    # parameter than that call expression.
                    if formals.length() == params.length() + 1
                    then
                        node.type_var() <- ret_type
                        %and params.ilogic_all(
                            (param, i) =>
                            param.expr().expected_type_var()
                            <- formals?[i + 1].formal_decl().formal_type()
                            %and param.expr().matches_expected_type()
                        )
                    else %false
                }
            )
        else %false
    }

    @with_dynvars(env, origin, logic_context)
    fun subprogram_equation(
        subp_spec: Entity[BaseFormalParamHolder],
        dottable_subp: Bool
    ): Equation =
        subp_spec.do(
            (subp_spec) =>
            (
                # The type of the expression is the expr_type of the
                # subprogram.
                node.type_var() <- subp_spec.as[BaseSubpSpec]?.return_type()
                %and (
                    # This node represents a call to a subprogram which
                    # specification is given by ``subp_spec``.
                    {
                        bind logic_context = null[LogicContext];
                        node.subp_spec_var() <- subp_spec
                    }
                )
            )
            %and (
                # For each parameter, the type of the expression matches
                # the expected type for this subprogram.
                subp_spec.match_param_list(self.params(), dottable_subp)
                .logic_all(
                    (pm) =>
                    if pm.has_matched
                    then
                        subp_spec.call_argument_equation(
                            pm.formal.formal_decl(),
                            pm.actual.assoc.expr()
                        )
                        %and (
                            # Bind actuals designators to parameters if there
                            # are designators.
                            if pm.actual.name.is_null then %true
                            else {
                                bind logic_context = null[LogicContext];
                                pm.actual.name.ref_var()
                                <- {
                                    val n =
                                        subp_spec.corresponding_actual_param(
                                            pm.formal
                                        )
                                        .formal_decl();

                                    self.entity_no_md(
                                        n.node,
                                        n.info.rebindings,
                                        n.info.from_rebound
                                    )
                                }
                            }
                        )
                    else %false
                )
            ),
            default_val=%false
        )

    |" Check that self is an appropriate CallExpr for given type, which must
    |" be a subscriptable type (eg; a type for which it makes senses to do a
    |" call expr on an instance of the type, like an array type, or an access
    |" to subprogram type.
    @with_dynvars(env, origin)
    fun check_for_type(typ: Entity[BaseTypeDecl]): Bool = {
        # Algorithm: We're Recursing down call expression and component types
        # up to self, checking for each level that the call expression
        # corresponds.
        val atd = typ.do((t) => t.array_def_with_deref());

        {
            bind origin = node.origin_node();

            typ.do(
                (typ) =>
                (
                    (
                        # Arrays
                        atd.do(
                            (_) =>
                            match node.suffix {
                                # Array indexing case
                                case al: AssocList =>
                                    atd.array_ndims() == al.length()

                                # Array slice cases
                                case _: BinOp => atd.array_ndims() == 1
                                case _: SubtypeIndication =>
                                    atd.array_ndims() == 1
                                case _: AttributeRef => atd.array_ndims() == 1
                                case _ => false
                            },
                            default_val=false
                        )
                    )
                    or (
                        # Accesses to subprograms
                        typ.access_def().as[AccessToSubpDef].do(
                            (sa) =>
                            sa.subp_spec.is_matching_param_list(
                                self.params(),
                                false
                            )
                        )
                    )
                    or (
                        # Types with user defined indexing
                        typ.has_ud_indexing()
                        and node.suffix.as[AssocList].do(
                            (al) => al.length() >= 1
                        )
                    )
                )
                and (
                    # All such `CallExpr`s shall have at least two parameters
                    # (:rmlink:`4.1.6`).
                    self.parent.as[CallExpr].do(
                        (ce) =>
                        # Since the result type of self is ``typ``, the result
                        # type of its parent CallExpr (if it exists) must be
                        # the component type of ``typ``, except in case of an
                        # array slice.  Note: we use subscript=True because a
                        # CallExpr will dereference implicitly.
                        ce.check_for_type(
                            if self.check_array_slice(typ) then typ
                            else
                            # TODO: see comment in Name.parent_name_equation
                                if typ.is_iterable_type()
                                then typ.iterable_comp_type()
                                else typ.comp_type(is_subscript=true)
                        ),

                        # We are done if the parent is not a CallExpr. We could
                        # actually do more here by considering ExplicitDerefs,
                        # but this should be sufficient for the current purpose
                        # of check_for_type (e.g. to preemptively discard
                        # inadequate candidates in env_elements_impl).
                        default_val=true
                    )
                )
            )
        }
    }
}

|" Name that defines an entity (:rmlink:`3.1`).
@custom_short_image
class DefiningName: Name {
    @parse_field
    name: Name

    @with_dynvars(env)
    fun parent_scope(): LexicalEnv = node.name.parent_scope()

    @with_dynvars(env)
    fun scope(): LexicalEnv = node.name.scope()

    fun relative_name(): Entity[Name] = self.name.relative_name()

    fun ref_var(): LogicVar = node.name.ref_var()

    @with_dynvars(env)
    fun env_elements_impl(): Array[Entity[AdaNode]] =
        self.name.env_elements_impl()

    |" Return the parent ``BaseFormalParamDecl`` of this ``DefiningName``.
    |" Raise an error otherwise.
    fun formal_decl(): Entity[BaseFormalParamDecl] =
        self.parents().find((n) => n is BaseFormalParamDecl)
        .as![BaseFormalParamDecl]

    |" Return the fully qualified name corresponding to this declaration, as
    |" an array of symbols.
    fun fully_qualified_name_impl(
        include_profile: Bool,
        suffix: String
    ): Array[String] = {
        val def_name_array = match node {
            case scel: SyntheticDefiningName => [scel.name_symbol().image()]
            case n => n.as_single_tok_node_array().map((t) => t.text)
        };
        val bd = self.basic_decl();
        val self_name =
            def_name_array.imap(
                (t, i) =>
                t & (if include_profile then bd.custom_id_text() else "")
                & (if i == def_name_array.length() - 1 then suffix else "")
            );
        val parent_decl = bd.parent_basic_decl();
        val is_instantiated =
            (bd is GenericDecl | Body) and parent_decl is GenericInstantiation;
        val fqn =
            if not is_instantiated and bd.is_compilation_unit_root()
            then self_name
            else
                parent_decl?.fully_qualified_name_string_array(
                    include_profile=include_profile
                )
                .do(
                    (fqn) =>
                    # If we were on an instantiated generic declaration, we
                    # don't want to include the name of the generic but the
                    # name of the instance (which is `fqn`).
                    if is_instantiated then fqn else fqn & self_name
                );

        bd.parent.as[Subunit].do((su) => su.name.as_single_tok_node_array())
        .map((t) => t.text)
        & fqn
        or? fqn
    }

    |" Implementation of canonical_fully_qualified_name.
    fun canonical_fully_qualified_name_impl(
        include_profile: Bool,
        suffix: String
    ): String =
        ".".join(
            self.fully_qualified_name_impl(
                include_profile=include_profile,
                suffix=suffix
            )
            # Map to symbol & back to canonicalize
            .map((t) => t.to_symbol)
            .map((t) => t.image())
        )

    |" Implementation for unique_identifying_name.
    fun unique_identifying_name_impl(suffix: String): String = match
        self.basic_decl()
    {
        case atd: AnonymousTypeDecl => atd.custom_id_text()
        case _ =>
            self.canonical_fully_qualified_name_impl(
                include_profile=true,
                suffix=suffix
            )
    }

    |" Return a canonical representation of the fully qualified name
    |" corresponding to this defining name.
    @exported
    fun canonical_fully_qualified_name(): String =
        self.canonical_fully_qualified_name_impl(
            include_profile=false,
            suffix=""
        )

    |" Return a unique identifying name for this defining name, provided this
    |" declaration is a public declaration. In the case of subprograms, this
    |" will include the profile.
    |"
    |" .. attention::
    |"     This will only return a unique name for public declarations.
    |"     Notably, anything nested in an unnamed declare block won't be
    |"     handled correctly.
    @exported
    fun unique_identifying_name(): String =
        self.unique_identifying_name_impl(suffix="")

    |" Return the fully qualified name corresponding to this defining name, as
    |" an array of symbols.
    @exported
    fun fully_qualified_name_array(): Array[Symbol] =
        self.fully_qualified_name_impl(include_profile=false, suffix="").map(
            (t) => t.to_symbol
        )

    |" Return the fully qualified name corresponding to this defining name.
    @exported
    fun fully_qualified_name(): String =
        ".".join(
            self.fully_qualified_name_impl(include_profile=false, suffix="")
        )

    @with_dynvars(env, origin)
    fun all_env_els_impl(
        seq: Bool = true,
        seq_from: AdaNode = null[AdaNode],
        categories: RefCategories = RefCategories(_=true)
    ): Array[Entity[AdaNode]] =
        self.name.all_env_els_impl(seq, seq_from, categories)

    |" Return this DefiningName's basic declaration, discarding internal nodes
    |" such as Generic*Internal wrappers.
    @exported
    fun basic_decl(): Entity[BasicDecl] =
        self.basic_decl_internal().do(
            (bd) =>
            if
                bd is GenericPackageInternal
                | GenericSubpInternal
                | SingleTaskTypeDecl
            then bd.parent.as![BasicDecl]
            else bd
        )

    |" Return this DefiningName's basic declaration, but do not bypass
    |" internal nodes (such as Generic*Internal wrappers).
    @memoized
    fun basic_decl_internal(): Entity[BasicDecl] =
        self.parents().find((p) => p is BasicDecl).as![BasicDecl]

    |" Find all references to this defining name in the given ``root`` and its
    |" children.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun find_refs(root: Entity[AdaNode]): Array[RefResult] =
        self.canonical_part().find_refs_impl(root, node)

    |" Internal implementation for find_refs. Find all references to self in
    |" the given ``root``. The ``skip_name`` is used to filter out a
    |" DefiningName from the result (typically, the name of self in order to
    |" avoid to report a reference to itself).
    @with_dynvars(imprecise_fallback)
    fun find_refs_impl(
        root: Entity[AdaNode],
        skip_name: DefiningName
    ): Array[RefResult] =
        # TODO: Factor the traversal between this and `find_derived_types`
        root.children.do(
            (c) =>
            c.filter((n) => not (n.is_null or n.node == skip_name)).mapcat(
                (n) => self.find_refs_impl(n, skip_name)
            )
        )
        & root.as[BaseId].do(
            (id) =>
            self.is_referenced_by(id).do(
                (ref_kind) =>
                if ref_kind in RefResultKind.precise | RefResultKind.imprecise
                then [RefResult(ref=id, kind=ref_kind)]
                else null[Array[RefResult]]
            )
        )

    |" Return whether this is a name that defines an "=" operator which
    |" implicitly declares an "/=" operator giving the complementary result,
    |" which is True iff this "=" declaration returns a Boolean
    |" (:rmlink:`6.6` 6/3).
    @memoized
    fun is_derivable_equal(): Bool =
        node.name_is(s"\"=\"")
        and self.basic_decl().subp_spec_or_null().do(
            (s) => s.returns()?.designated_type_decl() == self.bool_type()
        )

    |" Return whether the given symbol could be a reference to this defining
    |" name.
    @memoized
    fun is_potential_reference(symbol: Symbol): Bool =
        node.name_is(symbol)
        or (self.is_derivable_equal() and symbol == s"\"/=\"")

    |" Returns True iff the given node is an identifier referring to self.
    |" Note that this takes into account both direct references as well as
    |" potential references.
    |"
    |" Potential references can occur in the context of dispatching calls: an
    |" identifier having for direct reference the declaration of an
    |" overridable subprogram is considered a potential reference to all
    |" subprograms that override it if the identifier appears in a dispatching
    |" call.
    @with_dynvars(imprecise_fallback=false)
    fun is_referenced_by(id: Entity[BaseId]): RefResultKind =
        if self.is_potential_reference(id.name_symbol())
        then
            (
                if id.is_defining()
                then
                    RefdDef(
                        def_name=id.enclosing_defining_name(),
                        kind=RefResultKind.precise
                    )
                else id.failsafe_referenced_def_name()
            )
            .do(
                (def_res) => {
                    val canon = def_res.def_name?.canonical_part()?.node;

                    if
                        (
                            # Either `id` is a direct reference
                            node == canon
                        )
                        or (
                            # Or `id` refers to one of the base subprograms of
                            # defined by self, and `x` appears in a dispatching
                            # call context.
                            self.basic_decl().base_subp_declarations().do(
                                (decls) =>
                                decls.any(
                                    (d) => d.defining_name().node == canon
                                )
                                and id.is_dispatching_call()
                            )
                        )
                    then def_res.kind
                    else RefResultKind.no_ref
                }
            )
        else RefResultKind.no_ref

    |" Searches all references to this defining name in the given list of
    |" units.
    |"
    |" If ``follow_renamings`` is True, also this also includes references
    |" that ultimately refer to this defining name, by unwinding renaming
    |" clauses.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun find_all_references(
        units: Array[AnalysisUnit],
        follow_renamings: Bool = false
    ): Array[RefResult] = {
        val dn = self.canonical_part();
        # If `dn` defines a subprogram which overrides some subprogram P, we
        # need to do the unit filtering from the declaration of P so that we
        # don't omit units in which we may have potential references to self
        # through dispatching calls. This is valid because all units that would
        # import `dn` will necessarily import `base` as well, as `dn`
        # necessarily imports `base` to define its overriding subprogram.
        # This only works if filter_is_imported_by is called with transitive
        # set to True.
        val bases = {
            bind origin = node;

            dn.basic_decl().root_subp_declarations() or? [dn.basic_decl()]
        };
        val all_units =
            bases.mapcat((base) => base.filter_is_imported_by(units, true))
            .unique();
        val refs =
            all_units.mapcat(
                (u) =>
                u.root.do((r) => dn.find_refs_impl(r.as_bare_entity, node))
            );

        if follow_renamings
        then
            refs
            & refs.filter(
                (f) =>
                f.ref.parents().find((p) => p is RenamingClause)
                .as[RenamingClause]
                .do(
                    (r) =>
                    r.renamed_object.referenced_defining_name()
                    .canonical_part()
                    .node
                    == dn.node
                )
            )
            .mapcat(
                (f) =>
                f.ref.parents().find((p) => p is RenamingClause)
                .parent
                .as![BasicDecl]
                .do(
                    (bd) =>
                    # Get the all renaming clauses *for which the renamed
                    # entity is self* (it is possible to find a reference
                    # inside a renaming clause but that this clause does not
                    # rename self, such as `X` in  `... renames X.Y`, in which
                    # case we don't want to recursively find its references!).
                    # Since a renaming clause is always part of a BasicDecl,
                    # retrieve the BasicDecl from the renaming clauses and
                    # recursively find all references on those.
                    bd.defining_name().find_all_references(
                        units=units,
                        follow_renamings=true
                    )
                )
            )
        else refs
    }

    |" Helper for navigation proxies. Will return the defining name matching
    |" self on the given BasicDecl.
    fun find_matching_name(bd: Entity[BasicDecl]): Entity[DefiningName] =
        bd?.defining_names().find((di) => self.name.name_is(di.name_symbol()))

    |" Return the list of all possible calls to the subprogram which self is
    |" the defining name of.
    |"
    |" This will return the name corresponding to the call, excluding the
    |" parameters if there are any. For instance, it will return ``A`` for the
    |" ``A (B)`` call.
    |"
    |" .. note:: This does not yet support calls done inside generics.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun find_all_calls(
        units: Array[AnalysisUnit],
        follow_renamings: Bool = false
    ): Array[RefResult] =
        self.find_all_references(units, follow_renamings).filter(
            (r) => r.ref.is_direct_call()
        )

    |" Like ``BasicDecl.next_part_for_decl`` on a defining name
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun next_part(): Entity[DefiningName] =
        self.find_matching_name(
            self.basic_decl().next_part_for_name(self.name_symbol())
        )

    |" Like ``BasicDecl.previous_part_for_decl`` on a defining name
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun previous_part(): Entity[DefiningName] =
        self.find_matching_name(
            self.basic_decl().previous_part_for_name(self.name_symbol())
        )

    |" Like ``BasicDecl.canonical_part`` on a defining name
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun canonical_part(): Entity[DefiningName] =
        self.find_matching_name(
            self.basic_decl().canonical_part_for_name(self.name_symbol())
        )

    |" Given an origin node and the entity represented by self, this property
    |" returns the most visible completion of self that can be seen by origin,
    |" according to Ada's visibility rules.
    @exported
    @with_dynvars(origin, imprecise_fallback=false)
    fun most_visible_part(): Entity[DefiningName] =
        self.find_matching_name(
            self.basic_decl().most_visible_part_for_name(self.name_symbol())
        )

    |" Return all previous parts of this entity, where the first part
    |" is at the beginning of the array.
    @with_dynvars(imprecise_fallback=false)
    fun all_previous_parts(): Array[Entity[DefiningName]] =
        self.previous_part().do(
            (pp) =>
            if self == pp then null[Array[Entity[DefiningName]]]
            else pp.all_previous_parts() & [pp]
        )

    |" Return all next parts of this entity, where the last part is at the
    |" end of the array.
    @with_dynvars(imprecise_fallback=false)
    fun all_next_parts(): Array[Entity[DefiningName]] =
        self.next_part().do(
            (np) =>
            if self == np then null[Array[Entity[DefiningName]]]
            else [np] & np.all_next_parts()
        )

    |" Return all parts that define this entity, sorted from first part to
    |" last part.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun all_parts(): Array[Entity[DefiningName]] = {
        val prevs = self.all_previous_parts();
        val nexts = self.all_next_parts();

        prevs & [self] & nexts
    }

    |" Return the aspect with the name ``name`` associated to this specific
    |" entity part.
    @with_dynvars(imprecise_fallback=false)
    fun get_aspect_impl(name: Symbol, inherited: Bool): Aspect =
        (
            (
                self.get_pragma(name).do((p) => p.as_aspect(inherited))
                or? self.basic_decl_internal().get_aspect_assoc(name).do(
                    (aa) =>
                    Aspect(
                        exists=true,
                        node=aa,
                        value=aa.expr,
                        inherited=inherited
                    )
                )
            )
            or? self.get_representation_clause(name).do(
                (rc) =>
                Aspect(
                    exists=true,
                    node=rc,
                    value=rc.expr,
                    inherited=inherited
                )
            )
        )
        or? if name == s"Address"
        then
            self.get_at_clause().do(
                (atc) =>
                Aspect(
                    exists=true,
                    node=atc,
                    value=atc.expr,
                    inherited=inherited
                )
            )
        else null[Aspect]

    |" Return the aspect with name ``name`` associated to entity that this
    |" name defines.
    |"
    |" First, check for aspect on all parts of entity (``previous_parts_only``
    |" can be used to restrict the search to entity and its previous part to
    |" comply with visibility rules).
    |"
    |" If no aspect if found on entity, recursively check for it on its
    |" parents.
    @with_dynvars(imprecise_fallback=false)
    fun get_aspect_on_parts(
        name: Symbol,
        inherited: Bool,
        previous_parts_only: Bool
    ): Aspect = {
        val parts_to_check =
        # SPARK_Mode has its own logic (see `is_spark`). For instance, if
        # defined on a body, it doesn't apply to the corresponding
        # specification, and conversely. Only consider the current part
        # when looking for it.
            if name == s"SPARK_Mode" then [self]
            elif previous_parts_only then [self] & self.all_previous_parts()
            else self.all_parts();
        val self_aspects =
        # The following aspects only support the Ada 2012 aspect
        # association syntax, so use a faster path to avoid looking for
        # pragmas and representation clauses for them as they are often
        # queried during name resolution.
            if
                name in s"Implicit_Dereference"
                    | s"Constant_Indexing"
                    | s"Variable_Indexing"
                    | s"Iterable"
                    | s"Iterator_Element"
                    | s"Integer_Literal"
                    | s"Real_Literal"
                    | s"String_Literal"
            then
                parts_to_check.map(
                    (p) =>
                    p.basic_decl_internal().get_aspect_assoc(name).do(
                        (aa) =>
                        Aspect(
                            exists=true,
                            node=aa,
                            value=aa.expr,
                            inherited=inherited
                        )
                    )
                )
            else parts_to_check.map((p) => p.get_aspect_impl(name, inherited));

        self_aspects.find((a) => a.exists)
        or? self.basic_decl().as[BaseTypeDecl].do(
            (bd) => {
                # If nothing has been found so far for entity, check out for
                # any inherited aspect.
                val typ =
                    if bd is BaseSubtypeDecl
                    then bd.as[BaseSubtypeDecl].get_type()
                    else bd.base_type();

                if typ.is_null or typ == bd then null[Aspect]
                else
                    typ.name.get_aspect_on_parts(
                        name,
                        inherited=true,
                        previous_parts_only=previous_parts_only
                    )
            }
        )
    }

    |" Return the aspect with name ``name`` associated to entity that this
    |" name defines.
    |"
    |" Aspects are properties of entities that can be specified by the Ada
    |" program, either via aspect specifications, pragmas, or attributes.
    |"
    |" Note: by default, Libadalang will check if the aspect is defined on any
    |" part of the entity. However, the ``previous_parts_only`` parameter can
    |" be set to True to limit the search to the current entity and its
    |" previous parts in order to comply with visibilily rules. That way, if
    |" an aspect is defined on the private part of a type, calling this
    |" property on its corresponding public view won't return the aspect
    |" unlike the call on the private view.
    |"
    |" Moreover, since aspects can be inherited, if none was found for the
    |" current entity, Libadalang will also search for the aspect on the
    |" parents of entity (in that case the ``inherited`` field will be set
    |" to ``True`` in the returned result).
    @exported
    @memoized
    @with_dynvars(imprecise_fallback=false)
    fun get_aspect(name: Symbol, previous_parts_only: Bool = false): Aspect =
        self.get_aspect_on_parts(name, false, previous_parts_only)

    |" Returns whether the boolean aspect named ``name`` is set on the entity
    |" represented by this node.
    |"
    |" Note: The ``previous_parts_only`` parameter controls how aspects are
    |" retrieved. See ``DefiningName.get_aspect`` for more information.
    |"
    |" Aspects are properties of entities that can be specified by the Ada
    |" program, either via aspect specifications, pragmas, or attributes.
    |"
    |" "Aspect" is used as in RM terminology (see :rmlink:`13.1`).
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun has_aspect(name: Symbol, previous_parts_only: Bool = false): Bool = {
        val a = self.get_aspect(name, previous_parts_only);

        a.exists
        and (
            if node.is_contract_aspect(name)
            then (
                # We don't want to evaluate the predicate condition to
                # determine if its present.
                true
            )
            else
                a.value.do(
                    (value) =>
                    # Only check the value of the expression if it is
                    # determined to be of a boolean type, so we don't
                    # erroneously try to cast a value to bool when it would
                    # be wrong.
                    value.expression_type() != node.bool_type()
                    or value.eval_as_int() == 1b,
                    default_val=true
                )
        )
    }

    |" Helper property for ``get_pragma``. Used to check that ``decl`` is a
    |" pragma declaration that has the given name and is a valid pragma for
    |" the entity defined by this defining name.
    fun is_valid_pragma_for_name(name: Symbol, decl: Entity[AdaNode]): Bool =
        decl.as[Pragma].do(
            (p) =>
            (
                # Check pragma's name
                p.id.name_is(name)
            )
            and (
                # Check that it's associated to self
                not p.associated_entities().find((d) => self == d).is_null
            )
            and (
                # Check that the pragma is after the decl
                node < p.node
            )
        )

    |" Given an array of regions in which to look for pragmas for this entity,
    |" search through all of them in sequence until finding a pragma of the
    |" given name. This is functionnally equivalent to flattening the array of
    |" regions and then finding the pragma, but this implementation avoids
    |" eagerly creating the big flattened array of nodes.
    fun find_valid_pragma_for_name(
        name: Symbol,
        regions: Array[Entity[ASTList[AdaNode]]],
        region_index: Int = 0
    ): Entity[Pragma] =
        regions?[region_index].do(
            (r) =>
            r.find((d) => self.is_valid_pragma_for_name(name, d)).as[Pragma]
            or? self.find_valid_pragma_for_name(
                name,
                regions,
                region_index + 1
            )
        )

    |" Return the pragma with name ``name`` associated to this entity.
    |"
    |" Please use the ``p_get_aspect`` property instead if you are interested
    |" in aspects, i.e. information that can be represented by either aspect
    |" specification nodes, pragma nodes or attribute definition nodes.
    @exported
    fun get_pragma(name: Symbol): Entity[Pragma] = {
        val bd = match self.basic_decl() {
            # If self is an EnumLiteralDecl, search the pragma from the enum
            # type declaration node.
            case eld: EnumLiteralDecl =>
                eld.parent.parent.parent.as![BasicDecl]
            case o => o
        };

        # First look at library level pragmas if self is a library item
        bd.library_item_pragmas().do(
            (plist) =>
            plist.find(
                # Check pragma's name
                (p) => p.id.name_is(name)
            )
        )
        or? # Else check in the surrounding regions of this entity
        self
        .find_valid_pragma_for_name(name, bd.pragma_regions())
    }

    |" Return the representation clause associated to this entity that
    |" defines the given attribute name.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun get_representation_clause(name: Symbol): Entity[AttributeDefClause] =
        self.declarative_scope()?.decls.as_entity.find(
            (d) =>
            d.as[AttributeDefClause].do(
                (p) => {
                    val attr = p.attribute_expr.as![AttributeRef];

                    attr.attribute.name_is(name)
                    and attr.prefix.referenced_defining_name() == self
                }
            )
        )
        .as[AttributeDefClause]

    |" Return the at clause associated to this entity.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun get_at_clause(): Entity[AtClause] =
        self.declarative_scope()?.decls.as_entity.find(
            (d) =>
            d.as[AtClause].do((p) => p.name.referenced_defining_name() == self)
        )
        .as[AtClause]

    |" Return all the ``Annotate`` aspects associated to this specific entity
    |" part.
    @with_dynvars(imprecise_fallback=false)
    fun get_annotations_impl(): Array[Aspect] = {
        val bd = self.basic_decl_internal();
        # Gather aspects defined by pragmas
        val pragmas =
            match bd {
                # If self is an EnumLiteralDecl, search the pragma from the
                # enum type declaration node.
                case eld: EnumLiteralDecl =>
                    eld.parent.parent.parent.as![BasicDecl]
                case o => o
            }
            .pragma_regions()
            .mapcat(
                (r) =>
                r.filtermap(
                    (d) =>
                    Aspect(
                        exists=true,
                        node=d,
                        value=d.as[Pragma].args?[0].assoc_expr(),
                        inherited=false
                    ),
                    (d) => self.is_valid_pragma_for_name(s"Annotate", d)
                )
            );
        # But also those defined with aspect associations
        val aspects =
            bd.get_aspect_spec()?.aspect_assocs.filtermap(
                (asp) =>
                Aspect(
                    exists=true,
                    node=asp,
                    value=asp.expr.as[BaseAggregate].assocs?[0].expr(),
                    inherited=false
                ),
                (asp) => asp.id.name_is(s"Annotate")
            );

        pragmas & aspects
    }

    |" Return all the ``Annotate`` aspects defined on this entity, both
    |" through pragmas and aspect specifications. For a type declaration,
    |" this also includes all annotations defined on its base type,
    |" when relevant (the field ``inherited`` will be set for those).
    |"
    |" The ``value`` field of each returned ``Aspect`` will be set to be the
    |" identifier that designates the tool which is concerned by the
    |" annotation.
    |"
    |" Note: Libadalang will look for the ``Annotate`` aspects on any part of
    |" the entity.
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun get_annotations(): Array[Aspect] = {
        val self_annotations =
            self.all_parts().mapcat((p) => p.get_annotations_impl());
        val inherited_annotations =
            self.basic_decl().as[BaseTypeDecl].do(
                (bd) => {
                    val typ =
                        if bd is BaseSubtypeDecl
                        then bd.as[BaseSubtypeDecl].get_type()
                        else bd.base_type();

                    if typ.is_null or typ == bd then null[Array[Aspect]]
                    else
                        typ.name.get_annotations().map(
                            (a) =>
                            Aspect(
                                exists=a.exists,
                                node=a.node,
                                value=a.value,
                                inherited=true
                            )
                        )
                }
            );
        val config_annotations =
            self.enclosing_compilation_unit().config_pragmas(s"Annotate").map(
                (p) =>
                Aspect(
                    exists=true,
                    node=p,
                    value=p.args?[0].assoc_expr(),
                    inherited=false
                )
            );

        # We use `.unique` because for declarations split in multiple parts,
        # a pragma Annotate may be associated to all of them, and since
        # we concatenate aspects from all parts, we might end up with the
        # same pragma multiple times. Also, since we recursively look on base
        # types, we might end up with the same configuration pragmas.
        (self_annotations & inherited_annotations & config_annotations)
        .unique()
    }

    |" Whether this entity defined by this name is imported from another
    |" language.
    @exported
    fun is_imported(): Bool =
        self.has_aspect(s"Import") or self.has_aspect(s"Interface")

    |" Return whether the entity defined by this name is ghost or not.
    |" See SPARK RM 6.9.
    @exported
    @memoized
    fun is_ghost_code(): Bool = {
        val bd = self.basic_decl();

        self.has_aspect(s"Ghost") or bd.parent_basic_decl()?.is_ghost_code()
        or (
            # Instantiation of generic ghost entity is ghost code
            bd.as[GenericInstantiation].do(
                (gi) => gi.designated_bare_generic_decl().is_ghost_code()
            )
        )
        or (
            # Renaming of ghost entity is ghost code
            match bd {
                case sr: SubpRenamingDecl => sr.renames.renamed_object
                case pr: PackageRenamingDecl => pr.renames.renamed_object
                case gr: GenericRenamingDecl => gr.renaming_name()
                case _ => null[Entity[Name]]
            }
            .do((c) => c.referenced_defining_name()?.is_ghost_code())
        )
    }

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        # The name field of a defining name must be an Identifier or a
        # DottedName. So we can special case the construction of the xref
        # equation here.
        self.name.as[DottedName].do(
            (dn) => {
                # In case this name denotes a package/library level
                # task/procedure name, it must be resolved as seen from the
                # standard package (same logic as for EndName).
                bind env = self.std_env();

                dn.prefix.xref_equation()
            },
            default_val=%true
        )

    # There are names to resolve in a defining name only if its name field is
    # a dotted name, in which case we must resolve its prefix.
    fun xref_entry_point(): Bool = node.name is DottedName
}

|" Synthetic DefiningName.
@synthetic
class SyntheticDefiningName: DefiningName {
    # It is not possible to override Name.relative_name (which name_symbol is
    # defined in terms of), so we override name_symbol directly.
    fun name_symbol(): Symbol = node.name.name_symbol()

    fun as_symbol_array(): Array[Symbol] = [node.name_symbol()]
}

|" Subtype name for membership test expressions (:rmlink:`3.6`).
class DiscreteSubtypeName: Name {
    @parse_field
    subtype: DiscreteSubtypeIndication
}

|" Name to select a suffix in a prefix (:rmlink:`4.1.3`).
class DottedName: Name {
    @parse_field
    prefix: Name
    @parse_field
    suffix: BaseId

    fun ref_var(): LogicVar = node.suffix.ref_var()

    fun subp_spec_var(): LogicVar = node.suffix.subp_spec_var()

    fun defines_subp_spec_var(): Bool = true

    fun has_context_free_type(): Bool = not node.suffix is CharLiteral

    @with_dynvars(origin)
    fun complete_items(): Array[CompletionItem] = {
        bind origin = node.origin_node();
        bind env = node.node_env;
        val complete_env = {
            bind no_visibility = true;
            self.prefix.designated_env()
        };
        val visible_env = {
            bind no_visibility = false;
            self.prefix.designated_env()
        };
        # In completion we always want to return everything, and flag invisible
        # things as invisible, so we first query `complete_env` to discover all
        # possible items, and then check whether they are actually visible by
        # querying `visible_env`.
        node.env_get_public(complete_env, null[Symbol], LookupKind.flat)
        .filtermap(
            (n) =>
            CompletionItem(
                decl=n.as[BasicDecl],
                is_dot_call=n.info.md.dottable_subp,
                is_visible=(
                    # Dottable subprograms are always visible
                    n.info.md.dottable_subp
                )
                or (
                    # Else check visibility on the unit containing n
                    node.has_visibility(n)
                    and node.env_get_public(
                        visible_env,
                        n.as[BasicDecl].name_symbol(),
                        LookupKind.flat
                    )
                    .contains(n)
                ),
                weight=self.complete_item_weight(n.as[BasicDecl])
            ),
            (n) =>
            (
                # Filter elements that are coming from a body that is not
                # visible. This can happen with dottable subprograms
                # defined in bodies.
                # NOTE: We also filter `PrivatePart`s here as they are
                # useless from the completion point of view.
                # Order matters here, `has_visibility` below should not
                # be called with n being a PrivatePart.
                not n is PrivatePart
            )
            and (
                n.owning_unit_kind() == AnalysisUnitKind.unit_specification
                or node.has_visibility(n)
            )
        )
    }

    @with_dynvars(origin)
    fun complete_item_weight(item: Entity[BasicDecl]): Int =
        # Give components and discriminants the highest weigth
        if item is ComponentDecl | DiscriminantSpec then 100
        # Then, promote primitives

        elif item is BasicSubpDecl | BaseSubpBody then 75
        # Treat everything else the default way
        else self.super(item)

    @with_dynvars(env, origin, no_visibility=false)
    fun designated_env_no_overloading(): LexicalEnv = {
        val pfx_env = self.prefix.designated_env_no_overloading();

        {
            bind env = pfx_env;

            self.suffix.designated_env_no_overloading()
        }
    }

    @with_dynvars(env, origin, no_visibility=false)
    fun designated_env(): LexicalEnv = {
        val pfx_env = self.prefix.designated_env();

        {
            bind env = pfx_env;

            self.suffix.designated_env()
        }
    }

    @with_dynvars(env, origin)
    fun all_env_els_impl(
        seq: Bool = true,
        seq_from: AdaNode = null[AdaNode],
        categories: RefCategories = RefCategories(_=true)
    ): Array[Entity[AdaNode]] = {
        val pfx_env = self.prefix.designated_env();

        {
            bind env = pfx_env;

            self.suffix.all_env_els_impl(seq, seq_from, categories)
        }
    }

    @with_dynvars(env)
    fun scope(): LexicalEnv =
        node.suffix.do(
            (sfx) => {
                bind env = node.parent_scope();

                sfx.scope()
            },
            default_val=null[LexicalEnv]
        )

    @with_dynvars(env)
    fun parent_scope(): LexicalEnv = node.prefix.scope()

    fun relative_name(): Entity[Name] = self.suffix.relative_name()

    @with_dynvars(env)
    fun env_elements_impl(): Array[Entity[AdaNode]] = {
        val pfx_env = {
            bind origin = node.origin_node();

            self.prefix.designated_env()
        };

        {
            bind env = pfx_env;

            self.suffix.env_elements_impl()
        }
    }

    @with_dynvars(env, origin)
    fun designated_type_impl(): Entity[BaseTypeDecl] = {
        bind env = self.prefix.designated_env_no_overloading();

        self.suffix.designated_type_impl()
    }

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        val base =
            self.prefix.sub_equation()
            %and {
                bind env = self.prefix.designated_env();

                self.suffix.sub_equation()
            };

        if not self.designated_type_impl().is_null then
            base
        else
            base
            %and node.expected_type_var() <-> node.suffix.expected_type_var()
            %and node.type_var() <-> node.suffix.type_var()
            %and self.env_elements().do(
                (env_els) => env_els.logic_any((e) => {
                    val actual = e.as[BasicDecl].corresponding_actual();
                    node.suffix.ref_var() <- actual
                    %and actual.constrain_prefix(node.prefix)
                }),
                default_val=self.undefined_reference_equation()
            )
    }

    fun is_constant(): Bool =
        # A dotted name references a constant object if the prefix or the
        # suffix does.
        self.prefix.is_constant() or self.suffix.is_constant()
}


|" Name for an array subcomponent choice of a deep delta aggregate.
class ArraySubcomponentChoiceName: Name {
    # This node can basically be seen as a CallExpr where `name` can be a null
    # node.

    # The name field can be null when the ArraySubcomponentChoiceName is of the
    # form "(suffix)" (where suffix is a list of expression: "expr{, expr}"
    # representing the indexes of a mono- or multi-dimentional array, or a
    # range). When the node is of the form of "name (suffix)", name can only be
    # another ArraySubcomponentChoiceName or a DottedName.
    @parse_field
    @nullable
    name: Name
    @parse_field
    suffix: AdaNode

    fun suffix_exprs(): Array[Entity[Expr]] =
        self.suffix.as![AssocList].map((a) => a.as![ParamAssoc].expr())

    |" Return the corresponding delta aggregate's ancestor expression type.
    @memoized
    fun delta_aggregate_ancestor_expr_type(): Entity[BaseTypeDecl] =
        node.parents(with_self=false).find((p) => p is DeltaAggregate)
        .as[DeltaAggregate]
        .ancestor_expr
        .as_bare_entity
        .expression_type()

    fun ref_var(): LogicVar =
        node.as_bare_entity.delta_aggregate_ancestor_expr_type().name.ref_var()

    fun name_symbol(): Symbol = node.name.do((n) => n.name_symbol())

    fun xref_equation(): Equation =
        # Resolve name if any
        self.name.do((n) => n.sub_equation(), default_val=%true)
        %and (
            self.suffix_exprs().ilogic_all(
                # Resolve all suffix's indexes/range independently
                (a, i) =>
                a.sub_equation()
                %and a.expected_type_var()
                <- node.delta_aggregate_ancestor_expr_type().index_type(i)
                %and a.matches_expected_type()
            )
        )
        # Self's type is bound to the component type of Self's name
        # designated type if any (if name is null, the type is given by the
        # delta aggregate itself).
        %and if self.name is DottedName
        then self.type_var() <- BaseTypeDecl.comp_type%(self.name.type_var())
        else
            self.type_var()
            <- self.name.do(
                (n) => n.name_designated_type().comp_type(),
                default_val=node.delta_aggregate_ancestor_expr_type()
                .comp_type()
            )

    fun designated_type_impl(): Entity[BaseTypeDecl] =
        self.name.do(
            (n) => n.designated_type_impl(),
            default_val=node.delta_aggregate_ancestor_expr_type().comp_type()
        )

    fun designated_env(): LexicalEnv =
        self.name.do(
            (n) => n.name_designated_type().defining_env(),
            default_val={
                bind include_ud_indexing = false;

                node.delta_aggregate_ancestor_expr_type().defining_env()
            }
        )
}


|" self name in ``end ...;`` syntactic constructs.
class EndName: Name {
    @parse_field
    name: Name

    @with_dynvars(env)
    fun parent_scope(): LexicalEnv = node.name.parent_scope()

    @with_dynvars(env)
    fun scope(): LexicalEnv = node.name.scope()

    fun relative_name(): Entity[Name] = self.name.relative_name()

    fun ref_var(): LogicVar = node.name.ref_var()

    @with_dynvars(env)
    fun env_elements_impl(): Array[Entity[AdaNode]] =
        self.name.env_elements_impl()

    |" Returns this EndName's basic declaration
    @exported
    @memoized
    fun basic_decl(): Entity[BasicDecl] =
        node.parents().find((p) => p is BasicDecl | NamedStmt).do(
            (p) =>
            if p is BasicDecl then p.as[BasicDecl].as_entity
            else p.as![NamedStmt].decl.as_entity
        )

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.parent.as[AcceptStmtWithStmts].do(
            (stmt) => node.ref_var() <- stmt.designated_entry(),
            default_val=node.ref_var() <- self.basic_decl()
        )
        %and self.name.as[DottedName].do(
            # Also resolve the prefix of the dotted name, in case this
            # subprogram/package is a child unit: the fully qualified name must
            # be resolved as seen from the standard package.
            (dn) => {
                bind env = self.std_env();

                dn.prefix.xref_no_overloading()
            },
            default_val=%true
        )

    fun xref_entry_point(): Bool = true
}

|" Explicit dereference expression (``.all``) (:rmlink:`4.1`).
class ExplicitDeref: Name {
    @parse_field
    prefix: Name
    r_called_spec: LogicVar

    fun ref_var(): LogicVar = node.prefix.ref_var()

    fun subp_spec_var(): LogicVar = node.r_called_spec

    fun defines_subp_spec_var(): Bool = true

    fun relative_name(): Entity[Name] = self.prefix.relative_name()

    @with_dynvars(env, origin, no_visibility=false)
    fun designated_env(): LexicalEnv =
        # Since we have implicit dereference in Ada, everything is directly
        # accessible through the prefix, so we just use the prefix's env.
        self.prefix.designated_env()

    @with_dynvars(env)
    fun env_elements_impl(): Array[Entity[AdaNode]] =
        self.prefix.env_elements_impl()

    @with_dynvars(env, origin)
    fun eq_for_type(typ: Entity[BaseTypeDecl]): Equation =
        if typ.is_access_type()
        then
            (
                node.prefix.expected_type_var() <- typ
                %and self.prefix.matches_expected_type()
            )
            %and node.type_var() <- typ.accessed_type()
        else %false

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = self.bottom_up_name_equation()

    @with_dynvars(env, origin, entry_point)
    fun general_xref_equation(root: Name = null[Name]): Equation =
        # Attribute ref case: we can always resolve the AttributeRef first
        # without ambiguity. This allows us to use its type in order to
        # solve the rest of the expression.
        self.all_args_xref_equation(root)
        %and if self.prefix is AttributeRef
        then
            self.prefix.resolve_names_internal(false).do(
                (_) =>
                self.prefix.type_val().as[BaseTypeDecl].do(
                    (typ) =>
                    (
                        node.prefix.expected_type_var() <- typ
                        %and node.prefix.type_var() <- typ
                        %and self.parent_name_equation(typ, root)
                    ),
                    default_val=%false
                ),
                default_val=%false
            )
        else
            self.prefix.sub_equation()
            %and self.env_elements().logic_any(
                (el) => {
                    val typ = el.as[BasicDecl].expr_type();
                    if typ?.is_access_type()
                    then
                        node.prefix.ref_var() <- el
                        %and self.parent_name_equation(typ, root)
                    else %false
                }
            )

    fun is_constant(): Bool =
    # The dereference expression is constant if its access type is
    # constant.
    {
        bind origin = node;

        self.prefix.expression_type()?.access_def()
        .as[TypeAccessDef]
        ?.has_constant
        .as_bool()
    }
}

|" Qualified expression (``...'(...)``) .(:rmlink:`4.7`).
class QualExpr: Name {
    @parse_field
    prefix: Name
    @parse_field
    suffix: Expr

    fun ref_var(): LogicVar = node.prefix.ref_var()

    fun relative_name(): Entity[Name] = self.prefix.relative_name()

    fun is_constant(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun general_xref_equation(root: Name = null[Name]): Equation =
        self.xref_equation() %and self.all_args_xref_equation(root)
        %and self.parent_name(root).do(
            (pn) =>
            pn.parent_name_equation(self.prefix.designated_type_impl(), root),
            default_val=%true
        )

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.prefix.xref_type_equation() %and self.suffix.sub_equation()
        %and node.suffix.expected_type_var() <-> node.prefix.ref_var()
        %and self.suffix.matches_expected_type()
        # A qualified expression that appears as a statement denotes a machine
        # code insertion, in GNAT, it is parsed as a parameterless procedure
        # call. In that case, self.type_var shouldn't denote any type. Note
        # that we are more flexible than Ada since we allow any type to be code
        # statements whereas Ada restricts that to types defined in package
        # `System.Machine_Code` (see :rmlink:`13.8`).
        %and if self.parent is CallStmt then %true
        else node.type_var() <-> node.prefix.ref_var()

    @with_dynvars(env, origin, no_visibility=false)
    fun designated_env(): LexicalEnv =
        self.prefix.name_designated_type().defining_env()

    @with_dynvars(env)
    fun env_elements_impl(): Array[Entity[AdaNode]] =
        self.prefix.env_elements_impl()
}

|" Reduction expression (``Reduce`` attribute). Ada 2022, RM 4.5.10.
class ReduceAttributeRef: Name {
    @parse_field
    prefix: AdaNode
    @parse_field
    attribute: Identifier
    @parse_field
    args: AssocList
    r_ref_var: LogicVar

    fun ref_var(): LogicVar = node.r_ref_var

    |" Return the nameres equation for the Reduce attribute:
    |" ``Expr'Reduce (Reducer, InitVal)``
    |" where Expr is either a ``Name`` or a ``SequenceValue`` denoting a
    |" collection to reduce, ``Reducer`` is the subprogram to use to perform
    |" the reduction and ``InitVal`` is the initial value to be used by the
    |" reducer.
    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        val reducer = self.args?[0].expr();

        node.env_get(
            env=env,
            symbol=reducer.as[BaseId].sym(),
            from_node=node.origin_node()
        )
        .logic_any(
            (subp) =>
            subp.as[BasicDecl].do(
                (bd) =>
                bd.is_valid_reducer_candidate().do(
                    (_) =>
                    self.xref_equation_for_reducer_candidate(
                        subp.as[BasicDecl]
                    ),
                    default_val=%false
                ),
                default_val=%false
            )
        )
    }

    |" Build the equation for a reducer candidate.
    @with_dynvars(env, origin, entry_point)
    fun xref_equation_for_reducer_candidate(
        subp: Entity[BasicDecl]
    ): Equation = {
        val reducer = self.args?[0].expr().as[BaseId];
        val initial_value_expression = self.args?[1].expr();
        # We don't need to take too many precautions here since we are sure the
        # subp parameter is a valid reducer candidate, its supb_spec isn't null
        # and it has parameters.
        val param_types = subp.subp_spec_or_null().param_types();
        val accum_type = param_types?[0];
        val value_type = param_types?[1];

        self.prefix.as[ValueSequence].do(
            (vs) =>
            vs.iter_assoc.expr().expected_type_var() <- value_type
            %and vs.iter_assoc.expr().matches_expected_type(),
            default_val=%true
        )
        %and self.prefix.sub_equation()
        %and node.type_var() <- accum_type
        %and reducer.ref_var() <- subp
        %and initial_value_expression.expected_type_var() <- accum_type
        %and initial_value_expression.sub_equation()
        %and initial_value_expression.matches_expected_formal_type()
    }
}

|" Base class for nodes that are made up of a single token.
@abstract
class SingleTokNode: Name implements TokenNode {
    fun relative_name(): Entity[Name] = self

    @external()
    fun subp_spec_var(): LogicVar

    @external()
    fun ref_var(): LogicVar

    fun defines_subp_spec_var(): Bool = true

    |" Shortcut to get the symbol of this node. We keep this short form, even
    |" though the public property canonical_text is equivalent because it is
    |" very used inside of the internal properties
    fun sym(): Symbol = node.symbol

    fun name_symbol(): Symbol = node.symbol

    fun canonical_text(): Symbol = node.sym()

    |" Like env.get_first, but returning the first visible element in the Ada
    |" sense.
    |"
    |" If ``no_visibility``, discard visibility checks.
    @with_dynvars(no_visibility=false)
    fun env_get_first_visible(
        lex_env: LexicalEnv,
        lookup_type: LookupKind,
        from_node: AdaNode
    ): Entity[AdaNode] =
        node.env_get(
            lex_env,
            node.symbol,
            lookup=lookup_type,
            from_node=from_node,
            categories=RefCategories(inherited_primitives=false, _=true)
        )
        .find(
            (el) =>
            (
                # If no_visibility, then don't check visibility, (so return the
                # first).
                no_visibility
            )
            or node.has_visibility(el)
        )
}

|" Base class for identifiers.
@abstract
@custom_short_image
class BaseId: SingleTokNode implements TokenNode {
    @memoized
    @with_dynvars(env)
    fun scope(): LexicalEnv = {
        val elt =
            env.get_first(
                node.symbol,
                lookup=if node.is_prefix() then LookupKind.recursive
                else LookupKind.flat,
                categories=RefCategories(inherited_primitives=false, _=true)
            );
        val ret =
            if not elt.is_null and elt.node is BasicDecl then elt.children_env
            else null[LexicalEnv];

        # If this the corresponding decl is a generic, go grab the internal
        # package decl.
        ret.env_node.as[GenericPackageDecl].do(
            (gen_pkg_decl) => gen_pkg_decl.package_decl.children_env,
            default_val=ret
        )
    }

    @with_dynvars(env, origin, no_visibility=false)
    fun designated_env_no_overloading(): LexicalEnv =
        node.env_get_first_visible(
            env,
            lookup_type=if node.is_prefix() then LookupKind.recursive
            else LookupKind.flat,
            from_node=node.origin_node()
        )
        .as[BasicDecl]
        .do(
            # Getting back an ObjectDecl necessarily means we are dealing with
            # incorrect Ada code, because `designated_env_no_overloading` is
            # always called in context where we expect a package/type
            # declaration. In that case we now directly return an empty result,
            # in order to avoid cases of invalid code that trigger infinite
            # recursions (e.g. `Foo : Foo.T;`).
            (bd) =>
            if bd is ObjectDecl then node.empty_env()
            elif bd?.is_package() then self.pkg_env(bd)
            else {
                bind origin = node.origin_node();

                bd.defining_env()
            }
        )

    |" Decoupled implementation for designated_env, specifically used by
    |" DottedName when the parent is a library level package.
    @with_dynvars(env, origin, no_visibility=false)
    fun designated_env(): LexicalEnv = {
        val bd = node.parents().find((p) => p is GenericPackageInstantiation);
        val env_el =
            node.env_get_first_visible(
                env,
                lookup_type=if node.is_prefix() then LookupKind.recursive
                else LookupKind.flat,
                from_node=node.origin_node()
            )
            .as[BasicDecl];

        # If first element is a package, then return the pkg env
        if env_el?.is_package() and env_el.node != bd then self.pkg_env(env_el)
        else
            self.env_elements_impl().do(
                (all_env_els) =>
                all_env_els.filter(
                    (e) =>
                    (
                        # Exclude own generic package instantiation from the
                        # lookup.
                        e.node != bd
                    )
                    and node.has_visibility(e)
                )
            )
            .map((e) => e.as[BasicDecl].defining_env())
            .env_group()
    }

    |" Return the lexical environment for this identifier, should it be a
    |" package. This method handles resolving to the most visible part of a
    |" package - private or body - if necessary. It also unwinds package
    |" renamings if necessary.
    |"
    |" If ``inst_from_formal`` is True, we know that bd is a generic package
    |" instantiation coming from a rebound formal package, and that we need
    |" visibility on the formals.
    @with_dynvars(env, origin)
    fun pkg_env(from_pkg: Entity[BasicDecl]): LexicalEnv = {
        # If the given package is a renaming (after potentially several levels
        # of renamings) of another package P, do the rest of the work on P
        # instead.
        val pkg =
            from_pkg.as[PackageRenamingDecl].do(
                (r) => r.final_renamed_package(),
                default_val=from_pkg
            );
        # If pkg is a generic package (non instantiated) and it is
        # rebound somewhere in the context of self's rebindings, then
        # we want to put back those rebindings on it, because it means
        # we are inside a generic instantiation, so referring to the
        # generic package actually means referring to the
        # instantiation.
        val bd = pkg.unshed_rebindings(self.info.rebindings);
        # Check whether the package comes from a rebound env in order to
        # determine if we have visibility on its formal part. Look at both
        # ``from_pkg`` or ``pkg`` as we may have a renaming of a rebound
        # package, or a rebound package being a package renaming, and in
        # both cases we have visibility on the final renamed package's
        # formal part.
        val is_inst_from_formal =
            pkg is GenericPackageInstantiation
            and (from_pkg.info.from_rebound or pkg.info.from_rebound);
        val env =
            if bd is GenericPackageInstantiation and is_inst_from_formal
            then bd.as[GenericPackageInstantiation].defining_env_impl(true)
            else bd.defining_env();
        # If the basic_decl is a package decl with a private part, we get it.
        # Else we keep the defining env.
        val private_part_env =
            env.get(
                s"__privatepart",
                lookup=LookupKind.flat,
                categories=RefCategories(inherited_primitives=false, _=true)
            )?[
                0
            ]
            .do((pp) => pp.children_env, default_val=env);
        val package_body_env =
            private_part_env.get(
                s"__nextpart",
                lookup=LookupKind.flat,
                categories=RefCategories(inherited_primitives=false, _=true)
            )?[
                0
            ]
            .do(
                (pb) =>
                # If the package is implemented as a separate, we need to
                # jump through one more link to get to the body.
                if pb is PackageBodyStub
                then
                    pb.children_env.get(
                        s"__nextpart",
                        lookup=LookupKind.flat,
                        categories=RefCategories(
                            inherited_primitives=false,
                            _=true
                        )
                    )?[
                        0
                    ]
                    .do((pb) => pb.children_env)
                else pb.children_env,
                default_val=null[LexicalEnv]
            );
        val formals_env =
            bd.as[GenericPackageDecl].do(
                (pkg_g) => pkg_g.formal_part.children_env,
                default_val=null[LexicalEnv]
            );

        # If we're looking from the body, return a group of all the
        # relevant envs together.
        if
            package_body_env != null[LexicalEnv]
            and (
                # Since origin or self do not carry rebindings,
                # `is_children_env` would always return False in instantiated
                # generics (since `package_body_env` is a rebound environment).
                # Fortunately, these visibility rules are not
                # instantiation-dependent, so we can use
                # `.env_node.children_env` on `package_body_env` to do the
                # check on the bare non-rebound lexical envs.
                node.is_children_env(
                    package_body_env.env_node?.children_env,
                    (origin or? node).node_env
                )
            )
        then [package_body_env, private_part_env, env, formals_env].env_group()
        # If we're looking from the private part, return a group of private
        # part + public part.
        # See corresponding comment on `package_body_env` to understand why
        # we use `.env_node.children_env`.

        elif
            node.is_children_env(
                private_part_env.env_node?.children_env,
                (origin or? node).node_env
            ) then [private_part_env, env, formals_env].env_group()
        # If we're not looking from the private part, we could be looking
        # from the public part of a generic package decl. In such a case
        # the returned env should also include the formals environment for
        # that package.

        elif bd is GenericPackageDecl then [env, formals_env].env_group()
        # TODO: Probably some special handling for separates here, because
        # they'll have full visibility on the package body in which they're
        # defined.
        else env
    }

    @with_dynvars(env)
    fun parent_scope(): LexicalEnv = env

    @with_dynvars(env, origin)
    fun designated_type_impl(): Entity[BaseTypeDecl] =
        node.env_get_first_visible(
            env,
            from_node=node.origin_node(),
            lookup_type=if node.is_prefix() then LookupKind.recursive
            else LookupKind.minimal
        )
        .do(
            (env_el) =>
            env_el.as[BaseTypeDecl].do(
                (t) =>
                if origin.is_null
                then {
                    # When no origin is given (e.g. we are resolving from an
                    # aspect), try to find a more complete definition of `t`
                    # as seen from the reference if any, otherwise use `t`.
                    bind origin = node.origin_node();

                    t.most_visible_forward_part_for_name(
                        t.name_symbol(),
                        seq=false
                    )
                }
                else
                    if self.info.from_rebound
                    then
                    # When the type was resolved from a formal using generic
                    # instance information, try to find a more complete
                    # definition from the origin if possible, otherwise `t`
                    # will be used.
                        t
                        .most_visible_forward_part_for_name(
                            t.name_symbol(),
                            seq=false
                        )
                    else
                    # Otherwise, `t` itself might not actually be a visible
                    # part of the type as seen from `origin`. So, check amongst
                    # the previous and next part of `t` to find the most
                    # complete part, or return null if the type is not at all
                    # visible.
                        t
                        .most_visible_part(),
                default_val=env_el
            )
            .do(
                (v1) =>
                match v1 {
                    case t: BaseTypeDecl => t
                    case tb: TaskBody => tb.task_type()
                    case pb: ProtectedBody => pb.protected_type()
                    case tbs: TaskBodyStub =>
                        tbs.body_part_for_decl().as[TaskBody].task_type()
                    case pbs: ProtectedBodyStub =>
                        pbs.body_part_for_decl()
                        .as[ProtectedBody]
                        .protected_type()
                    case _ => null[Entity[BaseTypeDecl]]
                }
            )
        )
        .do(
            (type) =>
            # When the type is a generic formal type, if we are resolving it
            # from it's instantiation, that means that no actual has been given
            # for that formal (name resolution directly calls
            # resolve_generic_actual on actuals names), therefore the
            # designated type should be the default one if any. On the other
            # hand, outside it's own instantion context, the designated type is
            # the formal type, whether it has a default value or not.
            type.parent.as[GenericFormalTypeDecl].do(
                (formal_decl) =>
                if
                    formal_decl.generic_instantiations().any(
                        (inst) =>
                        inst.designated_generic_decl().node
                        == formal_decl.parent_decl().node
                    )
                then formal_decl.default_type() or? type
                else type
            )
            or? type
        )

    @with_dynvars(env, origin)
    fun all_env_els_impl(
        seq: Bool = true,
        seq_from: AdaNode = null[AdaNode],
        categories: RefCategories = RefCategories(_=true)
    ): Array[Entity[AdaNode]] =
        node.env_get(
            env,
            node.name_symbol(),
            lookup=if node.is_prefix() then LookupKind.recursive
            else LookupKind.flat,
            from_node=if seq
            then if not seq_from.is_null then seq_from else node
            else null[AdaNode],
            categories=categories
        )

    @memoized
    @with_dynvars(env)
    fun env_elements_impl(): Array[Entity[AdaNode]] = {
        val items =
            node.env_get(
                env,
                node.symbol,
                lookup=if node.is_prefix() then LookupKind.recursive
                else LookupKind.flat,
                # If we are in an aspect, then lookup is not sequential
                from_node=node.origin_node(),
                categories=if node.can_designate_primitive()
                then RefCategories(_=true)
                else RefCategories(inherited_primitives=false, _=true)
            )
            .filter(
                (e) =>
                e.as[AnonymousExprDecl].do(
                    (aed) =>
                    self.parents().find((p) => p is GenericFormal).do(
                        # If we are in a generic formal part, we do not
                        # necessarily have visibility on all the actuals coming
                        # from the instantiation.
                        (_) =>
                        aed.get_formal().formal_decl().is_directly_reachable(
                            self
                        ),
                        default_val=true
                    ),
                    default_val=true
                )
            );
        # TODO: there is a big smell here: We're doing the filtering for parent
        # expressions in the baseid env_elements. We should solve that.
        val pc = self.parent_callexpr();
        val is_prefix = not node.is_suffix();

        {
            bind origin = node.origin_node();

            if pc.is_null
            then (
                # If it is not the main id in a CallExpr: either the name
                # designates something else than a subprogram, either it
                # designates a subprogram that accepts no explicit argument. So
                # filter out other subprograms.
                items.filter((e) => e.as![BasicDecl].can_be_paramless())
                & (
                    # If there is a subp_spec, check that it corresponds to a
                    # parameterless subprogram.
                    #
                    # Make sure that the enclosing body is in the list of items
                    # in case this name is the prefix of a qualified name
                    # refering to local variables.
                    if is_prefix
                    then
                        self.semantic_parents().find(
                            (n) =>
                            (n is TaskBody | BaseSubpBody).do(
                                (_) =>
                                n.as[BasicDecl].defining_name().name.name_is(
                                    node.symbol
                                )
                            )
                        )
                        .do(
                            (b) => [b],
                            default_val=null[Array[Entity[AdaNode]]]
                        )
                    else null[Array[Entity[AdaNode]]]
                )
            )
            # This identifier is the name for a called subprogram, entry, or an
            # array.
            # So only keep:
            # * subprograms/entries for which the actuals match
            # * arrays for which the number of dimensions match
            # * any type that has a user defined indexing aspect.
            else
                pc.suffix.as[AssocList].do(
                    (params) =>
                    items.filter(
                        (e) =>
                        match e {
                            # Type conversion case
                            case _: BaseTypeDecl => params.length() == 1
                            case b: BasicDecl =>
                                b.subp_spec_or_null().do(
                                    (spec) =>
                                    self.call_matches_spec(
                                        spec,
                                        pc,
                                        params,
                                        b
                                    ),
                                    # In the case of ObjectDecls/CompDecls in
                                    # general, verify that the callexpr is
                                    # valid for the given type designator.
                                    default_val=pc.check_for_type(
                                        b.expr_type()
                                    )
                                )
                            case _ => false
                        }
                    ),

                    # Discard BaseTypeDecls when resolving a CallExpr that
                    # cannot be a type conversion.
                    default_val=items.filter((e) => not e is BaseTypeDecl)
                )
        }
    }

    |" Return whether the BasicDecl ``b`` should be kept during
    |" ``env_elements_impl`` items filtering. This piece of code has been
    |" extracted from ``env_elements_impl`` to improve code readability.
    @with_dynvars(env, origin)
    fun call_matches_spec(
        spec: Entity[BaseSubpSpec],
        pc: Entity[CallExpr],
        params: Entity[AssocList],
        b: Entity[BasicDecl]
    ): Bool = {
        val family_type = spec.as[EntrySpec]?.family_type;
        # If b is a `EntryDecl` with a specified family type, then the real
        # `CallExpr` is its parent, as in: `Task.Entry (Family) (Arg1, Arg2)`,
        # where `Entry (Family) (Arg1, Arg2)` is the real `CallExpr`, not just
        # `Entry (Family)`. Adjust `pc` and `params` accordingly:
        val real_pc =
            if family_type.is_null then pc else pc.parent.as[CallExpr];
        val real_params =
            if family_type.is_null then params
            else pc.parent.as[CallExpr].do((ce) => ce.suffix.as![AssocList]);

        (
            # ``real_pc`` can be null if we are handling a paramless entry decl
            # that has an entry family, in which case the subsequent checks are
            # not relevant.
            real_pc.is_null
            or (
                # Either the subprogram/entry is matching the CallExpr's
                # parameters.
                spec.is_matching_param_list(
                    real_params,
                    b.info.md.dottable_subp
                )
                and real_pc.parent.as[CallExpr].do(
                    (ce) => ce.check_for_type(b.expr_type()),
                    default_val=true
                )
            )
        )
        or (
            # Or the entity is parameterless, and the returned component (s)
            # matches the callexpr (s).
            real_pc.check_for_type(b.expr_type())
            and spec.paramless(b.info.md.dottable_subp)
        )
    }

    fun denotes_the_property_function(
        subp_spec: Entity[BaseSubpSpec]
    ): Bool = {
        # Return true whether this node can refer to a property function
        # denoted by `subp_spec`. (see RM 7.3.4 about stable properties of a
        # type). This equation has to be called in the scope of the
        # `Stable_Properties` aspect name resolution.
        val primitive_types = subp_spec.primitive_subp_types();

        # ``subp_decl`` is a property function of this node if it comes from a
        # `Stable_Properties` AspectAssoc and:
        (
            # It only has one single parameter (mode in but not checked here)
            subp_spec.params().length() == 1
        )
        and (
            # It matches the type for which the Stable_Properties is defined.
            # There are two cases:
            match self.parent_basic_decl() {
                # Either the Stable_Properties aspect is defined within a
                # TypeDecl.
                case td: TypeDecl =>
                    not primitive_types.find((t) => t == td).is_null

                # Or within a SubpDecl
                case sd: SubpDecl =>
                    not sd.subp_spec.primitive_subp_types().filter(
                        (t1) =>
                        not primitive_types.find((t2) => t1 == t2).is_null
                    )
                    .is_null
                case _ => false
            }
        )
    }

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        val is_prefix = not node.is_suffix();

        self.env_elements().do(
            (env_els) =>
            env_els.logic_any(
                (e) =>
                node.ref_var() <- e.as[BasicDecl].corresponding_actual()
                %and (
                    # If this BaseId refers to an enclosing subprogram and is
                    # the prefix of a dotted name, then it is not a call.
                    if is_prefix and e.as[BaseSubpBody]?.in_scope()
                    then node.type_var() <- null[Entity[BaseTypeDecl]]
                    else (
                        # If this BaseId represents a call, the called
                        # subprogram will be held in self.ref_var, in which
                        # case subp_spec_or_null will return the specification
                        # of the called subprogram. If ref_var does not contain
                        # a subprogram, this BaseId cannot be a call, and
                        # subp_spec_or_null would indeed return null in this
                        # case.
                        node.type_var() <- BasicDecl.expr_type%(node.ref_var())
                        %and node.subp_spec_var()
                        <- e.as[BasicDecl].subp_spec_or_null()
                    )
                )
            ),
            default_val=self.undefined_reference_equation()
        )
    }
}

|" Character literal (:rmlink:`4.1`).
@repr_name("Chr")
class CharLiteral: BaseId implements TokenNode {
    |" Return the value that this literal denotes.
    @exported
    @external()
    fun denoted_value(): Char

    fun has_context_free_type(): Bool = false

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        BaseTypeDecl.is_non_null_char_type%(node.expected_type_var())
        %and node.expected_type_var()
        <-> node.type_var()
        # Ada RM 4.2 (3): since the expected type of the `CharLiteral` is known
        # in this case (the predicates above let us through), we can use it to
        # determine what the literal refers to. Hackish: we use the `origin`
        # dynamic variable to pass an additional argument to the conversion
        # property ``corresponding_char_literal``.
        #
        # TODO: fix this once we can pass explicit parameters to conversion
        # properties.
        %and {
            bind origin = node;

            node.ref_var()
            <- BaseTypeDecl.corresponding_char_literal%(node.type_var())
        }
}

|" Regular identifier (:rmlink:`2.3`).
@with_abstract_list
@repr_name("Id")
class Identifier: BaseId implements TokenNode {

    # Some attributes return functions in Ada. However, LAL incorrectly parses
    # an "AttributeRef with arguments" as something magical rather than a
    # regular call (which is why AttributeRef has an `args` field.
    #
    # Additionally, resolution for a number of them was implemented as "magic
    # attributes" rather than built-in functions. This is wrong and needs to be
    # fixed (see S910-057). However, for the moment, we parse them as
    # ``AttributeRef (pfx, attr, args)``, and resolve them specially
    # rather than  ``CallExpr (AttrRef (pfx, attr), args)``.
    #
    # For other args, we deactivate this parsing, so that they're correctly
    # parsed as ``CallExpr (AttrRef (pfx, attr), args)``.
    fun is_attr_with_args(): Bool =
        node.symbol in s"First"
            | s"Last"
            | s"Range"
            | s"Length"
            | s"Has_Same_Storage"
            | s"Overlaps_Storage"
            | s"Deref"
            | s"Mechanism_Code"

    @with_dynvars(origin)
    fun complete_items(): Array[CompletionItem] = self.parent.complete_items()

    fun is_constant(): Bool = {
        val rd = self.referenced_decl();

        (
            # If this identifier is defining, call is_constant_object on
            # the object it defines.
            if self.is_defining()
            then
                self.enclosing_defining_name().basic_decl()
                .is_constant_object()
            # Check if the referenced declaration is constant (filter out
            # declarations that are not objects, as it makes no sense to
            # call is_constant_object on them).

            elif
                rd is ObjectDecl
                | ComponentDecl
                | EnumLiteralDecl
                | ParamSpec
                | NumberDecl then rd.is_constant_object()
            else false
        )
        or (
            # An instance of a protected variable is constant within
            # a function body of the corresponding protected unit.
            self.parents().find(
                (n) =>
                n.as[BaseSubpBody].do(
                    (v1) => v1.subp_spec.subp_kind is SubpKind.Function
                )
            )
            .do(
                (_) =>
                (
                    # We just check that the variable is used within a
                    # function first, then we ensure that it is protected
                    # by looking at its declaration, which should be inside
                    # the private part of the corresponding protected unit.
                    rd.is_in_private_part()
                )
                and not rd.parents().find((n) => n is ProtectedTypeDecl)
                .is_null
            )
        )
    }
}

|" Operation in a binary expression.
|"
|" Note that the ARM does not consider "double_dot" ("..") as a binary
|" operator, but we process it this way here anyway to keep things simple.
enum class Op: BaseId implements TokenNode {
    case
        And,
        Or,
        OrElse,
        AndThen,
        Xor,
        In,
        NotIn,
        Abs,
        Not,
        Pow,
        Mult,
        Div,
        Mod,
        Rem,
        Plus,
        Minus,
        Concat,
        Eq,
        Neq,
        Lt,
        Lte,
        Gt,
        Gte,
        DoubleDot

    |" Return the symbol that needs to be used to define an overload of this
    |" operator.
    fun subprogram_symbol(): Symbol = match node {
        case _: Op.And => s"\"and\""
        case _: Op.Or => s"\"or\""
        case _: Op.Xor => s"\"xor\""
        case _: Op.Abs => s"\"abs\""
        case _: Op.Not => s"\"not\""
        case _: Op.Pow => s"\"**\""
        case _: Op.Mult => s"\"*\""
        case _: Op.Div => s"\"/\""
        case _: Op.Mod => s"\"mod\""
        case _: Op.Rem => s"\"rem\""
        case _: Op.Plus => s"\"+\""
        case _: Op.Minus => s"\"-\""
        case _: Op.Concat => s"\"&\""
        case _: Op.Eq => s"\"=\""
        case _: Op.Neq => s"\"/=\""
        case _: Op.Lt => s"\"<\""
        case _: Op.Lte => s"\"<=\""
        case _: Op.Gt => s"\">\""
        case _: Op.Gte => s"\">=\""
        case _ => s"<<>>"
    }

    |" Return the list of all operator definitions for the given operator
    |" symbol. Note that corresponding operators of root types are returned
    |" first in the list, so as to implement the "preference" behavior
    |" described in :rmlink:`8.6` - 29 in BinOp and UnOp xref_equation.
    fun subprograms_for_symbol(
        sym: Symbol,
        from_node: Entity[AdaNode]
    ): Array[Entity[BasicDecl]] =
        node.root_type_ops(sym)
        & node.env_get(from_node.node_env, sym, from_node=from_node.node)
        .filtermap(
            (e) => e.as![BasicDecl],
            (e) =>
            e.as![BasicDecl].is_subprogram()
            and (
                # Note: here we explicitly filter out synthesized operators
                # (which correspond to built-in operators), because using them
                # for resolving arithmetic expressions would have a significant
                # performance impact. Instead, we use specific equations
                # tailored for the resolution of built-in operators. See
                # `BinOp.no_overload_equation`.
                # TODO: However these custom rules currently do not assign the
                # `ref_var` of operator references designating which built-in
                # operators have been called, which would be useful for users
                # and make this more transparent.
                not e is SyntheticSubpDecl
            )
        )

    |" Return the subprograms corresponding to this operator accessible in the
    |" lexical environment.
    fun subprograms(): Array[Entity[BasicDecl]] =
        node.subprograms_for_symbol(node.subprogram_symbol(), self)

    fun name_symbol(): Symbol = node.subprogram_symbol()

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        # An Op can only be a field of a BinOp or UnOp, so its ref var will
        # be bound in the xref equations of these two types.
        %false

    @with_dynvars(imprecise_fallback=false)
    fun is_dispatching_call(): Bool =
        self.referenced_decl().do(
            (decl) =>
            # TODO: It's a bit of a shame to not have a base class for
            # operators?
            match
                self.parents().find((n) => n is BinOp | ConcatOp | UnOp)
                .as![Expr]
            {
                # TODO: Not supported on ConcatOps yet. It would return false
                # anyway but this way it is obvious. See VC08-029.
                case _: ConcatOp => false
                case e => e.is_dispatching_call_impl(decl)
            }
        )
}

|" String literal (:rmlink:`2.6`).
@repr_name("Str")
class StringLiteral: BaseId implements TokenNode {
    |" Return the value that this literal denotes.
    @exported
    @external()
    fun denoted_value(): String

    fun has_context_free_type(): Bool = false

    |" Override of env_elements_impl for string literals, i.e. operators. We
    |" need to explicitly include operators on root types first, because those
    |" have precedence over the rest (see :rmlink:`8.6` - 29).
    @with_dynvars(env)
    fun env_elements_impl(): Array[Entity[AdaNode]] =
        node.root_type_ops(node.symbol).map((bd) => bd.as[AdaNode])
        & self.super()

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        # StringLiteral can be in a name, if it is an operator, in which
        # case we don't want to constrain its type.
        if node.parent is Name then self.super()
        else
            (
                node.expected_type_var() <-> node.type_var()
                %and {
                    bind error_location = node;
                    BaseTypeDecl.is_not_any_type%(node.expected_type_var())
                }
            )
            %and {
                bind error_location = node;
                BaseTypeDecl.allows_string_literal%(node.expected_type_var())
            }
}

|" The ``null`` literal (:rmlink:`4.4`).
@repr_name("Null")
class NullLiteral: SingleTokNode implements TokenNode {
    fun has_context_free_type(): Bool = false

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        BaseTypeDecl.is_access_type_predicate%(node.expected_type_var())
        %and node.expected_type_var() <-> node.type_var()
}

|" Base class for number literals (:rmlink:`2.4`).
@abstract
@repr_name("Num")
class NumLiteral: SingleTokNode implements TokenNode {
    fun is_constant(): Bool = true
}

|" Literal for an integer (:rmlink:`2.4`).
@repr_name("Int")
class IntLiteral: NumLiteral implements TokenNode {
    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = node.universal_int_bind(node.type_var())

    |" Return the value that this literal denotes.
    @exported
    @external()
    fun denoted_value(): BigInt
}

|" Literal for a real number (:rmlink:`2.4`).
@repr_name("Real")
class RealLiteral: NumLiteral implements TokenNode {
    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = node.universal_real_bind(node.type_var())
}

|" Synthetic identifier.
@synthetic
class SyntheticIdentifier: Name {
    sym: Symbol

    fun name_symbol(): Symbol = node.sym

    fun relative_name(): Entity[Name] = self
}

|" Name for Ada 2020 ``@`` (:rmlink:`5.2.1`).
class TargetName: Name {
    r_ref_var: LogicVar

    fun ref_var(): LogicVar = node.r_ref_var

    fun assign_statement(): AssignStmt =
        node.parents().find((p) => p is AssignStmt).as![AssignStmt]

    fun relative_name(): Entity[Name] =
        node.assign_statement().dest.as_entity.relative_name()

    @with_dynvars(env, origin, no_visibility=false)
    fun designated_env(): LexicalEnv =
        node.assign_statement().dest.as_entity.designated_env()

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        # Since we are binding self's variables to the corresponding variables
        # of an outer node, we use the ``bind_to_non_local`` constructor, which
        # will handle correctly the case where the current node and the outer
        # node are across a stop_resolution boundary.
        val dest = self.assign_statement().dest;

        node.bind_to_non_local(node.type_var(), dest, dest.type_var())
        %and node.bind_to_non_local(node.ref_var(), dest, dest.ref_var())
    }
}

|" Reference to the ``Update`` attribute, which is a non standard GNAT
|" attribute.
class UpdateAttributeRef: Name {
    @parse_field
    prefix: Name
    @parse_field
    attribute: Identifier
    @parse_field
    values: BaseAggregate
    r_ref_var: LogicVar

    fun ref_var(): LogicVar = node.r_ref_var

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        # Assign the type of the inner aggregate (self's ``values`` field) to
        # the type of the updated value. This allows the aggregate associations
        # inside of it to be resolved independently.
        # (see AggregateAssoc.xref_equation).
        val _ = self.prefix.resolve_names_internal(false);
        val prefix_type = self.prefix.type_val().as[BaseTypeDecl];

        self.values.as![Aggregate].type_var() <- prefix_type
        %and node.type_var() <- prefix_type
    }
}

|" Parenthesized expression.
class ParenExpr: Expr {
    @parse_field
    expr: Expr

    fun has_context_free_type(): Bool = node.expr.has_context_free_type()

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        (
            self.expr.sub_equation()
            %and node.expr.expected_type_var() <-> node.expected_type_var()
        )
        %and node.expr.type_var() <-> node.type_var()
}

|" Quantified expression (:rmlink:`4.5.8`).
class QuantifiedExpr: Expr {
    @parse_field
    quantifier: Quantifier
    @parse_field
    loop_spec: ForLoopSpec
    @parse_field
    expr: Expr

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        # NOTE: we need to resolve the spec first so that the indexing variable
        # has a type.
        val spec_success = self.loop_spec.resolve_names();

        if spec_success
        then
            (
                (
                    node.expr.expected_type_var() <- node.bool_type()
                    %and {
                        bind env = self.children_env;

                        self.expr.sub_equation()
                    }
                )
                %and self.expr.matches_expected_formal_type()
            )
            %and node.type_var() <-> node.expr.type_var()
        else %false
    }

    env_spec {
        add_env()
    }
}

|" Expression to raise an exception (:rmlink:`4.4`).
class RaiseExpr: Expr {
    @parse_field
    @nullable
    exception_name: Name
    @parse_field
    @nullable
    error_message: Expr

    fun has_context_free_type(): Bool = false

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.exception_name.sub_equation()
        %and node.expected_type_var() <-> node.type_var()
        %and self.error_message.do(
            (er) =>
            (
                # The expected type of that error message is always String,
                # according to RM 11.3 - 3.1/2.
                er.expected_type_var() <- node.std_string_type()
            )
            %and er.sub_equation(),
            default_val=%true
        )
}

|" Unary expression.
|"
|" This encompasses several ARM expressions, because it is used for every
|" unary operator in Ada. Those expressions are all documented in
|" :rmlink:`4.4`.
class UnOp: Expr {
    @parse_field
    op: Op
    @parse_field
    expr: Expr

    fun has_context_free_type(): Bool = false

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.expr.sub_equation()
        %and if
            node.in_aspect(s"Depends") or node.in_aspect(s"Refined_Depends")
        then %true
        else
            self.overload_equation()
            %or (
                node.expected_type_var() <-> node.expr.expected_type_var()
                %and {
                    bind logic_context =
                        LogicContext(
                            ref_node=self.op,
                            decl_node=null[Entity[AdaNode]]
                        );
                    node.type_var() <-> node.expr.type_var()
                }
            )

    @with_dynvars(origin, env)
    fun overload_equation(): Equation =
        self.op.subprograms().logic_any(
            (subp) => {
                bind logic_context =
                    LogicContext(ref_node=self.op, decl_node=subp);

                self.entity_eq(subp)
            }
        )

    @with_dynvars(origin, env, logic_context)
    fun entity_eq(subp: Entity[BasicDecl]): Equation = {
        val spec = subp.subp_spec_or_null();
        val ps = spec.unpacked_formal_params();

        if ps.length() == 1
        then (
            # The subprogram's first argument must match self's left
            # operand.
            (
                (
                    spec.call_argument_equation(
                        ps?[0].formal_decl(),
                        self.expr
                    )
                    %and (
                        # The subprogram's return type is the type of self
                        node.type_var() <- spec.return_type()
                    )
                )
                %and (
                    # The operator references the subprogram
                    {
                        bind logic_context = null[LogicContext];
                        node.op.ref_var() <- subp
                    }
                )
            )
            %and {
                bind logic_context = null[LogicContext];
                node.op.subp_spec_var() <- spec
            }
        )
        else %false
    }

    @with_dynvars(imprecise_fallback=false)
    fun potential_actuals_for_dispatch(
        spec: Entity[BaseSubpSpec]
    ): Array[ExpectedTypeForExpr] =
        [
            ExpectedTypeForExpr(
                expected_type=spec.abstract_formal_params()?[0]
                .type_expression(),
                expr=self.expr
            )
        ]

    @with_dynvars(imprecise_fallback=false)
    fun is_dispatching_call(): Bool = self.op.is_dispatching_call()
}

|" Represent the ``when ...`` filter after a for loop specification. This
|" class has no RM existence, it is used internally to wrap the filtering
|" expression, so as to have a dedicated name resolution entry point for it
|" and make sure it is resolved separatly from the ``ForLoopSpec`` itself
|" (which it cannot influence anyway).
class ForLoopIterFilter: AdaNode {
    @parse_field
    expr: Expr

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        val _ =
            self.parent.as[ForLoopSpec].do(
                (spec) =>
                if spec.is_iterated_assoc_spec()
                then spec.resolve_names_from_closest_entry_point()
                else true
            );

        node.expr.expected_type_var() <- node.bool_type()
        %and self.expr.sub_equation()
        %and self.expr.matches_expected_formal_type()
    }

    fun xref_entry_point(): Bool = true
}

|" Chunk of a format string literal.
class FormatStringChunk: AdaNode {
    @parse_field
    expr: Expr
    @parse_field
    string_tok: FormatStringTokNode

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.expr.sub_equation()
        # The RFC specifies that interpolated string expressions can be "of
        # any type", so we explicitly bind the expected type to null.
        %and node.expr.expected_type_var() <- null[Entity[AdaNode]]

    |" Return the Image subprogram declaration referred by this format string
    |" chunk expression.
    @exported
    fun image_subprogram(): Entity[BasicDecl] = {
        val expr_type = self.expr.expression_type();

        expr_type.get_aspect(s"Put_Image").value.as[Name].do(
            (pi) => pi.referenced_decl(),
            default_val=expr_type.synthesize_attribute_subprogram(s"Image")
        )
    }
}

|" Node holding a format string token.
@abstract
class FormatStringTokNode: AdaNode implements TokenNode {
    |" Return the value that this literal denotes.
    @exported
    @external()
    fun denoted_value(): String
}

|" Node holding a formatting "end" token.
class FormatStringTokEnd: FormatStringTokNode implements TokenNode {
}

|" Node holding a formatting "middle" token.
class FormatStringTokMid: FormatStringTokNode implements TokenNode {
}

|" Node holding a formatting "start" token.
class FormatStringTokStart: FormatStringTokNode implements TokenNode {
}

|" Node holding a formatting "string" token. This token is used when the
|" corresponding interpolated string doesn't have any expression to expand.
class FormatStringTokString: FormatStringTokStart implements TokenNode {
}

|" List of statements, with optional exception handlers (:rmlink:`11.2`).
@snaps
class HandledStmts: AdaNode {
    @parse_field
    stmts: StmtList
    @parse_field
    exceptions: ASTList[AdaNode]

    |" Return whether this list of statement has SPARK mode set to On
    |" (assuming that we are in a library-level package body statements
    |" section).
    fun spark_mode_aspect(): Aspect =
        self.stmts.take_while((stmt) => stmt is Pragma).find(
            (stmt) => stmt.as[Pragma].id.name_is(s"SPARK_Mode")
        )
        .do(
            (spark_mode) => spark_mode.as[Pragma].as_aspect(),
            # Else, look at the body declarative part
            default_val=self.parent.as[PackageBody].do(
                (body) => body.decls.spark_mode_aspect(),
                default_val=self.semantic_parent().spark_mode_aspect()
            )
        )
}

|" Kind of interface type.
enum class InterfaceKind: AdaNode {
    case Limited, Task, Protected, Synchronized
}

|" Iteration type for ``for`` loops.
enum class IterType: AdaNode {
    case In, Of
}

|" Library item in a compilation unit (:rmlink:`10.1.1`).
class LibraryItem: AdaNode {
    @parse_field
    has_private: Private
    @parse_field
    item: BasicDecl
}

|" Qualifier for the ``limited`` keyword.
@qualifier
enum class Limited: AdaNode {
}

|" Base class for loop specifications (:rmlink:`5.5`).
@abstract
class LoopSpec: AdaNode {
}

|" Specification for a ``for`` loop (:rmlink:`5.5`).
class ForLoopSpec: LoopSpec {
    @parse_field
    var_decl: ForLoopVarDecl
    @parse_field
    loop_type: IterType
    @parse_field
    has_reverse: Reverse
    @parse_field
    iter_expr: AdaNode
    @parse_field
    @nullable
    iter_filter: ForLoopIterFilter

    |" Return whether this for loop spec is part of an iterated component
    |" association.
    fun is_iterated_assoc_spec(): Bool = node.parent is IteratedAssoc

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.var_decl.sub_equation()
        %and match node.loop_type {
            # This is a for .. in
            case _: IterType.In =>
            # Let's handle the different possibilities
                match self.iter_expr {
                    # Anonymous range case: for I in 1 .. 100
                    case binop: BinOp =>
                        (
                            binop.sub_equation()
                            %and (
                                # The default type, if there is no other
                                # determined type, is Integer.
                                BaseTypeDecl.is_not_root_int_type%(binop
                                .type_var())
                            )
                        )
                        %and node.var_decl.id.type_var() <-> binop.type_var()

                    # Subtype indication case: the induction variable is of the
                    # type.
                    case t: SubtypeIndication =>
                        t.sub_equation()
                        %and node.var_decl.id.type_var()
                        <- t.designated_type().canonical_type()
                    case r: AttributeRef =>
                        r.sub_equation()
                        %and node.var_decl.id.type_var() <-> r.type_var()

                    # Name case: Either the name is a subtype indication, or an
                    # attribute on a subtype indication, in which case the
                    # logic is the same as above, either it's an expression
                    # that yields an iterator.
                    case t: Name =>
                        t.sub_equation()
                        %and t.name_designated_type().do(
                            (typ) =>
                            node.var_decl.id.type_var()
                            <- typ.canonical_type(),
                            default_val=(
                                # Make sure null is not a possible value to
                                # avoid a null dereference in the subsequent
                                # predicate.
                                AdaNode.is_not_null%(t.type_var())
                            )
                            %and BaseTypeDecl.is_iterator_type%(t.type_var())
                            %and node.var_decl.id.type_var()
                            <- BaseTypeDecl.cursor_type%(t.type_var())
                        )
                    case _ => %true
                }

            # Should never happen: this is a for .. of.
            case _: IterType.Of =>
                self.iter_expr.as[Expr].do(
                    (iter_expr) =>
                    (
                        (
                            self.var_decl.id_type.do(
                                (typ) =>
                                iter_expr.expected_type_var()
                                <- typ.designated_type(),
                                default_val=%true
                            )
                            %and iter_expr.sub_equation()
                        )
                        %and AdaNode.is_not_null%(iter_expr.type_var())
                    )
                    %and node.var_decl.id.type_var()
                    <- BaseTypeDecl.iterable_comp_type_or_null%(
                        iter_expr.type_var()
                    ),
                    default_val=%false
                )
        }

    # This spec is not a complete resolution context when part of an iterated
    # component association: we must know the type of the enclosing aggregate
    # to determine the type of the iteration variable in case of a `for I in`.
    fun xref_entry_point(): Bool = not node.is_iterated_assoc_spec()
}

|" Specification for a ``while`` loop (:rmlink:`5.5`).
class WhileLoopSpec: LoopSpec {
    @parse_field
    expr: Expr

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.expr.sub_equation() %and self.expr.expect_bool_derived_type()
}

|" Syntactic indicators for passing modes in formals (:rmlink:`6.1`).
enum class Mode: AdaNode {
    case In, Out, InOut, Default

    |" Return whether this mode allows the qualified entity to be written or
    |" not.
    fun is_writable(): Bool = node is Mode.Out | Mode.InOut
}

|" Node that holds several AbstractStateDecl nodes, which is necessary when
|" the Abstract_State aspect is associated with an aggregate in order to
|" declare a list of abstract states.
class MultiAbstractStateDecl: AdaNode {
    @parse_field
    decls: AbstractStateDeclList
}

|" Qualifier for the ``not null`` keywords.
@qualifier
enum class NotNull: AdaNode {
}

|" Placeholder for the ``null`` in lists of components (:rmlink:`3.8`).
class NullComponentDecl: AdaNode {
}

|" ``other`` designator.
class OthersDesignator: AdaNode {
    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = %true
}

|" Syntactic indicators for subprogram overriding modes.
enum class Overriding: AdaNode {
    case Overriding, NotOverriding, Unspecified
}

|" List of parameter specifications.
class Params: AdaNode {
    @parse_field
    params: ASTList[ParamSpec]
}

|" Holds an AbstractStateDecl between parentheses. Needed to support the
|" syntax:
|"
|" .. code:: ada
|"
|"     package Pkg
|"         with Abstract_State => (A, (B with Some_Aspect))
class ParenAbstractStateDecl: AdaNode {
    @parse_field
    decl: AdaNode
}

|" Base node for all preprocessor directives.
@abstract
class PpDirective: AdaNode {
}

|" ``else`` preprocessor directive.
class PpElseDirective: PpDirective {
}

|" ``elsif ... [then]`` preprocessor directive.
class PpElsifDirective: PpDirective {
    @parse_field
    expr: Expr
    @parse_field
    @nullable
    then_kw: PpThenKw
}

|" ``end if;`` preprocessor directive.
class PpEndIfDirective: PpDirective {
}

|" ``if ... [then]`` preprocessor directive.
class PpIfDirective: PpDirective {
    @parse_field
    expr: Expr
    @parse_field
    @nullable
    then_kw: PpThenKw
}

# Unparsers require to have a single sequence of tokens for a given node.
# We need parsers for ``PpIfDirective`` and ``PpElseDirective`` to accept
# both ``[els]if X then`` and ``[els]if X`` syntax forms, so we have to
# create a (possible null) ``then_kw`` field for both.
|" ``then`` keyword in preprocessor directives.
class PpThenKw: AdaNode {
}

|" Class for pragmas (:rmlink:`2.8`). Pragmas are compiler directives,
|" that can be language or compiler defined.
class Pragma: AdaNode {
    @parse_field
    id: Identifier
    @parse_field
    args: ASTList[BaseAssoc]

    fun xref_entry_point(): Bool = true

    |" Return whether this pragma is ghost code or not. See SPARK RM 6.9.
    @exported
    fun is_ghost_code(): Bool =
        # We only consider pragmas that can be in lists of statements for the
        # moment.
        self.id.sym() in s"Assert"
            | s"Assert_And_Cut"
            | s"Assume"
            | s"Loop_Invariant"

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        if
            self.id.name_is(s"Assert") or self.id.name_is(s"Loop_Invariant")
            or self.id.name_is(s"Compile_Time_Warning")
            or self.id.name_is(s"Compile_Time_Error")
        then
            {
                val expr = self.args?[0].assoc_expr();

                expr.sub_equation() %and expr.expect_bool_derived_type()
            }
            %and self.args?[1].do(
                (arg) =>
                arg.assoc_expr().do(
                    (msg) =>
                    (
                        msg.expected_type_var() <- node.std_string_type()
                        %and msg.sub_equation()
                    )
                    %and msg.matches_expected_type(),
                    default_val=%true
                ),
                default_val=%true
            )
        elif self.id.name_is(s"Unreferenced")
        then
            self.args.logic_all(
                (assoc) => assoc.assoc_expr().as![Name].xref_no_overloading()
            )
        elif
            self.id.name_symbol() in s"Import"
                | s"Export"
                | s"Interface"
                | s"Convention"
                | s"Pack"
                | s"Pure"
                | s"Preelaborate"
                | s"Elaborate_Body"
                | s"Inline"
                | s"Volatile"
        then
            self.associated_entity_names().logic_all(
                (n) => n.xref_no_overloading()
            )
        elif self.id.name_is(s"Warnings")
        then
            self.args.logic_all(
                (arg) =>
                arg.assoc_expr().do(
                    (expr) =>
                    if expr is Identifier
                    then (
                        if
                            expr.as[Identifier].name_symbol() in s"On"
                                | s"Off"
                                | s"GNAT"
                                | s"GNATprove"
                        then %true
                        else expr.as[Identifier].xref_no_overloading()
                    )
                    else (
                        expr.expected_type_var() <- node.std_string_type()
                        %and expr.sub_equation()
                        %and expr.matches_expected_type()
                    ),
                    default_val=%true
                )
            )

        # Pragmas we want to deliberately not resolve, either because there
        # is nothing to resolve in there, or because we don't know how to
        # resolve them and don't want to spend effort implementing
        # resolution for them (for example, other compilers implementation
        # defined pragmas).
        elif
            self.id.name_symbol() in s"Style_Checks"
                | s"Import_Function"
                | s"Import_Procedure" then %true
        elif
            self.id.name_symbol() in s"Pre"
                | s"Post"
                | s"Pre'Class"
                | s"Post'Class"
                | s"Precondition"
                | s"Postcondition"
                | s"Precondition'Class"
                | s"Postcondition'Class"
                | s"Initial_Condition"
        then
            self.args?[0].assoc_expr().do(
                (expr) =>
                (
                    expr.expected_type_var() <- node.bool_type()
                    %and expr.sub_equation()
                )
                %and expr.matches_expected_formal_type(),
                default_val=%false
            )
        elif self.id.name_is(s"Test_Case")
        then
            self.args.filter(
                (arg) =>
                arg.as[PragmaArgumentAssoc].do(
                    (parg) =>
                    parg.name.name_symbol() in s"Requires" | s"Ensures"
                )
            )
            .logic_all(
                (arg) =>
                (
                    arg.assoc_expr().expected_type_var() <- node.bool_type()
                    %and arg.assoc_expr().sub_equation()
                )
                %and arg.assoc_expr().matches_expected_formal_type()
            )
        elif self.id.name_is(s"Contract_Cases")
        then
            self.args?[0].assoc_expr().as[BaseAggregate].assocs.logic_all(
                (assoc) =>
                assoc.as[AggregateAssoc].contract_cases_assoc_equation()
            )
        elif self.id.name_is(s"Loop_Variant")
        then
            self.args.logic_all((arg) => {
                val parg = arg.as[PragmaArgumentAssoc];
                parg.expr.spark_variant_equation(parg.name.as[BaseId])
            })
        elif self.id.name_is(s"Debug")
        then
            (
                # If we have two arguments, the first one is a conditional
                # expression.
                if self.args.length() == 2
                then {
                    val expr = self.args?[0].assoc_expr();

                    (
                        expr.expected_type_var() <- node.bool_type()
                        %and expr.sub_equation()
                    )
                    %and expr.matches_expected_formal_type()
                }
                else %true
            )
            %and {
                val proc = self.args?[self.args.length() - 1]?.assoc_expr();

                proc.type_var() <- null[Entity[BaseTypeDecl]]
                %and proc.sub_equation()
            }
        elif self.id.name_is(s"Annotate")
        then (
            # For the Annotate pragma, the first two identifiers are not
            # analyzed. The rest are arbitrary expressions (see
            # `Expr.annotate_argument_equation`). Optionally, a final
            # association `Entity => <name>` can be given, where `name`
            # must resolve to a local declaration.
            self.args.ilogic_all(
                (arg, i) =>
                if i < 2 then %true
                elif arg.as[PragmaArgumentAssoc]?.name?.name_is(s"Entity")
                then arg.assoc_expr().as![Name].xref_no_overloading()
                else arg.assoc_expr().annotate_argument_equation()
            )
        )
        else
            self.args.logic_all(
                (a) =>
                (
                    # In the default case, we try to resolve every associated
                    # expression, but we never fail, in order to not generate
                    # diagnostics for unknown/implementation defined pragmas.
                    a.assoc_expr().sub_equation()
                )
                %or %true
            )

    |" Return the expression representing the "value" of this pragma, which
    |" will be used to fill the ``value`` field of the ``Aspect`` struct
    |" returned by calls to ``get_aspect``. This property doesn't make sense
    |" for all pragmas but tries to give the most reasonable answer, and in
    |" particular tries to match what ``get_aspect`` would return if the
    |" pragma was replaced by its equivalent aspect.
    |" For example, on ``pragma Convention (C, X)``, the returned value is
    |" ``C`` because one would write ``X : Integer with Convention => C``.
    fun value_expr(): Entity[Expr] =
        if
            self.id.name_symbol() in s"Import"
                | s"Export"
                | s"Interface"
                | s"Convention"
        then self.args?[0].assoc_expr()
        # SPARK_Mode can have no associated value (in that case, the
        # default is `On`) but if a value is provided, it's in first
        # position.

        elif self.id.name_is(s"SPARK_Mode") then self.args?[0]?.assoc_expr()
        else self.args?[1]?.assoc_expr()

    fun associated_entity_names(): Array[Entity[Name]] =
        if
            self.id.name_symbol() in s"Import"
                | s"Export"
                | s"Interface"
                | s"Convention"
        then [self.args?[1].assoc_expr().as![Name]]
        elif self.id.name_is(s"Inline")
        then self.args.map((a) => a.assoc_expr().as[Name])
        elif
            self.id.name_symbol() in s"Pack"
                | s"Pure"
                | s"Preelaborate"
                | s"Elaborate_Body"
                | s"Volatile"
                | s"Volatile_Components"
                | s"Unchecked_Union"
                | s"Atomic"
                | s"Atomic_Components"
                | s"No_Return"
                | s"Discard_Names"
                | s"Independent"
                | s"Independent_Components"
                | s"Asynchronous"
                | s"Interrupt_Handler"
                | s"Attach_Handler"
                | s"Predicate"
        then self.args?[0]?.assoc_expr().as[Name].do((v1) => [v1])
        elif self.id.name_is(s"Obsolescent")
        then
            self.args?[0]?.assoc_expr().as[Name].do(
                # Pragma Obsolescent can have a StringLiteral as a first
                # argument, in which case there is no associated entity with
                # it.
                (name) =>
                if not name is StringLiteral then [name]
                else null[Array[Entity[Name]]]
            )
        elif self.id.name_is(s"Annotate")
        then (
            # For pragma Annotate, the associated name is given by an
            # `Entity => <name>` association, if any.
            self.args.find(
                (a) => a.as[PragmaArgumentAssoc]?.name?.name_is(s"Entity")
            )
            .do(
                (a) => a.as[PragmaArgumentAssoc].expr.as[Name].do((v2) => [v2])
            )
        )
        else null[Array[Entity[Name]]]

    fun associated_entities_helper(): Array[Entity[DefiningName]] =
        self.associated_entity_names().mapcat(
            (name) =>
            self.semantic_parent().do(
                (parent) =>
                parent.children_env.get(
                    name.name_symbol(),
                    lookup=LookupKind.flat,
                    categories=RefCategories(
                        inherited_primitives=false,
                        _=true
                    )
                )
                .map(
                    (decl) =>
                    decl.as[BasicDecl].wrap_public_reference().defining_names()
                    .find(
                        (dn) =>
                        # Find the scope in which this pragma lies by fetching
                        # the closest lexical scope. We don't use
                        # ``declarative_scope`` here, as some decls do not lie
                        # in a DeclarativePart, such as ComponentDecls.  Get
                        # entities in it Map to the public view, to work on the
                        # instantiation nodes instead of the Generic*Internal
                        # nodes.
                        dn.name_is(name.name_symbol())
                    )
                )
            )
            .filter(
                (ent) =>
                # Only get entities that are after self in the *same*
                # source.
                ent.unit == node.unit and ent.node < node
            )
        )

    |" Return an array of ``BasicDecl`` instances associated with this pragma,
    |" or an empty array if non applicable.
    @exported
    fun associated_entities(): Array[Entity[DefiningName]] = {
        val top_level_decl =
            node.parent.parent.as[CompilationUnit].do(
                (cu) =>
                [cu.body.as![LibraryItem].item.as_entity.defining_name()],
                default_val=null[Array[Entity[DefiningName]]]
            );
        val enclosing_program_unit =
            node.parents(with_self=false).find((p) => p is BasicDecl)
            .as[BasicDecl]
            .as_entity;

        # TODO: This should be using a ._or, but is waiting on a fix for
        # R903-028.
        # NOTE: The whole reason we have to implement custom resolution for
        # decls associated to a pragma, is because there can be several
        # associated decls, so the regular crossref mechanism is not
        # sufficient, as in the following example::
        #
        #     procedure Foo;
        #     procedure Foo (A : Integer);
        #     pragma Inline (Foo);
        self.associated_entity_names().do(
            (names) => {
                val p = self.associated_entities_helper() or? top_level_decl;

                if p != null[Array[Entity[DefiningName]]] then p
                else
                    enclosing_program_unit.do(
                        (epu) =>
                        if
                            names.length() == 1
                            and names?[0].referenced_decl() == epu
                        then [epu.defining_name()]
                        else null[Array[Entity[DefiningName]]],
                        default_val=top_level_decl
                    )
            },
            default_val=(
                # If no name
                if
                    (
                        # either it's a contract pragma...
                        node.is_contract_aspect(self.id.name_symbol())
                    )
                    or (
                        # or the Obsolescent pragma
                        self.id.name_is(s"Obsolescent")
                    )
                then (
                    # in which case they are attached to the closest
                    # declaration above it. We could have used a call to
                    # previous_sibling here to find the closest declaration
                    # above it but since declarations are in lists we can
                    # directly search it in the parent list to save time
                    # (previous_sibling has a linear complexity so it can be
                    # very inefficient if we have a long list of pragma to
                    # process before reaching the declaration associated to
                    # them).
                    node.parent.as[ASTList[AdaNode]].do(
                        (decls) =>
                        decls.filter(
                            (decl) => decl is BasicDecl and node > decl
                        )
                        .do((decls) => decls?[decls.length() - 1])
                        .as[BasicDecl]
                        .as_entity
                        .do((v1) => [v1])
                    )
                    or? [enclosing_program_unit]
                )
                else (
                    # Or else to the closest parent subprogram.  Or else it's
                    # necessarily a program unit pragma.
                    [enclosing_program_unit]
                )
            )
            .map((bd) => bd.defining_name())
        )
    }

    |" Return the initial env name for a pragma clause. We use the
    |" Standard package for top level use clauses. For contract pragmas such
    |" as ``Precondition`` or ``Predicate``, we use the env of the entity the
    |" pragma is associated with in order to properly resolve references to
    |" formals or to the type's ``SyntheticObjectDecl`` instance.
    fun initial_env(): DesignatedEnv =
        if node.parent.parent is CompilationUnit
        then
            DesignatedEnv(
                kind=DesignatedEnvKind.named_env,
                env_name=s"Standard",
                direct_env=null[LexicalEnv]
            )
        elif
            node.as_bare_entity.id.name_symbol() in s"Pre"
                | s"Post"
                | s"Pre'Class"
                | s"Post'Class"
                | s"Precondition"
                | s"Postcondition"
                | s"Precondition'Class"
                | s"Postcondition'Class"
                | s"Test_Case"
                | s"Contract_Cases"
                | s"Predicate"
        then
            node.as_bare_entity.associated_entities()?[0].do(
                (ent) =>
                DesignatedEnv(
                    kind=DesignatedEnvKind.direct_env,
                    env_name=null[Symbol],
                    direct_env=ent.children_env
                ),
                default_val=DesignatedEnv(
                    kind=DesignatedEnvKind.current_env,
                    env_name=null[Symbol],
                    direct_env=null[LexicalEnv]
                )
            )
        else
            DesignatedEnv(
                kind=DesignatedEnvKind.current_env,
                env_name=null[Symbol],
                direct_env=null[LexicalEnv]
            )

    |" Return this pragma as an ``Aspect`` struct.
    fun as_aspect(inherited: Bool = false): Aspect =
        Aspect(
            exists=true,
            node=self,
            value=self.value_expr(),
            inherited=inherited
        )

    env_spec {
        set_initial_env(node.initial_env())
    }
}

|" Qualifier for the ``private`` keyword.
@qualifier
enum class Private: AdaNode {
}

|" Type definition for a protected object (:rmlink:`9.4`).
class ProtectedDef: AdaNode {
    @parse_field
    public_part: PublicPart
    @parse_field
    @nullable
    private_part: PrivatePart
    @parse_field
    @nullable
    end_name: EndName
}

|" Qualifier for the ``protected`` keyword.
@qualifier
enum class Protected: AdaNode {
}

|" Type for quantified expressions.
enum class Quantifier: AdaNode {
    case All, Some
}

|" Range specification (:rmlink:`3.5.7`).
class RangeSpec: AdaNode {
    @parse_field
    range: Expr

    @with_dynvars(env, origin)
    fun xref_stop_resolution(): Bool = node.parent is ComponentClause

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.range.xref_equation()
        # Ada RM says that for component clauses and signed int type
        # definitions, the expected type is any integer type.
        %and if node.parent is ComponentClause | SignedIntTypeDef
        then
            node.universal_int_bind(node.range.expected_type_var())
            %and self.range.matches_expected_type()

        # In the following cases, expressions from the range specification are
        # expected to be of any real type, the types need not be the same.
        elif
            node.parent is DeltaConstraint
            | DigitsConstraint
            | OrdinaryFixedPointDef
            | DecimalFixedPointDef
        then
            node.universal_real_bind(node.range.expected_type_var())
            %and self.range.matches_expected_type()

        else %true
}

|" Renaming clause, used everywhere renamings are valid.
class RenamingClause: AdaNode {
    @parse_field
    renamed_object: Name
}

|" Synthetic renaming clause. Used to synthesize object decls with renamings.
|" (See to_anonymous_object_decl).
@synthetic
class SyntheticRenamingClause: RenamingClause {
}

|" Qualifier for the ``reverse`` keyword.
@qualifier
enum class Reverse: AdaNode {
}

|" Alternative part in a ``select`` statements block (:rmlink:`9.7`).
class SelectWhenPart: AdaNode {
    @parse_field
    @nullable
    cond_expr: Expr
    @parse_field
    stmts: StmtList

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.cond_expr.do(
            (c) => c.sub_equation() %and c.expect_bool_derived_type(),
            default_val=%true
        )
}

|" Bass class for statements (:rmlink:`5.1`).
@abstract
class Stmt: AdaNode {
    fun xref_entry_point(): Bool = true

    |" Return whether this statement is ghost code or not. See SPARK RM 6.9.
    @exported
    fun is_ghost_code(): Bool =
        # Either this statement is part of a ghost declaration like a ghost
        # package or function.
        self.parent_basic_decl().do((bd) => bd.is_ghost_code())

        # Either it's an implicitly ghost statement, because it's assigning
        # to a ghost variable, or calling a ghost procedure.
        or match self {
            case ass: AssignStmt => ass.dest.failsafe_referenced_def_name()
            case call: CallStmt => call.call.failsafe_referenced_def_name()
            case _ => null[RefdDef]
        }
        .do(
            (res) =>
            # Sometimes name resolution errors are materialized by None
            # being returned from the queries instead of a property error.
            # But None doesn't necessarily mean there was an error, so we
            # explicitly handle the error cases by raising an exception as
            # we don't want errors to be silently ignored, and we use the
            # null coalescing operator to handle the legitimate cases.
            if res.kind == RefResultKind.error
            then raise[Bool] PropertyError("Name resolution error")
            else res.def_name?.is_ghost_code()
        )
}

|" Base class for composite statements (:rmlink:`5.1`).
@abstract
class CompositeStmt: Stmt {
}

|" ``accept`` statement (:rmlink:`9.5.2`).
class AcceptStmt: CompositeStmt {
    @parse_field
    body_decl: AcceptStmtBody
    @parse_field
    @nullable
    entry_index_expr: Expr
    @parse_field
    params: EntryCompletionFormalParams

    @with_dynvars(origin, env)
    fun designated_entry(): Entity[EntryDecl] =
        self.body_decl.name.all_env_els_impl().find(
            (e) =>
            e.as[EntryDecl].do((d) => d.spec.match_formal_params(self.params))
        )
        .as[EntryDecl]

    |" Return the entry which corresponds to this accept statement.
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun corresponding_entry(): Entity[EntryDecl] = {
        bind env = self.node_env;

        self.designated_entry()
    }

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        node.body_decl.name.ref_var() <- self.designated_entry()
        %and self.entry_index_expr.do(
            (e) =>
            (
                # :rmlink:`9.5.2`: The expected type for entry_index_expr is
                # that of the type defined by the definition of the
                # corresponding entry declaration.
                e.expected_type_var() <- self.designated_entry().family_type()
            )
            %and e.sub_equation(),
            default_val=%true
        )

    env_spec {
        add_all_to_env(
            [
                EnvAssoc(
                    key=self.body_decl.name.relative_name().name_symbol(),
                    value=node.body_decl,
                    dest_env=DesignatedEnv(
                        kind=DesignatedEnvKind.current_env,
                        env_name=null[Symbol],
                        direct_env=null[LexicalEnv]
                    ),
                    metadata=null[Metadata]
                )
            ]
        )
        add_env()
    }
}

|" Extended ``accept`` statement (:rmlink:`9.5.2`).
class AcceptStmtWithStmts: AcceptStmt {
    @parse_field
    stmts: HandledStmts
    @parse_field
    @nullable
    end_name: EndName
}

|" Base class for loop statements (:rmlink:`5.5`).
@abstract
class BaseLoopStmt: CompositeStmt {
    @parse_field
    @nullable
    spec: LoopSpec
    @parse_field
    stmts: StmtList
    @parse_field
    @nullable
    end_name: EndName

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.spec.do((s) => s.xref_equation(), default_val=%true)
}

|" Statement for ``for`` loops (``for ... loop ... end loop;``)
|" (:rmlink:`5.5`).
class ForLoopStmt: BaseLoopStmt {
    env_spec {
        add_env()
    }
}

|" Statement for simple loops (``loop ... end loop;``) (:rmlink:`5.5`).
class LoopStmt: BaseLoopStmt {
}

|" Statement for ``while`` loops (``while ... loop ... end loop;``)
|" (:rmlink:`5.5`).
class WhileLoopStmt: BaseLoopStmt {
}

|" Base class for statement blocks (:rmlink:`5.6`).
@abstract
class BlockStmt: CompositeStmt {
    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = %true

    env_spec {
        add_env()
    }
}

|" Statement block with no declarative part (:rmlink:`5.6`).
class BeginBlock: BlockStmt {
    @parse_field
    stmts: HandledStmts
    @parse_field
    @nullable
    end_name: EndName
}

|" Statement block with a declarative part (:rmlink:`5.6`).
class DeclBlock: BlockStmt {
    @parse_field
    decls: DeclarativePart
    @parse_field
    stmts: HandledStmts
    @parse_field
    @nullable
    end_name: EndName

    fun immediate_declarative_region(): LexicalEnv = self.children_env
}

|" ``case`` statement (:rmlink:`5.4`).
class CaseStmt: CompositeStmt {
    @parse_field
    expr: Expr
    @parse_field
    pragmas: ASTList[Pragma]
    @parse_field
    alternatives: ASTList[CaseStmtAlternative]

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.expr.sub_equation()
        %and (
            (
                # First make sure null is not a possible value for the type of
                # the expression so as to avoid a null check in subsequent
                # predicates.
                AdaNode.is_not_null%(node.expr.type_var())
            )
            %and (
                # Then make sure it is a discrete type
                BaseTypeDecl.is_discrete_type%(node.expr.type_var())
            )
        )
}

|" Extended ``return`` statement (:rmlink:`6.5`).
class ExtendedReturnStmt: CompositeStmt {
    @parse_field
    decl: ExtendedReturnStmtObjectDecl
    @parse_field
    @nullable
    stmts: HandledStmts

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = %true

    env_spec {
        add_env()
    }
}

|" ``if`` statement block (:rmlink:`5.3`).
class IfStmt: CompositeStmt {
    @parse_field
    cond_expr: Expr
    @parse_field
    then_stmts: StmtList
    @parse_field
    alternatives: ASTList[ElsifStmtPart]
    @parse_field
    else_stmts: StmtList

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.cond_expr.sub_equation()
        %and node.cond_expr.expect_bool_derived_type()
}

|" Wrapper class, used for composite statements that can be named (declare
|" blocks, loops). This allows to both have a BasicDecl for the named entity
|" declared, and a CompositeStmt for the statement hierarchy.
class NamedStmt: CompositeStmt {
    @parse_field
    decl: NamedStmtDecl
    @parse_field
    stmt: CompositeStmt

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = %true

    env_spec {
        add_to_env_kv(node.decl.name_symbol(), node.decl)
        add_env()
    }
}

|" ``select`` statements block (:rmlink:`9.7`).
class SelectStmt: CompositeStmt {
    @parse_field
    guards: ASTList[SelectWhenPart]
    @parse_field
    else_stmts: StmtList
    @parse_field
    abort_stmts: StmtList

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.guards.logic_all((wp) => wp.sub_equation())
}

|" Placeholder node for syntax errors in lists of statements.
class ErrorStmt: Stmt implements ErrorNode {
}

|" Base class for simple statements (:rmlink:`5.1`).
@abstract
class SimpleStmt: Stmt {
}

|" ``abort`` statement (:rmlink:`9.8`).
class AbortStmt: SimpleStmt {
    @parse_field
    names: ASTList[Name]

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.names.logic_all(
            (name) =>
            name.sub_equation()
            %and BaseTypeDecl.is_task_type%(name.type_var())
        )
}

|" Statement for assignments (:rmlink:`5.2`).
class AssignStmt: SimpleStmt {
    @parse_field
    dest: Name
    @parse_field
    expr: Expr

    @with_dynvars(origin)
    fun complete_item_weight(item: Entity[BasicDecl]): Int =
        node.complete_item_weight_matching_type(item, self.dest)

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        (
            (
                self.dest.sub_equation()
                %and node.expr.expected_type_var()
                <- BaseTypeDecl.derefed_type%(node.dest.type_var())
            )
            %and self.expr.sub_equation()
        )
        %and node.expr.matches_expected_assign_type()
}

|" Statement for entry or procedure calls (:rmlink:`6.4`).
class CallStmt: SimpleStmt {
    @parse_field
    call: Name

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.call.sub_equation()
        # Call statements can have no return value
        %and node.call.type_var() <- null[Entity[AdaNode]]
}

|" ``delay`` statement (:rmlink:`9.6`).
class DelayStmt: SimpleStmt {
    @parse_field
    has_until: Until
    @parse_field
    expr: Expr

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.expr.sub_equation()
        %and if node.has_until.as_bool() then %true
        else
            node.expr.expected_type_var() <- node.std_entity(s"Duration")
            %and self.expr.matches_expected_type()
}

|" ``exit`` statement (:rmlink:`5.7`).
class ExitStmt: SimpleStmt {
    @parse_field
    @nullable
    loop_name: Name
    @parse_field
    @nullable
    cond_expr: Expr

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.cond_expr.do(
            (cond) => cond.sub_equation() %and cond.expect_bool_derived_type(),
            default_val=%true
        )
        %and self.loop_name.do(
            (ln) => ln.xref_no_overloading(),
            default_val=%true
        )
}

|" ``goto`` statement (:rmlink:`5.8`).
class GotoStmt: SimpleStmt {
    @parse_field
    label_name: Name

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.label_name.xref_no_overloading(sequential=false)
}

|" Statement to declare a code label (:rmlink:`5.1`).
class Label: SimpleStmt {
    @parse_field
    decl: LabelDecl

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = %true
}

|" ``null;`` statement (:rmlink:`5.1`).
class NullStmt: SimpleStmt {
    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = %true
}

|" ``raise`` statement (:rmlink:`11.3`).
class RaiseStmt: SimpleStmt {
    @parse_field
    @nullable
    exception_name: Name
    @parse_field
    @nullable
    error_message: Expr

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.exception_name.do((en) => en.sub_equation(), default_val=%true)
        %and self.error_message.do(
            (er) =>
            (
                # The expected type of that error message is always String,
                # according to RM 11.3 - 3.1/2.
                er.expected_type_var() <- node.std_string_type()
            )
            %and er.sub_equation(),
            default_val=%true
        )
}

|" ``requeue`` statement (:rmlink:`9.5.4`).
class RequeueStmt: SimpleStmt {
    @parse_field
    call_name: Name
    @parse_field
    has_abort: Abort

    fun innermost_entry_or_accept_stmt_params(

    ): Entity[BaseFormalParamHolder] =
        match
            self.parents().find((p) => p is AcceptStmtWithStmts | EntryBody)
        {
            case a: AcceptStmtWithStmts => a.params
            case b: EntryBody => b.params
            case _ => null[Entity[EntryCompletionFormalParams]]
        }
        .as[BaseFormalParamHolder]

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        val ce = self.call_name.as[CallExpr];
        val name = ce.do((ce) => ce.name, default_val=self.call_name);
        val targets =
            name.all_env_elements_internal().filter(
                (n) =>
                n.as[BasicDecl].do(
                    (e) =>
                    (
                        # RM 9.5.4: the name shall resolve to denote a
                        # procedure or entry, where either:
                        #
                        # 1. The profile is empty.
                        e.subp_spec_or_null().do(
                            (ss) =>
                            ss.nb_max_params() == 0 and ss.returns().is_null
                        )
                    )
                    or (
                        # 2. The profile matches the profile of the enclosing
                        # entry/accept stmt.
                        e.subp_spec_or_null().do(
                            (ss) =>
                            ss.match_formal_params(
                                self.innermost_entry_or_accept_stmt_params(),
                                match_names=not e is SubpRenamingDecl
                            )
                        )
                    )
                    or (
                        # 3. The target denotes a prefixed view of a primitive
                        # subprogram of a synchronized interface, where the
                        # first parameter of the unprefixed view of the
                        # primitive subprogram shall be a controlling
                        # parameter, and the Synchronization aspect shall be
                        # specified with synchronization_kind By_Entry for the
                        # primitive subprogram.
                        if
                            e.get_aspect_spec_expr(s"Synchronization")
                            .as[Name]
                            ?.name_is(s"By_Entry")
                        then
                            e.subp_spec_or_null().do(
                                (ss) =>
                                ss.match_formal_params(
                                    self
                                    .innermost_entry_or_accept_stmt_params(),
                                    match_names=false,
                                    ignore_first_param=e.info.md.dottable_subp
                                )
                            )
                        else false
                    )
                )
            );

        (
            # We call xref_no_overloading to make sure that sub-names are
            # bound.
            match name {
                # If name is a DottedName, prefix can be a CallExpr that should
                # be resolved using sub_equation.
                case dn: DottedName =>
                    (
                        if dn.prefix is CallExpr then dn.prefix.sub_equation()
                        else dn.prefix.xref_no_overloading()
                    )
                    %and {
                        bind env = dn.prefix.designated_env();

                        dn.suffix.xref_no_overloading()
                    }
                case o => o.xref_no_overloading()
            }
        )
        %and (
            # Then, bind the name to any entry that fits the bills
            targets.logic_any(
                (e) => {
                    # If we're binding to an entry from an entry family,
                    # resolve the expression in the call expr, knowing that it
                    # can be used to resolve overloads.
                    val fam_type =
                        e
                        .as[EntryDecl]
                        ?.spec
                        .family_type
                        .as[SubtypeIndication]
                        ?.designated_type();
                    val first_param = ce?.params()?[0]?.expr();

                    first_param.do(
                        (p) =>
                        p.sub_equation()
                        %and fam_type.do(
                            (eft) =>
                            p.expected_type_var() <- eft
                            %and p.matches_expected_type(),
                            default_val=%true
                        ),
                        default_val=%true
                    )
                }
            )
        )
    }
}

|" ``return`` statement (:rmlink:`6.5`).
class ReturnStmt: SimpleStmt {
    @parse_field
    @nullable
    return_expr: Expr

    |" Returns the subprogram this return statement belongs to
    fun subp(): Entity[SubpBody] =
        node.parents().find((p) => p is SubpBody).as[SubpBody].as_entity

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.return_expr.do(
            (rexpr) =>
            (
                rexpr.expected_type_var()
                <- self.subp().subp_spec.returns().designated_type()
                %and rexpr.sub_equation()
            )
            %and rexpr.matches_expected_assign_type(),
            default_val=%true
        )
}

|" Statement wrapping a simple object declaration.
class SimpleDeclStmt: SimpleStmt {
    @parse_field
    decl: ObjectDecl

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = %true
}

|" ``terminate`` alternative in a ``select`` statement (:rmlink:`9.7`).
class TerminateAlternative: SimpleStmt {
    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = %true
}

|" Qualifier for a subprogram kind.
enum class SubpKind: AdaNode {
    case Procedure, Function
}

|" Subunit (``separate``) (:rmlink:`10.1.3`).
class Subunit: AdaNode {
    @parse_field
    name: Name
    @parse_field
    body: Body

    |" Return the compilation unit in which this subunit is rooted.
    fun root_unit(): Entity[CompilationUnit] =
        node.designated_compilation_unit(
            node.name.as_symbol_array(),
            AnalysisUnitKind.unit_body,
            load_if_needed=true,
            not_found_is_error=true
        )
        .as_bare_entity

    |" Helper for AdaNode.env_hook. Handle sub-units (separates).
    fun env_hook_subunit(): Bool = {
        # Subunit handling is very simple: we just want to fetch the containing
        # unit.
        val _ = node.root_unit();

        false
    }

    |" Return the body in which this subunit is rooted.
    @exported
    fun body_root(): Entity[BasicDecl] = node.root_unit().decl().as_bare_entity

    |" Return all the bodies this subunit is rooted in, so that for:
    |"
    |" .. code::ada
    |"
    |"     separate (P1.P2.P3)
    |"     procedure P4 is ...
    |"
    |" ``bodies_root`` will return ``[P3, P2, P1]``, an array containing all
    |" the nested subunits (``P2``, ``P3``), as well as the body root ``P1``,
    |" in which ``P4`` has been recursively rooted in.
    fun bodies_root(): Array[Entity[BasicDecl]] = {
        val br = node.root_unit().decl().as_bare_entity;

        br.parent.as[Subunit].do(
            (su) => [br] & su.bodies_root(),
            default_val=[br]
        )
    }

    |" Return the stub corresponding to this subunit.
    |"
    |" This is an internal helper for ``AdaNode.can_reach``: since it is used
    |" in all lexical env lookups, its implementation cannot do lookups itself
    |" as it would trigger infinite recursions. Libadalang users can use
    |" ``BasicDecl.previous_part_for_decl`` instead.
    # At the time of its introduction, this property was used only by
    # AdaNode.can_reach, which was an external property.
    @ignored
    fun stub(): BodyStub = {
        # Look for the declaration list that is supposed to contain the stub
        # for this subunit. This must be in the unit in which this subunit is
        # rooted, and that unit can only be a package body, a subprogram body
        # or a subunit itself.
        val root = node.root_unit().node;
        val root_body = match root.body {
            case li: LibraryItem => li.item.as[Body]
            case su: Subunit => su.body
            case _ => null[Body]
        };
        val decls = match root_body {
            case subp: SubpBody => subp.decls.decls
            case pkg: PackageBody => pkg.decls.decls
            case _ => null[ASTList[AdaNode]]
        };

        # Look for the stub in this list: it is supposed to be the only stub
        # whose name matches self.body's defining name.
        decls.find(
            (d) => {
                # d may not be a body stub, so we have to use "._" after the
                # cast.
                val stub_name =
                    d.as[BodyStub].as_bare_entity?.defining_name_or_raise()
                    .name;
                # By construction, self is a subunit, so for valid code, it is
                # supposed to have a unique defining name.
                val subunit_name =
                    node.body.as_bare_entity.defining_name_or_raise().name;

                stub_name?.name_is(subunit_name.name_symbol())
            }
        )
        .as[BodyStub]
    }

    fun xref_entry_point(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        node.name.ref_var()
        <- self.body_root()
        # Bind the parent unit's name to the enclosing body for this subunit
        %and self.name.as[DottedName].do(
            (dn) => {
                bind env = node.body.node_env;

                dn.prefix.xref_no_overloading()
            },
            default_val=%true
        )
}

|" Qualifier for the ``synchronized`` keyword.
@qualifier
enum class Synchronized: AdaNode {
}

|" Qualifier for the ``tagged`` keyword.
@qualifier
enum class Tagged: AdaNode {
}

|" Type definition for a task type (:rmlink:`9.1`).
class TaskDef: AdaNode {
    @parse_field
    interfaces: ParentList
    @parse_field
    public_part: PublicPart
    @parse_field
    @nullable
    private_part: PrivatePart
    @parse_field
    @nullable
    end_name: EndName

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.interfaces.logic_all((ifc) => ifc.xref_equation())
}

|" Synthetic node that contains the lazy fields for the attribute subprograms
|" of a given type. The lazy fields are not directly on the BaseTypeDecl node
|" itself to minimize its size in memory: with this indirection, a type for
|" which no function attribute is ever synthesized will not waste any memory.
@synthetic
class TypeAttributesRepository: AdaNode {
    base_type: BaseTypeDecl

    @lazy
    base_type_expr: NodeBuilder[SyntheticTypeExpr] =
        SyntheticTypeExpr.builder(target_type=node.base_type.to_builder())

    @lazy
    universal_int_type_expr: NodeBuilder[SyntheticTypeExpr] =
        SyntheticTypeExpr.builder(
            target_type=node.universal_int_type().node.to_builder()
        )

    @lazy
    universal_real_type_expr: NodeBuilder[SyntheticTypeExpr] =
        SyntheticTypeExpr.builder(
            target_type=node.universal_real_type().node.to_builder()
        )

    @lazy
    base_type_param: NodeBuilder[SyntheticFormalParamDecl] =
        SyntheticFormalParamDecl.builder(
            param_name=s"Value",
            param_type=node.base_type_expr
        )

    @lazy
    universal_int_param: NodeBuilder[SyntheticFormalParamDecl] =
        SyntheticFormalParamDecl.builder(
            param_name=s"Value",
            param_type=node.universal_int_type_expr
        )

    @lazy
    universal_real_param: NodeBuilder[SyntheticFormalParamDecl] =
        SyntheticFormalParamDecl.builder(
            param_name=s"Value",
            param_type=node.universal_real_type_expr
        )

    @lazy
    root_stream_param: NodeBuilder[SyntheticFormalParamDecl] =
        SyntheticFormalParamDecl.builder(
            param_name=s"S",
            param_type=SyntheticTypeExpr.builder(
                target_type=node.root_stream_type().anonymous_access_type()
                .node
                .to_builder()
            )
        )

    @lazy
    succ: BasicSubpDecl =
        SyntheticSubpDecl.builder(
            spec=SyntheticUnarySpec.builder(
                subp_symbol=s"Succ",
                right_param=node.base_type_param,
                return_type_expr=node.base_type_expr
            )
        )
        .build(parent=node.base_type)

    @lazy
    pred: BasicSubpDecl =
        SyntheticSubpDecl.builder(
            spec=SyntheticUnarySpec.builder(
                subp_symbol=s"Pred",
                right_param=node.base_type_param,
                return_type_expr=node.base_type_expr
            )
        )
        .build(parent=node.base_type)

    @lazy
    min: BasicSubpDecl =
        SyntheticSubpDecl.builder(
            spec=SyntheticBinarySpec.builder(
                subp_symbol=s"Min",
                left_param=node.base_type_param,
                right_param=node.base_type_param,
                return_type_expr=node.base_type_expr
            )
        )
        .build(parent=node.base_type)

    @lazy
    max: BasicSubpDecl =
        SyntheticSubpDecl.builder(
            spec=SyntheticBinarySpec.builder(
                subp_symbol=s"Max",
                left_param=node.base_type_param,
                right_param=node.base_type_param,
                return_type_expr=node.base_type_expr
            )
        )
        .build(parent=node.base_type)

    @lazy
    round: BasicSubpDecl = # As defined in :rmlink:`3.5.10`
        SyntheticSubpDecl
        .builder(
            spec=SyntheticUnarySpec.builder(
                subp_symbol=s"Round",
                right_param=node.universal_real_param,
                return_type_expr=node.base_type_expr
            )
        )
        .build(parent=node.base_type)

    @lazy
    rounding: BasicSubpDecl =
        SyntheticSubpDecl.builder(
            spec=SyntheticUnarySpec.builder(
                subp_symbol=s"Rounding",
                right_param=node.base_type_param,
                return_type_expr=node.base_type_expr
            )
        )
        .build(parent=node.base_type)

    @lazy
    unbiased_rounding: BasicSubpDecl =
        SyntheticSubpDecl.builder(
            spec=SyntheticUnarySpec.builder(
                subp_symbol=s"Unbiased_Rounding",
                right_param=node.base_type_param,
                return_type_expr=node.base_type_expr
            )
        )
        .build(parent=node.base_type)

    @lazy
    ceiling: BasicSubpDecl =
        SyntheticSubpDecl.builder(
            spec=SyntheticUnarySpec.builder(
                subp_symbol=s"Ceiling",
                right_param=node.base_type_param,
                return_type_expr=node.base_type_expr
            )
        )
        .build(parent=node.base_type)

    @lazy
    floor: BasicSubpDecl =
        SyntheticSubpDecl.builder(
            spec=SyntheticUnarySpec.builder(
                subp_symbol=s"Floor",
                right_param=node.base_type_param,
                return_type_expr=node.base_type_expr
            )
        )
        .build(parent=node.base_type)

    @lazy
    truncation: BasicSubpDecl =
        SyntheticSubpDecl.builder(
            spec=SyntheticUnarySpec.builder(
                subp_symbol=s"Truncation",
                right_param=node.base_type_param,
                return_type_expr=node.base_type_expr
            )
        )
        .build(parent=node.base_type)

    @lazy
    machine: BasicSubpDecl =
        SyntheticSubpDecl.builder(
            spec=SyntheticUnarySpec.builder(
                subp_symbol=s"Machine",
                right_param=node.base_type_param,
                return_type_expr=node.base_type_expr
            )
        )
        .build(parent=node.base_type)

    @lazy
    machine_rounding: BasicSubpDecl =
        SyntheticSubpDecl.builder(
            spec=SyntheticUnarySpec.builder(
                subp_symbol=s"Machine_Rounding",
                right_param=node.base_type_param,
                return_type_expr=node.base_type_expr
            )
        )
        .build(parent=node.base_type)

    @lazy
    fraction: BasicSubpDecl =
        SyntheticSubpDecl.builder(
            spec=SyntheticUnarySpec.builder(
                subp_symbol=s"Fraction",
                right_param=node.base_type_param,
                return_type_expr=node.base_type_expr
            )
        )
        .build(parent=node.base_type)

    @lazy
    exponent: BasicSubpDecl =
        SyntheticSubpDecl.builder(
            spec=SyntheticUnarySpec.builder(
                subp_symbol=s"Exponent",
                right_param=node.base_type_param,
                return_type_expr=node.universal_int_type_expr
            )
        )
        .build(parent=node.base_type)

    @lazy
    copy_sign: BasicSubpDecl =
        SyntheticSubpDecl.builder(
            spec=SyntheticBinarySpec.builder(
                subp_symbol=s"Copy_Sign",
                left_param=node.base_type_param,
                right_param=node.base_type_param,
                return_type_expr=node.base_type_expr
            )
        )
        .build(parent=node.base_type)

    @lazy
    remainder: BasicSubpDecl =
        SyntheticSubpDecl.builder(
            spec=SyntheticBinarySpec.builder(
                subp_symbol=s"Remainder",
                left_param=node.base_type_param,
                right_param=node.base_type_param,
                return_type_expr=node.base_type_expr
            )
        )
        .build(parent=node.base_type)

    @lazy
    adjacent: BasicSubpDecl =
        SyntheticSubpDecl.builder(
            spec=SyntheticBinarySpec.builder(
                subp_symbol=s"Adjacent",
                left_param=node.base_type_param,
                right_param=node.base_type_param,
                return_type_expr=node.base_type_expr
            )
        )
        .build(parent=node.base_type)

    @lazy
    scaling: BasicSubpDecl =
        SyntheticSubpDecl.builder(
            spec=SyntheticBinarySpec.builder(
                subp_symbol=s"Scaling",
                left_param=node.base_type_param,
                right_param=node.universal_int_param,
                return_type_expr=node.base_type_expr
            )
        )
        .build(parent=node.base_type)

    @lazy
    compose: BasicSubpDecl =
        SyntheticSubpDecl.builder(
            spec=SyntheticBinarySpec.builder(
                subp_symbol=s"Compose",
                left_param=node.base_type_param,
                right_param=node.universal_int_param,
                return_type_expr=node.base_type_expr
            )
        )
        .build(parent=node.base_type)

    @lazy
    leading_part: BasicSubpDecl =
        SyntheticSubpDecl.builder(
            spec=SyntheticBinarySpec.builder(
                subp_symbol=s"Leading_Part",
                left_param=node.base_type_param,
                right_param=node.universal_int_param,
                return_type_expr=node.base_type_expr
            )
        )
        .build(parent=node.base_type)

    @lazy
    mod: BasicSubpDecl =
        SyntheticSubpDecl.builder(
            spec=SyntheticUnarySpec.builder(
                subp_symbol=s"Mod",
                right_param=node.universal_int_param,
                return_type_expr=node.base_type_expr
            )
        )
        .build(parent=node.base_type)

    @lazy
    value: BasicSubpDecl =
        SyntheticSubpDecl.builder(
            spec=SyntheticUnarySpec.builder(
                subp_symbol=s"Value",
                right_param=SyntheticFormalParamDecl.builder(
                    param_name=s"Val",
                    param_type=SyntheticTypeExpr.builder(
                        target_type=node.std_entity(s"String")
                        .as[BaseTypeDecl]
                        .node
                        .to_builder()
                    )
                ),
                return_type_expr=node.base_type_expr
            )
        )
        .build(parent=node.base_type)

    @lazy
    wide_value: BasicSubpDecl =
        SyntheticSubpDecl.builder(
            spec=SyntheticUnarySpec.builder(
                subp_symbol=s"Wide_Value",
                right_param=SyntheticFormalParamDecl.builder(
                    param_name=s"Val",
                    param_type=SyntheticTypeExpr.builder(
                        target_type=node.std_entity(s"Wide_String")
                        .as[BaseTypeDecl]
                        .node
                        .to_builder()
                    )
                ),
                return_type_expr=node.base_type_expr
            )
        )
        .build(parent=node.base_type)

    @lazy
    wide_wide_value: BasicSubpDecl =
        SyntheticSubpDecl.builder(
            spec=SyntheticUnarySpec.builder(
                subp_symbol=s"Wide_Wide_Value",
                right_param=SyntheticFormalParamDecl.builder(
                    param_name=s"Val",
                    param_type=SyntheticTypeExpr.builder(
                        target_type=node.std_entity(s"Wide_Wide_String")
                        .as[BaseTypeDecl]
                        .node
                        .to_builder()
                    )
                ),
                return_type_expr=node.base_type_expr
            )
        )
        .build(parent=node.base_type)

    @lazy
    fixed_value: BasicSubpDecl =
        SyntheticSubpDecl.builder(
            spec=SyntheticUnarySpec.builder(
                subp_symbol=s"Fixed_Value",
                right_param=node.universal_int_param,
                return_type_expr=node.base_type_expr
            )
        )
        .build(parent=node.base_type)

    @lazy
    integer_value: BasicSubpDecl =
        SyntheticSubpDecl.builder(
            spec=SyntheticUnarySpec.builder(
                subp_symbol=s"Integer_Value",
                right_param=node.universal_real_param,
                return_type_expr=node.base_type_expr
            )
        )
        .build(parent=node.base_type)

    @lazy
    pos: BasicSubpDecl =
        SyntheticSubpDecl.builder(
            spec=SyntheticUnarySpec.builder(
                subp_symbol=s"Pos",
                right_param=node.base_type_param,
                return_type_expr=node.universal_int_type_expr
            )
        )
        .build(parent=node.base_type)

    # We can't name it just `val` as this is a keyword in LKT
    @lazy
    val_attr: BasicSubpDecl =
        SyntheticSubpDecl.builder(
            spec=SyntheticUnarySpec.builder(
                subp_symbol=s"Val",
                right_param=node.universal_int_param,
                return_type_expr=node.base_type_expr
            )
        )
        .build(parent=node.base_type)

    @lazy
    enum_rep: BasicSubpDecl =
        SyntheticSubpDecl.builder(
            spec=SyntheticUnarySpec.builder(
                subp_symbol=s"Enum_Rep",
                right_param=node.base_type_param,
                return_type_expr=node.universal_int_type_expr
            )
        )
        .build(parent=node.base_type)

    @lazy
    enum_val: BasicSubpDecl =
        SyntheticSubpDecl.builder(
            spec=SyntheticUnarySpec.builder(
                subp_symbol=s"Enum_Val",
                right_param=node.universal_int_param,
                return_type_expr=node.base_type_expr
            )
        )
        .build(parent=node.base_type)

    @lazy
    read: BasicSubpDecl =
        SyntheticSubpDecl.builder(
            spec=SyntheticBinarySpec.builder(
                subp_symbol=s"Read",
                left_param=node.root_stream_param,
                right_param=node.base_type_param,
                return_type_expr=null[TypeExpr].to_builder()
            )
        )
        .build(parent=node.base_type)

    @lazy
    write: BasicSubpDecl =
        SyntheticSubpDecl.builder(
            spec=SyntheticBinarySpec.builder(
                subp_symbol=s"Write",
                left_param=node.root_stream_param,
                right_param=node.base_type_param,
                return_type_expr=null[TypeExpr].to_builder()
            )
        )
        .build(parent=node.base_type)

    @lazy
    input: BasicSubpDecl =
        SyntheticSubpDecl.builder(
            spec=SyntheticUnarySpec.builder(
                subp_symbol=s"Input",
                right_param=node.root_stream_param,
                return_type_expr=node.base_type_expr
            )
        )
        .build(parent=node.base_type)

    @lazy
    output: BasicSubpDecl =
        SyntheticSubpDecl.builder(
            spec=SyntheticBinarySpec.builder(
                subp_symbol=s"Output",
                left_param=node.root_stream_param,
                right_param=node.base_type_param,
                return_type_expr=null[TypeExpr].to_builder()
            )
        )
        .build(parent=node.base_type)

    @lazy
    image: BasicSubpDecl =
        SyntheticSubpDecl.builder(
            spec=SyntheticUnarySpec.builder(
                subp_symbol=s"Image",
                right_param=node.base_type_param,
                return_type_expr=SyntheticTypeExpr.builder(
                    target_type=node.std_entity(s"String")
                    .as[BaseTypeDecl]
                    .node
                    .to_builder()
                )
            )
        )
        .build(parent=node.base_type)

    @lazy
    wide_image: BasicSubpDecl =
        SyntheticSubpDecl.builder(
            spec=SyntheticUnarySpec.builder(
                subp_symbol=s"Wide_Image",
                right_param=node.base_type_param,
                return_type_expr=SyntheticTypeExpr.builder(
                    target_type=node.std_entity(s"Wide_String")
                    .as[BaseTypeDecl]
                    .node
                    .to_builder()
                )
            )
        )
        .build(parent=node.base_type)

    @lazy
    wide_wide_image: BasicSubpDecl =
        SyntheticSubpDecl.builder(
            spec=SyntheticUnarySpec.builder(
                subp_symbol=s"Wide_Wide_Image",
                right_param=node.base_type_param,
                return_type_expr=SyntheticTypeExpr.builder(
                    target_type=node.std_entity(s"Wide_Wide_String")
                    .as[BaseTypeDecl]
                    .node
                    .to_builder()
                )
            )
        )
        .build(parent=node.base_type)

    @lazy
    put_image: BasicSubpDecl =
        SyntheticSubpDecl.builder(
            spec=SyntheticBinarySpec.builder(
                subp_symbol=s"Put_Image",
                left_param=SyntheticFormalParamDecl.builder(
                    param_name=s"Buffer",
                    param_type=SyntheticTypeExpr.builder(
                        target_type=node.root_buffer_type().classwide_type()
                        .node
                        .to_builder()
                    )
                ),
                right_param=node.base_type_param,
                return_type_expr=null[TypeExpr].to_builder()
            )
        )
        .build(parent=node.base_type)

    @lazy
    asm_input: BasicSubpDecl =
        {
            val input_type =
                node.get_unit_root_decl(
                    [s"System", s"Machine_Code"],
                    AnalysisUnitKind.unit_specification
                )
                ?.children_env
                .get_first(s"Asm_Input_Operand", lookup=LookupKind.flat)
                .node
                .as[BaseTypeDecl];

            SyntheticSubpDecl.builder(
                spec=SyntheticBinarySpec.builder(
                    subp_symbol=s"Asm_Input",
                    left_param=SyntheticFormalParamDecl.builder(
                        param_name=s"S",
                        param_type=SyntheticTypeExpr.builder(
                            target_type=node.std_entity(s"String")
                            .as[BaseTypeDecl]
                            .node
                            .to_builder()
                        )
                    ),
                    right_param=node.base_type_param,
                    return_type_expr=SyntheticTypeExpr.builder(
                        target_type=input_type.to_builder()
                    )
                )
            )
        }
        .build(parent=node.base_type)

    @lazy
    asm_output: BasicSubpDecl =
        {
            val output_type =
                node.get_unit_root_decl(
                    [s"System", s"Machine_Code"],
                    AnalysisUnitKind.unit_specification
                )
                ?.children_env
                .get_first(s"Asm_Output_Operand", lookup=LookupKind.flat)
                .node
                .as[BaseTypeDecl];

            SyntheticSubpDecl.builder(
                spec=SyntheticBinarySpec.builder(
                    subp_symbol=s"Asm_Output",
                    left_param=SyntheticFormalParamDecl.builder(
                        param_name=s"S",
                        param_type=SyntheticTypeExpr.builder(
                            target_type=node.std_entity(s"String")
                            .as[BaseTypeDecl]
                            .node
                            .to_builder()
                        )
                    ),
                    right_param=node.base_type_param,
                    return_type_expr=SyntheticTypeExpr.builder(
                        target_type=output_type.to_builder()
                    )
                )
            )
        }
        .build(parent=node.base_type)

    @lazy
    model: BasicSubpDecl =
        SyntheticSubpDecl.builder(
            spec=SyntheticUnarySpec.builder(
                subp_symbol=s"Model",
                right_param=node.universal_real_param,
                return_type_expr=node.base_type_expr
            )
        )
        .build(parent=node.base_type)
}

|" Base class for type definitions (:rmlink:`3.2.1`).
@abstract
class TypeDef: AdaNode {
    |" Whether type is a real type or not.
    @with_dynvars(origin)
    fun is_real_type(): Bool = self.is_float_type() or self.is_fixed_point()

    fun predefined_equality_operators(): Array[EnvAssoc] = {
        val self_type = node.parent.as[TypeDecl];
        val bool_type = node.bool_type().node;

        [
            node.create_binop_assoc(s"\"=\"", self_type, self_type, bool_type),
            node.create_binop_assoc(s"\"/=\"", self_type, self_type, bool_type)
        ]
    }

    |" Return all the base types for this type (base type + base interfaces)
    @with_dynvars(origin)
    fun base_types(): Array[Entity[BaseTypeDecl]] =
        self.base_type().do((bt) => [bt]) & self.base_interfaces()

    @with_dynvars(origin, include_ud_indexing, dottable_type=null[AdaNode])
    fun defining_env(): LexicalEnv =
        # Regroup implementations for subclasses here instead of overriding to
        # avoid code duplication (multiple cases have the same implementation).
        # A "record" or "private" type def may be the completion of a
        # previous type declaration, so we need to include the defining
        # env of its previous part as well.
        if node is RecordTypeDef | PrivateTypeDef
        then
            [
                self.children_env,
                self.dottable_subps_env(),
                self.previous_part_env()
            ]
            .env_group()
        # Same for "derived" and "interface" type definitions, but we also
        # need to include the defining environments of their base types.

        elif node is DerivedTypeDef | InterfaceTypeDef
        then (
            # Make sure to put own defining env before base types' defining
            # envs in the result, so that most-overridden subprograms will be
            # considered first during name resolution.
            (
                [self.children_env, self.dottable_subps_env()]
                & {
                    bind dottable_type = dottable_type or? node.parent;

                    self.base_types().map((bt) => bt?.defining_env())
                }
                & [self.previous_part_env()]
            )
            .env_group()
        )
        # Continue propagating the original `dottable_type`, or start
        # propagating self if it's not set yet.

        elif node is ArrayTypeDef
        then
            [
                self.as[ArrayTypeDef].comp_type().defining_env(),
                self.dottable_subps_env()
            ]
            .env_group()
        elif node is AccessDef
        then
            [
                self.as[AccessDef].accessed_type()?.defining_env(),
                self.dottable_subps_env()
            ]
            .env_group()
        # An access to procedure will have a null accessed_type, hence
        # the use of the underscore.
        # In any case, include the type's `dottable_subps_env` so as to
        # fully support the universal dot notation feature.
        else self.dottable_subps_env()

    |" Return the TypeDecl containing this TypeDef
    fun containing_type(): Entity[TypeDecl] = self.parent.as![TypeDecl]

    fun previous_part(): Entity[BaseTypeDecl] =
        self.containing_type().previous_part(true)

    @with_dynvars(origin, dottable_type)
    fun previous_part_env(): LexicalEnv = self.previous_part()?.defining_env()

    @with_dynvars(origin, dottable_type)
    fun dottable_subps_env(): LexicalEnv =
        # Return the environment containing all subprograms that can be called
        # with the dot-notation on values of the type which this is defined.
        # It is important to rebind the env with our current rebindings,
        # so that subsequent calls to env.get on this env return those
        # subprograms with the adequate rebindings.
        # Note that we also set the ``primitive`` and ``primitive_real_type``
        # metadata field (without checking that they are actual primitives)
        # so that user queries such as ``primitive_subp_tagged_type`` return a
        # precise type. This is OK because those fields are not used for
        # name resolution in any case. (see TODO in ``real_designated_type``).
        [
            self.containing_type().dottable_subps_env.rebind_env(
                self.info.rebindings
            )
        ]
        .env_group(
            with_md=dottable_type.do(
                (t) => Metadata(primitive=node.parent, primitive_real_type=t)
            )
        )

    |" Return the discrete range for this type def, if applicable.
    fun discrete_range(): DiscreteRange = null[DiscreteRange]

    |" If this designates an array type, return its number of dimensions.
    |" Return 0 otherwise.
    @with_dynvars(origin)
    fun array_ndims(): Int = 0

    |" Whether type is a float type or not.
    @with_dynvars(origin)
    fun is_float_type(): Bool = false

    |" Whether type is a fixed point type or not.
    @with_dynvars(origin)
    fun is_fixed_point(): Bool = false

    |" Return the list of predefined operators for this type definition.
    |" See TypeDecl.predefined_operators.
    |"
    |" This property is overridden by the various TypeDef concrete classes to
    |" implement type-specific logic.
    fun predefined_operators(): Array[EnvAssoc] = null[Array[EnvAssoc]]

    @with_dynvars(origin)
    fun is_discrete_type(): Bool =
        self.base_type().do(
            (bt) => bt.is_discrete_type(),
            default_val=self.is_int_type() or self.is_enum_type()
            or self.is_char_type()
        )

    |" Whether type is an integer type or not.
    @with_dynvars(origin)
    fun is_int_type(): Bool = false

    |" Whether type is an access type or not.
    @with_dynvars(origin)
    fun is_access_type(): Bool = false

    @with_dynvars(origin=null[AdaNode])
    fun is_char_type(): Bool = false

    @with_dynvars(origin=null[AdaNode])
    fun is_enum_type(): Bool = false

    @with_dynvars(origin)
    fun accessed_type(): Entity[BaseTypeDecl] = null[Entity[BaseTypeDecl]]

    |" Return whether this type is tagged.
    @with_dynvars(origin=null[AdaNode])
    fun is_tagged_type(): Bool = false

    @with_dynvars(origin=null[AdaNode])
    fun is_task_type(): Bool = false

    fun is_limited_type(): Bool = false

    |" Return the base type entity for this derived type definition.
    @with_dynvars(origin)
    fun base_type(): Entity[BaseTypeDecl] = null[Entity[BaseTypeDecl]]

    |" Return the interfaces this type derives from
    fun base_interfaces(): Array[Entity[BaseTypeDecl]] =
        null[Array[Entity[BaseTypeDecl]]]

    @with_dynvars(imprecise_fallback=false)
    fun is_static(): Bool = false
}

|" Base class for access type definitions (:rmlink:`3.10`).
@abstract
class AccessDef: TypeDef {
    @parse_field
    @nullable
    has_not_null: NotNull

    @with_dynvars(origin)
    fun is_access_type(): Bool = true

    @memoized
    fun predefined_operators(): Array[EnvAssoc] =
        node.predefined_equality_operators()
}

|" Type definition for accesses to subprograms (:rmlink:`3.10`).
class AccessToSubpDef: AccessDef {
    @parse_field
    has_protected: Protected
    @parse_field
    subp_spec: SubpSpec

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = %true

    @with_dynvars(origin)
    fun accessed_type(): Entity[BaseTypeDecl] = self.subp_spec.return_type()

    # We need to add an env to contain the subp_spec's parameters, so that they
    # don't leak in the external scope.
    env_spec {
        add_env()
    }
}

|" Base class for access type definitions (:rmlink:`3.10`).
@abstract
class BaseTypeAccessDef: AccessDef {
}

|" Synthetic type access, that will directly reference a type decl. It is used
|" to generate synthetic anonymous access types.
@synthetic
class AnonymousTypeAccessDef: BaseTypeAccessDef {
    @parse_field
    type_decl: BaseTypeDecl

    @with_dynvars(origin)
    fun accessed_type(): Entity[BaseTypeDecl] = self.type_decl
}

|" Syntactic type definition for accesses.
class TypeAccessDef: BaseTypeAccessDef {
    @parse_field
    has_all: All
    @parse_field
    has_constant: Constant
    @parse_field
    subtype_indication: SubtypeIndication

    @with_dynvars(origin)
    fun accessed_type(): Entity[BaseTypeDecl] =
        self.subtype_indication.designated_type()

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = self.subtype_indication.xref_equation()
}

|" Type definition for an array (:rmlink:`3.6`).
class ArrayTypeDef: TypeDef {
    @parse_field
    indices: ArrayIndices
    @parse_field
    component_type: ComponentDef

    |" Returns the type stored as a component in the array.
    @with_dynvars(origin)
    fun comp_type(): Entity[BaseTypeDecl] =
        self.component_type.type_expr.designated_type()

    @with_dynvars(origin)
    fun index_type(dim: Int): Entity[BaseTypeDecl] =
        self.indices.index_type(dim)

    @with_dynvars(origin)
    fun array_ndims(): Int = node.indices.ndims()

    fun is_limited_type(): Bool = {
        bind origin = null[AdaNode]; # We want full visibility

        self.comp_type().is_limited_type()
    }

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.indices.sub_equation() %and self.component_type.sub_equation()

    @memoized
    fun predefined_operators(): Array[EnvAssoc] = {
        val self_type = node.parent.as[TypeDecl];
        val bool_type = node.bool_type().node;
        val comp_type_expr = node.component_type.type_expr;

        # Note: here, we define the `and`, `or`, `xor` and `not` operators
        # for all array types (even if they don't make sense) because we have
        # no way to know at this stage if the component type is a boolean type
        # or not (e.g. the component type designates a generic formal).
        # This does not seem to cause any problem for now in practice, but in
        # theory it could hide user-defined operators in certain circumstances.
        # TODO: This could be fixed by filtering out invalid operators when
        # resolving names, somewhere the self info is available.
        [
            node.create_binop_assoc(s"\"<\"", self_type, self_type, bool_type),
            node.create_binop_assoc(
                s"\"<=\"",
                self_type,
                self_type,
                bool_type
            ),
            node.create_binop_assoc(s"\"=\"", self_type, self_type, bool_type),
            node.create_binop_assoc(
                s"\"/=\"",
                self_type,
                self_type,
                bool_type
            ),
            node.create_binop_assoc(s"\">\"", self_type, self_type, bool_type),
            node.create_binop_assoc(
                s"\">=\"",
                self_type,
                self_type,
                bool_type
            ),
            node.create_binop_assoc(
                s"\"and\"",
                self_type,
                self_type,
                self_type
            ),
            node.create_binop_assoc(
                s"\"or\"",
                self_type,
                self_type,
                self_type
            ),
            node.create_binop_assoc(
                s"\"xor\"",
                self_type,
                self_type,
                self_type
            ),
            node.create_unop_assoc(
                s"\"not\"",
                self_type,
                self_type
            ), # The 4 predefined array concatenation operators
            node.create_binop_assoc_l_r_expr(
                s"\"&\"",
                comp_type_expr,
                comp_type_expr,
                self_type
            ),
            node.create_binop_assoc_l_expr(
                s"\"&\"",
                comp_type_expr,
                self_type,
                self_type
            ),
            node.create_binop_assoc_r_expr(
                s"\"&\"",
                self_type,
                comp_type_expr,
                self_type
            ),
            node.create_binop_assoc(s"\"&\"", self_type, self_type, self_type)
        ]
    }

    @with_dynvars(imprecise_fallback=false)
    fun is_static(): Bool = self.indices.is_static()

    fun xref_entry_point(): Bool = true
}

|" Type definition for a derived type (:rmlink:`3.4`).
class DerivedTypeDef: TypeDef {
    @parse_field
    has_abstract: Abstract
    @parse_field
    has_limited: Limited
    @parse_field
    has_synchronized: Synchronized
    @parse_field
    subtype_indication: SubtypeIndication
    @parse_field
    interfaces: ParentList
    @parse_field
    @nullable
    record_extension: BaseRecordDef
    @parse_field
    has_with_private: WithPrivate

    @with_dynvars(origin)
    fun array_ndims(): Int =
        self.base_type().do((bt) => bt.array_ndims(), default_val=self.super())

    @with_dynvars(origin)
    fun base_type(): Entity[BaseTypeDecl] =
        self.subtype_indication.designated_type()

    fun base_interfaces(): Array[Entity[BaseTypeDecl]] =
        self.interfaces.map((i) => i.name_designated_type())

    @with_dynvars(origin=null[AdaNode])
    fun is_task_type(): Bool = self.base_type().is_task_type()

    @with_dynvars(origin)
    fun is_int_type(): Bool = self.base_type().is_int_type()

    @with_dynvars(origin)
    fun is_access_type(): Bool =
        node.as_bare_entity.base_type().is_access_type()

    @with_dynvars(origin=null[AdaNode])
    fun is_char_type(): Bool = self.base_type().is_char_type()

    @with_dynvars(origin)
    fun is_float_type(): Bool = self.base_type().is_float_type()

    @with_dynvars(origin)
    fun is_fixed_point(): Bool = self.base_type().is_fixed_point()

    @with_dynvars(origin)
    fun accessed_type(): Entity[BaseTypeDecl] =
        self.base_type()?.accessed_type()

    @with_dynvars(origin=null[AdaNode])
    fun is_tagged_type(): Bool =
        not self.record_extension.is_null or self.has_with_private.as_bool()

    @with_dynvars(origin=null[AdaNode])
    fun is_enum_type(): Bool = self.base_type().is_enum_type()

    fun is_limited_type(): Bool =
        (
            node.has_limited.as_bool()
            or self.record_extension?.comps()?.has_limited_component()
        )
        or {
            bind origin = null[AdaNode];

            self.base_type().do(
                (bt) =>
                (
                    # We want full visibility.  Note that we don't recurse on
                    # interfaces, because limitedness is not inherited from
                    # those (ARM 7.5 6.2/2).
                    not bt.is_interface_type()
                )
                and bt.is_limited_type()
            )
        }

    @with_dynvars(imprecise_fallback=false)
    fun is_static(): Bool = self.subtype_indication.is_static_subtype()

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
    # We want to make discriminants accessible, so need to evaluate this in
    # self's children_env.
    {
        bind env = self.children_env;

        self.subtype_indication.xref_equation()
        %and self.interfaces.logic_all((ifc) => ifc.xref_equation())
    }

    fun discrete_range(): DiscreteRange =
        self.subtype_indication.discrete_range()
}

|" Type definition for enumerations (:rmlink:`3.5.1`).
class EnumTypeDef: TypeDef {
    @parse_field
    enum_literals: ASTList[EnumLiteralDecl]

    @with_dynvars(origin=null[AdaNode])
    fun is_char_type(): Bool =
        node.enum_literals.any((lit) => lit.name.name is CharLiteral)

    @with_dynvars(origin=null[AdaNode])
    fun is_enum_type(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = %true

    @with_dynvars(imprecise_fallback=false)
    fun is_static(): Bool = true

    fun is_std_char_type(): Bool = {
        val self_type = node.parent.as[TypeDecl];

        self_type in node.std_char_type().node
            | node.std_wide_char_type().node
            | node.std_wide_wide_char_type().node
    }

    @memoized
    fun predefined_operators(): Array[EnvAssoc] = {
        val self_type = node.parent.as[TypeDecl];
        val bool_type = node.bool_type().node;
        val defaults =
            [
                node.create_binop_assoc(
                    s"\"<\"",
                    self_type,
                    self_type,
                    bool_type
                ),
                node.create_binop_assoc(
                    s"\"<=\"",
                    self_type,
                    self_type,
                    bool_type
                ),
                node.create_binop_assoc(
                    s"\"=\"",
                    self_type,
                    self_type,
                    bool_type
                ),
                node.create_binop_assoc(
                    s"\"/=\"",
                    self_type,
                    self_type,
                    bool_type
                ),
                node.create_binop_assoc(
                    s"\">\"",
                    self_type,
                    self_type,
                    bool_type
                ),
                node.create_binop_assoc(
                    s"\">=\"",
                    self_type,
                    self_type,
                    bool_type
                )
            ];
        # The boolean type has four additional builtin operations
        val specials =
            if self_type == bool_type
            then
                [
                    node.create_binop_assoc(
                        s"\"and\"",
                        self_type,
                        self_type,
                        self_type
                    ),
                    node.create_binop_assoc(
                        s"\"or\"",
                        self_type,
                        self_type,
                        self_type
                    ),
                    node.create_binop_assoc(
                        s"\"xor\"",
                        self_type,
                        self_type,
                        self_type
                    ),
                    node.create_unop_assoc(s"\"not\"", self_type, self_type)
                ]
            else null[Array[EnvAssoc]];

        defaults & specials
    }
}

|" Type definition for discrete types in generic formals
|" (:rmlink:`12.5.2`).
class FormalDiscreteTypeDef: TypeDef {
    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = %true

    @with_dynvars(origin)
    fun is_discrete_type(): Bool = true

    @memoized
    fun predefined_operators(): Array[EnvAssoc] = {
        val self_type = node.parent.as[TypeDecl];
        val bool_type = node.bool_type().node;

        [
            node.create_binop_assoc(s"\"<\"", self_type, self_type, bool_type),
            node.create_binop_assoc(
                s"\"<=\"",
                self_type,
                self_type,
                bool_type
            ),
            node.create_binop_assoc(s"\"=\"", self_type, self_type, bool_type),
            node.create_binop_assoc(
                s"\"/=\"",
                self_type,
                self_type,
                bool_type
            ),
            node.create_binop_assoc(s"\">\"", self_type, self_type, bool_type),
            node.create_binop_assoc(s"\">=\"", self_type, self_type, bool_type)
        ]
    }
}

|" Type definition for an interface (:rmlink:`3.9.4`).
class InterfaceTypeDef: TypeDef {
    @parse_field
    @nullable
    interface_kind: InterfaceKind
    @parse_field
    interfaces: ParentList

    @with_dynvars(origin=null[AdaNode])
    fun is_tagged_type(): Bool = true

    @with_dynvars(origin=null[AdaNode])
    fun is_task_type(): Bool =
        self.interface_kind is InterfaceKind.Task

        # All four interface kinds declare limited types. Also, limitedness is
        # not inherited from parent interfaces (ARM 7.5 6.2/2).
    fun is_limited_type(): Bool = not node.interface_kind.is_null

    fun base_interfaces(): Array[Entity[BaseTypeDecl]] =
        self.interfaces.map((i) => i.name_designated_type())

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.interfaces.logic_all((ifc) => ifc.xref_equation())
}

|" Type definition for a modular integer type (:rmlink:`3.5.4`).
class ModIntTypeDef: TypeDef {
    @parse_field
    expr: Expr

    @with_dynvars(origin)
    fun is_int_type(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = self.expr.sub_equation()

    @with_dynvars(imprecise_fallback=false)
    fun is_static(): Bool = self.expr.is_static_expr()

    fun discrete_range(): DiscreteRange =
        DiscreteRange(low_bound=null[Entity[Expr]], high_bound=self.expr)

    @memoized
    fun predefined_operators(): Array[EnvAssoc] = {
        val self_type = node.parent.as[TypeDecl];
        val bool_type = node.bool_type().node;
        val int_type = node.int_type().node;

        [
            node.create_binop_assoc(s"\"+\"", self_type, self_type, self_type),
            node.create_binop_assoc(s"\"-\"", self_type, self_type, self_type),
            node.create_binop_assoc(s"\"*\"", self_type, self_type, self_type),
            node.create_binop_assoc(s"\"/\"", self_type, self_type, self_type),
            node.create_binop_assoc(
                s"\"mod\"",
                self_type,
                self_type,
                self_type
            ),
            node.create_binop_assoc(
                s"\"rem\"",
                self_type,
                self_type,
                self_type
            ),
            node.create_binop_assoc(
                s"\"and\"",
                self_type,
                self_type,
                self_type
            ),
            node.create_binop_assoc(
                s"\"or\"",
                self_type,
                self_type,
                self_type
            ),
            node.create_binop_assoc(s"\"**\"", self_type, int_type, self_type),
            node.create_binop_assoc(s"\"<\"", self_type, self_type, bool_type),
            node.create_binop_assoc(
                s"\"<=\"",
                self_type,
                self_type,
                bool_type
            ),
            node.create_binop_assoc(s"\"=\"", self_type, self_type, bool_type),
            node.create_binop_assoc(
                s"\"/=\"",
                self_type,
                self_type,
                bool_type
            ),
            node.create_binop_assoc(s"\">\"", self_type, self_type, bool_type),
            node.create_binop_assoc(
                s"\">=\"",
                self_type,
                self_type,
                bool_type
            ),
            node.create_unop_assoc(s"\"+\"", self_type, self_type),
            node.create_unop_assoc(s"\"-\"", self_type, self_type),
            node.create_unop_assoc(s"\"abs\"", self_type, self_type),
            node.create_unop_assoc(s"\"not\"", self_type, self_type)
        ]
    }
}

|" Type definition for a private type.
|"
|" Libadalang diverges from the ARM here, treating private types like regular
|" type declarations that have an embedded type definition. This type
|" definition hence corresponds to :rmlink:`7.3`.
class PrivateTypeDef: TypeDef {
    @parse_field
    has_abstract: Abstract
    @parse_field
    has_tagged: Tagged
    @parse_field
    has_limited: Limited

    @with_dynvars(origin=null[AdaNode])
    fun is_tagged_type(): Bool = node.has_tagged.as_bool()

    fun is_limited_type(): Bool = node.has_limited.as_bool()

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = %true

    @memoized
    fun predefined_operators(): Array[EnvAssoc] =
        if node.has_limited.as_bool() then null[Array[EnvAssoc]]
        else node.predefined_equality_operators()
}

|" Type definition for real numbers (:rmlink:`3.5.6`).
@abstract
class RealTypeDef: TypeDef {
    @with_dynvars(imprecise_fallback=false)
    fun is_static(): Bool = true

    @memoized
    fun predefined_operators(): Array[EnvAssoc] = {
        val self_type = node.parent.as[TypeDecl];
        val bool_type = node.bool_type().node;
        val int_type = node.int_type().node;
        val root_int_type = node.root_int_type().node;
        val defaults =
            [
                node.create_binop_assoc(
                    s"\"+\"",
                    self_type,
                    self_type,
                    self_type
                ),
                node.create_binop_assoc(
                    s"\"-\"",
                    self_type,
                    self_type,
                    self_type
                ),
                node.create_binop_assoc(
                    s"\"*\"",
                    self_type,
                    self_type,
                    self_type
                ),
                node.create_binop_assoc(
                    s"\"/\"",
                    self_type,
                    self_type,
                    self_type
                ),
                node.create_binop_assoc(
                    s"\"**\"",
                    self_type,
                    int_type,
                    self_type
                ),
                node.create_binop_assoc(
                    s"\"<\"",
                    self_type,
                    self_type,
                    bool_type
                ),
                node.create_binop_assoc(
                    s"\"<=\"",
                    self_type,
                    self_type,
                    bool_type
                ),
                node.create_binop_assoc(
                    s"\"=\"",
                    self_type,
                    self_type,
                    bool_type
                ),
                node.create_binop_assoc(
                    s"\"/=\"",
                    self_type,
                    self_type,
                    bool_type
                ),
                node.create_binop_assoc(
                    s"\">\"",
                    self_type,
                    self_type,
                    bool_type
                ),
                node.create_binop_assoc(
                    s"\">=\"",
                    self_type,
                    self_type,
                    bool_type
                ),
                node.create_unop_assoc(s"\"+\"", self_type, self_type),
                node.create_unop_assoc(s"\"-\"", self_type, self_type),
                node.create_unop_assoc(s"\"abs\"", self_type, self_type)
            ];
        # The root_real type also defines the three following operators
        val specials =
            if self_type == node.root_real_type().node
            then
                [
                    node.create_binop_assoc(
                        s"\"*\"",
                        root_int_type,
                        self_type,
                        self_type
                    ),
                    node.create_binop_assoc(
                        s"\"*\"",
                        self_type,
                        root_int_type,
                        self_type
                    ),
                    node.create_binop_assoc(
                        s"\"/\"",
                        self_type,
                        root_int_type,
                        self_type
                    )
                ]
            else null[Array[EnvAssoc]];

        defaults & specials
    }

    |" Return the predefined multiplication operators for the
    |" universal_fixed type (:rmlink:`4.5.5` 18-19).
    @memoized
    fun universal_fixed_predefined_operators(): Array[EnvAssoc] = {
        val uf = node.universal_fixed_type().node;

        [
            node.create_binop_assoc(s"\"*\"", uf, uf, uf),
            node.create_binop_assoc(s"\"/\"", uf, uf, uf)
        ]
    }
}

|" Type definition for decimal fixed-point numbers (:rmlink:`3.5.9`).
class DecimalFixedPointDef: RealTypeDef {
    @parse_field
    delta: Expr
    @parse_field
    digits: Expr
    @parse_field
    @nullable
    range: RangeSpec

    @with_dynvars(origin)
    fun is_fixed_point(): Bool = true

    |" Build an equation for a decimal fixed point type definition.
    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        (
            # As per RM 3.5.9, the delta expression is expected to be of any
            # real type.
            self.universal_real_bind(self.delta.expected_type_var())
        )
        %and self.delta.sub_equation()
        %and self.delta.matches_expected_type()
        %and (
            # The digits expression is expected to be of any integer type
            self.universal_int_bind(self.digits.expected_type_var())
        )
        %and self.digits.sub_equation()
        %and self.digits.matches_expected_type()
        %and (if node.range.is_null then %true else self.range.sub_equation())

    @memoized
    fun predefined_operators(): Array[EnvAssoc] = {
        val self_type = node.parent.as[TypeDecl];
        val bool_type = node.bool_type().node;
        val int_type = node.int_type().node;

        [
            node.create_binop_assoc(s"\"+\"", self_type, self_type, self_type),
            node.create_binop_assoc(s"\"-\"", self_type, self_type, self_type),
            node.create_binop_assoc(s"\"*\"", self_type, self_type, self_type),
            node.create_binop_assoc(s"\"/\"", self_type, self_type, self_type),
            node.create_binop_assoc(s"\"*\"", int_type, self_type, self_type),
            node.create_binop_assoc(s"\"*\"", self_type, int_type, self_type),
            node.create_binop_assoc(s"\"/\"", self_type, int_type, self_type),
            node.create_binop_assoc(s"\"**\"", self_type, int_type, self_type),
            node.create_binop_assoc(s"\"<\"", self_type, self_type, bool_type),
            node.create_binop_assoc(
                s"\"<=\"",
                self_type,
                self_type,
                bool_type
            ),
            node.create_binop_assoc(s"\"=\"", self_type, self_type, bool_type),
            node.create_binop_assoc(
                s"\"/=\"",
                self_type,
                self_type,
                bool_type
            ),
            node.create_binop_assoc(s"\">\"", self_type, self_type, bool_type),
            node.create_binop_assoc(
                s"\">=\"",
                self_type,
                self_type,
                bool_type
            ),
            node.create_unop_assoc(s"\"+\"", self_type, self_type),
            node.create_unop_assoc(s"\"-\"", self_type, self_type),
            node.create_unop_assoc(s"\"abs\"", self_type, self_type)
        ]
    }
}

|" Type definition for floating-point numbers (:rmlink:`3.5.7`).
class FloatingPointDef: RealTypeDef {
    @parse_field
    num_digits: Expr
    @parse_field
    @nullable
    range: RangeSpec

    @with_dynvars(origin)
    fun is_float_type(): Bool = true

    |" Build an equation for a floating point type definition.
    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        # As per RM 3.5.7, the num_digits expression is expected to be of any
        # integer type.
        self.universal_int_bind(self.num_digits.expected_type_var())
        %and self.num_digits.sub_equation()
        %and self.num_digits.matches_expected_type()
        # Expressions from the range specification are expected to be of
        # any real type, the types need not be the same.
        %and self.range.do(
            (r) =>
            self.universal_real_bind(r.range.expected_type_var())
            %and r.range.sub_equation()
            %and r.range.matches_expected_type(),
            default_val=%true
        )
}

|" Type definition for ordinary fixed-point numbers (:rmlink:`3.5.9`).
class OrdinaryFixedPointDef: RealTypeDef {
    @parse_field
    delta: Expr
    @parse_field
    @nullable
    range: RangeSpec

    @with_dynvars(origin)
    fun is_fixed_point(): Bool = true

    |" Build an equation for an ordinary fixed point type definition.
    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        # As per RM 3.5.9, the delta expression is expected to be of any
        # real type.
        self.universal_real_bind(self.delta.expected_type_var())
        %and self.delta.sub_equation()
        %and self.delta.matches_expected_type()
        %and (if node.range.is_null then %true else self.range.sub_equation())

    @memoized
    fun predefined_operators(): Array[EnvAssoc] = {
        val self_type = node.parent.as[TypeDecl];
        val bool_type = node.bool_type().node;
        val int_type = node.int_type().node;

        [
            node.create_binop_assoc(s"\"+\"", self_type, self_type, self_type),
            node.create_binop_assoc(s"\"-\"", self_type, self_type, self_type),
            node.create_binop_assoc(s"\"*\"", self_type, self_type, self_type),
            node.create_binop_assoc(s"\"/\"", self_type, self_type, self_type),
            node.create_binop_assoc(s"\"*\"", int_type, self_type, self_type),
            node.create_binop_assoc(s"\"*\"", self_type, int_type, self_type),
            node.create_binop_assoc(s"\"/\"", self_type, int_type, self_type),
            node.create_binop_assoc(s"\"**\"", self_type, int_type, self_type),
            node.create_binop_assoc(s"\"<\"", self_type, self_type, bool_type),
            node.create_binop_assoc(
                s"\"<=\"",
                self_type,
                self_type,
                bool_type
            ),
            node.create_binop_assoc(s"\"=\"", self_type, self_type, bool_type),
            node.create_binop_assoc(
                s"\"/=\"",
                self_type,
                self_type,
                bool_type
            ),
            node.create_binop_assoc(s"\">\"", self_type, self_type, bool_type),
            node.create_binop_assoc(
                s"\">=\"",
                self_type,
                self_type,
                bool_type
            ),
            node.create_unop_assoc(s"\"+\"", self_type, self_type),
            node.create_unop_assoc(s"\"-\"", self_type, self_type),
            node.create_unop_assoc(s"\"abs\"", self_type, self_type)
        ]
    }
}

|" Type definition for a record (:rmlink:`3.8`).
class RecordTypeDef: TypeDef {
    @parse_field
    has_abstract: Abstract
    @parse_field
    has_tagged: Tagged
    @parse_field
    has_limited: Limited
    @parse_field
    record_def: BaseRecordDef

    @with_dynvars(origin=null[AdaNode])
    fun is_tagged_type(): Bool = node.has_tagged.as_bool()

    fun is_limited_type(): Bool =
        node.has_limited.as_bool()
        or self.record_def.comps().has_limited_component()

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = %true

    @memoized
    fun predefined_operators(): Array[EnvAssoc] =
        if node.has_limited.as_bool() then null[Array[EnvAssoc]]
        else node.predefined_equality_operators()
}

|" Type definition for a signed integer type (:rmlink:`3.5.4`).
class SignedIntTypeDef: TypeDef {
    @parse_field
    range: RangeSpec

    @with_dynvars(origin)
    fun is_int_type(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = self.range.xref_equation()

    fun discrete_range(): DiscreteRange = self.range.range.discrete_range()

    @memoized
    fun predefined_operators(): Array[EnvAssoc] = {
        val self_type = node.parent.as[TypeDecl];
        val bool_type = node.bool_type().node;
        val int_type = node.int_type().node;
        val defaults =
            [
                node.create_binop_assoc(
                    s"\"+\"",
                    self_type,
                    self_type,
                    self_type
                ),
                node.create_binop_assoc(
                    s"\"-\"",
                    self_type,
                    self_type,
                    self_type
                ),
                node.create_binop_assoc(
                    s"\"*\"",
                    self_type,
                    self_type,
                    self_type
                ),
                node.create_binop_assoc(
                    s"\"/\"",
                    self_type,
                    self_type,
                    self_type
                ),
                node.create_binop_assoc(
                    s"\"mod\"",
                    self_type,
                    self_type,
                    self_type
                ),
                node.create_binop_assoc(
                    s"\"rem\"",
                    self_type,
                    self_type,
                    self_type
                ),
                node.create_binop_assoc(
                    s"\"**\"",
                    self_type,
                    int_type,
                    self_type
                ),
                node.create_binop_assoc(
                    s"\"<\"",
                    self_type,
                    self_type,
                    bool_type
                ),
                node.create_binop_assoc(
                    s"\"<=\"",
                    self_type,
                    self_type,
                    bool_type
                ),
                node.create_binop_assoc(
                    s"\"=\"",
                    self_type,
                    self_type,
                    bool_type
                ),
                node.create_binop_assoc(
                    s"\"/=\"",
                    self_type,
                    self_type,
                    bool_type
                ),
                node.create_binop_assoc(
                    s"\">\"",
                    self_type,
                    self_type,
                    bool_type
                ),
                node.create_binop_assoc(
                    s"\">=\"",
                    self_type,
                    self_type,
                    bool_type
                ),
                node.create_unop_assoc(s"\"+\"", self_type, self_type),
                node.create_unop_assoc(s"\"-\"", self_type, self_type),
                node.create_unop_assoc(s"\"abs\"", self_type, self_type)
            ];

        defaults
    }

    @with_dynvars(imprecise_fallback=false)
    fun is_static(): Bool = self.range.range.is_static_expr()
}

|" A type expression is an abstract node that embodies the concept of a
|" reference to a type.
|"
|" Since Ada has both subtype_indications and anonymous (inline) type
|" declarations, a type expression contains one or the other.
|"
|" This node has no ARM correspondence.
@abstract
class TypeExpr: AdaNode {
    fun array_ndims(): Int = {
        bind origin = node.origin_node();

        self.designated_type().array_ndims()
    }

    |" Return the name node for this type expression, if applicable, else null
    @exported
    fun type_name(): Entity[Name] =
        self.as[SubtypeIndication].do((sti) => sti.name)

    @with_dynvars(origin, include_ud_indexing, dottable_type=null[AdaNode])
    fun defining_env(): LexicalEnv = self.designated_type().defining_env()

    |" Return the type designated by this type expression.
    @abstract
    @with_dynvars(origin)
    fun designated_type(): Entity[BaseTypeDecl]

    |" Returns the type declaration designated by this type expression.
    @exported
    fun designated_type_decl(): Entity[BaseTypeDecl] = {
        bind origin = node.origin_node();

        self.designated_type()
    }

    |" Return the type declaration designated by this type expression as
    |" viewed from the node given by origin_node.
    @exported
    fun designated_type_decl_from(
        origin_node: Entity[AdaNode]
    ): Entity[BaseTypeDecl] = {
        bind origin = origin_node.node.origin_node();

        self.designated_type()
    }

    |" If self is an anonymous access, return the accessed type. Otherwise,
    |" return the designated type.
    @with_dynvars(origin)
    fun element_type(): Entity[BaseTypeDecl] = {
        val d = self.designated_type();

        if
            d is AnonymousTypeDecl
            and d.as[AnonymousTypeDecl].type_def is AccessDef
        then d.accessed_type()
        else d
    }

    @with_dynvars(origin)
    @ignored
    fun canonical_type(): Entity[BaseTypeDecl] =
        self.designated_type()?.canonical_type()

    |" Return the constraint that this type expression defines on its
    |" designated subtype, if any.
    @exported
    @with_dynvars(origin=null[AdaNode])
    fun subtype_constraint(): Entity[Constraint] =
        self.as[SubtypeIndication].do((si) => si.constraint)
        or? self.designated_type().as[SubtypeDecl].do(
            (st) => st.subtype.subtype_constraint()
        )

    |" If this type expression designates a constrained discriminated type,
    |" return an array of pairs, associating each discriminant to its actual
    |" or default expression.
    @exported
    fun discriminant_constraints(): Array[ParamActual] =
        self.subtype_constraint().as[CompositeConstraint].do(
            (cc) => cc.discriminant_params()
        )

    |" Returns whether this designates a definite subtype.
    @exported
    fun is_definite_subtype(): Bool =
        self.designated_type_decl().is_definite_subtype()

    fun custom_id_text(): String = {
        bind origin = node;
        self.designated_type().canonical_fully_qualified_name()
    }
}

|" Container for inline anonymous array and access types declarations.
class AnonymousType: TypeExpr {
    @parse_field
    type_decl: AnonymousTypeDecl

    @with_dynvars(origin)
    fun designated_type(): Entity[BaseTypeDecl] = self.type_decl

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = self.type_decl.sub_equation()

    # TODO: This implementation is not satisfying, because the formatting will
    # be the original source formatting, but will do for the moment.
    # Ideally we would compute a properly formatted version of the anonymous
    # type declaration. Using unparsing in order to avoid duplicating logic
    # between parsing/unparsing.
    fun custom_id_text(): String = self.type_decl.text
}

|" Synthetic node. Represents the type expression for an enum literal.
@synthetic
class EnumLitSynthTypeExpr: TypeExpr {
    @with_dynvars(origin)
    fun designated_type(): Entity[BaseTypeDecl] =
        self.parent.as[EnumLiteralDecl].enum_type()

    fun custom_id_text(): String = {
        bind origin = node;

        self.designated_type().canonical_fully_qualified_name()
        & "."
        # The custom_id_text is the combination of the enum type name and of
        # the enum literal name.
        & self.sym_join(
            self.parent.as[EnumLiteralDecl].defining_name().as_symbol_array(),
            ""
        )
    }
}

|" Reference to a type by name (:rmlink:`3.2.2`).
class SubtypeIndication: TypeExpr {
    @parse_field
    has_not_null: NotNull
    @parse_field
    name: Name
    @parse_field
    @nullable
    constraint: Constraint

    # The name for this type has to be evaluated in the context of the
    # SubtypeIndication node itself: we don't want to use whatever lexical
    # environment the caller is using. However we need to inherit the
    # visibility (origin node) of the caller.
    @with_dynvars(origin)
    fun designated_type(): Entity[BaseTypeDecl] = {
        bind env = self.node_env;

        self.name.designated_type_impl()
    }

    fun is_definite_subtype(): Bool =
        not self.constraint.is_null
        or self.designated_type_decl().is_definite_subtype()

    |" Return possible completions for a type indication at this point in the
    |" file. Completions for a type indication are more likely coming from a
    |" type declaration. PackageDecls have a medium weight in order to provide
    |" completion of fully qualified names.
    @with_dynvars(origin)
    fun complete_items(): Array[CompletionItem] =
        self.children_env.get(null[Symbol]).map(
            (n) =>
            CompletionItem(
                decl=n.as[BasicDecl],
                is_dot_call=n.info.md.dottable_subp,
                is_visible=node.has_visibility(n),
                weight=match n {
                    case btd: BaseTypeDecl =>
                    # Do not promote self as a possible completion for
                    # itself::
                    #
                    #     type My_Type is new M
                    #                          ^ set My_Type's weight to 0
                        if
                            self.parent is DerivedTypeDef
                            and self.parent.parent == btd
                        then 0
                        else 100
                    case _: PackageDecl => 50
                    case _ => 0
                }
            )
        )

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        # Called by allocator.xref_equation, since the suffix can be either a
        # qual expr or a subtype indication.
        self.name.subtype_indication_equation()
        %and self.constraint.do((c) => c.sub_equation(), default_val=%true)

    fun discrete_range(): DiscreteRange = {
        val rc = self.constraint.as![RangeConstraint];

        rc.do(
            (r) => r.range.range.discrete_range(),
            # If no additional range constraint is specified, the range is
            # that of the indicated subtype.
            default_val=self.designated_type_decl().discrete_range()
        )
    }

    |" Returns whether self denotes a static subtype or not (i.e. determinable
    |" at compile time, see :rmlink:`4.9`).
    @exported
    @with_dynvars(imprecise_fallback=false)
    fun is_static_subtype(): Bool = {
        bind origin = node.origin_node();

        not self.semantic_parent().as[BasicDecl].has_aspect(
            s"Dynamic_Predicate"
        )
        and self.constraint.do(
            (c) => c.is_static(),
            default_val=self.designated_type().is_static_decl()
        )
    }
}

|" Reference to a type with a range constraint.
class ConstrainedSubtypeIndication: SubtypeIndication {
}

|" Reference to a type with a general constraint.
class DiscreteSubtypeIndication: SubtypeIndication {
}

|" Synthetic type expression. The designated type is already known at
|" instantiation time and is to be given in the ``target_type`` field.
@synthetic
class SyntheticTypeExpr: TypeExpr {
    @parse_field
    target_type: BaseTypeDecl

    @with_dynvars(origin)
    fun designated_type(): Entity[BaseTypeDecl] = {
        # The `target_type` field stores the bare designated BaseTypeDecl,
        # but self may be carrying rebindings that need to be put back on
        # the bare node.
        # However, all of self's rebinding may not be relevant. For example,
        # if `target_type` is the definition of `Standard.Boolean`, no
        # rebindings will ever be relevant.
        # Hence we use the built-in `shed_rebindings` construct from the type
        # definition's lexical environment so as to only keep relevant ones.
        val relevant_rebindings =
            node.target_type.children_env.shed_rebindings(self.info)
            .rebindings;

        # Return a rebound `target_type`
        Entity[BaseTypeDecl](
            node=node.target_type,
            info=EntityInfo(
                md=null[Metadata],
                rebindings=relevant_rebindings,
                from_rebound=self.info.from_rebound
            )
        )
    }
}

|" List of unconstrained array indexes.
class UnconstrainedArrayIndex: AdaNode {
    @parse_field
    subtype_name: Name
    @parse_field
    @nullable
    lower_bound: Expr

    @with_dynvars(origin)
    fun designated_type(): Entity[BaseTypeDecl] =
        self.subtype_name.name_designated_type()
}

|" Qualifier for the ``until`` keyword.
@qualifier
enum class Until: AdaNode {
}

|" Base class for use clauses (:rmlink:`10.1.2`).
@abstract
class UseClause: AdaNode {
    fun xref_entry_point(): Bool = true

    |" Return the environment grouping all environments that are referred
    |" to by this use clause.
    fun used_envs(): LexicalEnv = match self {
        case upc: UsePackageClause => upc.designated_envs().env_group()
        case utc: UseTypeClause =>
            utc.types.map((n) => n.name_designated_type_env()).env_group()
    }

    |" Return the initial env for a use clause. Always the standard package
    |" for top level use clauses.
    fun initial_env(): DesignatedEnv =
        if node.parent.parent is CompilationUnit
        then
            DesignatedEnv(
                kind=DesignatedEnvKind.named_env,
                env_name=s"Standard",
                direct_env=null[LexicalEnv]
            )
        else
            DesignatedEnv(
                kind=DesignatedEnvKind.current_env,
                env_name=null[Symbol],
                direct_env=null[LexicalEnv]
            )
}

|" Use clause for packages (:rmlink:`8.4`).
class UsePackageClause: UseClause {
    @parse_field
    packages: ASTList[Name]

    |" Return the lexical env designated by the index'th package name in this
    |" use clause.
    fun designated_env(index: Int): LexicalEnv = {
        val pkg = node.packages?[index];

        {
            bind env = self.node_env;
            bind origin = pkg.origin_node();

            pkg.as_bare_entity.designated_env()
        }
    }

    |" Return the array of designated envs corresponding to each package name.
    |"
    |" It is very important for this property to be memoized, as it is used a
    |" lot during lexical environment lookups.
    fun designated_envs(): Array[LexicalEnv] =
        node.packages.imap((_, i) => self.designated_env(i))

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.packages.logic_all((p) => p.xref_no_overloading())

    env_spec {
        set_initial_env(node.initial_env())
        # Run PLE on the children (i.e. the names of USE'd packages) so that we
        # can run name resolution on them in the call to reference() below.
        handle_children()
        reference(
            node.packages.map((n) => n.as[AdaNode]),
            Name.use_package_name_designated_env,
            cond=not node.parent.parent is CompilationUnit
        )
    }
}

|" Use clause for types (:rmlink:`8.4`).
class UseTypeClause: UseClause {
    @parse_field
    has_all: All
    @parse_field
    types: ASTList[Name]

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        self.types.logic_all((p) => p.xref_type_equation())

    env_spec {
        set_initial_env(node.initial_env())
        # Run PLE on the children (i.e. the names of USE'd packages) so that we
        # can run name resolution on them in the call to reference() below.
        handle_children()
        reference(
            node.types.map((n) => n.as[AdaNode]),
            Name.name_designated_type_env,
            cond=not node.parent.parent is CompilationUnit
        )
    }
}

|" The value sequence of a reduction expression (see ``ReduceAttributeRef``).
|" Ada 2022, RM 4.5.10.
class ValueSequence: AdaNode {
    # NOTE: add chunk and aspect specification fields when parallel keyword is
    # supported.
    @parse_field
    iter_assoc: IteratedAssoc

    |" Return the nameres equation for this ValueSequence.
    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = self.iter_assoc.xref_equation_for_reduce()
}

|" Single variant in a discriminated type record declaration.
|"
|" This corresponds to a ``when ... => ...`` section in a variant part.
class Variant: AdaNode {
    @parse_field
    choices: AlternativesList
    @parse_field
    components: ComponentList

    |" Return the default expression of the discriminant this Variant
    |" depends on, if any.
    fun default_discriminant_expr(): Entity[Expr] = {
        # First, get the record type declaration to extract the
        # discriminant specifications.
        val discr_specs =
            self.parents(with_self=false).find((p) => p is ConcreteTypeDecl)
            .as![ConcreteTypeDecl]
            .discriminants
            .as![KnownDiscriminantPart]
            .discr_specs;
        val discr_symbol =
            self.parent.parent.as![VariantPart].discr_name.symbol;

        # Then, get the default expression that applies to self's variant
        # part discriminant.
        discr_specs.find(
            (d) => d.defining_names().any((n) => n.name_is(discr_symbol))
        )
        .default_expr
    }

    |" Check if any choice in the choice list matches expr's value.
    fun matches(expr: Entity[Expr]): Bool = {
        # Statically evaluate expr

        val expr_val =
            (
                # If expr is a box expr, `expr_val` is the value of the default
                # expression of the given discriminant (:rmlink:`4.3.1`).
                if expr is BoxExpr then self.default_discriminant_expr()
                else expr
            )
            .eval_as_int();

        self.choices.any((c) => c.choice_match(expr_val))
    }
}

|" Variant part in a discriminated type record declaration
|" (:rmlink:`3.8.1`).
|"
|" This corresponds to the whole ``case ... is ... end case;`` block.
class VariantPart: AdaNode {
    @parse_field
    discr_name: Identifier
    @parse_field
    variant: ASTList[Variant]

    fun xref_entry_point(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation = {
        val _ = self.discr_name.resolve_names_internal(false);

        self.variant.logic_all(
            (var) =>
            var.choices.logic_all(
                (c) =>
                match c {
                    # Expression case
                    case e: Expr =>
                        if
                            e is Name
                            and not e.as[Name].name_designated_type().is_null
                        then e.as[Name].xref_type_equation()
                        else
                            e.expected_type_var() <- node.discr_name.type_val()
                            %and e.sub_equation()
                            %and e.matches_expected_type()

                    # SubtypeIndication case (``when Color range Red .. Blue``)
                    case t: SubtypeIndication => t.xref_equation()
                    case _: OthersDesignator => %true
                    case _ =>
                        raise[Equation] PropertyError("Should not happen")
                }
            )
        )
    }

    |" Get components for this variant part, depending on the values of
    |" discriminants.
    fun get_components(
        discriminants: Array[ParamMatch]
    ): Array[Entity[BaseFormalParamDecl]] = {
        # Get the specific discriminant this variant part depends upon
        val discr =
            discriminants.find(
                (d) => d.formal.name.name_is(node.discr_name.symbol)
            )
            .do(
                (d) => d.actual.assoc.expr(),
                default_val=self.parents().find((n) => n is ConcreteTypeDecl)
                .as[ConcreteTypeDecl]
                .discriminants
                .abstract_formal_params()
                .find(
                    (d) =>
                    not d.as[DiscriminantSpec].defining_names().filter(
                        # If the discriminant is found in aggregate params we
                        # are looking for, then take its actual's expression.
                        # Else, take the default expression of the this
                        # variant's related discriminant specification.
                        (n) => n.name.name_is(node.discr_name.symbol)
                    )
                    .is_null
                )
                .as[DiscriminantSpec]
                .default_expr
            );
        # Get the variant branch with a choice that matches the discriminant's
        # value.
        val variant = self.variant.find((v) => v.matches(discr));

        # Get the components for this variant branch. We're passing down
        # discriminants, because there might be a nested variant part in this
        # variant branch.
        variant.components.abstract_formal_params_impl(
            discriminants,
            false,
            false
        )
    }
}

|" With clause (:rmlink:`10.1.2`).
class WithClause: AdaNode {
    @parse_field
    has_limited: Limited
    @parse_field
    has_private: Private
    @parse_field
    packages: ASTList[Name]

    |" Given a name that fully qualified a library-level declaration (i.e.
    |" a name in a with clause), return an xref equation that binds every
    |" part of the name to its corresponding library-level declarations.
    fun child_unit_xref_equation(name: Name): Equation = {
        val self_eq =
            name.ref_var() <- node.withed_unit_helper(name)?.decl().as_entity;

        self_eq
        %and name.as[DottedName].do(
            (dn) => self.child_unit_xref_equation(dn.prefix),
            default_val=%true
        )
    }

    fun xref_entry_point(): Bool = true

    @with_dynvars(env, origin, entry_point)
    fun xref_equation(): Equation =
        node.packages.logic_all((p) => self.child_unit_xref_equation(p))

    env_spec {
        set_initial_env(
            DesignatedEnv(
                kind=DesignatedEnvKind.named_env,
                env_name=s"Standard",
                direct_env=null[LexicalEnv]
            )
        )
    }
}

|" Qualifier for the ``private`` keyword in ``with private`` record clauses.
@qualifier
enum class WithPrivate: AdaNode {
}

@metadata
struct Metadata {
    |" Whether the stored element is a subprogram accessed through
    |" the dot notation
    dottable_subp: Bool = false
    |" The type for which this subprogram is a primitive, if any
    @used_in_equality
    primitive: AdaNode = null[AdaNode]
    |" The type for which this subprogram is a primitive, if any
    @used_in_equality
    primitive_real_type: AdaNode = null[AdaNode]
}

|" Composite field representing the aspect of an entity (:rmlink:`13`).
struct Aspect {
    |" Whether the aspect is defined or not
    exists: Bool
    |" Syntactic node that defines the aspect
    node: Entity[AdaNode]
    |" Expr node defining the value of the aspect
    value: Entity[Expr]
    |" Whether the aspect is inherited (it has been defined by a parent)
    inherited: Bool
}

struct CompletionItem {
    decl: Entity[BasicDecl]
    is_dot_call: Bool = false
    is_visible: Bool = true
    |" The higher the weight, the more relevant the completion item is
    weight: Int = 0
    # See `AdaNode.complete_item_weight` for implementation details.
}

|" Represent the range of a discrete type or subtype. The bounds are not
|" evaluated, you need to call ``eval_as_int`` on them, if they're static, to
|" get their value.
struct DiscreteRange {
    low_bound: Entity[Expr]
    high_bound: Entity[Expr]
}

|" Represent a set of values (as a list of choices) on a discriminant.
struct DiscriminantValues {
    discriminant: Entity[Identifier]
    values: Entity[AlternativesList]
}

|" Documentation annotation.
struct DocAnnotation {
    |" Annotation key
    key: String
    |" Annotation value
    value: String
}

|" Represent the range of a discrete type or subtype. The bounds are already
|" evaluated, so the type of the fields is BigInt.
struct EvalDiscreteRange {
    low_bound: BigInt
    high_bound: BigInt
}

|" Struct used by ``potential_actuals_for_dispatch`` to store an expression
|" together with the type that is expected for it.
struct ExpectedTypeForExpr {
    expected_type: Entity[TypeExpr]
    expr: Entity[Expr]
}

|" Represent the result of a call to logic_val. ``success`` is True iff
|" solving the logic equation was successful, and ``value`` holds the value of
|" the logic variable.
struct LogicValResult {
    success: Bool
    value: Entity[AdaNode]
}

|" Struct enclosing information about aggregates for multidimensional array
|" types.
struct MultidimAggregateInfo {
    |" the top level aggregate
    agg: Entity[BaseAggregate]
    |" the type of the array
    typ: Entity[BaseTypeDecl]
    |" the rank of the original sub-aggregate
    rank: Int
}

|" Data structure used by zip_with_params, Name.call_params,
|" GenericInstantiation.inst_params, BaseAggregate.aggregate_params,
|" SubtypeIndication.subtype_constraints, and EnumRepClause.params
|" properties. Associates an expression (the actual) to a formal param
|" declaration (the parameter).
struct ParamActual {
    param: Entity[DefiningName]
    actual: Entity[Expr]
}

struct SingleActual {
    name: BaseId
    assoc: Entity[BasicAssoc]
}

|" Helper data structure to implement SubpSpec/ParamAssocList matching.
|"
|" Each value relates to one ParamAssoc.
struct ParamMatch {
    |" Whether the matched ParamAssoc a ParamSpec.
    has_matched: Bool
    actual: SingleActual
    formal: Entity[DefiningName]
}

|" Result for a cross reference query returning a reference.
struct RefResult {
    ref: Entity[BaseId]
    kind: RefResultKind = RefResultKind.no_ref
}

|" Result for a cross reference query returning a referenced decl.
struct RefdDecl {
    decl: Entity[BasicDecl] = null[Entity[BasicDecl]]
    kind: RefResultKind = RefResultKind.no_ref
}

|" Result for a cross reference query returning a referenced defining name.
struct RefdDef {
    def_name: Entity[DefiningName] = null[Entity[DefiningName]]
    kind: RefResultKind = RefResultKind.no_ref
}

|" Represent one of the shapes that a variant record can have, as a list of
|" the available components.
struct Shape {
    components: Array[Entity[BaseFormalParamDecl]]
    discriminants_values: Array[DiscriminantValues]
}

|" Represent a substitution of a BasicDecl by a given value. This can then
|" be used as part of an environment in the eval_as_*_in_env property. See
|" the declaration of those properties for more details.
struct Substitution {
    |" The declaration to substitute.
    from_decl: Entity[BasicDecl]

    # TODO: once we can call expr_eval from the DSL and get an actual
    # discriminated type, use that type instead of BigInt.
    # For now however, we only ever need to do BigInt substitutions.
    |" The value by which to substitute the declaration.
    to_value: BigInt
    |" The type of the substituted value.
    value_type: Entity[BaseTypeDecl]
}

|" Structure to hold an expected subprogram specification (parameters and
|" return types only) denoted by an user defined function.
struct UserDefinedFunctionSubpSpec {
    subp_params_types: Array[Entity[BaseTypeDecl]]
    subp_return_type: Entity[BaseTypeDecl]
}
